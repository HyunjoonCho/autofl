[
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__init__#326",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__init__(self, params=None, auto_init=True)",
        "snippet": "    def __init__(self, params=None, auto_init=True):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        if params is None:\n            params = {}\n        self._ies = []\n        self._ies_instances = {}\n        self._pps = []\n        self._progress_hooks = []\n        self._download_retcode = 0\n        self._num_downloads = 0\n        self._screen_file = [sys.stdout, sys.stderr][params.get('logtostderr', False)]\n        self._err_file = sys.stderr\n        self.params = {\n            # Default parameters\n            'nocheckcertificate': False,\n        }\n        self.params.update(params)\n        self.cache = Cache(self)\n\n        def check_deprecated(param, option, suggestion):\n            if self.params.get(param) is not None:\n                self.report_warning(\n                    '%s is deprecated. Use %s instead.' % (option, suggestion))\n                return True\n            return False\n\n        if check_deprecated('cn_verification_proxy', '--cn-verification-proxy', '--geo-verification-proxy'):\n            if self.params.get('geo_verification_proxy') is None:\n                self.params['geo_verification_proxy'] = self.params['cn_verification_proxy']\n\n        check_deprecated('autonumber_size', '--autonumber-size', 'output template with %(autonumber)0Nd, where N in the number of digits')\n        check_deprecated('autonumber', '--auto-number', '-o \"%(autonumber)s-%(title)s.%(ext)s\"')\n        check_deprecated('usetitle', '--title', '-o \"%(title)s-%(id)s.%(ext)s\"')\n\n        if params.get('bidi_workaround', False):\n            try:\n                import pty\n                master, slave = pty.openpty()\n                width = compat_get_terminal_size().columns\n                if width is None:\n                    width_args = []\n                else:\n                    width_args = ['-w', str(width)]\n                sp_kwargs = dict(\n                    stdin=subprocess.PIPE,\n                    stdout=slave,\n                    stderr=self._err_file)\n                try:\n                    self._output_process = subprocess.Popen(\n                        ['bidiv'] + width_args, **sp_kwargs\n                    )\n                except OSError:\n                    self._output_process = subprocess.Popen(\n                        ['fribidi', '-c', 'UTF-8'] + width_args, **sp_kwargs)\n                self._output_channel = os.fdopen(master, 'rb')\n            except OSError as ose:\n                if ose.errno == errno.ENOENT:\n                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')\n                else:\n                    raise\n\n        if (sys.platform != 'win32' and\n                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968'] and\n                not params.get('restrictfilenames', False)):\n            # Unicode filesystem API will throw errors (#1474, #13027)\n            self.report_warning(\n                'Assuming --restrict-filenames since file system encoding '\n                'cannot encode all characters. '\n                'Set the LC_ALL environment variable to fix this.')\n            self.params['restrictfilenames'] = True\n\n        if isinstance(params.get('outtmpl'), bytes):\n            self.report_warning(\n                'Parameter outtmpl is bytes, but should be a unicode string. '\n                'Put  from __future__ import unicode_literals  at the top of your code file or consider switching to Python 3.x.')\n\n        self._setup_opener()\n\n        if auto_init:\n            self.print_debug_header()\n            self.add_default_info_extractors()\n\n        for pp_def_raw in self.params.get('postprocessors', []):\n            pp_class = get_postprocessor(pp_def_raw['key'])\n            pp_def = dict(pp_def_raw)\n            del pp_def['key']\n            pp = pp_class(self, **compat_kwargs(pp_def))\n            self.add_post_processor(pp)\n\n        for ph in self.params.get('progress_hooks', []):\n            self.add_progress_hook(ph)\n\n        register_socks_protocols()",
        "begin_line": 326,
        "end_line": 418,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.warn_if_short_id#420",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.warn_if_short_id(self, argv)",
        "snippet": "    def warn_if_short_id(self, argv):\n        # short YouTube ID starting with dash?\n        idxs = [\n            i for i, a in enumerate(argv)\n            if re.match(r'^-[0-9A-Za-z_-]{10}$', a)]\n        if idxs:\n            correct_argv = (\n                ['youtube-dl'] +\n                [a for i, a in enumerate(argv) if i not in idxs] +\n                ['--'] + [argv[i] for i in idxs]\n            )\n            self.report_warning(\n                'Long argument string detected. '\n                'Use -- to separate parameters and URLs, like this:\\n%s\\n' %\n                args_to_str(correct_argv))",
        "begin_line": 420,
        "end_line": 434,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor#436",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor(self, ie)",
        "snippet": "    def add_info_extractor(self, ie):\n        \"\"\"Add an InfoExtractor object to the end of the list.\"\"\"\n        self._ies.append(ie)\n        if not isinstance(ie, type):\n            self._ies_instances[ie.ie_key()] = ie\n            ie.set_downloader(self)",
        "begin_line": 436,
        "end_line": 441,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor#443",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor(self, ie_key)",
        "snippet": "    def get_info_extractor(self, ie_key):\n        \"\"\"\n        Get an instance of an IE with name ie_key, it will try to get one from\n        the _ies list, if there's no instance it will create a new one and add\n        it to the extractor list.\n        \"\"\"\n        ie = self._ies_instances.get(ie_key)\n        if ie is None:\n            ie = get_info_extractor(ie_key)()\n            self.add_info_extractor(ie)\n        return ie",
        "begin_line": 443,
        "end_line": 453,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors#455",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors(self)",
        "snippet": "    def add_default_info_extractors(self):\n        \"\"\"\n        Add the InfoExtractors returned by gen_extractors to the end of the list\n        \"\"\"\n        for ie in gen_extractor_classes():\n            self.add_info_extractor(ie)",
        "begin_line": 455,
        "end_line": 460,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor#462",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor(self, pp)",
        "snippet": "    def add_post_processor(self, pp):\n        \"\"\"Add a PostProcessor object to the end of the chain.\"\"\"\n        self._pps.append(pp)\n        pp.set_downloader(self)",
        "begin_line": 462,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook#467",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\"Add the progress hook (currently only for the file downloader)\"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 467,
        "end_line": 469,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround#471",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround(self, message)",
        "snippet": "    def _bidi_workaround(self, message):\n        if not hasattr(self, '_output_channel'):\n            return message\n\n        assert hasattr(self, '_output_process')\n        assert isinstance(message, compat_str)\n        line_count = message.count('\\n') + 1\n        self._output_process.stdin.write((message + '\\n').encode('utf-8'))\n        self._output_process.stdin.flush()\n        res = ''.join(self._output_channel.readline().decode('utf-8')\n                      for _ in range(line_count))\n        return res[:-len('\\n')]",
        "begin_line": 471,
        "end_line": 482,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_screen#484",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_screen(self, message, skip_eol=False)",
        "snippet": "    def to_screen(self, message, skip_eol=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        return self.to_stdout(message, skip_eol, check_quiet=True)",
        "begin_line": 484,
        "end_line": 486,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_string#488",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_string(self, s, out=None)",
        "snippet": "    def _write_string(self, s, out=None):\n        write_string(s, out=out, encoding=self.params.get('encoding'))",
        "begin_line": 488,
        "end_line": 489,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout#491",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout(self, message, skip_eol=False, check_quiet=False)",
        "snippet": "    def to_stdout(self, message, skip_eol=False, check_quiet=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        if self.params.get('logger'):\n            self.params['logger'].debug(message)\n        elif not check_quiet or not self.params.get('quiet', False):\n            message = self._bidi_workaround(message)\n            terminator = ['\\n', ''][skip_eol]\n            output = message + terminator\n\n            self._write_string(output, self._screen_file)",
        "begin_line": 491,
        "end_line": 500,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr#502",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        \"\"\"Print message to stderr.\"\"\"\n        assert isinstance(message, compat_str)\n        if self.params.get('logger'):\n            self.params['logger'].error(message)\n        else:\n            message = self._bidi_workaround(message)\n            output = message + '\\n'\n            self._write_string(output, self._err_file)",
        "begin_line": 502,
        "end_line": 510,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title#512",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        if not self.params.get('consoletitle', False):\n            return\n        if compat_os_name == 'nt':\n            if ctypes.windll.kernel32.GetConsoleWindow():\n                # c_wchar_p() might not be necessary if `message` is\n                # already of type unicode()\n                ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))\n        elif 'TERM' in os.environ:\n            self._write_string('\\033]0;%s\\007' % message, self._screen_file)",
        "begin_line": 512,
        "end_line": 521,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title#523",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title(self)",
        "snippet": "    def save_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if compat_os_name != 'nt' and 'TERM' in os.environ:\n            # Save the title on stack\n            self._write_string('\\033[22;0t', self._screen_file)",
        "begin_line": 523,
        "end_line": 528,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title#530",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title(self)",
        "snippet": "    def restore_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if compat_os_name != 'nt' and 'TERM' in os.environ:\n            # Restore the title from stack\n            self._write_string('\\033[23;0t', self._screen_file)",
        "begin_line": 530,
        "end_line": 535,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__enter__#537",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.save_console_title()\n        return self",
        "begin_line": 537,
        "end_line": 539,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__exit__#541",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__exit__(self, *args)",
        "snippet": "    def __exit__(self, *args):\n        self.restore_console_title()\n\n        if self.params.get('cookiefile') is not None:\n            self.cookiejar.save()",
        "begin_line": 541,
        "end_line": 545,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.trouble#547",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.trouble(self, message=None, tb=None)",
        "snippet": "    def trouble(self, message=None, tb=None):\n        \"\"\"Determine action to take when a download problem appears.\n\n        Depending on if the downloader has been configured to ignore\n        download errors or not, this method may throw an exception or\n        not when errors are found, after printing the message.\n\n        tb, if given, is additional traceback information.\n        \"\"\"\n        if message is not None:\n            self.to_stderr(message)\n        if self.params.get('verbose'):\n            if tb is None:\n                if sys.exc_info()[0]:  # if .trouble has been called from an except block\n                    tb = ''\n                    if hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))\n                    tb += encode_compat_str(traceback.format_exc())\n                else:\n                    tb_data = traceback.format_list(traceback.extract_stack())\n                    tb = ''.join(tb_data)\n            self.to_stderr(tb)\n        if not self.params.get('ignoreerrors', False):\n            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                exc_info = sys.exc_info()[1].exc_info\n            else:\n                exc_info = sys.exc_info()\n            raise DownloadError(message, exc_info)\n        self._download_retcode = 1",
        "begin_line": 547,
        "end_line": 575,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_warning#577",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_warning(self, message)",
        "snippet": "    def report_warning(self, message):\n        '''\n        Print the message to stderr, it will be prefixed with 'WARNING:'\n        If stderr is a tty file the 'WARNING:' will be colored\n        '''\n        if self.params.get('logger') is not None:\n            self.params['logger'].warning(message)\n        else:\n            if self.params.get('no_warnings'):\n                return\n            if not self.params.get('no_color') and self._err_file.isatty() and compat_os_name != 'nt':\n                _msg_header = '\\033[0;33mWARNING:\\033[0m'\n            else:\n                _msg_header = 'WARNING:'\n            warning_message = '%s %s' % (_msg_header, message)\n            self.to_stderr(warning_message)",
        "begin_line": 577,
        "end_line": 592,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_error#594",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_error(self, message, tb=None)",
        "snippet": "    def report_error(self, message, tb=None):\n        '''\n        Do the same as trouble, but prefixes the message with 'ERROR:', colored\n        in red if stderr is a tty file.\n        '''\n        if not self.params.get('no_color') and self._err_file.isatty() and compat_os_name != 'nt':\n            _msg_header = '\\033[0;31mERROR:\\033[0m'\n        else:\n            _msg_header = 'ERROR:'\n        error_message = '%s %s' % (_msg_header, message)\n        self.trouble(error_message, tb)",
        "begin_line": 594,
        "end_line": 604,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded#606",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 606,
        "end_line": 611,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename#613",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename(self, info_dict)",
        "snippet": "    def prepare_filename(self, info_dict):\n        \"\"\"Generate the output filename.\"\"\"\n        try:\n            template_dict = dict(info_dict)\n\n            template_dict['epoch'] = int(time.time())\n            autonumber_size = self.params.get('autonumber_size')\n            if autonumber_size is None:\n                autonumber_size = 5\n            template_dict['autonumber'] = self.params.get('autonumber_start', 1) - 1 + self._num_downloads\n            if template_dict.get('resolution') is None:\n                if template_dict.get('width') and template_dict.get('height'):\n                    template_dict['resolution'] = '%dx%d' % (template_dict['width'], template_dict['height'])\n                elif template_dict.get('height'):\n                    template_dict['resolution'] = '%sp' % template_dict['height']\n                elif template_dict.get('width'):\n                    template_dict['resolution'] = '%dx?' % template_dict['width']\n\n            sanitize = lambda k, v: sanitize_filename(\n                compat_str(v),\n                restricted=self.params.get('restrictfilenames'),\n                is_id=(k == 'id' or k.endswith('_id')))\n            template_dict = dict((k, v if isinstance(v, compat_numeric_types) else sanitize(k, v))\n                                 for k, v in template_dict.items()\n                                 if v is not None and not isinstance(v, (list, tuple, dict)))\n            template_dict = collections.defaultdict(lambda: 'NA', template_dict)\n\n            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n\n            # For fields playlist_index and autonumber convert all occurrences\n            # of %(field)s to %(field)0Nd for backward compatibility\n            field_size_compat_map = {\n                'playlist_index': len(str(template_dict['n_entries'])),\n                'autonumber': autonumber_size,\n            }\n            FIELD_SIZE_COMPAT_RE = r'(?<!%)%\\((?P<field>autonumber|playlist_index)\\)s'\n            mobj = re.search(FIELD_SIZE_COMPAT_RE, outtmpl)\n            if mobj:\n                outtmpl = re.sub(\n                    FIELD_SIZE_COMPAT_RE,\n                    r'%%(\\1)0%dd' % field_size_compat_map[mobj.group('field')],\n                    outtmpl)\n\n            # Missing numeric fields used together with integer presentation types\n            # in format specification will break the argument substitution since\n            # string 'NA' is returned for missing fields. We will patch output\n            # template for missing fields to meet string presentation type.\n            for numeric_field in self._NUMERIC_FIELDS:\n                if numeric_field not in template_dict:\n                    # As of [1] format syntax is:\n                    #  %[mapping_key][conversion_flags][minimum_width][.precision][length_modifier]type\n                    # 1. https://docs.python.org/2/library/stdtypes.html#string-formatting\n                    FORMAT_RE = r'''(?x)\n                        (?<!%)\n                        %\n                        \\({0}\\)  # mapping key\n                        (?:[#0\\-+ ]+)?  # conversion flags (optional)\n                        (?:\\d+)?  # minimum field width (optional)\n                        (?:\\.\\d+)?  # precision (optional)\n                        [hlL]?  # length modifier (optional)\n                        [diouxXeEfFgGcrs%]  # conversion type\n                    '''\n                    outtmpl = re.sub(\n                        FORMAT_RE.format(numeric_field),\n                        r'%({0})s'.format(numeric_field), outtmpl)\n\n            # expand_path translates '%%' into '%' and '$$' into '$'\n            # correspondingly that is not what we want since we need to keep\n            # '%%' intact for template dict substitution step. Working around\n            # with boundary-alike separator hack.\n            sep = ''.join([random.choice(ascii_letters) for _ in range(32)])\n            outtmpl = outtmpl.replace('%%', '%{0}%'.format(sep)).replace('$$', '${0}$'.format(sep))\n\n            # outtmpl should be expand_path'ed before template dict substitution\n            # because meta fields may contain env variables we don't want to\n            # be expanded. For example, for outtmpl \"%(title)s.%(ext)s\" and\n            # title \"Hello $PATH\", we don't want `$PATH` to be expanded.\n            filename = expand_path(outtmpl).replace(sep, '') % template_dict\n\n            # Temporary fix for #4787\n            # 'Treat' all problem characters by passing filename through preferredencoding\n            # to workaround encoding issues with subprocess on python2 @ Windows\n            if sys.version_info < (3, 0) and sys.platform == 'win32':\n                filename = encodeFilename(filename, True).decode(preferredencoding())\n            return sanitize_path(filename)\n        except ValueError as err:\n            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')\n            return None",
        "begin_line": 613,
        "end_line": 700,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._match_entry#702",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._match_entry(self, info_dict, incomplete)",
        "snippet": "    def _match_entry(self, info_dict, incomplete):\n        \"\"\" Returns None iff the file should be downloaded \"\"\"\n\n        video_title = info_dict.get('title', info_dict.get('id', 'video'))\n        if 'title' in info_dict:\n            # This can happen when we're just evaluating the playlist\n            title = info_dict['title']\n            matchtitle = self.params.get('matchtitle', False)\n            if matchtitle:\n                if not re.search(matchtitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title did not match pattern \"' + matchtitle + '\"'\n            rejecttitle = self.params.get('rejecttitle', False)\n            if rejecttitle:\n                if re.search(rejecttitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title matched reject pattern \"' + rejecttitle + '\"'\n        date = info_dict.get('upload_date')\n        if date is not None:\n            dateRange = self.params.get('daterange', DateRange())\n            if date not in dateRange:\n                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)\n        view_count = info_dict.get('view_count')\n        if view_count is not None:\n            min_views = self.params.get('min_views')\n            if min_views is not None and view_count < min_views:\n                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)\n            max_views = self.params.get('max_views')\n            if max_views is not None and view_count > max_views:\n                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)\n        if age_restricted(info_dict.get('age_limit'), self.params.get('age_limit')):\n            return 'Skipping \"%s\" because it is age restricted' % video_title\n        if self.in_download_archive(info_dict):\n            return '%s has already been recorded in archive' % video_title\n\n        if not incomplete:\n            match_filter = self.params.get('match_filter')\n            if match_filter is not None:\n                ret = match_filter(info_dict)\n                if ret is not None:\n                    return ret\n\n        return None",
        "begin_line": 702,
        "end_line": 742,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info#745",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info(info_dict, extra_info)",
        "snippet": "    def add_extra_info(info_dict, extra_info):\n        '''Set the keys from extra_info in info dict if they are missing'''\n        for key, value in extra_info.items():\n            info_dict.setdefault(key, value)",
        "begin_line": 745,
        "end_line": 748,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.extract_info#750",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.extract_info(self, url, download=True, ie_key=None, extra_info={}, process=True, force_generic_extractor=False)",
        "snippet": "    def extract_info(self, url, download=True, ie_key=None, extra_info={},\n                     process=True, force_generic_extractor=False):\n        '''\n        Returns a list with a dictionary for each video we find.\n        If 'download', also downloads the videos.\n        extra_info is a dict containing the extra values to add to each result\n        '''\n\n        if not ie_key and force_generic_extractor:\n            ie_key = 'Generic'\n\n        if ie_key:\n            ies = [self.get_info_extractor(ie_key)]\n        else:\n            ies = self._ies\n\n        for ie in ies:\n            if not ie.suitable(url):\n                continue\n\n            ie = self.get_info_extractor(ie.ie_key())\n            if not ie.working():\n                self.report_warning('The program functionality for this site has been marked as broken, '\n                                    'and will probably not work.')\n\n            try:\n                ie_result = ie.extract(url)\n                if ie_result is None:  # Finished already (backwards compatibility; listformats and friends should be moved here)\n                    break\n                if isinstance(ie_result, list):\n                    # Backwards compatibility: old IE result format\n                    ie_result = {\n                        '_type': 'compat_list',\n                        'entries': ie_result,\n                    }\n                self.add_default_extra_info(ie_result, ie, url)\n                if process:\n                    return self.process_ie_result(ie_result, download, extra_info)\n                else:\n                    return ie_result\n            except GeoRestrictedError as e:\n                msg = e.msg\n                if e.countries:\n                    msg += '\\nThis video is available in %s.' % ', '.join(\n                        map(ISO3166Utils.short2full, e.countries))\n                msg += '\\nYou might want to use a VPN or a proxy server (with --proxy) to workaround.'\n                self.report_error(msg)\n                break\n            except ExtractorError as e:  # An error we somewhat expected\n                self.report_error(compat_str(e), e.format_traceback())\n                break\n            except MaxDownloadsReached:\n                raise\n            except Exception as e:\n                if self.params.get('ignoreerrors', False):\n                    self.report_error(error_to_compat_str(e), tb=encode_compat_str(traceback.format_exc()))\n                    break\n                else:\n                    raise\n        else:\n            self.report_error('no suitable InfoExtractor for URL %s' % url)",
        "begin_line": 750,
        "end_line": 810,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info#812",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info(self, ie_result, ie, url)",
        "snippet": "    def add_default_extra_info(self, ie_result, ie, url):\n        self.add_extra_info(ie_result, {\n            'extractor': ie.IE_NAME,\n            'webpage_url': url,\n            'webpage_url_basename': url_basename(url),\n            'extractor_key': ie.ie_key(),\n        })",
        "begin_line": 812,
        "end_line": 818,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result#820",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result(self, ie_result, download=True, extra_info={})",
        "snippet": "    def process_ie_result(self, ie_result, download=True, extra_info={}):\n        \"\"\"\n        Take the result of the ie(may be modified) and resolve all unresolved\n        references (URLs, playlist items).\n\n        It will also download the videos if 'download'.\n        Returns the resolved ie_result.\n        \"\"\"\n        result_type = ie_result.get('_type', 'video')\n\n        if result_type in ('url', 'url_transparent'):\n            ie_result['url'] = sanitize_url(ie_result['url'])\n            extract_flat = self.params.get('extract_flat', False)\n            if ((extract_flat == 'in_playlist' and 'playlist' in extra_info) or\n                    extract_flat is True):\n                if self.params.get('forcejson', False):\n                    self.to_stdout(json.dumps(ie_result))\n                return ie_result\n\n        if result_type == 'video':\n            self.add_extra_info(ie_result, extra_info)\n            return self.process_video_result(ie_result, download=download)\n        elif result_type == 'url':\n            # We have to add extra_info to the results because it may be\n            # contained in a playlist\n            return self.extract_info(ie_result['url'],\n                                     download,\n                                     ie_key=ie_result.get('ie_key'),\n                                     extra_info=extra_info)\n        elif result_type == 'url_transparent':\n            # Use the information from the embedding page\n            info = self.extract_info(\n                ie_result['url'], ie_key=ie_result.get('ie_key'),\n                extra_info=extra_info, download=False, process=False)\n\n            # extract_info may return None when ignoreerrors is enabled and\n            # extraction failed with an error, don't crash and return early\n            # in this case\n            if not info:\n                return info\n\n            force_properties = dict(\n                (k, v) for k, v in ie_result.items() if v is not None)\n            for f in ('_type', 'url', 'id', 'extractor', 'extractor_key', 'ie_key'):\n                if f in force_properties:\n                    del force_properties[f]\n            new_result = info.copy()\n            new_result.update(force_properties)\n\n            # Extracted info may not be a video result (i.e.\n            # info.get('_type', 'video') != video) but rather an url or\n            # url_transparent. In such cases outer metadata (from ie_result)\n            # should be propagated to inner one (info). For this to happen\n            # _type of info should be overridden with url_transparent. This\n            # fixes issue from https://github.com/rg3/youtube-dl/pull/11163.\n            if new_result.get('_type') == 'url':\n                new_result['_type'] = 'url_transparent'\n\n            return self.process_ie_result(\n                new_result, download=download, extra_info=extra_info)\n        elif result_type in ('playlist', 'multi_video'):\n            # We process each entry in the playlist\n            playlist = ie_result.get('title') or ie_result.get('id')\n            self.to_screen('[download] Downloading playlist: %s' % playlist)\n\n            playlist_results = []\n\n            playliststart = self.params.get('playliststart', 1) - 1\n            playlistend = self.params.get('playlistend')\n            # For backwards compatibility, interpret -1 as whole list\n            if playlistend == -1:\n                playlistend = None\n\n            playlistitems_str = self.params.get('playlist_items')\n            playlistitems = None\n            if playlistitems_str is not None:\n                def iter_playlistitems(format):\n                    for string_segment in format.split(','):\n                        if '-' in string_segment:\n                            start, end = string_segment.split('-')\n                            for item in range(int(start), int(end) + 1):\n                                yield int(item)\n                        else:\n                            yield int(string_segment)\n                playlistitems = iter_playlistitems(playlistitems_str)\n\n            ie_entries = ie_result['entries']\n            if isinstance(ie_entries, list):\n                n_all_entries = len(ie_entries)\n                if playlistitems:\n                    entries = [\n                        ie_entries[i - 1] for i in playlistitems\n                        if -n_all_entries <= i - 1 < n_all_entries]\n                else:\n                    entries = ie_entries[playliststart:playlistend]\n                n_entries = len(entries)\n                self.to_screen(\n                    '[%s] playlist %s: Collected %d video ids (downloading %d of them)' %\n                    (ie_result['extractor'], playlist, n_all_entries, n_entries))\n            elif isinstance(ie_entries, PagedList):\n                if playlistitems:\n                    entries = []\n                    for item in playlistitems:\n                        entries.extend(ie_entries.getslice(\n                            item - 1, item\n                        ))\n                else:\n                    entries = ie_entries.getslice(\n                        playliststart, playlistend)\n                n_entries = len(entries)\n                self.to_screen(\n                    '[%s] playlist %s: Downloading %d videos' %\n                    (ie_result['extractor'], playlist, n_entries))\n            else:  # iterable\n                if playlistitems:\n                    entry_list = list(ie_entries)\n                    entries = [entry_list[i - 1] for i in playlistitems]\n                else:\n                    entries = list(itertools.islice(\n                        ie_entries, playliststart, playlistend))\n                n_entries = len(entries)\n                self.to_screen(\n                    '[%s] playlist %s: Downloading %d videos' %\n                    (ie_result['extractor'], playlist, n_entries))\n\n            if self.params.get('playlistreverse', False):\n                entries = entries[::-1]\n\n            if self.params.get('playlistrandom', False):\n                random.shuffle(entries)\n\n            x_forwarded_for = ie_result.get('__x_forwarded_for_ip')\n\n            for i, entry in enumerate(entries, 1):\n                self.to_screen('[download] Downloading video %s of %s' % (i, n_entries))\n                # This __x_forwarded_for_ip thing is a bit ugly but requires\n                # minimal changes\n                if x_forwarded_for:\n                    entry['__x_forwarded_for_ip'] = x_forwarded_for\n                extra = {\n                    'n_entries': n_entries,\n                    'playlist': playlist,\n                    'playlist_id': ie_result.get('id'),\n                    'playlist_title': ie_result.get('title'),\n                    'playlist_index': i + playliststart,\n                    'extractor': ie_result['extractor'],\n                    'webpage_url': ie_result['webpage_url'],\n                    'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                    'extractor_key': ie_result['extractor_key'],\n                }\n\n                reason = self._match_entry(entry, incomplete=True)\n                if reason is not None:\n                    self.to_screen('[download] ' + reason)\n                    continue\n\n                entry_result = self.process_ie_result(entry,\n                                                      download=download,\n                                                      extra_info=extra)\n                playlist_results.append(entry_result)\n            ie_result['entries'] = playlist_results\n            self.to_screen('[download] Finished downloading playlist: %s' % playlist)\n            return ie_result\n        elif result_type == 'compat_list':\n            self.report_warning(\n                'Extractor %s returned a compat_list result. '\n                'It needs to be updated.' % ie_result.get('extractor'))\n\n            def _fixup(r):\n                self.add_extra_info(\n                    r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    }\n                )\n                return r\n            ie_result['entries'] = [\n                self.process_ie_result(_fixup(r), download, extra_info)\n                for r in ie_result['entries']\n            ]\n            return ie_result\n        else:\n            raise Exception('Invalid result type: %s' % result_type)",
        "begin_line": 820,
        "end_line": 1005,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter#1007",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._build_format_filter(self, filter_spec)",
        "snippet": "    def _build_format_filter(self, filter_spec):\n        \" Returns a function to filter the formats according to the filter_spec \"\n\n        OPERATORS = {\n            '<': operator.lt,\n            '<=': operator.le,\n            '>': operator.gt,\n            '>=': operator.ge,\n            '=': operator.eq,\n            '!=': operator.ne,\n        }\n        operator_rex = re.compile(r'''(?x)\\s*\n            (?P<key>width|height|tbr|abr|vbr|asr|filesize|fps)\n            \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n            (?P<value>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)\n            $\n            ''' % '|'.join(map(re.escape, OPERATORS.keys())))\n        m = operator_rex.search(filter_spec)\n        if m:\n            try:\n                comparison_value = int(m.group('value'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('value'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('value') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid value %r in format specification %r' % (\n                            m.group('value'), filter_spec))\n            op = OPERATORS[m.group('op')]\n\n        if not m:\n            STR_OPERATORS = {\n                '=': operator.eq,\n                '!=': operator.ne,\n                '^=': lambda attr, value: attr.startswith(value),\n                '$=': lambda attr, value: attr.endswith(value),\n                '*=': lambda attr, value: value in attr,\n            }\n            str_operator_rex = re.compile(r'''(?x)\n                \\s*(?P<key>ext|acodec|vcodec|container|protocol|format_id)\n                \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\n                \\s*(?P<value>[a-zA-Z0-9._-]+)\n                \\s*$\n                ''' % '|'.join(map(re.escape, STR_OPERATORS.keys())))\n            m = str_operator_rex.search(filter_spec)\n            if m:\n                comparison_value = m.group('value')\n                op = STR_OPERATORS[m.group('op')]\n\n        if not m:\n            raise ValueError('Invalid filter specification %r' % filter_spec)\n\n        def _filter(f):\n            actual_value = f.get(m.group('key'))\n            if actual_value is None:\n                return m.group('none_inclusive')\n            return op(actual_value, comparison_value)\n        return _filter",
        "begin_line": 1007,
        "end_line": 1065,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._default_format_spec#1067",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._default_format_spec(self, info_dict, download=True)",
        "snippet": "    def _default_format_spec(self, info_dict, download=True):\n        req_format_list = []\n\n        def can_have_partial_formats():\n            if self.params.get('simulate', False):\n                return True\n            if not download:\n                return True\n            if self.params.get('outtmpl', DEFAULT_OUTTMPL) == '-':\n                return False\n            if info_dict.get('is_live'):\n                return False\n            merger = FFmpegMergerPP(self)\n            return merger.available and merger.can_merge()\n        if can_have_partial_formats():\n            req_format_list.append('bestvideo+bestaudio')\n        req_format_list.append('best')\n        return '/'.join(req_format_list)",
        "begin_line": 1067,
        "end_line": 1084,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector#1086",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.build_format_selector(self, format_spec)",
        "snippet": "    def build_format_selector(self, format_spec):\n        def syntax_error(note, start):\n            message = (\n                'Invalid format specification: '\n                '{0}\\n\\t{1}\\n\\t{2}^'.format(note, format_spec, ' ' * start[1]))\n            return SyntaxError(message)\n\n        PICKFIRST = 'PICKFIRST'\n        MERGE = 'MERGE'\n        SINGLE = 'SINGLE'\n        GROUP = 'GROUP'\n        FormatSelector = collections.namedtuple('FormatSelector', ['type', 'selector', 'filters'])\n\n        def _parse_filter(tokens):\n            filter_parts = []\n            for type, string, start, _, _ in tokens:\n                if type == tokenize.OP and string == ']':\n                    return ''.join(filter_parts)\n                else:\n                    filter_parts.append(string)\n\n        def _remove_unused_ops(tokens):\n            # Remove operators that we don't use and join them with the surrounding strings\n            # for example: 'mp4' '-' 'baseline' '-' '16x9' is converted to 'mp4-baseline-16x9'\n            ALLOWED_OPS = ('/', '+', ',', '(', ')')\n            last_string, last_start, last_end, last_line = None, None, None, None\n            for type, string, start, end, line in tokens:\n                if type == tokenize.OP and string == '[':\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                    # everything inside brackets will be handled by _parse_filter\n                    for type, string, start, end, line in tokens:\n                        yield type, string, start, end, line\n                        if type == tokenize.OP and string == ']':\n                            break\n                elif type == tokenize.OP and string in ALLOWED_OPS:\n                    if last_string:\n                        yield tokenize.NAME, last_string, last_start, last_end, last_line\n                        last_string = None\n                    yield type, string, start, end, line\n                elif type in [tokenize.NAME, tokenize.NUMBER, tokenize.OP]:\n                    if not last_string:\n                        last_string = string\n                        last_start = start\n                        last_end = end\n                    else:\n                        last_string += string\n            if last_string:\n                yield tokenize.NAME, last_string, last_start, last_end, last_line\n\n        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):\n            selectors = []\n            current_selector = None\n            for type, string, start, _, _ in tokens:\n                # ENCODING is only defined in python 3.x\n                if type == getattr(tokenize, 'ENCODING', None):\n                    continue\n                elif type in [tokenize.NAME, tokenize.NUMBER]:\n                    current_selector = FormatSelector(SINGLE, string, [])\n                elif type == tokenize.OP:\n                    if string == ')':\n                        if not inside_group:\n                            # ')' will be handled by the parentheses group\n                            tokens.restore_last_token()\n                        break\n                    elif inside_merge and string in ['/', ',']:\n                        tokens.restore_last_token()\n                        break\n                    elif inside_choice and string == ',':\n                        tokens.restore_last_token()\n                        break\n                    elif string == ',':\n                        if not current_selector:\n                            raise syntax_error('\",\" must follow a format selector', start)\n                        selectors.append(current_selector)\n                        current_selector = None\n                    elif string == '/':\n                        if not current_selector:\n                            raise syntax_error('\"/\" must follow a format selector', start)\n                        first_choice = current_selector\n                        second_choice = _parse_format_selection(tokens, inside_choice=True)\n                        current_selector = FormatSelector(PICKFIRST, (first_choice, second_choice), [])\n                    elif string == '[':\n                        if not current_selector:\n                            current_selector = FormatSelector(SINGLE, 'best', [])\n                        format_filter = _parse_filter(tokens)\n                        current_selector.filters.append(format_filter)\n                    elif string == '(':\n                        if current_selector:\n                            raise syntax_error('Unexpected \"(\"', start)\n                        group = _parse_format_selection(tokens, inside_group=True)\n                        current_selector = FormatSelector(GROUP, group, [])\n                    elif string == '+':\n                        video_selector = current_selector\n                        audio_selector = _parse_format_selection(tokens, inside_merge=True)\n                        if not video_selector or not audio_selector:\n                            raise syntax_error('\"+\" must be between two format selectors', start)\n                        current_selector = FormatSelector(MERGE, (video_selector, audio_selector), [])\n                    else:\n                        raise syntax_error('Operator not recognized: \"{0}\"'.format(string), start)\n                elif type == tokenize.ENDMARKER:\n                    break\n            if current_selector:\n                selectors.append(current_selector)\n            return selectors\n\n        def _build_selector_function(selector):\n            if isinstance(selector, list):\n                fs = [_build_selector_function(s) for s in selector]\n\n                def selector_function(ctx):\n                    for f in fs:\n                        for format in f(ctx):\n                            yield format\n                return selector_function\n            elif selector.type == GROUP:\n                selector_function = _build_selector_function(selector.selector)\n            elif selector.type == PICKFIRST:\n                fs = [_build_selector_function(s) for s in selector.selector]\n\n                def selector_function(ctx):\n                    for f in fs:\n                        picked_formats = list(f(ctx))\n                        if picked_formats:\n                            return picked_formats\n                    return []\n            elif selector.type == SINGLE:\n                format_spec = selector.selector\n\n                def selector_function(ctx):\n                    formats = list(ctx['formats'])\n                    if not formats:\n                        return\n                    if format_spec == 'all':\n                        for f in formats:\n                            yield f\n                    elif format_spec in ['best', 'worst', None]:\n                        format_idx = 0 if format_spec == 'worst' else -1\n                        audiovideo_formats = [\n                            f for f in formats\n                            if f.get('vcodec') != 'none' and f.get('acodec') != 'none']\n                        if audiovideo_formats:\n                            yield audiovideo_formats[format_idx]\n                        # for extractors with incomplete formats (audio only (soundcloud)\n                        # or video only (imgur)) we will fallback to best/worst\n                        # {video,audio}-only format\n                        elif ctx['incomplete_formats']:\n                            yield formats[format_idx]\n                    elif format_spec == 'bestaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[-1]\n                    elif format_spec == 'worstaudio':\n                        audio_formats = [\n                            f for f in formats\n                            if f.get('vcodec') == 'none']\n                        if audio_formats:\n                            yield audio_formats[0]\n                    elif format_spec == 'bestvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[-1]\n                    elif format_spec == 'worstvideo':\n                        video_formats = [\n                            f for f in formats\n                            if f.get('acodec') == 'none']\n                        if video_formats:\n                            yield video_formats[0]\n                    else:\n                        extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']\n                        if format_spec in extensions:\n                            filter_f = lambda f: f['ext'] == format_spec\n                        else:\n                            filter_f = lambda f: f['format_id'] == format_spec\n                        matches = list(filter(filter_f, formats))\n                        if matches:\n                            yield matches[-1]\n            elif selector.type == MERGE:\n                def _merge(formats_info):\n                    format_1, format_2 = [f['format_id'] for f in formats_info]\n                    # The first format must contain the video and the\n                    # second the audio\n                    if formats_info[0].get('vcodec') == 'none':\n                        self.report_error('The first format must '\n                                          'contain the video, try using '\n                                          '\"-f %s+%s\"' % (format_2, format_1))\n                        return\n                    # Formats must be opposite (video+audio)\n                    if formats_info[0].get('acodec') == 'none' and formats_info[1].get('acodec') == 'none':\n                        self.report_error(\n                            'Both formats %s and %s are video-only, you must specify \"-f video+audio\"'\n                            % (format_1, format_2))\n                        return\n                    output_ext = (\n                        formats_info[0]['ext']\n                        if self.params.get('merge_output_format') is None\n                        else self.params['merge_output_format'])\n                    return {\n                        'requested_formats': formats_info,\n                        'format': '%s+%s' % (formats_info[0].get('format'),\n                                             formats_info[1].get('format')),\n                        'format_id': '%s+%s' % (formats_info[0].get('format_id'),\n                                                formats_info[1].get('format_id')),\n                        'width': formats_info[0].get('width'),\n                        'height': formats_info[0].get('height'),\n                        'resolution': formats_info[0].get('resolution'),\n                        'fps': formats_info[0].get('fps'),\n                        'vcodec': formats_info[0].get('vcodec'),\n                        'vbr': formats_info[0].get('vbr'),\n                        'stretched_ratio': formats_info[0].get('stretched_ratio'),\n                        'acodec': formats_info[1].get('acodec'),\n                        'abr': formats_info[1].get('abr'),\n                        'ext': output_ext,\n                    }\n                video_selector, audio_selector = map(_build_selector_function, selector.selector)\n\n                def selector_function(ctx):\n                    for pair in itertools.product(\n                            video_selector(copy.deepcopy(ctx)), audio_selector(copy.deepcopy(ctx))):\n                        yield _merge(pair)\n\n            filters = [self._build_format_filter(f) for f in selector.filters]\n\n            def final_selector(ctx):\n                ctx_copy = copy.deepcopy(ctx)\n                for _filter in filters:\n                    ctx_copy['formats'] = list(filter(_filter, ctx_copy['formats']))\n                return selector_function(ctx_copy)\n            return final_selector\n\n        stream = io.BytesIO(format_spec.encode('utf-8'))\n        try:\n            tokens = list(_remove_unused_ops(compat_tokenize_tokenize(stream.readline)))\n        except tokenize.TokenError:\n            raise syntax_error('Missing closing/opening brackets or parenthesis', (0, len(format_spec)))\n\n        class TokenIterator(object):\n            def __init__(self, tokens):\n                self.tokens = tokens\n                self.counter = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.counter >= len(self.tokens):\n                    raise StopIteration()\n                value = self.tokens[self.counter]\n                self.counter += 1\n                return value\n\n            next = __next__\n\n            def restore_last_token(self):\n                self.counter -= 1\n\n        parsed_selector = _parse_format_selection(iter(TokenIterator(tokens)))\n        return _build_selector_function(parsed_selector)",
        "begin_line": 1086,
        "end_line": 1349,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers#1351",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_headers(self, info_dict)",
        "snippet": "    def _calc_headers(self, info_dict):\n        res = std_headers.copy()\n\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            res.update(add_headers)\n\n        cookies = self._calc_cookies(info_dict)\n        if cookies:\n            res['Cookie'] = cookies\n\n        if 'X-Forwarded-For' not in res:\n            x_forwarded_for_ip = info_dict.get('__x_forwarded_for_ip')\n            if x_forwarded_for_ip:\n                res['X-Forwarded-For'] = x_forwarded_for_ip\n\n        return res",
        "begin_line": 1351,
        "end_line": 1367,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies#1369",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._calc_cookies(self, info_dict)",
        "snippet": "    def _calc_cookies(self, info_dict):\n        pr = sanitized_Request(info_dict['url'])\n        self.cookiejar.add_cookie_header(pr)\n        return pr.get_header('Cookie')",
        "begin_line": 1369,
        "end_line": 1372,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result#1374",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result(self, info_dict, download=True)",
        "snippet": "    def process_video_result(self, info_dict, download=True):\n        assert info_dict.get('_type', 'video') == 'video'\n\n        if 'id' not in info_dict:\n            raise ExtractorError('Missing \"id\" field in extractor result')\n        if 'title' not in info_dict:\n            raise ExtractorError('Missing \"title\" field in extractor result')\n\n        def report_force_conversion(field, field_not, conversion):\n            self.report_warning(\n                '\"%s\" field is not %s - forcing %s conversion, there is an error in extractor'\n                % (field, field_not, conversion))\n\n        def sanitize_string_field(info, string_field):\n            field = info.get(string_field)\n            if field is None or isinstance(field, compat_str):\n                return\n            report_force_conversion(string_field, 'a string', 'string')\n            info[string_field] = compat_str(field)\n\n        def sanitize_numeric_fields(info):\n            for numeric_field in self._NUMERIC_FIELDS:\n                field = info.get(numeric_field)\n                if field is None or isinstance(field, compat_numeric_types):\n                    continue\n                report_force_conversion(numeric_field, 'numeric', 'int')\n                info[numeric_field] = int_or_none(field)\n\n        sanitize_string_field(info_dict, 'id')\n        sanitize_numeric_fields(info_dict)\n\n        if 'playlist' not in info_dict:\n            # It isn't part of a playlist\n            info_dict['playlist'] = None\n            info_dict['playlist_index'] = None\n\n        thumbnails = info_dict.get('thumbnails')\n        if thumbnails is None:\n            thumbnail = info_dict.get('thumbnail')\n            if thumbnail:\n                info_dict['thumbnails'] = thumbnails = [{'url': thumbnail}]\n        if thumbnails:\n            thumbnails.sort(key=lambda t: (\n                t.get('preference') if t.get('preference') is not None else -1,\n                t.get('width') if t.get('width') is not None else -1,\n                t.get('height') if t.get('height') is not None else -1,\n                t.get('id') if t.get('id') is not None else '', t.get('url')))\n            for i, t in enumerate(thumbnails):\n                t['url'] = sanitize_url(t['url'])\n                if t.get('width') and t.get('height'):\n                    t['resolution'] = '%dx%d' % (t['width'], t['height'])\n                if t.get('id') is None:\n                    t['id'] = '%d' % i\n\n        if self.params.get('list_thumbnails'):\n            self.list_thumbnails(info_dict)\n            return\n\n        thumbnail = info_dict.get('thumbnail')\n        if thumbnail:\n            info_dict['thumbnail'] = sanitize_url(thumbnail)\n        elif thumbnails:\n            info_dict['thumbnail'] = thumbnails[-1]['url']\n\n        if 'display_id' not in info_dict and 'id' in info_dict:\n            info_dict['display_id'] = info_dict['id']\n\n        if info_dict.get('upload_date') is None and info_dict.get('timestamp') is not None:\n            # Working around out-of-range timestamp values (e.g. negative ones on Windows,\n            # see http://bugs.python.org/issue1646728)\n            try:\n                upload_date = datetime.datetime.utcfromtimestamp(info_dict['timestamp'])\n                info_dict['upload_date'] = upload_date.strftime('%Y%m%d')\n            except (ValueError, OverflowError, OSError):\n                pass\n\n        # Auto generate title fields corresponding to the *_number fields when missing\n        # in order to always have clean titles. This is very common for TV series.\n        for field in ('chapter', 'season', 'episode'):\n            if info_dict.get('%s_number' % field) is not None and not info_dict.get(field):\n                info_dict[field] = '%s %d' % (field.capitalize(), info_dict['%s_number' % field])\n\n        subtitles = info_dict.get('subtitles')\n        if subtitles:\n            for _, subtitle in subtitles.items():\n                for subtitle_format in subtitle:\n                    if subtitle_format.get('url'):\n                        subtitle_format['url'] = sanitize_url(subtitle_format['url'])\n                    if subtitle_format.get('ext') is None:\n                        subtitle_format['ext'] = determine_ext(subtitle_format['url']).lower()\n\n        if self.params.get('listsubtitles', False):\n            if 'automatic_captions' in info_dict:\n                self.list_subtitles(info_dict['id'], info_dict.get('automatic_captions'), 'automatic captions')\n            self.list_subtitles(info_dict['id'], subtitles, 'subtitles')\n            return\n        info_dict['requested_subtitles'] = self.process_subtitles(\n            info_dict['id'], subtitles,\n            info_dict.get('automatic_captions'))\n\n        # We now pick which formats have to be downloaded\n        if info_dict.get('formats') is None:\n            # There's only one format available\n            formats = [info_dict]\n        else:\n            formats = info_dict['formats']\n\n        if not formats:\n            raise ExtractorError('No video formats found!')\n\n        def is_wellformed(f):\n            url = f.get('url')\n            if not url:\n                self.report_warning(\n                    '\"url\" field is missing or empty - skipping format, '\n                    'there is an error in extractor')\n                return False\n            if isinstance(url, bytes):\n                sanitize_string_field(f, 'url')\n            return True\n\n        # Filter out malformed formats for better extraction robustness\n        formats = list(filter(is_wellformed, formats))\n\n        formats_dict = {}\n\n        # We check that all the formats have the format and format_id fields\n        for i, format in enumerate(formats):\n            sanitize_string_field(format, 'format_id')\n            sanitize_numeric_fields(format)\n            format['url'] = sanitize_url(format['url'])\n            if not format.get('format_id'):\n                format['format_id'] = compat_str(i)\n            else:\n                # Sanitize format_id from characters used in format selector expression\n                format['format_id'] = re.sub(r'[\\s,/+\\[\\]()]', '_', format['format_id'])\n            format_id = format['format_id']\n            if format_id not in formats_dict:\n                formats_dict[format_id] = []\n            formats_dict[format_id].append(format)\n\n        # Make sure all formats have unique format_id\n        for format_id, ambiguous_formats in formats_dict.items():\n            if len(ambiguous_formats) > 1:\n                for i, format in enumerate(ambiguous_formats):\n                    format['format_id'] = '%s-%d' % (format_id, i)\n\n        for i, format in enumerate(formats):\n            if format.get('format') is None:\n                format['format'] = '{id} - {res}{note}'.format(\n                    id=format['format_id'],\n                    res=self.format_resolution(format),\n                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',\n                )\n            # Automatically determine file extension if missing\n            if format.get('ext') is None:\n                format['ext'] = determine_ext(format['url']).lower()\n            # Automatically determine protocol if missing (useful for format\n            # selection purposes)\n            if format.get('protocol') is None:\n                format['protocol'] = determine_protocol(format)\n            # Add HTTP headers, so that external programs can use them from the\n            # json output\n            full_format_info = info_dict.copy()\n            full_format_info.update(format)\n            format['http_headers'] = self._calc_headers(full_format_info)\n        # Remove private housekeeping stuff\n        if '__x_forwarded_for_ip' in info_dict:\n            del info_dict['__x_forwarded_for_ip']\n\n        # TODO Central sorting goes here\n\n        if formats[0] is not info_dict:\n            # only set the 'formats' fields if the original info_dict list them\n            # otherwise we end up with a circular reference, the first (and unique)\n            # element in the 'formats' field in info_dict is info_dict itself,\n            # which can't be exported to json\n            info_dict['formats'] = formats\n        if self.params.get('listformats'):\n            self.list_formats(info_dict)\n            return\n\n        req_format = self.params.get('format')\n        if req_format is None:\n            req_format = self._default_format_spec(info_dict, download=download)\n            if self.params.get('verbose'):\n                self.to_stdout('[debug] Default format spec: %s' % req_format)\n\n        format_selector = self.build_format_selector(req_format)\n\n        # While in format selection we may need to have an access to the original\n        # format set in order to calculate some metrics or do some processing.\n        # For now we need to be able to guess whether original formats provided\n        # by extractor are incomplete or not (i.e. whether extractor provides only\n        # video-only or audio-only formats) for proper formats selection for\n        # extractors with such incomplete formats (see\n        # https://github.com/rg3/youtube-dl/pull/5556).\n        # Since formats may be filtered during format selection and may not match\n        # the original formats the results may be incorrect. Thus original formats\n        # or pre-calculated metrics should be passed to format selection routines\n        # as well.\n        # We will pass a context object containing all necessary additional data\n        # instead of just formats.\n        # This fixes incorrect format selection issue (see\n        # https://github.com/rg3/youtube-dl/issues/10083).\n        incomplete_formats = (\n            # All formats are video-only or\n            all(f.get('vcodec') != 'none' and f.get('acodec') == 'none' for f in formats) or\n            # all formats are audio-only\n            all(f.get('vcodec') == 'none' and f.get('acodec') != 'none' for f in formats))\n\n        ctx = {\n            'formats': formats,\n            'incomplete_formats': incomplete_formats,\n        }\n\n        formats_to_download = list(format_selector(ctx))\n        if not formats_to_download:\n            raise ExtractorError('requested format not available',\n                                 expected=True)\n\n        if download:\n            if len(formats_to_download) > 1:\n                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))\n            for format in formats_to_download:\n                new_info = dict(info_dict)\n                new_info.update(format)\n                self.process_info(new_info)\n        # We update the info dict with the best quality format (backwards compatibility)\n        info_dict.update(formats_to_download[-1])\n        return info_dict",
        "begin_line": 1374,
        "end_line": 1604,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles#1606",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_subtitles(self, video_id, normal_subtitles, automatic_captions)",
        "snippet": "    def process_subtitles(self, video_id, normal_subtitles, automatic_captions):\n        \"\"\"Select the requested subtitles and their format\"\"\"\n        available_subs = {}\n        if normal_subtitles and self.params.get('writesubtitles'):\n            available_subs.update(normal_subtitles)\n        if automatic_captions and self.params.get('writeautomaticsub'):\n            for lang, cap_info in automatic_captions.items():\n                if lang not in available_subs:\n                    available_subs[lang] = cap_info\n\n        if (not self.params.get('writesubtitles') and not\n                self.params.get('writeautomaticsub') or not\n                available_subs):\n            return None\n\n        if self.params.get('allsubtitles', False):\n            requested_langs = available_subs.keys()\n        else:\n            if self.params.get('subtitleslangs', False):\n                requested_langs = self.params.get('subtitleslangs')\n            elif 'en' in available_subs:\n                requested_langs = ['en']\n            else:\n                requested_langs = [list(available_subs.keys())[0]]\n\n        formats_query = self.params.get('subtitlesformat', 'best')\n        formats_preference = formats_query.split('/') if formats_query else []\n        subs = {}\n        for lang in requested_langs:\n            formats = available_subs.get(lang)\n            if formats is None:\n                self.report_warning('%s subtitles not available for %s' % (lang, video_id))\n                continue\n            for ext in formats_preference:\n                if ext == 'best':\n                    f = formats[-1]\n                    break\n                matches = list(filter(lambda f: f['ext'] == ext, formats))\n                if matches:\n                    f = matches[-1]\n                    break\n            else:\n                f = formats[-1]\n                self.report_warning(\n                    'No subtitle format found matching \"%s\" for language %s, '\n                    'using %s' % (formats_query, lang, f['ext']))\n            subs[lang] = f\n        return subs",
        "begin_line": 1606,
        "end_line": 1653,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_info#1655",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_info(self, info_dict)",
        "snippet": "    def process_info(self, info_dict):\n        \"\"\"Process a single resolved IE result.\"\"\"\n\n        assert info_dict.get('_type', 'video') == 'video'\n\n        max_downloads = self.params.get('max_downloads')\n        if max_downloads is not None:\n            if self._num_downloads >= int(max_downloads):\n                raise MaxDownloadsReached()\n\n        info_dict['fulltitle'] = info_dict['title']\n        if len(info_dict['title']) > 200:\n            info_dict['title'] = info_dict['title'][:197] + '...'\n\n        if 'format' not in info_dict:\n            info_dict['format'] = info_dict['ext']\n\n        reason = self._match_entry(info_dict, incomplete=False)\n        if reason is not None:\n            self.to_screen('[download] ' + reason)\n            return\n\n        self._num_downloads += 1\n\n        info_dict['_filename'] = filename = self.prepare_filename(info_dict)\n\n        # Forced printings\n        if self.params.get('forcetitle', False):\n            self.to_stdout(info_dict['fulltitle'])\n        if self.params.get('forceid', False):\n            self.to_stdout(info_dict['id'])\n        if self.params.get('forceurl', False):\n            if info_dict.get('requested_formats') is not None:\n                for f in info_dict['requested_formats']:\n                    self.to_stdout(f['url'] + f.get('play_path', ''))\n            else:\n                # For RTMP URLs, also include the playpath\n                self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))\n        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:\n            self.to_stdout(info_dict['thumbnail'])\n        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:\n            self.to_stdout(info_dict['description'])\n        if self.params.get('forcefilename', False) and filename is not None:\n            self.to_stdout(filename)\n        if self.params.get('forceduration', False) and info_dict.get('duration') is not None:\n            self.to_stdout(formatSeconds(info_dict['duration']))\n        if self.params.get('forceformat', False):\n            self.to_stdout(info_dict['format'])\n        if self.params.get('forcejson', False):\n            self.to_stdout(json.dumps(info_dict))\n\n        # Do nothing else if in simulate mode\n        if self.params.get('simulate', False):\n            return\n\n        if filename is None:\n            return\n\n        try:\n            dn = os.path.dirname(sanitize_path(encodeFilename(filename)))\n            if dn and not os.path.exists(dn):\n                os.makedirs(dn)\n        except (OSError, IOError) as err:\n            self.report_error('unable to create directory ' + error_to_compat_str(err))\n            return\n\n        if self.params.get('writedescription', False):\n            descfn = replace_extension(filename, 'description', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(descfn)):\n                self.to_screen('[info] Video description is already present')\n            elif info_dict.get('description') is None:\n                self.report_warning('There\\'s no description to write.')\n            else:\n                try:\n                    self.to_screen('[info] Writing video description to: ' + descfn)\n                    with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:\n                        descfile.write(info_dict['description'])\n                except (OSError, IOError):\n                    self.report_error('Cannot write description file ' + descfn)\n                    return\n\n        if self.params.get('writeannotations', False):\n            annofn = replace_extension(filename, 'annotations.xml', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(annofn)):\n                self.to_screen('[info] Video annotations are already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video annotations to: ' + annofn)\n                    with io.open(encodeFilename(annofn), 'w', encoding='utf-8') as annofile:\n                        annofile.write(info_dict['annotations'])\n                except (KeyError, TypeError):\n                    self.report_warning('There are no annotations to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write annotations file: ' + annofn)\n                    return\n\n        subtitles_are_requested = any([self.params.get('writesubtitles', False),\n                                       self.params.get('writeautomaticsub')])\n\n        if subtitles_are_requested and info_dict.get('requested_subtitles'):\n            # subtitles download errors are already managed as troubles in relevant IE\n            # that way it will silently go on when used with unsupporting IE\n            subtitles = info_dict['requested_subtitles']\n            ie = self.get_info_extractor(info_dict['extractor_key'])\n            for sub_lang, sub_info in subtitles.items():\n                sub_format = sub_info['ext']\n                if sub_info.get('data') is not None:\n                    sub_data = sub_info['data']\n                else:\n                    try:\n                        sub_data = ie._download_webpage(\n                            sub_info['url'], info_dict['id'], note=False)\n                    except ExtractorError as err:\n                        self.report_warning('Unable to download subtitle for \"%s\": %s' %\n                                            (sub_lang, error_to_compat_str(err.cause)))\n                        continue\n                try:\n                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)\n                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):\n                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))\n                    else:\n                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)\n                        # Use newline='' to prevent conversion of newline characters\n                        # See https://github.com/rg3/youtube-dl/issues/10268\n                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8', newline='') as subfile:\n                            subfile.write(sub_data)\n                except (OSError, IOError):\n                    self.report_error('Cannot write subtitles file ' + sub_filename)\n                    return\n\n        if self.params.get('writeinfojson', False):\n            infofn = replace_extension(filename, 'info.json', info_dict.get('ext'))\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):\n                self.to_screen('[info] Video description metadata is already present')\n            else:\n                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)\n                try:\n                    write_json_file(self.filter_requested_info(info_dict), infofn)\n                except (OSError, IOError):\n                    self.report_error('Cannot write metadata to JSON file ' + infofn)\n                    return\n\n        self._write_thumbnails(info_dict, filename)\n\n        if not self.params.get('skip_download', False):\n            try:\n                def dl(name, info):\n                    fd = get_suitable_downloader(info, self.params)(self, self.params)\n                    for ph in self._progress_hooks:\n                        fd.add_progress_hook(ph)\n                    if self.params.get('verbose'):\n                        self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                    return fd.download(name, info)\n\n                if info_dict.get('requested_formats') is not None:\n                    downloaded = []\n                    success = True\n                    merger = FFmpegMergerPP(self)\n                    if not merger.available:\n                        postprocessors = []\n                        self.report_warning('You have requested multiple '\n                                            'formats but ffmpeg or avconv are not installed.'\n                                            ' The formats won\\'t be merged.')\n                    else:\n                        postprocessors = [merger]\n\n                    def compatible_formats(formats):\n                        video, audio = formats\n                        # Check extension\n                        video_ext, audio_ext = audio.get('ext'), video.get('ext')\n                        if video_ext and audio_ext:\n                            COMPATIBLE_EXTS = (\n                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v', 'ismv', 'isma'),\n                                ('webm')\n                            )\n                            for exts in COMPATIBLE_EXTS:\n                                if video_ext in exts and audio_ext in exts:\n                                    return True\n                        # TODO: Check acodec/vcodec\n                        return False\n\n                    filename_real_ext = os.path.splitext(filename)[1][1:]\n                    filename_wo_ext = (\n                        os.path.splitext(filename)[0]\n                        if filename_real_ext == info_dict['ext']\n                        else filename)\n                    requested_formats = info_dict['requested_formats']\n                    if self.params.get('merge_output_format') is None and not compatible_formats(requested_formats):\n                        info_dict['ext'] = 'mkv'\n                        self.report_warning(\n                            'Requested formats are incompatible for merge and will be merged into mkv.')\n                    # Ensure filename always has a correct extension for successful merge\n                    filename = '%s.%s' % (filename_wo_ext, info_dict['ext'])\n                    if os.path.exists(encodeFilename(filename)):\n                        self.to_screen(\n                            '[download] %s has already been downloaded and '\n                            'merged' % filename)\n                    else:\n                        for f in requested_formats:\n                            new_info = dict(info_dict)\n                            new_info.update(f)\n                            fname = self.prepare_filename(new_info)\n                            fname = prepend_extension(fname, 'f%s' % f['format_id'], new_info['ext'])\n                            downloaded.append(fname)\n                            partial_success = dl(fname, new_info)\n                            success = success and partial_success\n                        info_dict['__postprocessors'] = postprocessors\n                        info_dict['__files_to_merge'] = downloaded\n                else:\n                    # Just a single file\n                    success = dl(filename, info_dict)\n            except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                self.report_error('unable to download video data: %s' % error_to_compat_str(err))\n                return\n            except (OSError, IOError) as err:\n                raise UnavailableVideoError(err)\n            except (ContentTooShortError, ) as err:\n                self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))\n                return\n\n            if success and filename != '-':\n                # Fixup content\n                fixup_policy = self.params.get('fixup')\n                if fixup_policy is None:\n                    fixup_policy = 'detect_or_warn'\n\n                INSTALL_FFMPEG_MESSAGE = 'Install ffmpeg or avconv to fix this automatically.'\n\n                stretched_ratio = info_dict.get('stretched_ratio')\n                if stretched_ratio is not None and stretched_ratio != 1:\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: Non-uniform pixel ratio (%s)' % (\n                            info_dict['id'], stretched_ratio))\n                    elif fixup_policy == 'detect_or_warn':\n                        stretched_pp = FFmpegFixupStretchedPP(self)\n                        if stretched_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(stretched_pp)\n                        else:\n                            self.report_warning(\n                                '%s: Non-uniform pixel ratio (%s). %s'\n                                % (info_dict['id'], stretched_ratio, INSTALL_FFMPEG_MESSAGE))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                if (info_dict.get('requested_formats') is None and\n                        info_dict.get('container') == 'm4a_dash'):\n                    if fixup_policy == 'warn':\n                        self.report_warning(\n                            '%s: writing DASH m4a. '\n                            'Only some players support this container.'\n                            % info_dict['id'])\n                    elif fixup_policy == 'detect_or_warn':\n                        fixup_pp = FFmpegFixupM4aPP(self)\n                        if fixup_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(fixup_pp)\n                        else:\n                            self.report_warning(\n                                '%s: writing DASH m4a. '\n                                'Only some players support this container. %s'\n                                % (info_dict['id'], INSTALL_FFMPEG_MESSAGE))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                if (info_dict.get('protocol') == 'm3u8_native' or\n                        info_dict.get('protocol') == 'm3u8' and\n                        self.params.get('hls_prefer_native')):\n                    if fixup_policy == 'warn':\n                        self.report_warning('%s: malformed AAC bitstream detected.' % (\n                            info_dict['id']))\n                    elif fixup_policy == 'detect_or_warn':\n                        fixup_pp = FFmpegFixupM3u8PP(self)\n                        if fixup_pp.available:\n                            info_dict.setdefault('__postprocessors', [])\n                            info_dict['__postprocessors'].append(fixup_pp)\n                        else:\n                            self.report_warning(\n                                '%s: malformed AAC bitstream detected. %s'\n                                % (info_dict['id'], INSTALL_FFMPEG_MESSAGE))\n                    else:\n                        assert fixup_policy in ('ignore', 'never')\n\n                try:\n                    self.post_process(filename, info_dict)\n                except (PostProcessingError) as err:\n                    self.report_error('postprocessing: %s' % str(err))\n                    return\n                self.record_download_archive(info_dict)",
        "begin_line": 1655,
        "end_line": 1943,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download#1945",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download(self, url_list)",
        "snippet": "    def download(self, url_list):\n        \"\"\"Download a given list of URLs.\"\"\"\n        outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n        if (len(url_list) > 1 and\n                outtmpl != '-' and\n                '%' not in outtmpl and\n                self.params.get('max_downloads') != 1):\n            raise SameFileError(outtmpl)\n\n        for url in url_list:\n            try:\n                # It also downloads the videos\n                res = self.extract_info(\n                    url, force_generic_extractor=self.params.get('force_generic_extractor', False))\n            except UnavailableVideoError:\n                self.report_error('unable to download video')\n            except MaxDownloadsReached:\n                self.to_screen('[info] Maximum number of downloaded files reached.')\n                raise\n            else:\n                if self.params.get('dump_single_json', False):\n                    self.to_stdout(json.dumps(res))\n\n        return self._download_retcode",
        "begin_line": 1945,
        "end_line": 1968,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file#1970",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file(self, info_filename)",
        "snippet": "    def download_with_info_file(self, info_filename):\n        with contextlib.closing(fileinput.FileInput(\n                [info_filename], mode='r',\n                openhook=fileinput.hook_encoded('utf-8'))) as f:\n            # FileInput doesn't have a read method, we can't call json.load\n            info = self.filter_requested_info(json.loads('\\n'.join(f)))\n        try:\n            self.process_ie_result(info, download=True)\n        except DownloadError:\n            webpage_url = info.get('webpage_url')\n            if webpage_url is not None:\n                self.report_warning('The info failed to download, trying with \"%s\"' % webpage_url)\n                return self.download([webpage_url])\n            else:\n                raise\n        return self._download_retcode",
        "begin_line": 1970,
        "end_line": 1985,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info#1988",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.filter_requested_info(info_dict)",
        "snippet": "    def filter_requested_info(info_dict):\n        return dict(\n            (k, v) for k, v in info_dict.items()\n            if k not in ['requested_formats', 'requested_subtitles'])",
        "begin_line": 1988,
        "end_line": 1991,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.post_process#1993",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.post_process(self, filename, ie_info)",
        "snippet": "    def post_process(self, filename, ie_info):\n        \"\"\"Run all the postprocessors on the given file.\"\"\"\n        info = dict(ie_info)\n        info['filepath'] = filename\n        pps_chain = []\n        if ie_info.get('__postprocessors') is not None:\n            pps_chain.extend(ie_info['__postprocessors'])\n        pps_chain.extend(self._pps)\n        for pp in pps_chain:\n            files_to_delete = []\n            try:\n                files_to_delete, info = pp.run(info)\n            except PostProcessingError as e:\n                self.report_error(e.msg)\n            if files_to_delete and not self.params.get('keepvideo', False):\n                for old_filename in files_to_delete:\n                    self.to_screen('Deleting original file %s (pass -k to keep)' % old_filename)\n                    try:\n                        os.remove(encodeFilename(old_filename))\n                    except (IOError, OSError):\n                        self.report_warning('Unable to remove downloaded original file')",
        "begin_line": 1993,
        "end_line": 2013,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id#2015",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id(self, info_dict)",
        "snippet": "    def _make_archive_id(self, info_dict):\n        # Future-proof against any change in case\n        # and backwards compatibility with prior versions\n        extractor = info_dict.get('extractor_key')\n        if extractor is None:\n            if 'id' in info_dict:\n                extractor = info_dict.get('ie_key')  # key in a playlist\n        if extractor is None:\n            return None  # Incomplete video information\n        return extractor.lower() + ' ' + info_dict['id']",
        "begin_line": 2015,
        "end_line": 2024,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive#2026",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive(self, info_dict)",
        "snippet": "    def in_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return False\n\n        vid_id = self._make_archive_id(info_dict)\n        if vid_id is None:\n            return False  # Incomplete video information\n\n        try:\n            with locked_file(fn, 'r', encoding='utf-8') as archive_file:\n                for line in archive_file:\n                    if line.strip() == vid_id:\n                        return True\n        except IOError as ioe:\n            if ioe.errno != errno.ENOENT:\n                raise\n        return False",
        "begin_line": 2026,
        "end_line": 2043,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive#2045",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive(self, info_dict)",
        "snippet": "    def record_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return\n        vid_id = self._make_archive_id(info_dict)\n        assert vid_id\n        with locked_file(fn, 'a', encoding='utf-8') as archive_file:\n            archive_file.write(vid_id + '\\n')",
        "begin_line": 2045,
        "end_line": 2052,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution#2055",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution(format, default='unknown')",
        "snippet": "    def format_resolution(format, default='unknown'):\n        if format.get('vcodec') == 'none':\n            return 'audio only'\n        if format.get('resolution') is not None:\n            return format['resolution']\n        if format.get('height') is not None:\n            if format.get('width') is not None:\n                res = '%sx%s' % (format['width'], format['height'])\n            else:\n                res = '%sp' % format['height']\n        elif format.get('width') is not None:\n            res = '%dx?' % format['width']\n        else:\n            res = default\n        return res",
        "begin_line": 2055,
        "end_line": 2069,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._format_note#2071",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._format_note(self, fdict)",
        "snippet": "    def _format_note(self, fdict):\n        res = ''\n        if fdict.get('ext') in ['f4f', 'f4m']:\n            res += '(unsupported) '\n        if fdict.get('language'):\n            if res:\n                res += ' '\n            res += '[%s] ' % fdict['language']\n        if fdict.get('format_note') is not None:\n            res += fdict['format_note'] + ' '\n        if fdict.get('tbr') is not None:\n            res += '%4dk ' % fdict['tbr']\n        if fdict.get('container') is not None:\n            if res:\n                res += ', '\n            res += '%s container' % fdict['container']\n        if (fdict.get('vcodec') is not None and\n                fdict.get('vcodec') != 'none'):\n            if res:\n                res += ', '\n            res += fdict['vcodec']\n            if fdict.get('vbr') is not None:\n                res += '@'\n        elif fdict.get('vbr') is not None and fdict.get('abr') is not None:\n            res += 'video@'\n        if fdict.get('vbr') is not None:\n            res += '%4dk' % fdict['vbr']\n        if fdict.get('fps') is not None:\n            if res:\n                res += ', '\n            res += '%sfps' % fdict['fps']\n        if fdict.get('acodec') is not None:\n            if res:\n                res += ', '\n            if fdict['acodec'] == 'none':\n                res += 'video only'\n            else:\n                res += '%-5s' % fdict['acodec']\n        elif fdict.get('abr') is not None:\n            if res:\n                res += ', '\n            res += 'audio'\n        if fdict.get('abr') is not None:\n            res += '@%3dk' % fdict['abr']\n        if fdict.get('asr') is not None:\n            res += ' (%5dHz)' % fdict['asr']\n        if fdict.get('filesize') is not None:\n            if res:\n                res += ', '\n            res += format_bytes(fdict['filesize'])\n        elif fdict.get('filesize_approx') is not None:\n            if res:\n                res += ', '\n            res += '~' + format_bytes(fdict['filesize_approx'])\n        return res",
        "begin_line": 2071,
        "end_line": 2125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_formats#2127",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_formats(self, info_dict)",
        "snippet": "    def list_formats(self, info_dict):\n        formats = info_dict.get('formats', [info_dict])\n        table = [\n            [f['format_id'], f['ext'], self.format_resolution(f), self._format_note(f)]\n            for f in formats\n            if f.get('preference') is None or f['preference'] >= -1000]\n        if len(formats) > 1:\n            table[-1][-1] += (' ' if table[-1][-1] else '') + '(best)'\n\n        header_line = ['format code', 'extension', 'resolution', 'note']\n        self.to_screen(\n            '[info] Available formats for %s:\\n%s' %\n            (info_dict['id'], render_table(header_line, table)))",
        "begin_line": 2127,
        "end_line": 2139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails#2141",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_thumbnails(self, info_dict)",
        "snippet": "    def list_thumbnails(self, info_dict):\n        thumbnails = info_dict.get('thumbnails')\n        if not thumbnails:\n            self.to_screen('[info] No thumbnails present for %s' % info_dict['id'])\n            return\n\n        self.to_screen(\n            '[info] Thumbnails for %s:' % info_dict['id'])\n        self.to_screen(render_table(\n            ['ID', 'width', 'height', 'URL'],\n            [[t['id'], t.get('width', 'unknown'), t.get('height', 'unknown'), t['url']] for t in thumbnails]))",
        "begin_line": 2141,
        "end_line": 2151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles#2153",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_subtitles(self, video_id, subtitles, name='subtitles')",
        "snippet": "    def list_subtitles(self, video_id, subtitles, name='subtitles'):\n        if not subtitles:\n            self.to_screen('%s has no %s' % (video_id, name))\n            return\n        self.to_screen(\n            'Available %s for %s:' % (name, video_id))\n        self.to_screen(render_table(\n            ['Language', 'formats'],\n            [[lang, ', '.join(f['ext'] for f in reversed(formats))]\n                for lang, formats in subtitles.items()]))",
        "begin_line": 2153,
        "end_line": 2162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.urlopen#2164",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.urlopen(self, req)",
        "snippet": "    def urlopen(self, req):\n        \"\"\" Start an HTTP download \"\"\"\n        if isinstance(req, compat_basestring):\n            req = sanitized_Request(req)\n        return self._opener.open(req, timeout=self._socket_timeout)",
        "begin_line": 2164,
        "end_line": 2168,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header#2170",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header(self)",
        "snippet": "    def print_debug_header(self):\n        if not self.params.get('verbose'):\n            return\n\n        if type('') is not compat_str:\n            # Python 2.6 on SLES11 SP1 (https://github.com/rg3/youtube-dl/issues/3326)\n            self.report_warning(\n                'Your Python is broken! Update to a newer and supported version')\n\n        stdout_encoding = getattr(\n            sys.stdout, 'encoding', 'missing (%s)' % type(sys.stdout).__name__)\n        encoding_str = (\n            '[debug] Encodings: locale %s, fs %s, out %s, pref %s\\n' % (\n                locale.getpreferredencoding(),\n                sys.getfilesystemencoding(),\n                stdout_encoding,\n                self.get_encoding()))\n        write_string(encoding_str, encoding=None)\n\n        self._write_string('[debug] youtube-dl version ' + __version__ + '\\n')\n        if _LAZY_LOADER:\n            self._write_string('[debug] Lazy loading extractors enabled' + '\\n')\n        try:\n            sp = subprocess.Popen(\n                ['git', 'rev-parse', '--short', 'HEAD'],\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                cwd=os.path.dirname(os.path.abspath(__file__)))\n            out, err = sp.communicate()\n            out = out.decode().strip()\n            if re.match('[0-9a-f]+', out):\n                self._write_string('[debug] Git HEAD: ' + out + '\\n')\n        except Exception:\n            try:\n                sys.exc_clear()\n            except Exception:\n                pass\n        self._write_string('[debug] Python version %s - %s\\n' % (\n            platform.python_version(), platform_name()))\n\n        exe_versions = FFmpegPostProcessor.get_versions(self)\n        exe_versions['rtmpdump'] = rtmpdump_version()\n        exe_str = ', '.join(\n            '%s %s' % (exe, v)\n            for exe, v in sorted(exe_versions.items())\n            if v\n        )\n        if not exe_str:\n            exe_str = 'none'\n        self._write_string('[debug] exe versions: %s\\n' % exe_str)\n\n        proxy_map = {}\n        for handler in self._opener.handlers:\n            if hasattr(handler, 'proxies'):\n                proxy_map.update(handler.proxies)\n        self._write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\\n')\n\n        if self.params.get('call_home', False):\n            ipaddr = self.urlopen('https://yt-dl.org/ip').read().decode('utf-8')\n            self._write_string('[debug] Public IP address: %s\\n' % ipaddr)\n            latest_version = self.urlopen(\n                'https://yt-dl.org/latest/version').read().decode('utf-8')\n            if version_tuple(latest_version) > version_tuple(__version__):\n                self.report_warning(\n                    'You are using an outdated version (newest version: %s)! '\n                    'See https://yt-dl.org/update if you need help updating.' %\n                    latest_version)",
        "begin_line": 2170,
        "end_line": 2235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener#2237",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener(self)",
        "snippet": "    def _setup_opener(self):\n        timeout_val = self.params.get('socket_timeout')\n        self._socket_timeout = 600 if timeout_val is None else float(timeout_val)\n\n        opts_cookiefile = self.params.get('cookiefile')\n        opts_proxy = self.params.get('proxy')\n\n        if opts_cookiefile is None:\n            self.cookiejar = compat_cookiejar.CookieJar()\n        else:\n            opts_cookiefile = expand_path(opts_cookiefile)\n            self.cookiejar = compat_cookiejar.MozillaCookieJar(\n                opts_cookiefile)\n            if os.access(opts_cookiefile, os.R_OK):\n                self.cookiejar.load()\n\n        cookie_processor = YoutubeDLCookieProcessor(self.cookiejar)\n        if opts_proxy is not None:\n            if opts_proxy == '':\n                proxies = {}\n            else:\n                proxies = {'http': opts_proxy, 'https': opts_proxy}\n        else:\n            proxies = compat_urllib_request.getproxies()\n            # Set HTTPS proxy to HTTP one if given (https://github.com/rg3/youtube-dl/issues/805)\n            if 'http' in proxies and 'https' not in proxies:\n                proxies['https'] = proxies['http']\n        proxy_handler = PerRequestProxyHandler(proxies)\n\n        debuglevel = 1 if self.params.get('debug_printtraffic') else 0\n        https_handler = make_HTTPS_handler(self.params, debuglevel=debuglevel)\n        ydlh = YoutubeDLHandler(self.params, debuglevel=debuglevel)\n        data_handler = compat_urllib_request_DataHandler()\n\n        # When passing our own FileHandler instance, build_opener won't add the\n        # default FileHandler and allows us to disable the file protocol, which\n        # can be used for malicious purposes (see\n        # https://github.com/rg3/youtube-dl/issues/8227)\n        file_handler = compat_urllib_request.FileHandler()\n\n        def file_open(*args, **kwargs):\n            raise compat_urllib_error.URLError('file:// scheme is explicitly disabled in youtube-dl for security reasons')\n        file_handler.file_open = file_open\n\n        opener = compat_urllib_request.build_opener(\n            proxy_handler, https_handler, cookie_processor, ydlh, data_handler, file_handler)\n\n        # Delete the default user-agent header, which would otherwise apply in\n        # cases where our custom HTTP handler doesn't come into play\n        # (See https://github.com/rg3/youtube-dl/issues/1309 for details)\n        opener.addheaders = []\n        self._opener = opener",
        "begin_line": 2237,
        "end_line": 2288,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.encode#2290",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.encode(self, s)",
        "snippet": "    def encode(self, s):\n        if isinstance(s, bytes):\n            return s  # Already encoded\n\n        try:\n            return s.encode(self.get_encoding())\n        except UnicodeEncodeError as err:\n            err.reason = err.reason + '. Check your system encoding configuration or use the --encoding option.'\n            raise",
        "begin_line": 2290,
        "end_line": 2298,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding#2300",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding(self)",
        "snippet": "    def get_encoding(self):\n        encoding = self.params.get('encoding')\n        if encoding is None:\n            encoding = preferredencoding()\n        return encoding",
        "begin_line": 2300,
        "end_line": 2304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails#2306",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_thumbnails(self, info_dict, filename)",
        "snippet": "    def _write_thumbnails(self, info_dict, filename):\n        if self.params.get('writethumbnail', False):\n            thumbnails = info_dict.get('thumbnails')\n            if thumbnails:\n                thumbnails = [thumbnails[-1]]\n        elif self.params.get('write_all_thumbnails', False):\n            thumbnails = info_dict.get('thumbnails')\n        else:\n            return\n\n        if not thumbnails:\n            # No thumbnails present, so return immediately\n            return\n\n        for t in thumbnails:\n            thumb_ext = determine_ext(t['url'], 'jpg')\n            suffix = '_%s' % t['id'] if len(thumbnails) > 1 else ''\n            thumb_display_id = '%s ' % t['id'] if len(thumbnails) > 1 else ''\n            t['filename'] = thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext\n\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):\n                self.to_screen('[%s] %s: Thumbnail %sis already present' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n            else:\n                self.to_screen('[%s] %s: Downloading thumbnail %s...' %\n                               (info_dict['extractor'], info_dict['id'], thumb_display_id))\n                try:\n                    uf = self.urlopen(t['url'])\n                    with open(encodeFilename(thumb_filename), 'wb') as thumbf:\n                        shutil.copyfileobj(uf, thumbf)\n                    self.to_screen('[%s] %s: Writing thumbnail %sto: %s' %\n                                   (info_dict['extractor'], info_dict['id'], thumb_display_id, thumb_filename))\n                except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                    self.report_warning('Unable to download thumbnail \"%s\": %s' %\n                                        (t['url'], error_to_compat_str(err)))",
        "begin_line": 2306,
        "end_line": 2340,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.__init__._real_main#48",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._real_main(argv=None)",
        "snippet": "def _real_main(argv=None):\n    # Compatibility fixes for Windows\n    if sys.platform == 'win32':\n        # https://github.com/rg3/youtube-dl/issues/820\n        codecs.register(lambda name: codecs.lookup('utf-8') if name == 'cp65001' else None)\n\n    workaround_optparse_bug9161()\n\n    setproctitle('youtube-dl')\n\n    parser, opts, args = parseOpts(argv)\n\n    # Set user agent\n    if opts.user_agent is not None:\n        std_headers['User-Agent'] = opts.user_agent\n\n    # Set referer\n    if opts.referer is not None:\n        std_headers['Referer'] = opts.referer\n\n    # Custom HTTP headers\n    if opts.headers is not None:\n        for h in opts.headers:\n            if ':' not in h:\n                parser.error('wrong header formatting, it should be key:value, not \"%s\"' % h)\n            key, value = h.split(':', 1)\n            if opts.verbose:\n                write_string('[debug] Adding header from command line option %s:%s\\n' % (key, value))\n            std_headers[key] = value\n\n    # Dump user agent\n    if opts.dump_user_agent:\n        write_string(std_headers['User-Agent'] + '\\n', out=sys.stdout)\n        sys.exit(0)\n\n    # Batch file verification\n    batch_urls = []\n    if opts.batchfile is not None:\n        try:\n            if opts.batchfile == '-':\n                batchfd = sys.stdin\n            else:\n                batchfd = io.open(\n                    expand_path(opts.batchfile),\n                    'r', encoding='utf-8', errors='ignore')\n            batch_urls = read_batch_urls(batchfd)\n            if opts.verbose:\n                write_string('[debug] Batch file urls: ' + repr(batch_urls) + '\\n')\n        except IOError:\n            sys.exit('ERROR: batch file could not be read')\n    all_urls = batch_urls + [url.strip() for url in args]  # batch_urls are already striped in read_batch_urls\n    _enc = preferredencoding()\n    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]\n\n    if opts.list_extractors:\n        for ie in list_extractors(opts.age_limit):\n            write_string(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else '') + '\\n', out=sys.stdout)\n            matchedUrls = [url for url in all_urls if ie.suitable(url)]\n            for mu in matchedUrls:\n                write_string('  ' + mu + '\\n', out=sys.stdout)\n        sys.exit(0)\n    if opts.list_extractor_descriptions:\n        for ie in list_extractors(opts.age_limit):\n            if not ie._WORKING:\n                continue\n            desc = getattr(ie, 'IE_DESC', ie.IE_NAME)\n            if desc is False:\n                continue\n            if hasattr(ie, 'SEARCH_KEY'):\n                _SEARCHES = ('cute kittens', 'slithering pythons', 'falling cat', 'angry poodle', 'purple fish', 'running tortoise', 'sleeping bunny', 'burping cow')\n                _COUNTS = ('', '5', '10', 'all')\n                desc += ' (Example: \"%s%s:%s\" )' % (ie.SEARCH_KEY, random.choice(_COUNTS), random.choice(_SEARCHES))\n            write_string(desc + '\\n', out=sys.stdout)\n        sys.exit(0)\n    if opts.ap_list_mso:\n        table = [[mso_id, mso_info['name']] for mso_id, mso_info in MSO_INFO.items()]\n        write_string('Supported TV Providers:\\n' + render_table(['mso', 'mso name'], table) + '\\n', out=sys.stdout)\n        sys.exit(0)\n\n    # Conflicting, missing and erroneous options\n    if opts.usenetrc and (opts.username is not None or opts.password is not None):\n        parser.error('using .netrc conflicts with giving username/password')\n    if opts.password is not None and opts.username is None:\n        parser.error('account username missing\\n')\n    if opts.ap_password is not None and opts.ap_username is None:\n        parser.error('TV Provider account username missing\\n')\n    if opts.outtmpl is not None and (opts.usetitle or opts.autonumber or opts.useid):\n        parser.error('using output template conflicts with using title, video ID or auto number')\n    if opts.autonumber_size is not None:\n        if opts.autonumber_size <= 0:\n            parser.error('auto number size must be positive')\n    if opts.autonumber_start is not None:\n        if opts.autonumber_start < 0:\n            parser.error('auto number start must be positive or 0')\n    if opts.usetitle and opts.useid:\n        parser.error('using title conflicts with using video ID')\n    if opts.username is not None and opts.password is None:\n        opts.password = compat_getpass('Type account password and press [Return]: ')\n    if opts.ap_username is not None and opts.ap_password is None:\n        opts.ap_password = compat_getpass('Type TV provider account password and press [Return]: ')\n    if opts.ratelimit is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.ratelimit)\n        if numeric_limit is None:\n            parser.error('invalid rate limit specified')\n        opts.ratelimit = numeric_limit\n    if opts.min_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.min_filesize)\n        if numeric_limit is None:\n            parser.error('invalid min_filesize specified')\n        opts.min_filesize = numeric_limit\n    if opts.max_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.max_filesize)\n        if numeric_limit is None:\n            parser.error('invalid max_filesize specified')\n        opts.max_filesize = numeric_limit\n    if opts.sleep_interval is not None:\n        if opts.sleep_interval < 0:\n            parser.error('sleep interval must be positive or 0')\n    if opts.max_sleep_interval is not None:\n        if opts.max_sleep_interval < 0:\n            parser.error('max sleep interval must be positive or 0')\n        if opts.max_sleep_interval < opts.sleep_interval:\n            parser.error('max sleep interval must be greater than or equal to min sleep interval')\n    else:\n        opts.max_sleep_interval = opts.sleep_interval\n    if opts.ap_mso and opts.ap_mso not in MSO_INFO:\n        parser.error('Unsupported TV Provider, use --ap-list-mso to get a list of supported TV Providers')\n\n    def parse_retries(retries):\n        if retries in ('inf', 'infinite'):\n            parsed_retries = float('inf')\n        else:\n            try:\n                parsed_retries = int(retries)\n            except (TypeError, ValueError):\n                parser.error('invalid retry count specified')\n        return parsed_retries\n    if opts.retries is not None:\n        opts.retries = parse_retries(opts.retries)\n    if opts.fragment_retries is not None:\n        opts.fragment_retries = parse_retries(opts.fragment_retries)\n    if opts.buffersize is not None:\n        numeric_buffersize = FileDownloader.parse_bytes(opts.buffersize)\n        if numeric_buffersize is None:\n            parser.error('invalid buffer size specified')\n        opts.buffersize = numeric_buffersize\n    if opts.playliststart <= 0:\n        raise ValueError('Playlist start must be positive')\n    if opts.playlistend not in (-1, None) and opts.playlistend < opts.playliststart:\n        raise ValueError('Playlist end must be greater than playlist start')\n    if opts.extractaudio:\n        if opts.audioformat not in ['best', 'aac', 'flac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:\n            parser.error('invalid audio format specified')\n    if opts.audioquality:\n        opts.audioquality = opts.audioquality.strip('k').strip('K')\n        if not opts.audioquality.isdigit():\n            parser.error('invalid audio quality specified')\n    if opts.recodevideo is not None:\n        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv', 'avi']:\n            parser.error('invalid video recode format specified')\n    if opts.convertsubtitles is not None:\n        if opts.convertsubtitles not in ['srt', 'vtt', 'ass']:\n            parser.error('invalid subtitle format specified')\n\n    if opts.date is not None:\n        date = DateRange.day(opts.date)\n    else:\n        date = DateRange(opts.dateafter, opts.datebefore)\n\n    # Do not download videos when there are audio-only formats\n    if opts.extractaudio and not opts.keepvideo and opts.format is None:\n        opts.format = 'bestaudio/best'\n\n    # --all-sub automatically sets --write-sub if --write-auto-sub is not given\n    # this was the old behaviour if only --all-sub was given.\n    if opts.allsubtitles and not opts.writeautomaticsub:\n        opts.writesubtitles = True\n\n    outtmpl = ((opts.outtmpl is not None and opts.outtmpl) or\n               (opts.format == '-1' and opts.usetitle and '%(title)s-%(id)s-%(format)s.%(ext)s') or\n               (opts.format == '-1' and '%(id)s-%(format)s.%(ext)s') or\n               (opts.usetitle and opts.autonumber and '%(autonumber)s-%(title)s-%(id)s.%(ext)s') or\n               (opts.usetitle and '%(title)s-%(id)s.%(ext)s') or\n               (opts.useid and '%(id)s.%(ext)s') or\n               (opts.autonumber and '%(autonumber)s-%(id)s.%(ext)s') or\n               DEFAULT_OUTTMPL)\n    if not os.path.splitext(outtmpl)[1] and opts.extractaudio:\n        parser.error('Cannot download a video and extract audio into the same'\n                     ' file! Use \"{0}.%(ext)s\" instead of \"{0}\" as the output'\n                     ' template'.format(outtmpl))\n\n    any_getting = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson or opts.dump_single_json\n    any_printing = opts.print_json\n    download_archive_fn = expand_path(opts.download_archive) if opts.download_archive is not None else opts.download_archive\n\n    # PostProcessors\n    postprocessors = []\n    if opts.metafromtitle:\n        postprocessors.append({\n            'key': 'MetadataFromTitle',\n            'titleformat': opts.metafromtitle\n        })\n    if opts.extractaudio:\n        postprocessors.append({\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': opts.audioformat,\n            'preferredquality': opts.audioquality,\n            'nopostoverwrites': opts.nopostoverwrites,\n        })\n    if opts.recodevideo:\n        postprocessors.append({\n            'key': 'FFmpegVideoConvertor',\n            'preferedformat': opts.recodevideo,\n        })\n    # FFmpegMetadataPP should be run after FFmpegVideoConvertorPP and\n    # FFmpegExtractAudioPP as containers before conversion may not support\n    # metadata (3gp, webm, etc.)\n    # And this post-processor should be placed before other metadata\n    # manipulating post-processors (FFmpegEmbedSubtitle) to prevent loss of\n    # extra metadata. By default ffmpeg preserves metadata applicable for both\n    # source and target containers. From this point the container won't change,\n    # so metadata can be added here.\n    if opts.addmetadata:\n        postprocessors.append({'key': 'FFmpegMetadata'})\n    if opts.convertsubtitles:\n        postprocessors.append({\n            'key': 'FFmpegSubtitlesConvertor',\n            'format': opts.convertsubtitles,\n        })\n    if opts.embedsubtitles:\n        postprocessors.append({\n            'key': 'FFmpegEmbedSubtitle',\n        })\n    if opts.embedthumbnail:\n        already_have_thumbnail = opts.writethumbnail or opts.write_all_thumbnails\n        postprocessors.append({\n            'key': 'EmbedThumbnail',\n            'already_have_thumbnail': already_have_thumbnail\n        })\n        if not already_have_thumbnail:\n            opts.writethumbnail = True\n    # XAttrMetadataPP should be run after post-processors that may change file\n    # contents\n    if opts.xattrs:\n        postprocessors.append({'key': 'XAttrMetadata'})\n    # Please keep ExecAfterDownload towards the bottom as it allows the user to modify the final file in any way.\n    # So if the user is able to remove the file before your postprocessor runs it might cause a few problems.\n    if opts.exec_cmd:\n        postprocessors.append({\n            'key': 'ExecAfterDownload',\n            'exec_cmd': opts.exec_cmd,\n        })\n    external_downloader_args = None\n    if opts.external_downloader_args:\n        external_downloader_args = compat_shlex_split(opts.external_downloader_args)\n    postprocessor_args = None\n    if opts.postprocessor_args:\n        postprocessor_args = compat_shlex_split(opts.postprocessor_args)\n    match_filter = (\n        None if opts.match_filter is None\n        else match_filter_func(opts.match_filter))\n\n    ydl_opts = {\n        'usenetrc': opts.usenetrc,\n        'username': opts.username,\n        'password': opts.password,\n        'twofactor': opts.twofactor,\n        'videopassword': opts.videopassword,\n        'ap_mso': opts.ap_mso,\n        'ap_username': opts.ap_username,\n        'ap_password': opts.ap_password,\n        'quiet': (opts.quiet or any_getting or any_printing),\n        'no_warnings': opts.no_warnings,\n        'forceurl': opts.geturl,\n        'forcetitle': opts.gettitle,\n        'forceid': opts.getid,\n        'forcethumbnail': opts.getthumbnail,\n        'forcedescription': opts.getdescription,\n        'forceduration': opts.getduration,\n        'forcefilename': opts.getfilename,\n        'forceformat': opts.getformat,\n        'forcejson': opts.dumpjson or opts.print_json,\n        'dump_single_json': opts.dump_single_json,\n        'simulate': opts.simulate or any_getting,\n        'skip_download': opts.skip_download,\n        'format': opts.format,\n        'listformats': opts.listformats,\n        'outtmpl': outtmpl,\n        'autonumber_size': opts.autonumber_size,\n        'autonumber_start': opts.autonumber_start,\n        'restrictfilenames': opts.restrictfilenames,\n        'ignoreerrors': opts.ignoreerrors,\n        'force_generic_extractor': opts.force_generic_extractor,\n        'ratelimit': opts.ratelimit,\n        'nooverwrites': opts.nooverwrites,\n        'retries': opts.retries,\n        'fragment_retries': opts.fragment_retries,\n        'skip_unavailable_fragments': opts.skip_unavailable_fragments,\n        'keep_fragments': opts.keep_fragments,\n        'buffersize': opts.buffersize,\n        'noresizebuffer': opts.noresizebuffer,\n        'continuedl': opts.continue_dl,\n        'noprogress': opts.noprogress,\n        'progress_with_newline': opts.progress_with_newline,\n        'playliststart': opts.playliststart,\n        'playlistend': opts.playlistend,\n        'playlistreverse': opts.playlist_reverse,\n        'playlistrandom': opts.playlist_random,\n        'noplaylist': opts.noplaylist,\n        'logtostderr': opts.outtmpl == '-',\n        'consoletitle': opts.consoletitle,\n        'nopart': opts.nopart,\n        'updatetime': opts.updatetime,\n        'writedescription': opts.writedescription,\n        'writeannotations': opts.writeannotations,\n        'writeinfojson': opts.writeinfojson,\n        'writethumbnail': opts.writethumbnail,\n        'write_all_thumbnails': opts.write_all_thumbnails,\n        'writesubtitles': opts.writesubtitles,\n        'writeautomaticsub': opts.writeautomaticsub,\n        'allsubtitles': opts.allsubtitles,\n        'listsubtitles': opts.listsubtitles,\n        'subtitlesformat': opts.subtitlesformat,\n        'subtitleslangs': opts.subtitleslangs,\n        'matchtitle': decodeOption(opts.matchtitle),\n        'rejecttitle': decodeOption(opts.rejecttitle),\n        'max_downloads': opts.max_downloads,\n        'prefer_free_formats': opts.prefer_free_formats,\n        'verbose': opts.verbose,\n        'dump_intermediate_pages': opts.dump_intermediate_pages,\n        'write_pages': opts.write_pages,\n        'test': opts.test,\n        'keepvideo': opts.keepvideo,\n        'min_filesize': opts.min_filesize,\n        'max_filesize': opts.max_filesize,\n        'min_views': opts.min_views,\n        'max_views': opts.max_views,\n        'daterange': date,\n        'cachedir': opts.cachedir,\n        'youtube_print_sig_code': opts.youtube_print_sig_code,\n        'age_limit': opts.age_limit,\n        'download_archive': download_archive_fn,\n        'cookiefile': opts.cookiefile,\n        'nocheckcertificate': opts.no_check_certificate,\n        'prefer_insecure': opts.prefer_insecure,\n        'proxy': opts.proxy,\n        'socket_timeout': opts.socket_timeout,\n        'bidi_workaround': opts.bidi_workaround,\n        'debug_printtraffic': opts.debug_printtraffic,\n        'prefer_ffmpeg': opts.prefer_ffmpeg,\n        'include_ads': opts.include_ads,\n        'default_search': opts.default_search,\n        'youtube_include_dash_manifest': opts.youtube_include_dash_manifest,\n        'encoding': opts.encoding,\n        'extract_flat': opts.extract_flat,\n        'mark_watched': opts.mark_watched,\n        'merge_output_format': opts.merge_output_format,\n        'postprocessors': postprocessors,\n        'fixup': opts.fixup,\n        'source_address': opts.source_address,\n        'call_home': opts.call_home,\n        'sleep_interval': opts.sleep_interval,\n        'max_sleep_interval': opts.max_sleep_interval,\n        'external_downloader': opts.external_downloader,\n        'list_thumbnails': opts.list_thumbnails,\n        'playlist_items': opts.playlist_items,\n        'xattr_set_filesize': opts.xattr_set_filesize,\n        'match_filter': match_filter,\n        'no_color': opts.no_color,\n        'ffmpeg_location': opts.ffmpeg_location,\n        'hls_prefer_native': opts.hls_prefer_native,\n        'hls_use_mpegts': opts.hls_use_mpegts,\n        'external_downloader_args': external_downloader_args,\n        'postprocessor_args': postprocessor_args,\n        'cn_verification_proxy': opts.cn_verification_proxy,\n        'geo_verification_proxy': opts.geo_verification_proxy,\n        'config_location': opts.config_location,\n        'geo_bypass': opts.geo_bypass,\n        'geo_bypass_country': opts.geo_bypass_country,\n        # just for deprecation check\n        'autonumber': opts.autonumber if opts.autonumber is True else None,\n        'usetitle': opts.usetitle if opts.usetitle is True else None,\n    }\n\n    with YoutubeDL(ydl_opts) as ydl:\n        # Update version\n        if opts.update_self:\n            update_self(ydl.to_screen, opts.verbose, ydl._opener)\n\n        # Remove cache dir\n        if opts.rm_cachedir:\n            ydl.cache.remove()\n\n        # Maybe do nothing\n        if (len(all_urls) < 1) and (opts.load_info_filename is None):\n            if opts.update_self or opts.rm_cachedir:\n                sys.exit()\n\n            ydl.warn_if_short_id(sys.argv[1:] if argv is None else argv)\n            parser.error(\n                'You must provide at least one URL.\\n'\n                'Type youtube-dl --help to see a list of all options.')\n\n        try:\n            if opts.load_info_filename is not None:\n                retcode = ydl.download_with_info_file(expand_path(opts.load_info_filename))\n            else:\n                retcode = ydl.download(all_urls)\n        except MaxDownloadsReached:\n            ydl.to_screen('--max-download limit reached, aborting.')\n            retcode = 101\n\n    sys.exit(retcode)",
        "begin_line": 48,
        "end_line": 460,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.__init__.main#463",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.main(argv=None)",
        "snippet": "def main(argv=None):\n    try:\n        _real_main(argv)\n    except DownloadError:\n        sys.exit(1)\n    except SameFileError:\n        sys.exit('ERROR: fixed output name but more than one file to download')\n    except KeyboardInterrupt:\n        sys.exit('\\nERROR: Interrupted by user')",
        "begin_line": 463,
        "end_line": 471,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_ctr_decrypt#11",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_ctr_decrypt(data, key, counter)",
        "snippet": "def aes_ctr_decrypt(data, key, counter):\n    \"\"\"\n    Decrypt with aes in counter mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {instance} counter  Instance whose next_value function (@returns {int[]}  16-Byte block)\n                               returns the next counter block\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    for i in range(block_count):\n        counter_block = counter.next_value()\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        cipher_counter_block = aes_encrypt(counter_block, expanded_key)\n        decrypted_data += xor(block, cipher_counter_block)\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 11,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_cbc_decrypt#37",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_decrypt(data, key, iv)",
        "snippet": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data",
        "begin_line": 37,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_cbc_encrypt#63",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_encrypt(data, key, iv)",
        "snippet": "def aes_cbc_encrypt(data, key, iv):\n    \"\"\"\n    Encrypt with aes in CBC mode. Using PKCS#7 padding\n\n    @param {int[]} data        cleartext\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           encrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    encrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        remaining_length = BLOCK_SIZE_BYTES - len(block)\n        block += [remaining_length] * remaining_length\n        mixed_block = xor(block, previous_cipher_block)\n\n        encrypted_block = aes_encrypt(mixed_block, expanded_key)\n        encrypted_data += encrypted_block\n\n        previous_cipher_block = encrypted_block\n\n    return encrypted_data",
        "begin_line": 63,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.key_expansion#91",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_expansion(data)",
        "snippet": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n\n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key\n    \"\"\"\n    data = data[:]  # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n\n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3 if key_size_bytes == 32 else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n\n    return data",
        "begin_line": 91,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_encrypt#126",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_encrypt(data, expanded_key)",
        "snippet": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n\n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds + 1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 126,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_decrypt#147",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt(data, expanded_key)",
        "snippet": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n\n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 147,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.aes_decrypt_text#168",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter(object):\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext",
        "begin_line": 168,
        "end_line": 203,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.sub_bytes#281",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes(data)",
        "snippet": "def sub_bytes(data):\n    return [SBOX[x] for x in data]",
        "begin_line": 281,
        "end_line": 282,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.sub_bytes_inv#285",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes_inv(data)",
        "snippet": "def sub_bytes_inv(data):\n    return [SBOX_INV[x] for x in data]",
        "begin_line": 285,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.rotate#289",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rotate(data)",
        "snippet": "def rotate(data):\n    return data[1:] + [data[0]]",
        "begin_line": 289,
        "end_line": 290,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.key_schedule_core#293",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_schedule_core(data, rcon_iteration)",
        "snippet": "def key_schedule_core(data, rcon_iteration):\n    data = rotate(data)\n    data = sub_bytes(data)\n    data[0] = data[0] ^ RCON[rcon_iteration]\n\n    return data",
        "begin_line": 293,
        "end_line": 298,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.xor#301",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.xor(data1, data2)",
        "snippet": "def xor(data1, data2):\n    return [x ^ y for x, y in zip(data1, data2)]",
        "begin_line": 301,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.rijndael_mul#305",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rijndael_mul(a, b)",
        "snippet": "def rijndael_mul(a, b):\n    if(a == 0 or b == 0):\n        return 0\n    return RIJNDAEL_EXP_TABLE[(RIJNDAEL_LOG_TABLE[a] + RIJNDAEL_LOG_TABLE[b]) % 0xFF]",
        "begin_line": 305,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.mix_column#311",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_column(data, matrix)",
        "snippet": "def mix_column(data, matrix):\n    data_mixed = []\n    for row in range(4):\n        mixed = 0\n        for column in range(4):\n            # xor is (+) and (-)\n            mixed ^= rijndael_mul(data[column], matrix[row][column])\n        data_mixed.append(mixed)\n    return data_mixed",
        "begin_line": 311,
        "end_line": 319,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.mix_columns#322",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns(data, matrix=MIX_COLUMN_MATRIX)",
        "snippet": "def mix_columns(data, matrix=MIX_COLUMN_MATRIX):\n    data_mixed = []\n    for i in range(4):\n        column = data[i * 4: (i + 1) * 4]\n        data_mixed += mix_column(column, matrix)\n    return data_mixed",
        "begin_line": 322,
        "end_line": 327,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.mix_columns_inv#330",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns_inv(data)",
        "snippet": "def mix_columns_inv(data):\n    return mix_columns(data, MIX_COLUMN_MATRIX_INV)",
        "begin_line": 330,
        "end_line": 331,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.shift_rows#334",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows(data)",
        "snippet": "def shift_rows(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column + row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 334,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.shift_rows_inv#342",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows_inv(data)",
        "snippet": "def shift_rows_inv(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append(data[((column - row) & 0b11) * 4 + row])\n    return data_shifted",
        "begin_line": 342,
        "end_line": 347,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.aes.inc#350",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.inc(data)",
        "snippet": "def inc(data):\n    data = data[:]  # copy\n    for i in range(len(data) - 1, -1, -1):\n        if data[i] == 255:\n            data[i] = 0\n        else:\n            data[i] = data[i] + 1\n            break\n    return data",
        "begin_line": 350,
        "end_line": 358,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache.__init__#19",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.__init__(self, ydl)",
        "snippet": "    def __init__(self, ydl):\n        self._ydl = ydl",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache._get_root_dir#22",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_root_dir(self)",
        "snippet": "    def _get_root_dir(self):\n        res = self._ydl.params.get('cachedir')\n        if res is None:\n            cache_root = compat_getenv('XDG_CACHE_HOME', '~/.cache')\n            res = os.path.join(cache_root, 'youtube-dl')\n        return expand_path(res)",
        "begin_line": 22,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache._get_cache_fn#29",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_cache_fn(self, section, key, dtype)",
        "snippet": "    def _get_cache_fn(self, section, key, dtype):\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', section), \\\n            'invalid section %r' % section\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', key), 'invalid key %r' % key\n        return os.path.join(\n            self._get_root_dir(), section, '%s.%s' % (key, dtype))",
        "begin_line": 29,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache.enabled#37",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.enabled(self)",
        "snippet": "    def enabled(self):\n        return self._ydl.params.get('cachedir') is not False",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache.store#40",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.store(self, section, key, data, dtype='json')",
        "snippet": "    def store(self, section, key, data, dtype='json'):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return\n\n        fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                os.makedirs(os.path.dirname(fn))\n            except OSError as ose:\n                if ose.errno != errno.EEXIST:\n                    raise\n            write_json_file(data, fn)\n        except Exception:\n            tb = traceback.format_exc()\n            self._ydl.report_warning(\n                'Writing cache to %r failed: %s' % (fn, tb))",
        "begin_line": 40,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache.load#59",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.load(self, section, key, dtype='json', default=None)",
        "snippet": "    def load(self, section, key, dtype='json', default=None):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return default\n\n        cache_fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:\n                    return json.load(cachef)\n            except ValueError:\n                try:\n                    file_size = os.path.getsize(cache_fn)\n                except (OSError, IOError) as oe:\n                    file_size = str(oe)\n                self._ydl.report_warning(\n                    'Cache retrieval from %s failed (%s)' % (cache_fn, file_size))\n        except IOError:\n            pass  # No cache available\n\n        return default",
        "begin_line": 59,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.cache.Cache.remove#82",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.remove(self)",
        "snippet": "    def remove(self):\n        if not self.enabled:\n            self._ydl.to_screen('Cache is disabled (Did you combine --no-cache-dir and --rm-cache-dir?)')\n            return\n\n        cachedir = self._get_root_dir()\n        if not any((term in cachedir) for term in ('cache', 'tmp')):\n            raise Exception('Not removing directory %s - this does not look like a cache dir' % cachedir)\n\n        self._ydl.to_screen(\n            'Removing cache dir %s .' % cachedir, skip_eol=True)\n        if os.path.exists(cachedir):\n            self._ydl.to_screen('.', skip_eol=True)\n            shutil.rmtree(cachedir)\n        self._ydl.to_screen('.')",
        "begin_line": 82,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat._TreeBuilder.doctype#2504",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat._TreeBuilder",
        "signature": "youtube_dl.compat._TreeBuilder.doctype(self, name, pubid, system)",
        "snippet": "    def doctype(self, name, pubid, system):\n        pass",
        "begin_line": 2504,
        "end_line": 2505,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat.compat_etree_fromstring#2509",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_etree_fromstring(text)",
        "snippet": "    def compat_etree_fromstring(text):\n        return etree.XML(text, parser=etree.XMLParser(target=_TreeBuilder()))",
        "begin_line": 2509,
        "end_line": 2510,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat.compat_ord#2653",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_ord(c)",
        "snippet": "def compat_ord(c):\n    if type(c) is int:\n        return c\n    else:\n        return ord(c)",
        "begin_line": 2653,
        "end_line": 2657,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat.compat_setenv#2664",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_setenv(key, value, env=os.environ)",
        "snippet": "    def compat_setenv(key, value, env=os.environ):\n        env[key] = value",
        "begin_line": 2664,
        "end_line": 2665,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat.compat_print#2750",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.compat_print(s)",
        "snippet": "    def compat_print(s):\n        assert isinstance(s, compat_str)\n        print(s)",
        "begin_line": 2750,
        "end_line": 2752,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat._testfunc#2771",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat._testfunc(x)",
        "snippet": "    def _testfunc(x):\n        pass",
        "begin_line": 2771,
        "end_line": 2772,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.compat.workaround_optparse_bug9161#2815",
        "src_path": "youtube_dl/compat.py",
        "class_name": "youtube_dl.compat",
        "signature": "youtube_dl.compat.workaround_optparse_bug9161()",
        "snippet": "def workaround_optparse_bug9161():\n    op = optparse.OptionParser()\n    og = optparse.OptionGroup(op, 'foo')\n    try:\n        og.add_option('-t')\n    except TypeError:\n        real_add_option = optparse.OptionGroup.add_option\n\n        def _compat_add_option(self, *args, **kwargs):\n            enc = lambda v: (\n                v.encode('ascii', 'replace') if isinstance(v, compat_str)\n                else v)\n            bargs = [enc(a) for a in args]\n            bkwargs = dict(\n                (k, enc(v)) for k, v in kwargs.items())\n            return real_add_option(self, *bargs, **bkwargs)\n        optparse.OptionGroup.add_option = _compat_add_option",
        "begin_line": 2815,
        "end_line": 2831,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.__init__.get_suitable_downloader#32",
        "src_path": "youtube_dl/downloader/__init__.py",
        "class_name": "youtube_dl.downloader.__init__",
        "signature": "youtube_dl.downloader.__init__.get_suitable_downloader(info_dict, params={})",
        "snippet": "def get_suitable_downloader(info_dict, params={}):\n    \"\"\"Get the downloader class that can handle the info dict.\"\"\"\n    protocol = determine_protocol(info_dict)\n    info_dict['protocol'] = protocol\n\n    # if (info_dict.get('start_time') or info_dict.get('end_time')) and not info_dict.get('requested_formats') and FFmpegFD.can_download(info_dict):\n    #     return FFmpegFD\n\n    external_downloader = params.get('external_downloader')\n    if external_downloader is not None:\n        ed = get_external_downloader(external_downloader)\n        if ed.can_download(info_dict):\n            return ed\n\n    if protocol.startswith('m3u8') and info_dict.get('is_live'):\n        return FFmpegFD\n\n    if protocol == 'm3u8' and params.get('hls_prefer_native') is True:\n        return HlsFD\n\n    if protocol == 'm3u8_native' and params.get('hls_prefer_native') is False:\n        return FFmpegFD\n\n    return PROTOCOL_MAP.get(protocol, HttpFD)",
        "begin_line": 32,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.__init__#59",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.__init__(self, ydl, params)",
        "snippet": "    def __init__(self, ydl, params):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        self.ydl = ydl\n        self._progress_hooks = []\n        self.params = params\n        self.add_progress_hook(self.report_progress)",
        "begin_line": 59,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_seconds#67",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_seconds(seconds)",
        "snippet": "    def format_seconds(seconds):\n        (mins, secs) = divmod(seconds, 60)\n        (hours, mins) = divmod(mins, 60)\n        if hours > 99:\n            return '--:--:--'\n        if hours == 0:\n            return '%02d:%02d' % (mins, secs)\n        else:\n            return '%02d:%02d:%02d' % (hours, mins, secs)",
        "begin_line": 67,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_percent#78",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_percent(byte_counter, data_len)",
        "snippet": "    def calc_percent(byte_counter, data_len):\n        if data_len is None:\n            return None\n        return float(byte_counter) / float(data_len) * 100.0",
        "begin_line": 78,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_percent#84",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_percent(percent)",
        "snippet": "    def format_percent(percent):\n        if percent is None:\n            return '---.-%'\n        return '%6s' % ('%3.1f%%' % percent)",
        "begin_line": 84,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_eta#90",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_eta(start, now, total, current)",
        "snippet": "    def calc_eta(start, now, total, current):\n        if total is None:\n            return None\n        if now is None:\n            now = time.time()\n        dif = now - start\n        if current == 0 or dif < 0.001:  # One millisecond\n            return None\n        rate = float(current) / dif\n        return int((float(total) - float(current)) / rate)",
        "begin_line": 90,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_eta#102",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_eta(eta)",
        "snippet": "    def format_eta(eta):\n        if eta is None:\n            return '--:--'\n        return FileDownloader.format_seconds(eta)",
        "begin_line": 102,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_speed#108",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_speed(start, now, bytes)",
        "snippet": "    def calc_speed(start, now, bytes):\n        dif = now - start\n        if bytes == 0 or dif < 0.001:  # One millisecond\n            return None\n        return float(bytes) / dif",
        "begin_line": 108,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_speed#115",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_speed(speed)",
        "snippet": "    def format_speed(speed):\n        if speed is None:\n            return '%10s' % '---b/s'\n        return '%10s' % ('%s/s' % format_bytes(speed))",
        "begin_line": 115,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_retries#121",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_retries(retries)",
        "snippet": "    def format_retries(retries):\n        return 'inf' if retries == float('inf') else '%.0f' % retries",
        "begin_line": 121,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.best_block_size#125",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.best_block_size(elapsed_time, bytes)",
        "snippet": "    def best_block_size(elapsed_time, bytes):\n        new_min = max(bytes / 2.0, 1.0)\n        new_max = min(max(bytes * 2.0, 1.0), 4194304)  # Do not surpass 4 MB\n        if elapsed_time < 0.001:\n            return int(new_max)\n        rate = bytes / elapsed_time\n        if rate > new_max:\n            return int(new_max)\n        if rate < new_min:\n            return int(new_min)\n        return int(rate)",
        "begin_line": 125,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.parse_bytes#138",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.parse_bytes(bytestr)",
        "snippet": "    def parse_bytes(bytestr):\n        \"\"\"Parse a string indicating a byte quantity into an integer.\"\"\"\n        matchobj = re.match(r'(?i)^(\\d+(?:\\.\\d+)?)([kMGTPEZY]?)$', bytestr)\n        if matchobj is None:\n            return None\n        number = float(matchobj.group(1))\n        multiplier = 1024.0 ** 'bkmgtpezy'.index(matchobj.group(2).lower())\n        return int(round(number * multiplier))",
        "begin_line": 138,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_screen#147",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        self.ydl.to_screen(*args, **kargs)",
        "begin_line": 147,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_stderr#150",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        self.ydl.to_screen(message)",
        "begin_line": 150,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_console_title#153",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        self.ydl.to_console_title(message)",
        "begin_line": 153,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.trouble#156",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.trouble(self, *args, **kargs)",
        "snippet": "    def trouble(self, *args, **kargs):\n        self.ydl.trouble(*args, **kargs)",
        "begin_line": 156,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_warning#159",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_warning(self, *args, **kargs)",
        "snippet": "    def report_warning(self, *args, **kargs):\n        self.ydl.report_warning(*args, **kargs)",
        "begin_line": 159,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_error#162",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_error(self, *args, **kargs)",
        "snippet": "    def report_error(self, *args, **kargs):\n        self.ydl.report_error(*args, **kargs)",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.slow_down#165",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.slow_down(self, start_time, now, byte_counter)",
        "snippet": "    def slow_down(self, start_time, now, byte_counter):\n        \"\"\"Sleep if the download speed is over the rate limit.\"\"\"\n        rate_limit = self.params.get('ratelimit')\n        if rate_limit is None or byte_counter == 0:\n            return\n        if now is None:\n            now = time.time()\n        elapsed = now - start_time\n        if elapsed <= 0.0:\n            return\n        speed = float(byte_counter) / elapsed\n        if speed > rate_limit:\n            time.sleep(max((byte_counter // rate_limit) - elapsed, 0))",
        "begin_line": 165,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.temp_name#179",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.temp_name(self, filename)",
        "snippet": "    def temp_name(self, filename):\n        \"\"\"Returns a temporary filename for the given filename.\"\"\"\n        if self.params.get('nopart', False) or filename == '-' or \\\n                (os.path.exists(encodeFilename(filename)) and not os.path.isfile(encodeFilename(filename))):\n            return filename\n        return filename + '.part'",
        "begin_line": 179,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.undo_temp_name#186",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.undo_temp_name(self, filename)",
        "snippet": "    def undo_temp_name(self, filename):\n        if filename.endswith('.part'):\n            return filename[:-len('.part')]\n        return filename",
        "begin_line": 186,
        "end_line": 189,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.ytdl_filename#191",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.ytdl_filename(self, filename)",
        "snippet": "    def ytdl_filename(self, filename):\n        return filename + '.ytdl'",
        "begin_line": 191,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_rename#194",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_rename(self, old_filename, new_filename)",
        "snippet": "    def try_rename(self, old_filename, new_filename):\n        try:\n            if old_filename == new_filename:\n                return\n            os.rename(encodeFilename(old_filename), encodeFilename(new_filename))\n        except (IOError, OSError) as err:\n            self.report_error('unable to rename file: %s' % error_to_compat_str(err))",
        "begin_line": 194,
        "end_line": 200,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_utime#202",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_utime(self, filename, last_modified_hdr)",
        "snippet": "    def try_utime(self, filename, last_modified_hdr):\n        \"\"\"Try to set the last-modified time of the given file.\"\"\"\n        if last_modified_hdr is None:\n            return\n        if not os.path.isfile(encodeFilename(filename)):\n            return\n        timestr = last_modified_hdr\n        if timestr is None:\n            return\n        filetime = timeconvert(timestr)\n        if filetime is None:\n            return filetime\n        # Ignore obviously invalid dates\n        if filetime == 0:\n            return\n        try:\n            os.utime(filename, (time.time(), filetime))\n        except Exception:\n            pass\n        return filetime",
        "begin_line": 202,
        "end_line": 221,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_destination#223",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_destination(self, filename)",
        "snippet": "    def report_destination(self, filename):\n        \"\"\"Report destination filename.\"\"\"\n        self.to_screen('[download] Destination: ' + filename)",
        "begin_line": 223,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._report_progress_status#227",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._report_progress_status(self, msg, is_last_line=False)",
        "snippet": "    def _report_progress_status(self, msg, is_last_line=False):\n        fullmsg = '[download] ' + msg\n        if self.params.get('progress_with_newline', False):\n            self.to_screen(fullmsg)\n        else:\n            if compat_os_name == 'nt':\n                prev_len = getattr(self, '_report_progress_prev_line_length',\n                                   0)\n                if prev_len > len(fullmsg):\n                    fullmsg += ' ' * (prev_len - len(fullmsg))\n                self._report_progress_prev_line_length = len(fullmsg)\n                clear_line = '\\r'\n            else:\n                clear_line = ('\\r\\x1b[K' if sys.stderr.isatty() else '\\r')\n            self.to_screen(clear_line + fullmsg, skip_eol=not is_last_line)\n        self.to_console_title('youtube-dl ' + msg)",
        "begin_line": 227,
        "end_line": 242,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress#244",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress(self, s)",
        "snippet": "    def report_progress(self, s):\n        if s['status'] == 'finished':\n            if self.params.get('noprogress', False):\n                self.to_screen('[download] Download completed')\n            else:\n                s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n                if s.get('elapsed') is not None:\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '100%% of %(_total_bytes_str)s in %(_elapsed_str)s'\n                else:\n                    msg_template = '100%% of %(_total_bytes_str)s'\n                self._report_progress_status(\n                    msg_template % s, is_last_line=True)\n\n        if self.params.get('noprogress'):\n            return\n\n        if s['status'] != 'downloading':\n            return\n\n        if s.get('eta') is not None:\n            s['_eta_str'] = self.format_eta(s['eta'])\n        else:\n            s['_eta_str'] = 'Unknown ETA'\n\n        if s.get('total_bytes') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes'])\n        elif s.get('total_bytes_estimate') and s.get('downloaded_bytes') is not None:\n            s['_percent_str'] = self.format_percent(100 * s['downloaded_bytes'] / s['total_bytes_estimate'])\n        else:\n            if s.get('downloaded_bytes') == 0:\n                s['_percent_str'] = self.format_percent(0)\n            else:\n                s['_percent_str'] = 'Unknown %'\n\n        if s.get('speed') is not None:\n            s['_speed_str'] = self.format_speed(s['speed'])\n        else:\n            s['_speed_str'] = 'Unknown speed'\n\n        if s.get('total_bytes') is not None:\n            s['_total_bytes_str'] = format_bytes(s['total_bytes'])\n            msg_template = '%(_percent_str)s of %(_total_bytes_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        elif s.get('total_bytes_estimate') is not None:\n            s['_total_bytes_estimate_str'] = format_bytes(s['total_bytes_estimate'])\n            msg_template = '%(_percent_str)s of ~%(_total_bytes_estimate_str)s at %(_speed_str)s ETA %(_eta_str)s'\n        else:\n            if s.get('downloaded_bytes') is not None:\n                s['_downloaded_bytes_str'] = format_bytes(s['downloaded_bytes'])\n                if s.get('elapsed'):\n                    s['_elapsed_str'] = self.format_seconds(s['elapsed'])\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s (%(_elapsed_str)s)'\n                else:\n                    msg_template = '%(_downloaded_bytes_str)s at %(_speed_str)s'\n            else:\n                msg_template = '%(_percent_str)s % at %(_speed_str)s ETA %(_eta_str)s'\n\n        self._report_progress_status(msg_template % s)",
        "begin_line": 244,
        "end_line": 301,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte#303",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte(self, resume_len)",
        "snippet": "    def report_resuming_byte(self, resume_len):\n        \"\"\"Report attempt to resume at given byte.\"\"\"\n        self.to_screen('[download] Resuming download at byte %s' % resume_len)",
        "begin_line": 303,
        "end_line": 305,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_retry#307",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_retry(self, count, retries)",
        "snippet": "    def report_retry(self, count, retries):\n        \"\"\"Report retry in case of HTTP error 5xx\"\"\"\n        self.to_screen(\n            '[download] Got server HTTP error. Retrying (attempt %d of %s)...'\n            % (count, self.format_retries(retries)))",
        "begin_line": 307,
        "end_line": 311,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded#313",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 313,
        "end_line": 318,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume#320",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume(self)",
        "snippet": "    def report_unable_to_resume(self):\n        \"\"\"Report it was impossible to resume download.\"\"\"\n        self.to_screen('[download] Unable to resume')",
        "begin_line": 320,
        "end_line": 322,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.download#324",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.download(self, filename, info_dict)",
        "snippet": "    def download(self, filename, info_dict):\n        \"\"\"Download to a filename using the info from info_dict\n        Return True on success and False otherwise\n        \"\"\"\n\n        nooverwrites_and_exists = (\n            self.params.get('nooverwrites', False) and\n            os.path.exists(encodeFilename(filename))\n        )\n\n        if not hasattr(filename, 'write'):\n            continuedl_and_exists = (\n                self.params.get('continuedl', True) and\n                os.path.isfile(encodeFilename(filename)) and\n                not self.params.get('nopart', False)\n            )\n\n            # Check file already present\n            if filename != '-' and (nooverwrites_and_exists or continuedl_and_exists):\n                self.report_file_already_downloaded(filename)\n                self._hook_progress({\n                    'filename': filename,\n                    'status': 'finished',\n                    'total_bytes': os.path.getsize(encodeFilename(filename)),\n                })\n                return True\n\n        min_sleep_interval = self.params.get('sleep_interval')\n        if min_sleep_interval:\n            max_sleep_interval = self.params.get('max_sleep_interval', min_sleep_interval)\n            sleep_interval = random.uniform(min_sleep_interval, max_sleep_interval)\n            self.to_screen(\n                '[download] Sleeping %s seconds...' % (\n                    int(sleep_interval) if sleep_interval.is_integer()\n                    else '%.2f' % sleep_interval))\n            time.sleep(sleep_interval)\n\n        return self.real_download(filename, info_dict)",
        "begin_line": 324,
        "end_line": 361,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.real_download#363",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        \"\"\"Real download process. Redefine in subclasses.\"\"\"\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 363,
        "end_line": 365,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._hook_progress#367",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._hook_progress(self, status)",
        "snippet": "    def _hook_progress(self, status):\n        for ph in self._progress_hooks:\n            ph(status)",
        "begin_line": 367,
        "end_line": 369,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.add_progress_hook#371",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        # See YoutubeDl.py (search for progress_hooks) for a description of\n        # this interface\n        self._progress_hooks.append(ph)",
        "begin_line": 371,
        "end_line": 374,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._debug_cmd#376",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._debug_cmd(self, args, exe=None)",
        "snippet": "    def _debug_cmd(self, args, exe=None):\n        if not self.params.get('verbose', False):\n            return\n\n        str_args = [decodeArgument(a) for a in args]\n\n        if exe is None:\n            exe = os.path.basename(str_args[0])\n\n        self.to_screen('[debug] %s command line: %s' % (\n            exe, shell_quote(str_args)))",
        "begin_line": 376,
        "end_line": 386,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.dash.DashSegmentsFD.real_download#15",
        "src_path": "youtube_dl/downloader/dash.py",
        "class_name": "youtube_dl.downloader.dash.DashSegmentsFD",
        "signature": "youtube_dl.downloader.dash.DashSegmentsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        fragment_base_url = info_dict.get('fragment_base_url')\n        fragments = info_dict['fragments'][:1] if self.params.get(\n            'test', False) else info_dict['fragments']\n\n        ctx = {\n            'filename': filename,\n            'total_frags': len(fragments),\n        }\n\n        self._prepare_and_start_frag_download(ctx)\n\n        fragment_retries = self.params.get('fragment_retries', 0)\n        skip_unavailable_fragments = self.params.get('skip_unavailable_fragments', True)\n\n        frag_index = 0\n        for i, fragment in enumerate(fragments):\n            frag_index += 1\n            if frag_index <= ctx['fragment_index']:\n                continue\n            # In DASH, the first segment contains necessary headers to\n            # generate a valid MP4 file, so always abort for the first segment\n            fatal = i == 0 or not skip_unavailable_fragments\n            count = 0\n            while count <= fragment_retries:\n                try:\n                    fragment_url = fragment.get('url')\n                    if not fragment_url:\n                        assert fragment_base_url\n                        fragment_url = urljoin(fragment_base_url, fragment['path'])\n                    success, frag_content = self._download_fragment(ctx, fragment_url, info_dict)\n                    if not success:\n                        return False\n                    self._append_fragment(ctx, frag_content)\n                    break\n                except compat_urllib_error.HTTPError as err:\n                    # YouTube may often return 404 HTTP error for a fragment causing the\n                    # whole download to fail. However if the same fragment is immediately\n                    # retried with the same request data this usually succeeds (1-2 attemps\n                    # is usually enough) thus allowing to download the whole file successfully.\n                    # To be future-proof we will retry all fragments that fail with any\n                    # HTTP error.\n                    count += 1\n                    if count <= fragment_retries:\n                        self.report_retry_fragment(err, frag_index, count, fragment_retries)\n            if count > fragment_retries:\n                if not fatal:\n                    self.report_skip_fragment(frag_index)\n                    continue\n                self.report_error('giving up after %s fragment retries' % fragment_retries)\n                return False\n\n        self._finish_frag_download(ctx)\n\n        return True",
        "begin_line": 15,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.real_download#28",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        try:\n            retval = self._call_downloader(tmpfilename, info_dict)\n        except KeyboardInterrupt:\n            if not info_dict.get('is_live'):\n                raise\n            # Live stream downloading cancellation should be considered as\n            # correct and expected termination thus all postprocessing\n            # should take place\n            retval = 0\n            self.to_screen('[%s] Interrupted by user' % self.get_basename())\n\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('\\r[%s] Downloaded %s bytes' % (self.get_basename(), fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('%s exited with code %d' % (\n                self.get_basename(), retval))\n            return False",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.get_basename#61",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.get_basename(cls)",
        "snippet": "    def get_basename(cls):\n        return cls.__name__[:-2].lower()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.exe#65",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.exe(self)",
        "snippet": "    def exe(self):\n        return self.params.get('external_downloader')",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.available#69",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.available(cls)",
        "snippet": "    def available(cls):\n        return check_executable(cls.get_basename(), [cls.AVAILABLE_OPT])",
        "begin_line": 69,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.supports#73",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.supports(cls, info_dict)",
        "snippet": "    def supports(cls, info_dict):\n        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps')",
        "begin_line": 73,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD.can_download#77",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD.can_download(cls, info_dict)",
        "snippet": "    def can_download(cls, info_dict):\n        return cls.available() and cls.supports(info_dict)",
        "begin_line": 77,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._option#80",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._option(self, command_option, param)",
        "snippet": "    def _option(self, command_option, param):\n        return cli_option(self.params, command_option, param)",
        "begin_line": 80,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._bool_option#83",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._bool_option(self, command_option, param, true_value='true', false_value='false', separator=None)",
        "snippet": "    def _bool_option(self, command_option, param, true_value='true', false_value='false', separator=None):\n        return cli_bool_option(self.params, command_option, param, true_value, false_value, separator)",
        "begin_line": 83,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._valueless_option#86",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._valueless_option(self, command_option, param, expected_value=True)",
        "snippet": "    def _valueless_option(self, command_option, param, expected_value=True):\n        return cli_valueless_option(self.params, command_option, param, expected_value)",
        "begin_line": 86,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._configuration_args#89",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._configuration_args(self, default=[])",
        "snippet": "    def _configuration_args(self, default=[]):\n        return cli_configuration_args(self.params, 'external_downloader_args', default)",
        "begin_line": 89,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.ExternalFD._call_downloader#92",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.ExternalFD",
        "signature": "youtube_dl.downloader.external.ExternalFD._call_downloader(self, tmpfilename, info_dict)",
        "snippet": "    def _call_downloader(self, tmpfilename, info_dict):\n        \"\"\" Either overwrite this or implement _make_cmd \"\"\"\n        cmd = [encodeArgument(a) for a in self._make_cmd(tmpfilename, info_dict)]\n\n        self._debug_cmd(cmd)\n\n        p = subprocess.Popen(\n            cmd, stderr=subprocess.PIPE)\n        _, stderr = p.communicate()\n        if p.returncode != 0:\n            self.to_stderr(stderr.decode('utf-8', 'replace'))\n        return p.returncode",
        "begin_line": 92,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.CurlFD._make_cmd#109",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.CurlFD",
        "signature": "youtube_dl.downloader.external.CurlFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '--location', '-o', tmpfilename]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._bool_option('--continue-at', 'continuedl', '-', '0')\n        cmd += self._valueless_option('--silent', 'noprogress')\n        cmd += self._valueless_option('--verbose', 'verbose')\n        cmd += self._option('--limit-rate', 'ratelimit')\n        cmd += self._option('--retry', 'retries')\n        cmd += self._option('--max-filesize', 'max_filesize')\n        cmd += self._option('--interface', 'source_address')\n        cmd += self._option('--proxy', 'proxy')\n        cmd += self._valueless_option('--insecure', 'nocheckcertificate')\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 109,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.CurlFD._call_downloader#126",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.CurlFD",
        "signature": "youtube_dl.downloader.external.CurlFD._call_downloader(self, tmpfilename, info_dict)",
        "snippet": "    def _call_downloader(self, tmpfilename, info_dict):\n        cmd = [encodeArgument(a) for a in self._make_cmd(tmpfilename, info_dict)]\n\n        self._debug_cmd(cmd)\n\n        # curl writes the progress to stderr so don't capture it.\n        p = subprocess.Popen(cmd)\n        p.communicate()\n        return p.returncode",
        "begin_line": 126,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.AxelFD._make_cmd#140",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.AxelFD",
        "signature": "youtube_dl.downloader.external.AxelFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-o', tmpfilename]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['-H', '%s: %s' % (key, val)]\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 140,
        "end_line": 146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.WgetFD._make_cmd#152",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.WgetFD",
        "signature": "youtube_dl.downloader.external.WgetFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-O', tmpfilename, '-nv', '--no-cookies']\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._option('--bind-address', 'source_address')\n        cmd += self._option('--proxy', 'proxy')\n        cmd += self._valueless_option('--no-check-certificate', 'nocheckcertificate')\n        cmd += self._configuration_args()\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 152,
        "end_line": 161,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.Aria2cFD._make_cmd#167",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.Aria2cFD",
        "signature": "youtube_dl.downloader.external.Aria2cFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = [self.exe, '-c']\n        cmd += self._configuration_args([\n            '--min-split-size', '1M', '--max-connection-per-server', '4'])\n        dn = os.path.dirname(tmpfilename)\n        if dn:\n            cmd += ['--dir', dn]\n        cmd += ['--out', os.path.basename(tmpfilename)]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['--header', '%s: %s' % (key, val)]\n        cmd += self._option('--interface', 'source_address')\n        cmd += self._option('--all-proxy', 'proxy')\n        cmd += self._bool_option('--check-certificate', 'nocheckcertificate', 'false', 'true', '=')\n        cmd += ['--', info_dict['url']]\n        return cmd",
        "begin_line": 167,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.HttpieFD.available#186",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.HttpieFD",
        "signature": "youtube_dl.downloader.external.HttpieFD.available(cls)",
        "snippet": "    def available(cls):\n        return check_executable('http', ['--version'])",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.HttpieFD._make_cmd#189",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.HttpieFD",
        "signature": "youtube_dl.downloader.external.HttpieFD._make_cmd(self, tmpfilename, info_dict)",
        "snippet": "    def _make_cmd(self, tmpfilename, info_dict):\n        cmd = ['http', '--download', '--output', tmpfilename, info_dict['url']]\n        for key, val in info_dict['http_headers'].items():\n            cmd += ['%s:%s' % (key, val)]\n        return cmd",
        "begin_line": 189,
        "end_line": 193,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.FFmpegFD.supports#198",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.FFmpegFD",
        "signature": "youtube_dl.downloader.external.FFmpegFD.supports(cls, info_dict)",
        "snippet": "    def supports(cls, info_dict):\n        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps', 'm3u8', 'rtsp', 'rtmp', 'mms')",
        "begin_line": 198,
        "end_line": 199,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.FFmpegFD.available#202",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.FFmpegFD",
        "signature": "youtube_dl.downloader.external.FFmpegFD.available(cls)",
        "snippet": "    def available(cls):\n        return FFmpegPostProcessor().available",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.FFmpegFD._call_downloader#205",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external.FFmpegFD",
        "signature": "youtube_dl.downloader.external.FFmpegFD._call_downloader(self, tmpfilename, info_dict)",
        "snippet": "    def _call_downloader(self, tmpfilename, info_dict):\n        url = info_dict['url']\n        ffpp = FFmpegPostProcessor(downloader=self)\n        if not ffpp.available:\n            self.report_error('m3u8 download detected but ffmpeg or avconv could not be found. Please install one.')\n            return False\n        ffpp.check_version()\n\n        args = [ffpp.executable, '-y']\n\n        for log_level in ('quiet', 'verbose'):\n            if self.params.get(log_level, False):\n                args += ['-loglevel', log_level]\n                break\n\n        seekable = info_dict.get('_seekable')\n        if seekable is not None:\n            # setting -seekable prevents ffmpeg from guessing if the server\n            # supports seeking(by adding the header `Range: bytes=0-`), which\n            # can cause problems in some cases\n            # https://github.com/rg3/youtube-dl/issues/11800#issuecomment-275037127\n            # http://trac.ffmpeg.org/ticket/6125#comment:10\n            args += ['-seekable', '1' if seekable else '0']\n\n        args += self._configuration_args()\n\n        # start_time = info_dict.get('start_time') or 0\n        # if start_time:\n        #     args += ['-ss', compat_str(start_time)]\n        # end_time = info_dict.get('end_time')\n        # if end_time:\n        #     args += ['-t', compat_str(end_time - start_time)]\n\n        if info_dict['http_headers'] and re.match(r'^https?://', url):\n            # Trailing \\r\\n after each HTTP header is important to prevent warning from ffmpeg/avconv:\n            # [http @ 00000000003d2fa0] No trailing CRLF found in HTTP header.\n            headers = handle_youtubedl_headers(info_dict['http_headers'])\n            args += [\n                '-headers',\n                ''.join('%s: %s\\r\\n' % (key, val) for key, val in headers.items())]\n\n        env = None\n        proxy = self.params.get('proxy')\n        if proxy:\n            if not re.match(r'^[\\da-zA-Z]+://', proxy):\n                proxy = 'http://%s' % proxy\n\n            if proxy.startswith('socks'):\n                self.report_warning(\n                    '%s does not support SOCKS proxies. Downloading is likely to fail. '\n                    'Consider adding --hls-prefer-native to your command.' % self.get_basename())\n\n            # Since December 2015 ffmpeg supports -http_proxy option (see\n            # http://git.videolan.org/?p=ffmpeg.git;a=commit;h=b4eb1f29ebddd60c41a2eb39f5af701e38e0d3fd)\n            # We could switch to the following code if we are able to detect version properly\n            # args += ['-http_proxy', proxy]\n            env = os.environ.copy()\n            compat_setenv('HTTP_PROXY', proxy, env=env)\n            compat_setenv('http_proxy', proxy, env=env)\n\n        protocol = info_dict.get('protocol')\n\n        if protocol == 'rtmp':\n            player_url = info_dict.get('player_url')\n            page_url = info_dict.get('page_url')\n            app = info_dict.get('app')\n            play_path = info_dict.get('play_path')\n            tc_url = info_dict.get('tc_url')\n            flash_version = info_dict.get('flash_version')\n            live = info_dict.get('rtmp_live', False)\n            if player_url is not None:\n                args += ['-rtmp_swfverify', player_url]\n            if page_url is not None:\n                args += ['-rtmp_pageurl', page_url]\n            if app is not None:\n                args += ['-rtmp_app', app]\n            if play_path is not None:\n                args += ['-rtmp_playpath', play_path]\n            if tc_url is not None:\n                args += ['-rtmp_tcurl', tc_url]\n            if flash_version is not None:\n                args += ['-rtmp_flashver', flash_version]\n            if live:\n                args += ['-rtmp_live', 'live']\n\n        args += ['-i', url, '-c', 'copy']\n\n        if self.params.get('test', False):\n            args += ['-fs', compat_str(self._TEST_FILE_SIZE)]\n\n        if protocol in ('m3u8', 'm3u8_native'):\n            if self.params.get('hls_use_mpegts', False) or tmpfilename == '-':\n                args += ['-f', 'mpegts']\n            else:\n                args += ['-f', 'mp4']\n                if (ffpp.basename == 'ffmpeg' and is_outdated_version(ffpp._versions['ffmpeg'], '3.2', False)) and (not info_dict.get('acodec') or info_dict['acodec'].split('.')[0] in ('aac', 'mp4a')):\n                    args += ['-bsf:a', 'aac_adtstoasc']\n        elif protocol == 'rtmp':\n            args += ['-f', 'flv']\n        else:\n            args += ['-f', EXT_TO_OUT_FORMATS.get(info_dict['ext'], info_dict['ext'])]\n\n        args = [encodeArgument(opt) for opt in args]\n        args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))\n\n        self._debug_cmd(args)\n\n        proc = subprocess.Popen(args, stdin=subprocess.PIPE, env=env)\n        try:\n            retval = proc.wait()\n        except KeyboardInterrupt:\n            # subprocces.run would send the SIGKILL signal to ffmpeg and the\n            # mp4 file couldn't be played, but if we ask ffmpeg to quit it\n            # produces a file that is playable (this is mostly useful for live\n            # streams). Note that Windows is not affected and produces playable\n            # files (see https://github.com/rg3/youtube-dl/issues/8300).\n            if sys.platform != 'win32':\n                proc.communicate(b'q')\n            raise\n        return retval",
        "begin_line": 205,
        "end_line": 324,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.list_external_downloaders#338",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external",
        "signature": "youtube_dl.downloader.external.list_external_downloaders()",
        "snippet": "def list_external_downloaders():\n    return sorted(_BY_NAME.keys())",
        "begin_line": 338,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.external.get_external_downloader#342",
        "src_path": "youtube_dl/downloader/external.py",
        "class_name": "youtube_dl.downloader.external",
        "signature": "youtube_dl.downloader.external.get_external_downloader(external_downloader)",
        "snippet": "def get_external_downloader(external_downloader):\n    \"\"\" Given the name of the executable, see whether we support the given\n        downloader . \"\"\"\n    # Drop .exe extension on Windows\n    bn = os.path.splitext(os.path.basename(external_downloader))[0]\n    return _BY_NAME[bn]",
        "begin_line": 342,
        "end_line": 347,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_bytes#33",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_bytes(self, n)",
        "snippet": "    def read_bytes(self, n):\n        data = self.read(n)\n        if len(data) < n:\n            raise DataTruncatedError(\n                'FlvReader error: need %d bytes while only %d bytes got' % (\n                    n, len(data)))\n        return data",
        "begin_line": 33,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long#42",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long(self)",
        "snippet": "    def read_unsigned_long_long(self):\n        return compat_struct_unpack('!Q', self.read_bytes(8))[0]",
        "begin_line": 42,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int#45",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int(self)",
        "snippet": "    def read_unsigned_int(self):\n        return compat_struct_unpack('!I', self.read_bytes(4))[0]",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char#48",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char(self)",
        "snippet": "    def read_unsigned_char(self):\n        return compat_struct_unpack('!B', self.read_bytes(1))[0]",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_string#51",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_string(self)",
        "snippet": "    def read_string(self):\n        res = b''\n        while True:\n            char = self.read_bytes(1)\n            if char == b'\\x00':\n                break\n            res += char\n        return res",
        "begin_line": 51,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_box_info#60",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_box_info(self)",
        "snippet": "    def read_box_info(self):\n        \"\"\"\n        Read a box and return the info as a tuple: (box_size, box_type, box_data)\n        \"\"\"\n        real_size = size = self.read_unsigned_int()\n        box_type = self.read_bytes(4)\n        header_end = 8\n        if size == 1:\n            real_size = self.read_unsigned_long_long()\n            header_end = 16\n        return real_size, box_type, self.read_bytes(real_size - header_end)",
        "begin_line": 60,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_asrt#72",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_asrt(self)",
        "snippet": "    def read_asrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read_bytes(3)\n        quality_entry_count = self.read_unsigned_char()\n        # QualityEntryCount\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        segment_run_count = self.read_unsigned_int()\n        segments = []\n        for i in range(segment_run_count):\n            first_segment = self.read_unsigned_int()\n            fragments_per_segment = self.read_unsigned_int()\n            segments.append((first_segment, fragments_per_segment))\n\n        return {\n            'segment_run': segments,\n        }",
        "begin_line": 72,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_afrt#93",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_afrt(self)",
        "snippet": "    def read_afrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read_bytes(3)\n        # time scale\n        self.read_unsigned_int()\n\n        quality_entry_count = self.read_unsigned_char()\n        # QualitySegmentUrlModifiers\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        fragments_count = self.read_unsigned_int()\n        fragments = []\n        for i in range(fragments_count):\n            first = self.read_unsigned_int()\n            first_ts = self.read_unsigned_long_long()\n            duration = self.read_unsigned_int()\n            if duration == 0:\n                discontinuity_indicator = self.read_unsigned_char()\n            else:\n                discontinuity_indicator = None\n            fragments.append({\n                'first': first,\n                'ts': first_ts,\n                'duration': duration,\n                'discontinuity_indicator': discontinuity_indicator,\n            })\n\n        return {\n            'fragments': fragments,\n        }",
        "begin_line": 93,
        "end_line": 125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_abst#127",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_abst(self)",
        "snippet": "    def read_abst(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read_bytes(3)\n\n        self.read_unsigned_int()  # BootstrapinfoVersion\n        # Profile,Live,Update,Reserved\n        flags = self.read_unsigned_char()\n        live = flags & 0x20 != 0\n        # time scale\n        self.read_unsigned_int()\n        # CurrentMediaTime\n        self.read_unsigned_long_long()\n        # SmpteTimeCodeOffset\n        self.read_unsigned_long_long()\n\n        self.read_string()  # MovieIdentifier\n        server_count = self.read_unsigned_char()\n        # ServerEntryTable\n        for i in range(server_count):\n            self.read_string()\n        quality_count = self.read_unsigned_char()\n        # QualityEntryTable\n        for i in range(quality_count):\n            self.read_string()\n        # DrmData\n        self.read_string()\n        # MetaData\n        self.read_string()\n\n        segments_count = self.read_unsigned_char()\n        segments = []\n        for i in range(segments_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'asrt'\n            segment = FlvReader(box_data).read_asrt()\n            segments.append(segment)\n        fragments_run_count = self.read_unsigned_char()\n        fragments = []\n        for i in range(fragments_run_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'afrt'\n            fragments.append(FlvReader(box_data).read_afrt())\n\n        return {\n            'segments': segments,\n            'fragments': fragments,\n            'live': live,\n        }",
        "begin_line": 127,
        "end_line": 176,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info#178",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info(self)",
        "snippet": "    def read_bootstrap_info(self):\n        total_size, box_type, box_data = self.read_box_info()\n        assert box_type == b'abst'\n        return FlvReader(box_data).read_abst()",
        "begin_line": 178,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.read_bootstrap_info#184",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.read_bootstrap_info(bootstrap_bytes)",
        "snippet": "def read_bootstrap_info(bootstrap_bytes):\n    return FlvReader(bootstrap_bytes).read_bootstrap_info()",
        "begin_line": 184,
        "end_line": 185,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.build_fragments_list#188",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.build_fragments_list(boot_info)",
        "snippet": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n    res = []\n    segment_run_table = boot_info['segments'][0]\n    fragment_run_entry_table = boot_info['fragments'][0]['fragments']\n    first_frag_number = fragment_run_entry_table[0]['first']\n    fragments_counter = itertools.count(first_frag_number)\n    for segment, fragments_count in segment_run_table['segment_run']:\n        # In some live HDS streams (for example Rai), `fragments_count` is\n        # abnormal and causing out-of-memory errors. It's OK to change the\n        # number of fragments for live streams as they are updated periodically\n        if fragments_count == 4294967295 and boot_info['live']:\n            fragments_count = 2\n        for _ in range(fragments_count):\n            res.append((segment, next(fragments_counter)))\n\n    if boot_info['live']:\n        res = res[-2:]\n\n    return res",
        "begin_line": 188,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.write_unsigned_int#210",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_unsigned_int(stream, val)",
        "snippet": "def write_unsigned_int(stream, val):\n    stream.write(compat_struct_pack('!I', val))",
        "begin_line": 210,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.write_unsigned_int_24#214",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_unsigned_int_24(stream, val)",
        "snippet": "def write_unsigned_int_24(stream, val):\n    stream.write(compat_struct_pack('!I', val)[1:])",
        "begin_line": 214,
        "end_line": 215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.write_flv_header#218",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_flv_header(stream)",
        "snippet": "def write_flv_header(stream):\n    \"\"\"Writes the FLV header to stream\"\"\"\n    # FLV header\n    stream.write(b'FLV\\x01')\n    stream.write(b'\\x05')\n    stream.write(b'\\x00\\x00\\x00\\x09')\n    stream.write(b'\\x00\\x00\\x00\\x00')",
        "begin_line": 218,
        "end_line": 224,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.write_metadata_tag#227",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_metadata_tag(stream, metadata)",
        "snippet": "def write_metadata_tag(stream, metadata):\n    \"\"\"Writes optional metadata tag to stream\"\"\"\n    SCRIPT_TAG = b'\\x12'\n    FLV_TAG_HEADER_LEN = 11\n\n    if metadata:\n        stream.write(SCRIPT_TAG)\n        write_unsigned_int_24(stream, len(metadata))\n        stream.write(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n        stream.write(metadata)\n        write_unsigned_int(stream, FLV_TAG_HEADER_LEN + len(metadata))",
        "begin_line": 227,
        "end_line": 237,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.remove_encrypted_media#240",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.remove_encrypted_media(media)",
        "snippet": "def remove_encrypted_media(media):\n    return list(filter(lambda e: 'drmAdditionalHeaderId' not in e.attrib and\n                                 'drmAdditionalHeaderSetId' not in e.attrib,\n                       media))",
        "begin_line": 240,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m._add_ns#246",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m._add_ns(prop)",
        "snippet": "def _add_ns(prop):\n    return '{http://ns.adobe.com/f4m/1.0}%s' % prop",
        "begin_line": 246,
        "end_line": 247,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._get_unencrypted_media#257",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._get_unencrypted_media(self, doc)",
        "snippet": "    def _get_unencrypted_media(self, doc):\n        media = doc.findall(_add_ns('media'))\n        if not media:\n            self.report_error('No media found')\n        for e in (doc.findall(_add_ns('drmAdditionalHeader')) +\n                  doc.findall(_add_ns('drmAdditionalHeaderSet'))):\n            # If id attribute is missing it's valid for all media nodes\n            # without drmAdditionalHeaderId or drmAdditionalHeaderSetId attribute\n            if 'id' not in e.attrib:\n                self.report_error('Missing ID in f4m DRM')\n        media = remove_encrypted_media(media)\n        if not media:\n            self.report_error('Unsupported DRM')\n        return media",
        "begin_line": 257,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._get_bootstrap_from_url#272",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._get_bootstrap_from_url(self, bootstrap_url)",
        "snippet": "    def _get_bootstrap_from_url(self, bootstrap_url):\n        bootstrap = self.ydl.urlopen(bootstrap_url).read()\n        return read_bootstrap_info(bootstrap)",
        "begin_line": 272,
        "end_line": 274,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._update_live_fragments#276",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._update_live_fragments(self, bootstrap_url, latest_fragment)",
        "snippet": "    def _update_live_fragments(self, bootstrap_url, latest_fragment):\n        fragments_list = []\n        retries = 30\n        while (not fragments_list) and (retries > 0):\n            boot_info = self._get_bootstrap_from_url(bootstrap_url)\n            fragments_list = build_fragments_list(boot_info)\n            fragments_list = [f for f in fragments_list if f[1] > latest_fragment]\n            if not fragments_list:\n                # Retry after a while\n                time.sleep(5.0)\n                retries -= 1\n\n        if not fragments_list:\n            self.report_error('Failed to update fragments')\n\n        return fragments_list",
        "begin_line": 276,
        "end_line": 291,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD._parse_bootstrap_node#293",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD._parse_bootstrap_node(self, node, base_url)",
        "snippet": "    def _parse_bootstrap_node(self, node, base_url):\n        # Sometimes non empty inline bootstrap info can be specified along\n        # with bootstrap url attribute (e.g. dummy inline bootstrap info\n        # contains whitespace characters in [1]). We will prefer bootstrap\n        # url over inline bootstrap info when present.\n        # 1. http://live-1-1.rutube.ru/stream/1024/HDS/SD/C2NKsS85HQNckgn5HdEmOQ/1454167650/S-s604419906/move/four/dirs/upper/1024-576p.f4m\n        bootstrap_url = node.get('url')\n        if bootstrap_url:\n            bootstrap_url = compat_urlparse.urljoin(\n                base_url, bootstrap_url)\n            boot_info = self._get_bootstrap_from_url(bootstrap_url)\n        else:\n            bootstrap_url = None\n            bootstrap = base64.b64decode(node.text.encode('ascii'))\n            boot_info = read_bootstrap_info(bootstrap)\n        return boot_info, bootstrap_url",
        "begin_line": 293,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD.real_download#310",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        requested_bitrate = info_dict.get('tbr')\n        self.to_screen('[%s] Downloading f4m manifest' % self.FD_NAME)\n\n        urlh = self.ydl.urlopen(self._prepare_url(info_dict, man_url))\n        man_url = urlh.geturl()\n        # Some manifests may be malformed, e.g. prosiebensat1 generated manifests\n        # (see https://github.com/rg3/youtube-dl/issues/6215#issuecomment-121704244\n        # and https://github.com/rg3/youtube-dl/issues/7823)\n        manifest = fix_xml_ampersands(urlh.read().decode('utf-8', 'ignore')).strip()\n\n        doc = compat_etree_fromstring(manifest)\n        formats = [(int(f.attrib.get('bitrate', -1)), f)\n                   for f in self._get_unencrypted_media(doc)]\n        if requested_bitrate is None or len(formats) == 1:\n            # get the best format\n            formats = sorted(formats, key=lambda f: f[0])\n            rate, media = formats[-1]\n        else:\n            rate, media = list(filter(\n                lambda f: int(f[0]) == requested_bitrate, formats))[0]\n\n        base_url = compat_urlparse.urljoin(man_url, media.attrib['url'])\n        bootstrap_node = doc.find(_add_ns('bootstrapInfo'))\n        # From Adobe F4M 3.0 spec:\n        # The <baseURL> element SHALL be the base URL for all relative\n        # (HTTP-based) URLs in the manifest. If <baseURL> is not present, said\n        # URLs should be relative to the location of the containing document.\n        boot_info, bootstrap_url = self._parse_bootstrap_node(bootstrap_node, man_url)\n        live = boot_info['live']\n        metadata_node = media.find(_add_ns('metadata'))\n        if metadata_node is not None:\n            metadata = base64.b64decode(metadata_node.text.encode('ascii'))\n        else:\n            metadata = None\n\n        fragments_list = build_fragments_list(boot_info)\n        test = self.params.get('test', False)\n        if test:\n            # We only download the first fragment\n            fragments_list = fragments_list[:1]\n        total_frags = len(fragments_list)\n        # For some akamai manifests we'll need to add a query to the fragment url\n        akamai_pv = xpath_text(doc, _add_ns('pv-2.0'))\n\n        ctx = {\n            'filename': filename,\n            'total_frags': total_frags,\n            'live': live,\n        }\n\n        self._prepare_frag_download(ctx)\n\n        dest_stream = ctx['dest_stream']\n\n        if ctx['complete_frags_downloaded_bytes'] == 0:\n            write_flv_header(dest_stream)\n            if not live:\n                write_metadata_tag(dest_stream, metadata)\n\n        base_url_parsed = compat_urllib_parse_urlparse(base_url)\n\n        self._start_frag_download(ctx)\n\n        frag_index = 0\n        while fragments_list:\n            seg_i, frag_i = fragments_list.pop(0)\n            frag_index += 1\n            if frag_index <= ctx['fragment_index']:\n                continue\n            name = 'Seg%d-Frag%d' % (seg_i, frag_i)\n            query = []\n            if base_url_parsed.query:\n                query.append(base_url_parsed.query)\n            if akamai_pv:\n                query.append(akamai_pv.strip(';'))\n            if info_dict.get('extra_param_to_segment_url'):\n                query.append(info_dict['extra_param_to_segment_url'])\n            url_parsed = base_url_parsed._replace(path=base_url_parsed.path + name, query='&'.join(query))\n            try:\n                success, down_data = self._download_fragment(ctx, url_parsed.geturl(), info_dict)\n                if not success:\n                    return False\n                reader = FlvReader(down_data)\n                while True:\n                    try:\n                        _, box_type, box_data = reader.read_box_info()\n                    except DataTruncatedError:\n                        if test:\n                            # In tests, segments may be truncated, and thus\n                            # FlvReader may not be able to parse the whole\n                            # chunk. If so, write the segment as is\n                            # See https://github.com/rg3/youtube-dl/issues/9214\n                            dest_stream.write(down_data)\n                            break\n                        raise\n                    if box_type == b'mdat':\n                        self._append_fragment(ctx, box_data)\n                        break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if live and (err.code == 404 or err.code == 410):\n                    # We didn't keep up with the live window. Continue\n                    # with the next available fragment.\n                    msg = 'Fragment %d unavailable' % frag_i\n                    self.report_warning(msg)\n                    fragments_list = []\n                else:\n                    raise\n\n            if not fragments_list and not test and live and bootstrap_url:\n                fragments_list = self._update_live_fragments(bootstrap_url, frag_i)\n                total_frags += len(fragments_list)\n                if fragments_list and (fragments_list[0][1] > frag_i + 1):\n                    msg = 'Missed %d fragments' % (fragments_list[0][1] - (frag_i + 1))\n                    self.report_warning(msg)\n\n        self._finish_frag_download(ctx)\n\n        return True",
        "begin_line": 310,
        "end_line": 429,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.HttpQuietDownloader.to_screen#18",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.HttpQuietDownloader",
        "signature": "youtube_dl.downloader.fragment.HttpQuietDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        pass",
        "begin_line": 18,
        "end_line": 19,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD.report_retry_fragment#56",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD.report_retry_fragment(self, err, frag_index, count, retries)",
        "snippet": "    def report_retry_fragment(self, err, frag_index, count, retries):\n        self.to_screen(\n            '[download] Got server HTTP error: %s. Retrying fragment %d (attempt %d of %s)...'\n            % (error_to_compat_str(err), frag_index, count, self.format_retries(retries)))",
        "begin_line": 56,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD.report_skip_fragment#61",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD.report_skip_fragment(self, frag_index)",
        "snippet": "    def report_skip_fragment(self, frag_index):\n        self.to_screen('[download] Skipping fragment %d...' % frag_index)",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._prepare_url#64",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._prepare_url(self, info_dict, url)",
        "snippet": "    def _prepare_url(self, info_dict, url):\n        headers = info_dict.get('http_headers')\n        return sanitized_Request(url, None, headers) if headers else url",
        "begin_line": 64,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._prepare_and_start_frag_download#68",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._prepare_and_start_frag_download(self, ctx)",
        "snippet": "    def _prepare_and_start_frag_download(self, ctx):\n        self._prepare_frag_download(ctx)\n        self._start_frag_download(ctx)",
        "begin_line": 68,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD.__do_ytdl_file#73",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD.__do_ytdl_file(ctx)",
        "snippet": "    def __do_ytdl_file(ctx):\n        return not ctx['live'] and not ctx['tmpfilename'] == '-'",
        "begin_line": 73,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._read_ytdl_file#76",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._read_ytdl_file(self, ctx)",
        "snippet": "    def _read_ytdl_file(self, ctx):\n        stream, _ = sanitize_open(self.ytdl_filename(ctx['filename']), 'r')\n        ctx['fragment_index'] = json.loads(stream.read())['downloader']['current_fragment']['index']\n        stream.close()",
        "begin_line": 76,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._write_ytdl_file#81",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._write_ytdl_file(self, ctx)",
        "snippet": "    def _write_ytdl_file(self, ctx):\n        frag_index_stream, _ = sanitize_open(self.ytdl_filename(ctx['filename']), 'w')\n        downloader = {\n            'current_fragment': {\n                'index': ctx['fragment_index'],\n            },\n        }\n        if ctx.get('fragment_count') is not None:\n            downloader['fragment_count'] = ctx['fragment_count']\n        frag_index_stream.write(json.dumps({'downloader': downloader}))\n        frag_index_stream.close()",
        "begin_line": 81,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._download_fragment#93",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._download_fragment(self, ctx, frag_url, info_dict, headers=None)",
        "snippet": "    def _download_fragment(self, ctx, frag_url, info_dict, headers=None):\n        fragment_filename = '%s-Frag%d' % (ctx['tmpfilename'], ctx['fragment_index'])\n        success = ctx['dl'].download(fragment_filename, {\n            'url': frag_url,\n            'http_headers': headers or info_dict.get('http_headers'),\n        })\n        if not success:\n            return False, None\n        down, frag_sanitized = sanitize_open(fragment_filename, 'rb')\n        ctx['fragment_filename_sanitized'] = frag_sanitized\n        frag_content = down.read()\n        down.close()\n        return True, frag_content",
        "begin_line": 93,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._append_fragment#107",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._append_fragment(self, ctx, frag_content)",
        "snippet": "    def _append_fragment(self, ctx, frag_content):\n        try:\n            ctx['dest_stream'].write(frag_content)\n        finally:\n            if self.__do_ytdl_file(ctx):\n                self._write_ytdl_file(ctx)\n            if not self.params.get('keep_fragments', False):\n                os.remove(ctx['fragment_filename_sanitized'])\n            del ctx['fragment_filename_sanitized']",
        "begin_line": 107,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._prepare_frag_download#117",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._prepare_frag_download(self, ctx)",
        "snippet": "    def _prepare_frag_download(self, ctx):\n        if 'live' not in ctx:\n            ctx['live'] = False\n        self.to_screen(\n            '[%s] Total fragments: %s'\n            % (self.FD_NAME, ctx['total_frags'] if not ctx['live'] else 'unknown (live)'))\n        self.report_destination(ctx['filename'])\n        dl = HttpQuietDownloader(\n            self.ydl,\n            {\n                'continuedl': True,\n                'quiet': True,\n                'noprogress': True,\n                'ratelimit': self.params.get('ratelimit'),\n                'retries': self.params.get('retries', 0),\n                'nopart': self.params.get('nopart', False),\n                'test': self.params.get('test', False),\n            }\n        )\n        tmpfilename = self.temp_name(ctx['filename'])\n        open_mode = 'wb'\n        resume_len = 0\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            open_mode = 'ab'\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n\n        # Should be initialized before ytdl file check\n        ctx.update({\n            'tmpfilename': tmpfilename,\n            'fragment_index': 0,\n        })\n\n        if self.__do_ytdl_file(ctx):\n            if os.path.isfile(encodeFilename(self.ytdl_filename(ctx['filename']))):\n                self._read_ytdl_file(ctx)\n            else:\n                self._write_ytdl_file(ctx)\n            if ctx['fragment_index'] > 0:\n                assert resume_len > 0\n\n        dest_stream, tmpfilename = sanitize_open(tmpfilename, open_mode)\n\n        ctx.update({\n            'dl': dl,\n            'dest_stream': dest_stream,\n            'tmpfilename': tmpfilename,\n            # Total complete fragments downloaded so far in bytes\n            'complete_frags_downloaded_bytes': resume_len,\n        })",
        "begin_line": 117,
        "end_line": 167,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._start_frag_download#169",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._start_frag_download(self, ctx)",
        "snippet": "    def _start_frag_download(self, ctx):\n        total_frags = ctx['total_frags']\n        # This dict stores the download progress, it's updated by the progress\n        # hook\n        state = {\n            'status': 'downloading',\n            'downloaded_bytes': ctx['complete_frags_downloaded_bytes'],\n            'fragment_index': ctx['fragment_index'],\n            'fragment_count': total_frags,\n            'filename': ctx['filename'],\n            'tmpfilename': ctx['tmpfilename'],\n        }\n\n        start = time.time()\n        ctx.update({\n            'started': start,\n            # Amount of fragment's bytes downloaded by the time of the previous\n            # frag progress hook invocation\n            'prev_frag_downloaded_bytes': 0,\n        })\n\n        def frag_progress_hook(s):\n            if s['status'] not in ('downloading', 'finished'):\n                return\n\n            time_now = time.time()\n            state['elapsed'] = time_now - start\n            frag_total_bytes = s.get('total_bytes') or 0\n            if not ctx['live']:\n                estimated_size = (\n                    (ctx['complete_frags_downloaded_bytes'] + frag_total_bytes) /\n                    (state['fragment_index'] + 1) * total_frags)\n                state['total_bytes_estimate'] = estimated_size\n\n            if s['status'] == 'finished':\n                state['fragment_index'] += 1\n                ctx['fragment_index'] = state['fragment_index']\n                state['downloaded_bytes'] += frag_total_bytes - ctx['prev_frag_downloaded_bytes']\n                ctx['complete_frags_downloaded_bytes'] = state['downloaded_bytes']\n                ctx['prev_frag_downloaded_bytes'] = 0\n            else:\n                frag_downloaded_bytes = s['downloaded_bytes']\n                state['downloaded_bytes'] += frag_downloaded_bytes - ctx['prev_frag_downloaded_bytes']\n                if not ctx['live']:\n                    state['eta'] = self.calc_eta(\n                        start, time_now, estimated_size,\n                        state['downloaded_bytes'])\n                state['speed'] = s.get('speed') or ctx.get('speed')\n                ctx['speed'] = state['speed']\n                ctx['prev_frag_downloaded_bytes'] = frag_downloaded_bytes\n            self._hook_progress(state)\n\n        ctx['dl'].add_progress_hook(frag_progress_hook)\n\n        return start",
        "begin_line": 169,
        "end_line": 223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.fragment.FragmentFD._finish_frag_download#225",
        "src_path": "youtube_dl/downloader/fragment.py",
        "class_name": "youtube_dl.downloader.fragment.FragmentFD",
        "signature": "youtube_dl.downloader.fragment.FragmentFD._finish_frag_download(self, ctx)",
        "snippet": "    def _finish_frag_download(self, ctx):\n        ctx['dest_stream'].close()\n        if self.__do_ytdl_file(ctx):\n            ytdl_filename = encodeFilename(self.ytdl_filename(ctx['filename']))\n            if os.path.isfile(ytdl_filename):\n                os.remove(ytdl_filename)\n        elapsed = time.time() - ctx['started']\n        self.try_rename(ctx['tmpfilename'], ctx['filename'])\n        fsize = os.path.getsize(encodeFilename(ctx['filename']))\n\n        self._hook_progress({\n            'downloaded_bytes': fsize,\n            'total_bytes': fsize,\n            'filename': ctx['filename'],\n            'status': 'finished',\n            'elapsed': elapsed,\n        })",
        "begin_line": 225,
        "end_line": 241,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.hls.HlsFD.can_download#31",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.HlsFD",
        "signature": "youtube_dl.downloader.hls.HlsFD.can_download(manifest, info_dict)",
        "snippet": "    def can_download(manifest, info_dict):\n        UNSUPPORTED_FEATURES = (\n            r'#EXT-X-KEY:METHOD=(?!NONE|AES-128)',  # encrypted streams [1]\n            # r'#EXT-X-BYTERANGE',  # playlists composed of byte ranges of media files [2]\n\n            # Live streams heuristic does not always work (e.g. geo restricted to Germany\n            # http://hls-geo.daserste.de/i/videoportal/Film/c_620000/622873/format,716451,716457,716450,716458,716459,.mp4.csmil/index_4_av.m3u8?null=0)\n            # r'#EXT-X-MEDIA-SEQUENCE:(?!0$)',  # live streams [3]\n\n            # This heuristic also is not correct since segments may not be appended as well.\n            # Twitch vods of finished streams have EXT-X-PLAYLIST-TYPE:EVENT despite\n            # no segments will definitely be appended to the end of the playlist.\n            # r'#EXT-X-PLAYLIST-TYPE:EVENT',  # media segments may be appended to the end of\n            #                                 # event media playlists [4]\n\n            # 1. https://tools.ietf.org/html/draft-pantos-http-live-streaming-17#section-4.3.2.4\n            # 2. https://tools.ietf.org/html/draft-pantos-http-live-streaming-17#section-4.3.2.2\n            # 3. https://tools.ietf.org/html/draft-pantos-http-live-streaming-17#section-4.3.3.2\n            # 4. https://tools.ietf.org/html/draft-pantos-http-live-streaming-17#section-4.3.3.5\n        )\n        check_results = [not re.search(feature, manifest) for feature in UNSUPPORTED_FEATURES]\n        is_aes128_enc = '#EXT-X-KEY:METHOD=AES-128' in manifest\n        check_results.append(can_decrypt_frag or not is_aes128_enc)\n        check_results.append(not (is_aes128_enc and r'#EXT-X-BYTERANGE' in manifest))\n        check_results.append(not info_dict.get('is_live'))\n        return all(check_results)",
        "begin_line": 31,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.hls.HlsFD.real_download#58",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.HlsFD",
        "signature": "youtube_dl.downloader.hls.HlsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        self.to_screen('[%s] Downloading m3u8 manifest' % self.FD_NAME)\n\n        urlh = self.ydl.urlopen(self._prepare_url(info_dict, man_url))\n        man_url = urlh.geturl()\n        s = urlh.read().decode('utf-8', 'ignore')\n\n        if not self.can_download(s, info_dict):\n            if info_dict.get('extra_param_to_segment_url'):\n                self.report_error('pycrypto not found. Please install it.')\n                return False\n            self.report_warning(\n                'hlsnative has detected features it does not support, '\n                'extraction will be delegated to ffmpeg')\n            fd = FFmpegFD(self.ydl, self.params)\n            for ph in self._progress_hooks:\n                fd.add_progress_hook(ph)\n            return fd.real_download(filename, info_dict)\n\n        total_frags = 0\n        for line in s.splitlines():\n            line = line.strip()\n            if line and not line.startswith('#'):\n                total_frags += 1\n\n        ctx = {\n            'filename': filename,\n            'total_frags': total_frags,\n        }\n\n        self._prepare_and_start_frag_download(ctx)\n\n        fragment_retries = self.params.get('fragment_retries', 0)\n        skip_unavailable_fragments = self.params.get('skip_unavailable_fragments', True)\n        test = self.params.get('test', False)\n\n        extra_query = None\n        extra_param_to_segment_url = info_dict.get('extra_param_to_segment_url')\n        if extra_param_to_segment_url:\n            extra_query = compat_urlparse.parse_qs(extra_param_to_segment_url)\n        i = 0\n        media_sequence = 0\n        decrypt_info = {'METHOD': 'NONE'}\n        byte_range = {}\n        frag_index = 0\n        for line in s.splitlines():\n            line = line.strip()\n            if line:\n                if not line.startswith('#'):\n                    frag_index += 1\n                    if frag_index <= ctx['fragment_index']:\n                        continue\n                    frag_url = (\n                        line\n                        if re.match(r'^https?://', line)\n                        else compat_urlparse.urljoin(man_url, line))\n                    if extra_query:\n                        frag_url = update_url_query(frag_url, extra_query)\n                    count = 0\n                    headers = info_dict.get('http_headers', {})\n                    if byte_range:\n                        headers['Range'] = 'bytes=%d-%d' % (byte_range['start'], byte_range['end'])\n                    while count <= fragment_retries:\n                        try:\n                            success, frag_content = self._download_fragment(\n                                ctx, frag_url, info_dict, headers)\n                            if not success:\n                                return False\n                            break\n                        except compat_urllib_error.HTTPError as err:\n                            # Unavailable (possibly temporary) fragments may be served.\n                            # First we try to retry then either skip or abort.\n                            # See https://github.com/rg3/youtube-dl/issues/10165,\n                            # https://github.com/rg3/youtube-dl/issues/10448).\n                            count += 1\n                            if count <= fragment_retries:\n                                self.report_retry_fragment(err, frag_index, count, fragment_retries)\n                    if count > fragment_retries:\n                        if skip_unavailable_fragments:\n                            i += 1\n                            media_sequence += 1\n                            self.report_skip_fragment(frag_index)\n                            continue\n                        self.report_error(\n                            'giving up after %s fragment retries' % fragment_retries)\n                        return False\n                    if decrypt_info['METHOD'] == 'AES-128':\n                        iv = decrypt_info.get('IV') or compat_struct_pack('>8xq', media_sequence)\n                        decrypt_info['KEY'] = decrypt_info.get('KEY') or self.ydl.urlopen(decrypt_info['URI']).read()\n                        frag_content = AES.new(\n                            decrypt_info['KEY'], AES.MODE_CBC, iv).decrypt(frag_content)\n                    self._append_fragment(ctx, frag_content)\n                    # We only download the first fragment during the test\n                    if test:\n                        break\n                    i += 1\n                    media_sequence += 1\n                elif line.startswith('#EXT-X-KEY'):\n                    decrypt_url = decrypt_info.get('URI')\n                    decrypt_info = parse_m3u8_attributes(line[11:])\n                    if decrypt_info['METHOD'] == 'AES-128':\n                        if 'IV' in decrypt_info:\n                            decrypt_info['IV'] = binascii.unhexlify(decrypt_info['IV'][2:].zfill(32))\n                        if not re.match(r'^https?://', decrypt_info['URI']):\n                            decrypt_info['URI'] = compat_urlparse.urljoin(\n                                man_url, decrypt_info['URI'])\n                        if extra_query:\n                            decrypt_info['URI'] = update_url_query(decrypt_info['URI'], extra_query)\n                        if decrypt_url != decrypt_info['URI']:\n                            decrypt_info['KEY'] = None\n                elif line.startswith('#EXT-X-MEDIA-SEQUENCE'):\n                    media_sequence = int(line[22:])\n                elif line.startswith('#EXT-X-BYTERANGE'):\n                    splitted_byte_range = line[17:].split('@')\n                    sub_range_start = int(splitted_byte_range[1]) if len(splitted_byte_range) == 2 else byte_range['end']\n                    byte_range = {\n                        'start': sub_range_start,\n                        'end': sub_range_start + int(splitted_byte_range[0]),\n                    }\n\n        self._finish_frag_download(ctx)\n\n        return True",
        "begin_line": 58,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.http.HttpFD.real_download#23",
        "src_path": "youtube_dl/downloader/http.py",
        "class_name": "youtube_dl.downloader.http.HttpFD",
        "signature": "youtube_dl.downloader.http.HttpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        tmpfilename = self.temp_name(filename)\n        stream = None\n\n        # Do not include the Accept-Encoding header\n        headers = {'Youtubedl-no-compression': 'True'}\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            headers.update(add_headers)\n        basic_request = sanitized_Request(url, None, headers)\n        request = sanitized_Request(url, None, headers)\n\n        is_test = self.params.get('test', False)\n\n        if is_test:\n            request.add_header('Range', 'bytes=0-%s' % str(self._TEST_FILE_SIZE - 1))\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n        else:\n            resume_len = 0\n\n        open_mode = 'wb'\n        if resume_len != 0:\n            if self.params.get('continuedl', True):\n                self.report_resuming_byte(resume_len)\n                request.add_header('Range', 'bytes=%d-' % resume_len)\n                open_mode = 'ab'\n            else:\n                resume_len = 0\n\n        count = 0\n        retries = self.params.get('retries', 0)\n        while count <= retries:\n            # Establish connection\n            try:\n                data = self.ydl.urlopen(request)\n                # When trying to resume, Content-Range HTTP header of response has to be checked\n                # to match the value of requested Range HTTP header. This is due to a webservers\n                # that don't support resuming and serve a whole file with no Content-Range\n                # set in response despite of requested Range (see\n                # https://github.com/rg3/youtube-dl/issues/6057#issuecomment-126129799)\n                if resume_len > 0:\n                    content_range = data.headers.get('Content-Range')\n                    if content_range:\n                        content_range_m = re.search(r'bytes (\\d+)-', content_range)\n                        # Content-Range is present and matches requested Range, resume is possible\n                        if content_range_m and resume_len == int(content_range_m.group(1)):\n                            break\n                    # Content-Range is either not present or invalid. Assuming remote webserver is\n                    # trying to send the whole file, resume is not possible, so wiping the local file\n                    # and performing entire redownload\n                    self.report_unable_to_resume()\n                    resume_len = 0\n                    open_mode = 'wb'\n                break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if (err.code < 500 or err.code >= 600) and err.code != 416:\n                    # Unexpected HTTP error\n                    raise\n                elif err.code == 416:\n                    # Unable to resume (requested range not satisfiable)\n                    try:\n                        # Open the connection again without the range header\n                        data = self.ydl.urlopen(basic_request)\n                        content_length = data.info()['Content-Length']\n                    except (compat_urllib_error.HTTPError, ) as err:\n                        if err.code < 500 or err.code >= 600:\n                            raise\n                    else:\n                        # Examine the reported length\n                        if (content_length is not None and\n                                (resume_len - 100 < int(content_length) < resume_len + 100)):\n                            # The file had already been fully downloaded.\n                            # Explanation to the above condition: in issue #175 it was revealed that\n                            # YouTube sometimes adds or removes a few bytes from the end of the file,\n                            # changing the file size slightly and causing problems for some users. So\n                            # I decided to implement a suggested change and consider the file\n                            # completely downloaded if the file size differs less than 100 bytes from\n                            # the one in the hard drive.\n                            self.report_file_already_downloaded(filename)\n                            self.try_rename(tmpfilename, filename)\n                            self._hook_progress({\n                                'filename': filename,\n                                'status': 'finished',\n                                'downloaded_bytes': resume_len,\n                                'total_bytes': resume_len,\n                            })\n                            return True\n                        else:\n                            # The length does not match, we start the download over\n                            self.report_unable_to_resume()\n                            resume_len = 0\n                            open_mode = 'wb'\n                            break\n            except socket.error as e:\n                if e.errno != errno.ECONNRESET:\n                    # Connection reset is no problem, just retry\n                    raise\n\n            # Retry\n            count += 1\n            if count <= retries:\n                self.report_retry(count, retries)\n\n        if count > retries:\n            self.report_error('giving up after %s retries' % retries)\n            return False\n\n        data_len = data.info().get('Content-length', None)\n\n        # Range HTTP header may be ignored/unsupported by a webserver\n        # (e.g. extractor/scivee.py, extractor/bambuser.py).\n        # However, for a test we still would like to download just a piece of a file.\n        # To achieve this we limit data_len to _TEST_FILE_SIZE and manually control\n        # block size when downloading a file.\n        if is_test and (data_len is None or int(data_len) > self._TEST_FILE_SIZE):\n            data_len = self._TEST_FILE_SIZE\n\n        if data_len is not None:\n            data_len = int(data_len) + resume_len\n            min_data_len = self.params.get('min_filesize')\n            max_data_len = self.params.get('max_filesize')\n            if min_data_len is not None and data_len < min_data_len:\n                self.to_screen('\\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))\n                return False\n            if max_data_len is not None and data_len > max_data_len:\n                self.to_screen('\\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))\n                return False\n\n        byte_counter = 0 + resume_len\n        block_size = self.params.get('buffersize', 1024)\n        start = time.time()\n\n        # measure time over whole while-loop, so slow_down() and best_block_size() work together properly\n        now = None  # needed for slow_down() in the first loop run\n        before = start  # start measuring\n        while True:\n\n            # Download and write\n            data_block = data.read(block_size if not is_test else min(block_size, data_len - byte_counter))\n            byte_counter += len(data_block)\n\n            # exit loop when download is finished\n            if len(data_block) == 0:\n                break\n\n            # Open destination file just in time\n            if stream is None:\n                try:\n                    (stream, tmpfilename) = sanitize_open(tmpfilename, open_mode)\n                    assert stream is not None\n                    filename = self.undo_temp_name(tmpfilename)\n                    self.report_destination(filename)\n                except (OSError, IOError) as err:\n                    self.report_error('unable to open for writing: %s' % str(err))\n                    return False\n\n                if self.params.get('xattr_set_filesize', False) and data_len is not None:\n                    try:\n                        write_xattr(tmpfilename, 'user.ytdl.filesize', str(data_len).encode('utf-8'))\n                    except (XAttrUnavailableError, XAttrMetadataError) as err:\n                        self.report_error('unable to set filesize xattr: %s' % str(err))\n\n            try:\n                stream.write(data_block)\n            except (IOError, OSError) as err:\n                self.to_stderr('\\n')\n                self.report_error('unable to write data: %s' % str(err))\n                return False\n\n            # Apply rate limit\n            self.slow_down(start, now, byte_counter - resume_len)\n\n            # end measuring of one loop run\n            now = time.time()\n            after = now\n\n            # Adjust block size\n            if not self.params.get('noresizebuffer', False):\n                block_size = self.best_block_size(after - before, len(data_block))\n\n            before = after\n\n            # Progress message\n            speed = self.calc_speed(start, now, byte_counter - resume_len)\n            if data_len is None:\n                eta = None\n            else:\n                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)\n\n            self._hook_progress({\n                'status': 'downloading',\n                'downloaded_bytes': byte_counter,\n                'total_bytes': data_len,\n                'tmpfilename': tmpfilename,\n                'filename': filename,\n                'eta': eta,\n                'speed': speed,\n                'elapsed': now - start,\n            })\n\n            if is_test and byte_counter == data_len:\n                break\n\n        if stream is None:\n            self.to_stderr('\\n')\n            self.report_error('Did not get any data blocks')\n            return False\n        if tmpfilename != '-':\n            stream.close()\n\n        if data_len is not None and byte_counter != data_len:\n            raise ContentTooShortError(byte_counter, int(data_len))\n        self.try_rename(tmpfilename, filename)\n\n        # Update file modification time\n        if self.params.get('updatetime', True):\n            info_dict['filetime'] = self.try_utime(filename, data.info().get('last-modified', None))\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n            'elapsed': time.time() - start,\n        })\n\n        return True",
        "begin_line": 23,
        "end_line": 253,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.ism.box#33",
        "src_path": "youtube_dl/downloader/ism.py",
        "class_name": "youtube_dl.downloader.ism",
        "signature": "youtube_dl.downloader.ism.box(box_type, payload)",
        "snippet": "def box(box_type, payload):\n    return u32.pack(8 + len(payload)) + box_type + payload",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.ism.full_box#37",
        "src_path": "youtube_dl/downloader/ism.py",
        "class_name": "youtube_dl.downloader.ism",
        "signature": "youtube_dl.downloader.ism.full_box(box_type, version, flags, payload)",
        "snippet": "def full_box(box_type, version, flags, payload):\n    return box(box_type, u8.pack(version) + u32.pack(flags)[1:] + payload)",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.ism.write_piff_header#41",
        "src_path": "youtube_dl/downloader/ism.py",
        "class_name": "youtube_dl.downloader.ism",
        "signature": "youtube_dl.downloader.ism.write_piff_header(stream, params)",
        "snippet": "def write_piff_header(stream, params):\n    track_id = params['track_id']\n    fourcc = params['fourcc']\n    duration = params['duration']\n    timescale = params.get('timescale', 10000000)\n    language = params.get('language', 'und')\n    height = params.get('height', 0)\n    width = params.get('width', 0)\n    is_audio = width == 0 and height == 0\n    creation_time = modification_time = int(time.time())\n\n    ftyp_payload = b'isml'  # major brand\n    ftyp_payload += u32.pack(1)  # minor version\n    ftyp_payload += b'piff' + b'iso2'  # compatible brands\n    stream.write(box(b'ftyp', ftyp_payload))  # File Type Box\n\n    mvhd_payload = u64.pack(creation_time)\n    mvhd_payload += u64.pack(modification_time)\n    mvhd_payload += u32.pack(timescale)\n    mvhd_payload += u64.pack(duration)\n    mvhd_payload += s1616.pack(1)  # rate\n    mvhd_payload += s88.pack(1)  # volume\n    mvhd_payload += u16.pack(0)  # reserved\n    mvhd_payload += u32.pack(0) * 2  # reserved\n    mvhd_payload += unity_matrix\n    mvhd_payload += u32.pack(0) * 6  # pre defined\n    mvhd_payload += u32.pack(0xffffffff)  # next track id\n    moov_payload = full_box(b'mvhd', 1, 0, mvhd_payload)  # Movie Header Box\n\n    tkhd_payload = u64.pack(creation_time)\n    tkhd_payload += u64.pack(modification_time)\n    tkhd_payload += u32.pack(track_id)  # track id\n    tkhd_payload += u32.pack(0)  # reserved\n    tkhd_payload += u64.pack(duration)\n    tkhd_payload += u32.pack(0) * 2  # reserved\n    tkhd_payload += s16.pack(0)  # layer\n    tkhd_payload += s16.pack(0)  # alternate group\n    tkhd_payload += s88.pack(1 if is_audio else 0)  # volume\n    tkhd_payload += u16.pack(0)  # reserved\n    tkhd_payload += unity_matrix\n    tkhd_payload += u1616.pack(width)\n    tkhd_payload += u1616.pack(height)\n    trak_payload = full_box(b'tkhd', 1, TRACK_ENABLED | TRACK_IN_MOVIE | TRACK_IN_PREVIEW, tkhd_payload)  # Track Header Box\n\n    mdhd_payload = u64.pack(creation_time)\n    mdhd_payload += u64.pack(modification_time)\n    mdhd_payload += u32.pack(timescale)\n    mdhd_payload += u64.pack(duration)\n    mdhd_payload += u16.pack(((ord(language[0]) - 0x60) << 10) | ((ord(language[1]) - 0x60) << 5) | (ord(language[2]) - 0x60))\n    mdhd_payload += u16.pack(0)  # pre defined\n    mdia_payload = full_box(b'mdhd', 1, 0, mdhd_payload)  # Media Header Box\n\n    hdlr_payload = u32.pack(0)  # pre defined\n    hdlr_payload += b'soun' if is_audio else b'vide'  # handler type\n    hdlr_payload += u32.pack(0) * 3  # reserved\n    hdlr_payload += (b'Sound' if is_audio else b'Video') + b'Handler\\0'  # name\n    mdia_payload += full_box(b'hdlr', 0, 0, hdlr_payload)  # Handler Reference Box\n\n    if is_audio:\n        smhd_payload = s88.pack(0)  # balance\n        smhd_payload += u16.pack(0)  # reserved\n        media_header_box = full_box(b'smhd', 0, 0, smhd_payload)  # Sound Media Header\n    else:\n        vmhd_payload = u16.pack(0)  # graphics mode\n        vmhd_payload += u16.pack(0) * 3  # opcolor\n        media_header_box = full_box(b'vmhd', 0, 1, vmhd_payload)  # Video Media Header\n    minf_payload = media_header_box\n\n    dref_payload = u32.pack(1)  # entry count\n    dref_payload += full_box(b'url ', 0, SELF_CONTAINED, b'')  # Data Entry URL Box\n    dinf_payload = full_box(b'dref', 0, 0, dref_payload)  # Data Reference Box\n    minf_payload += box(b'dinf', dinf_payload)  # Data Information Box\n\n    stsd_payload = u32.pack(1)  # entry count\n\n    sample_entry_payload = u8.pack(0) * 6  # reserved\n    sample_entry_payload += u16.pack(1)  # data reference index\n    if is_audio:\n        sample_entry_payload += u32.pack(0) * 2  # reserved\n        sample_entry_payload += u16.pack(params.get('channels', 2))\n        sample_entry_payload += u16.pack(params.get('bits_per_sample', 16))\n        sample_entry_payload += u16.pack(0)  # pre defined\n        sample_entry_payload += u16.pack(0)  # reserved\n        sample_entry_payload += u1616.pack(params['sampling_rate'])\n\n        if fourcc == 'AACL':\n            sample_entry_box = box(b'mp4a', sample_entry_payload)\n    else:\n        sample_entry_payload += u16.pack(0)  # pre defined\n        sample_entry_payload += u16.pack(0)  # reserved\n        sample_entry_payload += u32.pack(0) * 3  # pre defined\n        sample_entry_payload += u16.pack(width)\n        sample_entry_payload += u16.pack(height)\n        sample_entry_payload += u1616.pack(0x48)  # horiz resolution 72 dpi\n        sample_entry_payload += u1616.pack(0x48)  # vert resolution 72 dpi\n        sample_entry_payload += u32.pack(0)  # reserved\n        sample_entry_payload += u16.pack(1)  # frame count\n        sample_entry_payload += u8.pack(0) * 32  # compressor name\n        sample_entry_payload += u16.pack(0x18)  # depth\n        sample_entry_payload += s16.pack(-1)  # pre defined\n\n        codec_private_data = binascii.unhexlify(params['codec_private_data'])\n        if fourcc in ('H264', 'AVC1'):\n            sps, pps = codec_private_data.split(u32.pack(1))[1:]\n            avcc_payload = u8.pack(1)  # configuration version\n            avcc_payload += sps[1:4]  # avc profile indication + profile compatibility + avc level indication\n            avcc_payload += u8.pack(0xfc | (params.get('nal_unit_length_field', 4) - 1))  # complete represenation (1) + reserved (11111) + length size minus one\n            avcc_payload += u8.pack(1)  # reserved (0) + number of sps (0000001)\n            avcc_payload += u16.pack(len(sps))\n            avcc_payload += sps\n            avcc_payload += u8.pack(1)  # number of pps\n            avcc_payload += u16.pack(len(pps))\n            avcc_payload += pps\n            sample_entry_payload += box(b'avcC', avcc_payload)  # AVC Decoder Configuration Record\n            sample_entry_box = box(b'avc1', sample_entry_payload)  # AVC Simple Entry\n    stsd_payload += sample_entry_box\n\n    stbl_payload = full_box(b'stsd', 0, 0, stsd_payload)  # Sample Description Box\n\n    stts_payload = u32.pack(0)  # entry count\n    stbl_payload += full_box(b'stts', 0, 0, stts_payload)  # Decoding Time to Sample Box\n\n    stsc_payload = u32.pack(0)  # entry count\n    stbl_payload += full_box(b'stsc', 0, 0, stsc_payload)  # Sample To Chunk Box\n\n    stco_payload = u32.pack(0)  # entry count\n    stbl_payload += full_box(b'stco', 0, 0, stco_payload)  # Chunk Offset Box\n\n    minf_payload += box(b'stbl', stbl_payload)  # Sample Table Box\n\n    mdia_payload += box(b'minf', minf_payload)  # Media Information Box\n\n    trak_payload += box(b'mdia', mdia_payload)  # Media Box\n\n    moov_payload += box(b'trak', trak_payload)  # Track Box\n\n    mehd_payload = u64.pack(duration)\n    mvex_payload = full_box(b'mehd', 1, 0, mehd_payload)  # Movie Extends Header Box\n\n    trex_payload = u32.pack(track_id)  # track id\n    trex_payload += u32.pack(1)  # default sample description index\n    trex_payload += u32.pack(0)  # default sample duration\n    trex_payload += u32.pack(0)  # default sample size\n    trex_payload += u32.pack(0)  # default sample flags\n    mvex_payload += full_box(b'trex', 0, 0, trex_payload)  # Track Extends Box\n\n    moov_payload += box(b'mvex', mvex_payload)  # Movie Extends Box\n    stream.write(box(b'moov', moov_payload))  # Movie Box",
        "begin_line": 41,
        "end_line": 188,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.ism.extract_box_data#191",
        "src_path": "youtube_dl/downloader/ism.py",
        "class_name": "youtube_dl.downloader.ism",
        "signature": "youtube_dl.downloader.ism.extract_box_data(data, box_sequence)",
        "snippet": "def extract_box_data(data, box_sequence):\n    data_reader = io.BytesIO(data)\n    while True:\n        box_size = u32.unpack(data_reader.read(4))[0]\n        box_type = data_reader.read(4)\n        if box_type == box_sequence[0]:\n            box_data = data_reader.read(box_size - 8)\n            if len(box_sequence) == 1:\n                return box_data\n            return extract_box_data(box_data, box_sequence[1:])\n        data_reader.seek(box_size - 8, 1)",
        "begin_line": 191,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.ism.IsmFD.real_download#211",
        "src_path": "youtube_dl/downloader/ism.py",
        "class_name": "youtube_dl.downloader.ism.IsmFD",
        "signature": "youtube_dl.downloader.ism.IsmFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        segments = info_dict['fragments'][:1] if self.params.get(\n            'test', False) else info_dict['fragments']\n\n        ctx = {\n            'filename': filename,\n            'total_frags': len(segments),\n        }\n\n        self._prepare_and_start_frag_download(ctx)\n\n        fragment_retries = self.params.get('fragment_retries', 0)\n        skip_unavailable_fragments = self.params.get('skip_unavailable_fragments', True)\n\n        track_written = False\n        frag_index = 0\n        for i, segment in enumerate(segments):\n            frag_index += 1\n            if frag_index <= ctx['fragment_index']:\n                continue\n            count = 0\n            while count <= fragment_retries:\n                try:\n                    success, frag_content = self._download_fragment(ctx, segment['url'], info_dict)\n                    if not success:\n                        return False\n                    if not track_written:\n                        tfhd_data = extract_box_data(frag_content, [b'moof', b'traf', b'tfhd'])\n                        info_dict['_download_params']['track_id'] = u32.unpack(tfhd_data[4:8])[0]\n                        write_piff_header(ctx['dest_stream'], info_dict['_download_params'])\n                        track_written = True\n                    self._append_fragment(ctx, frag_content)\n                    break\n                except compat_urllib_error.HTTPError as err:\n                    count += 1\n                    if count <= fragment_retries:\n                        self.report_retry_fragment(err, frag_index, count, fragment_retries)\n            if count > fragment_retries:\n                if skip_unavailable_fragments:\n                    self.report_skip_fragment(frag_index)\n                    continue\n                self.report_error('giving up after %s fragment retries' % fragment_retries)\n                return False\n\n        self._finish_frag_download(ctx)\n\n        return True",
        "begin_line": 211,
        "end_line": 257,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.rtmp.rtmpdump_version#18",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp",
        "signature": "youtube_dl.downloader.rtmp.rtmpdump_version()",
        "snippet": "def rtmpdump_version():\n    return get_exe_version(\n        'rtmpdump', ['--help'], r'(?i)RTMPDump\\s*v?([0-9a-zA-Z._-]+)')",
        "begin_line": 18,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.rtmp.RtmpFD.real_download#24",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp.RtmpFD",
        "signature": "youtube_dl.downloader.rtmp.RtmpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        def run_rtmpdump(args):\n            start = time.time()\n            resume_percent = None\n            resume_downloaded_data_len = None\n            proc = subprocess.Popen(args, stderr=subprocess.PIPE)\n            cursor_in_new_line = True\n            proc_stderr_closed = False\n            while not proc_stderr_closed:\n                # read line from stderr\n                line = ''\n                while True:\n                    char = proc.stderr.read(1)\n                    if not char:\n                        proc_stderr_closed = True\n                        break\n                    if char in [b'\\r', b'\\n']:\n                        break\n                    line += char.decode('ascii', 'replace')\n                if not line:\n                    # proc_stderr_closed is True\n                    continue\n                mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec \\(([0-9]{1,2}\\.[0-9])%\\)', line)\n                if mobj:\n                    downloaded_data_len = int(float(mobj.group(1)) * 1024)\n                    percent = float(mobj.group(2))\n                    if not resume_percent:\n                        resume_percent = percent\n                        resume_downloaded_data_len = downloaded_data_len\n                    time_now = time.time()\n                    eta = self.calc_eta(start, time_now, 100 - resume_percent, percent - resume_percent)\n                    speed = self.calc_speed(start, time_now, downloaded_data_len - resume_downloaded_data_len)\n                    data_len = None\n                    if percent > 0:\n                        data_len = int(downloaded_data_len * 100 / percent)\n                    self._hook_progress({\n                        'status': 'downloading',\n                        'downloaded_bytes': downloaded_data_len,\n                        'total_bytes_estimate': data_len,\n                        'tmpfilename': tmpfilename,\n                        'filename': filename,\n                        'eta': eta,\n                        'elapsed': time_now - start,\n                        'speed': speed,\n                    })\n                    cursor_in_new_line = False\n                else:\n                    # no percent for live streams\n                    mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec', line)\n                    if mobj:\n                        downloaded_data_len = int(float(mobj.group(1)) * 1024)\n                        time_now = time.time()\n                        speed = self.calc_speed(start, time_now, downloaded_data_len)\n                        self._hook_progress({\n                            'downloaded_bytes': downloaded_data_len,\n                            'tmpfilename': tmpfilename,\n                            'filename': filename,\n                            'status': 'downloading',\n                            'elapsed': time_now - start,\n                            'speed': speed,\n                        })\n                        cursor_in_new_line = False\n                    elif self.params.get('verbose', False):\n                        if not cursor_in_new_line:\n                            self.to_screen('')\n                        cursor_in_new_line = True\n                        self.to_screen('[rtmpdump] ' + line)\n            proc.wait()\n            if not cursor_in_new_line:\n                self.to_screen('')\n            return proc.returncode\n\n        url = info_dict['url']\n        player_url = info_dict.get('player_url')\n        page_url = info_dict.get('page_url')\n        app = info_dict.get('app')\n        play_path = info_dict.get('play_path')\n        tc_url = info_dict.get('tc_url')\n        flash_version = info_dict.get('flash_version')\n        live = info_dict.get('rtmp_live', False)\n        conn = info_dict.get('rtmp_conn')\n        protocol = info_dict.get('rtmp_protocol')\n        real_time = info_dict.get('rtmp_real_time', False)\n        no_resume = info_dict.get('no_resume', False)\n        continue_dl = self.params.get('continuedl', True)\n\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n        test = self.params.get('test', False)\n\n        # Check for rtmpdump first\n        if not check_executable('rtmpdump', ['-h']):\n            self.report_error('RTMP download detected but \"rtmpdump\" could not be run. Please install it.')\n            return False\n\n        # Download using rtmpdump. rtmpdump returns exit code 2 when\n        # the connection was interrupted and resuming appears to be\n        # possible. This is part of rtmpdump's normal usage, AFAIK.\n        basic_args = [\n            'rtmpdump', '--verbose', '-r', url,\n            '-o', tmpfilename]\n        if player_url is not None:\n            basic_args += ['--swfVfy', player_url]\n        if page_url is not None:\n            basic_args += ['--pageUrl', page_url]\n        if app is not None:\n            basic_args += ['--app', app]\n        if play_path is not None:\n            basic_args += ['--playpath', play_path]\n        if tc_url is not None:\n            basic_args += ['--tcUrl', tc_url]\n        if test:\n            basic_args += ['--stop', '1']\n        if flash_version is not None:\n            basic_args += ['--flashVer', flash_version]\n        if live:\n            basic_args += ['--live']\n        if isinstance(conn, list):\n            for entry in conn:\n                basic_args += ['--conn', entry]\n        elif isinstance(conn, compat_str):\n            basic_args += ['--conn', conn]\n        if protocol is not None:\n            basic_args += ['--protocol', protocol]\n        if real_time:\n            basic_args += ['--realtime']\n\n        args = basic_args\n        if not no_resume and continue_dl and not live:\n            args += ['--resume']\n        if not live and continue_dl:\n            args += ['--skip', '1']\n\n        args = [encodeArgument(a) for a in args]\n\n        self._debug_cmd(args, exe='rtmpdump')\n\n        RD_SUCCESS = 0\n        RD_FAILED = 1\n        RD_INCOMPLETE = 2\n        RD_NO_CONNECT = 3\n\n        retval = run_rtmpdump(args)\n\n        if retval == RD_NO_CONNECT:\n            self.report_error('[rtmpdump] Could not connect to RTMP server.')\n            return False\n\n        while retval in (RD_INCOMPLETE, RD_FAILED) and not test and not live:\n            prevsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % prevsize)\n            time.sleep(5.0)  # This seems to be needed\n            args = basic_args + ['--resume']\n            if retval == RD_FAILED:\n                args += ['--skip', '1']\n            args = [encodeArgument(a) for a in args]\n            retval = run_rtmpdump(args)\n            cursize = os.path.getsize(encodeFilename(tmpfilename))\n            if prevsize == cursize and retval == RD_FAILED:\n                break\n            # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those\n            if prevsize == cursize and retval == RD_INCOMPLETE and cursize > 1024:\n                self.to_screen('[rtmpdump] Could not download the whole video. This can happen for some advertisements.')\n                retval = RD_SUCCESS\n                break\n        if retval == RD_SUCCESS or (test and retval == RD_INCOMPLETE):\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % fsize)\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('rtmpdump exited with code %d' % retval)\n            return False",
        "begin_line": 24,
        "end_line": 203,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.downloader.rtsp.RtspFD.real_download#14",
        "src_path": "youtube_dl/downloader/rtsp.py",
        "class_name": "youtube_dl.downloader.rtsp.RtspFD",
        "signature": "youtube_dl.downloader.rtsp.RtspFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        if check_executable('mplayer', ['-h']):\n            args = [\n                'mplayer', '-really-quiet', '-vo', 'null', '-vc', 'dummy',\n                '-dumpstream', '-dumpfile', tmpfilename, url]\n        elif check_executable('mpv', ['-h']):\n            args = [\n                'mpv', '-really-quiet', '--vo=null', '--stream-dump=' + tmpfilename, url]\n        else:\n            self.report_error('MMS or RTSP download detected but neither \"mplayer\" nor \"mpv\" could be run. Please install any.')\n            return False\n\n        self._debug_cmd(args)\n\n        retval = subprocess.call(args)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('\\r[%s] %s bytes' % (args[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('%s exited with code %d' % (args[0], retval))\n            return False",
        "begin_line": 14,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractor_classes#19",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractor_classes()",
        "snippet": "def gen_extractor_classes():\n    \"\"\" Return a list of supported extractors.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return _ALL_CLASSES",
        "begin_line": 19,
        "end_line": 23,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractors#26",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractors()",
        "snippet": "def gen_extractors():\n    \"\"\" Return a list of an instance of every supported extractor.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return [klass() for klass in gen_extractor_classes()]",
        "begin_line": 26,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.__init__.list_extractors#33",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.list_extractors(age_limit)",
        "snippet": "def list_extractors(age_limit):\n    \"\"\"\n    Return a list of extractors that are suitable for the given age,\n    sorted by extractor ID.\n    \"\"\"\n\n    return sorted(\n        filter(lambda ie: ie.is_suitable(age_limit), gen_extractors()),\n        key=lambda ie: ie.IE_NAME.lower())",
        "begin_line": 33,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.__init__.get_info_extractor#44",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.get_info_extractor(ie_name)",
        "snippet": "def get_info_extractor(ie_name):\n    \"\"\"Returns the info extractor class with the given ie_name\"\"\"\n    return globals()[ie_name + 'IE']",
        "begin_line": 44,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abc.ABCIE._real_extract#58",
        "src_path": "youtube_dl/extractor/abc.py",
        "class_name": "youtube_dl.extractor.abc.ABCIE",
        "signature": "youtube_dl.extractor.abc.ABCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(\n            r'inline(?P<type>Video|Audio|YouTube)Data\\.push\\((?P<json_data>[^)]+)\\);',\n            webpage)\n        if mobj is None:\n            expired = self._html_search_regex(r'(?s)class=\"expired-(?:video|audio)\".+?<span>(.+?)</span>', webpage, 'expired', None)\n            if expired:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, expired), expected=True)\n            raise ExtractorError('Unable to extract video urls')\n\n        urls_info = self._parse_json(\n            mobj.group('json_data'), video_id, transform_source=js_to_json)\n\n        if not isinstance(urls_info, list):\n            urls_info = [urls_info]\n\n        if mobj.group('type') == 'YouTube':\n            return self.playlist_result([\n                self.url_result(url_info['url']) for url_info in urls_info])\n\n        formats = [{\n            'url': url_info['url'],\n            'vcodec': url_info.get('codec') if mobj.group('type') == 'Video' else 'none',\n            'width': int_or_none(url_info.get('width')),\n            'height': int_or_none(url_info.get('height')),\n            'tbr': int_or_none(url_info.get('bitrate')),\n            'filesize': int_or_none(url_info.get('filesize')),\n        } for url_info in urls_info]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 58,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abc.ABCIViewIE._real_extract#121",
        "src_path": "youtube_dl/extractor/abc.py",
        "class_name": "youtube_dl.extractor.abc.ABCIViewIE",
        "signature": "youtube_dl.extractor.abc.ABCIViewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_params = self._parse_json(self._search_regex(\n            r'videoParams\\s*=\\s*({.+?});', webpage, 'video params'), video_id)\n        title = video_params.get('title') or video_params['seriesTitle']\n        stream = next(s for s in video_params['playlist'] if s.get('type') == 'program')\n\n        format_urls = [\n            try_get(stream, lambda x: x['hds-unmetered'], compat_str)]\n\n        # May have higher quality video\n        sd_url = try_get(\n            stream, lambda x: x['streams']['hds']['sd'], compat_str)\n        if sd_url:\n            format_urls.append(sd_url.replace('metered', 'um'))\n\n        formats = []\n        for format_url in format_urls:\n            if format_url:\n                formats.extend(\n                    self._extract_akamai_formats(format_url, video_id))\n        self._sort_formats(formats)\n\n        subtitles = {}\n        src_vtt = stream.get('captions', {}).get('src-vtt')\n        if src_vtt:\n            subtitles['en'] = [{\n                'url': src_vtt,\n                'ext': 'vtt',\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': self._html_search_meta(['og:description', 'twitter:description'], webpage),\n            'thumbnail': self._html_search_meta(['og:image', 'twitter:image:src'], webpage),\n            'duration': int_or_none(video_params.get('eventDuration')),\n            'timestamp': parse_iso8601(video_params.get('pubDate'), ' '),\n            'series': video_params.get('seriesTitle'),\n            'series_id': video_params.get('seriesHouseNumber') or video_id[:7],\n            'episode_number': int_or_none(self._html_search_meta('episodeNumber', webpage, default=None)),\n            'episode': self._html_search_meta('episode_title', webpage, default=None),\n            'uploader_id': video_params.get('channel'),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 121,
        "end_line": 167,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abcnews.AbcNewsVideoIE._real_extract#48",
        "src_path": "youtube_dl/extractor/abcnews.py",
        "class_name": "youtube_dl.extractor.abcnews.AbcNewsVideoIE",
        "signature": "youtube_dl.extractor.abcnews.AbcNewsVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n        video_id = mobj.group('id')\n        info_dict = self._extract_feed_info(\n            'http://abcnews.go.com/video/itemfeed?id=%s' % video_id)\n        info_dict.update({\n            'id': video_id,\n            'display_id': display_id,\n        })\n        return info_dict",
        "begin_line": 48,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abcnews.AbcNewsIE._real_extract#101",
        "src_path": "youtube_dl/extractor/abcnews.py",
        "class_name": "youtube_dl.extractor.abcnews.AbcNewsIE",
        "signature": "youtube_dl.extractor.abcnews.AbcNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r'window\\.abcnvideo\\.url\\s*=\\s*\"([^\"]+)\"', webpage, 'video URL')\n        full_video_url = compat_urlparse.urljoin(url, video_url)\n\n        youtube_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"(https://www\\.youtube\\.com/embed/[^\"]+)\"',\n            webpage, 'YouTube URL', default=None)\n\n        timestamp = None\n        date_str = self._html_search_regex(\n            r'<span[^>]+class=\"timestamp\">([^<]+)</span>',\n            webpage, 'timestamp', fatal=False)\n        if date_str:\n            tz_offset = 0\n            if date_str.endswith(' ET'):  # Eastern Time\n                tz_offset = -5\n                date_str = date_str[:-3]\n            date_formats = ['%b. %d, %Y', '%b %d, %Y, %I:%M %p']\n            for date_format in date_formats:\n                try:\n                    timestamp = calendar.timegm(time.strptime(date_str.strip(), date_format))\n                except ValueError:\n                    continue\n            if timestamp is not None:\n                timestamp -= tz_offset * 3600\n\n        entry = {\n            '_type': 'url_transparent',\n            'ie_key': AbcNewsVideoIE.ie_key(),\n            'url': full_video_url,\n            'id': video_id,\n            'display_id': display_id,\n            'timestamp': timestamp,\n        }\n\n        if youtube_url:\n            entries = [entry, self.url_result(youtube_url, 'Youtube')]\n            return self.playlist_result(entries)\n\n        return entry",
        "begin_line": 101,
        "end_line": 146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abcotvs.ABCOTVSIE._real_extract#42",
        "src_path": "youtube_dl/extractor/abcotvs.py",
        "class_name": "youtube_dl.extractor.abcotvs.ABCOTVSIE",
        "signature": "youtube_dl.extractor.abcotvs.ABCOTVSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        m3u8 = self._html_search_meta(\n            'contentURL', webpage, 'm3u8 url', fatal=True).split('?')[0]\n\n        formats = self._extract_m3u8_formats(m3u8, display_id, 'mp4')\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage).strip()\n        description = self._og_search_description(webpage).strip()\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<div class=\"meta\">\\s*<time class=\"timeago\" datetime=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'rel=\"author\">([^<]+)</a>',\n            webpage, 'uploader', default=None)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 42,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.abcotvs.ABCOTVSClipsIE._real_extract#96",
        "src_path": "youtube_dl/extractor/abcotvs.py",
        "class_name": "youtube_dl.extractor.abcotvs.ABCOTVSClipsIE",
        "signature": "youtube_dl.extractor.abcotvs.ABCOTVSClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json('https://clips.abcotvs.com/vogo/video/getByIds?ids=' + video_id, video_id)['results'][0]\n        title = video_data['title']\n        formats = self._extract_m3u8_formats(\n            video_data['videoURL'].split('?')[0], video_id, 'mp4')\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnailURL'),\n            'duration': int_or_none(video_data.get('duration')),\n            'timestamp': int_or_none(video_data.get('pubDate')),\n            'formats': formats,\n        }",
        "begin_line": 96,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract#21",
        "src_path": "youtube_dl/extractor/academicearth.py",
        "class_name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE",
        "signature": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"playlist-name\"[^>]*?>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<p class=\"excerpt\"[^>]*?>(.*?)</p>',\n            webpage, 'description', fatal=False)\n        urls = re.findall(\n            r'<li class=\"lecture-preview\">\\s*?<a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage)\n        entries = [self.url_result(u) for u in urls]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.acast.ACastIE._real_extract#47",
        "src_path": "youtube_dl/extractor/acast.py",
        "class_name": "youtube_dl.extractor.acast.ACastIE",
        "signature": "youtube_dl.extractor.acast.ACastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel, display_id = re.match(self._VALID_URL, url).groups()\n        cast_data = self._download_json(\n            'https://embed.acast.com/api/acasts/%s/%s' % (channel, display_id), display_id)\n        return {\n            'id': compat_str(cast_data['id']),\n            'display_id': display_id,\n            'url': [b['audio'] for b in cast_data['blings'] if b['type'] == 'BlingAudio'][0],\n            'title': cast_data['name'],\n            'description': cast_data.get('description'),\n            'thumbnail': cast_data.get('image'),\n            'timestamp': parse_iso8601(cast_data.get('publishingDate')),\n            'duration': int_or_none(cast_data.get('duration')),\n        }",
        "begin_line": 47,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.acast.ACastChannelIE.suitable#79",
        "src_path": "youtube_dl/extractor/acast.py",
        "class_name": "youtube_dl.extractor.acast.ACastChannelIE",
        "signature": "youtube_dl.extractor.acast.ACastChannelIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if ACastIE.suitable(url) else super(ACastChannelIE, cls).suitable(url)",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.acast.ACastChannelIE._fetch_page#82",
        "src_path": "youtube_dl/extractor/acast.py",
        "class_name": "youtube_dl.extractor.acast.ACastChannelIE",
        "signature": "youtube_dl.extractor.acast.ACastChannelIE._fetch_page(self, channel_slug, page)",
        "snippet": "    def _fetch_page(self, channel_slug, page):\n        casts = self._download_json(\n            self._API_BASE_URL + 'channels/%s/acasts?page=%s' % (channel_slug, page),\n            channel_slug, note='Download page %d of channel data' % page)\n        for cast in casts:\n            yield self.url_result(\n                'https://www.acast.com/%s/%s' % (channel_slug, cast['url']),\n                'ACast', cast['id'])",
        "begin_line": 82,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.acast.ACastChannelIE._real_extract#91",
        "src_path": "youtube_dl/extractor/acast.py",
        "class_name": "youtube_dl.extractor.acast.ACastChannelIE",
        "signature": "youtube_dl.extractor.acast.ACastChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_slug = self._match_id(url)\n        channel_data = self._download_json(\n            self._API_BASE_URL + 'channels/%s' % channel_slug, channel_slug)\n        entries = OnDemandPagedList(functools.partial(\n            self._fetch_page, channel_slug), self._PAGE_SIZE)\n        return self.playlist_result(entries, compat_str(\n            channel_data['id']), channel_data['name'], channel_data.get('description'))",
        "begin_line": 91,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract#35",
        "src_path": "youtube_dl/extractor/addanime.py",
        "class_name": "youtube_dl.extractor.addanime.AddAnimeIE",
        "signature": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            webpage = self._download_webpage(url, video_id)\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError) or \\\n               ee.cause.code != 503:\n                raise\n\n            redir_webpage = ee.cause.read().decode('utf-8')\n            action = self._search_regex(\n                r'<form id=\"challenge-form\" action=\"([^\"]+)\"',\n                redir_webpage, 'Redirect form')\n            vc = self._search_regex(\n                r'<input type=\"hidden\" name=\"jschl_vc\" value=\"([^\"]+)\"/>',\n                redir_webpage, 'redirect vc value')\n            av = re.search(\n                r'a\\.value = ([0-9]+)[+]([0-9]+)[*]([0-9]+);',\n                redir_webpage)\n            if av is None:\n                raise ExtractorError('Cannot find redirect math task')\n            av_res = int(av.group(1)) + int(av.group(2)) * int(av.group(3))\n\n            parsed_url = compat_urllib_parse_urlparse(url)\n            av_val = av_res + len(parsed_url.netloc)\n            confirm_url = (\n                parsed_url.scheme + '://' + parsed_url.netloc +\n                action + '?' +\n                compat_urllib_parse_urlencode({\n                    'jschl_vc': vc, 'jschl_answer': compat_str(av_val)}))\n            self._download_webpage(\n                confirm_url, video_id,\n                note='Confirming after redirect')\n            webpage = self._download_webpage(url, video_id)\n\n        FORMATS = ('normal', 'hq')\n        quality = qualities(FORMATS)\n        formats = []\n        for format_id in FORMATS:\n            rex = r\"var %s_video_file = '(.*?)';\" % re.escape(format_id)\n            video_url = self._search_regex(rex, webpage, 'video file URLx',\n                                           fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n        video_title = self._og_search_title(webpage)\n        video_description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'description': video_description\n        }",
        "begin_line": 35,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adn.ADNIE._get_subtitles#37",
        "src_path": "youtube_dl/extractor/adn.py",
        "class_name": "youtube_dl.extractor.adn.ADNIE",
        "signature": "youtube_dl.extractor.adn.ADNIE._get_subtitles(self, sub_path, video_id)",
        "snippet": "    def _get_subtitles(self, sub_path, video_id):\n        if not sub_path:\n            return None\n\n        enc_subtitles = self._download_webpage(\n            urljoin(self._BASE_URL, sub_path),\n            video_id, fatal=False, headers={\n                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0',\n            })\n        if not enc_subtitles:\n            return None\n\n        # http://animedigitalnetwork.fr/components/com_vodvideo/videojs/adn-vjs.min.js\n        dec_subtitles = intlist_to_bytes(aes_cbc_decrypt(\n            bytes_to_intlist(base64.b64decode(enc_subtitles[24:])),\n            bytes_to_intlist(b'\\x1b\\xe0\\x29\\x61\\x38\\x94\\x24\\x00\\x12\\xbd\\xc5\\x80\\xac\\xce\\xbe\\xb0'),\n            bytes_to_intlist(base64.b64decode(enc_subtitles[:24]))\n        ))\n        subtitles_json = self._parse_json(\n            dec_subtitles[:-compat_ord(dec_subtitles[-1])].decode(),\n            None, fatal=False)\n        if not subtitles_json:\n            return None\n\n        subtitles = {}\n        for sub_lang, sub in subtitles_json.items():\n            srt = ''\n            for num, current in enumerate(sub):\n                start, end, text = (\n                    float_or_none(current.get('startTime')),\n                    float_or_none(current.get('endTime')),\n                    current.get('text'))\n                if start is None or end is None or text is None:\n                    continue\n                srt += os.linesep.join(\n                    (\n                        '%d' % num,\n                        '%s --> %s' % (\n                            srt_subtitles_timecode(start),\n                            srt_subtitles_timecode(end)),\n                        text,\n                        os.linesep,\n                    ))\n\n            if sub_lang == 'vostf':\n                sub_lang = 'fr'\n            subtitles.setdefault(sub_lang, []).extend([{\n                'ext': 'json',\n                'data': json.dumps(sub),\n            }, {\n                'ext': 'srt',\n                'data': srt,\n            }])\n        return subtitles",
        "begin_line": 37,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adn.ADNIE._real_extract#92",
        "src_path": "youtube_dl/extractor/adn.py",
        "class_name": "youtube_dl.extractor.adn.ADNIE",
        "signature": "youtube_dl.extractor.adn.ADNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        player_config = self._parse_json(self._search_regex(\n            r'playerConfig\\s*=\\s*({.+});', webpage, 'player config'), video_id)\n\n        video_info = {}\n        video_info_str = self._search_regex(\n            r'videoInfo\\s*=\\s*({.+});', webpage,\n            'video info', fatal=False)\n        if video_info_str:\n            video_info = self._parse_json(\n                video_info_str, video_id, fatal=False) or {}\n\n        options = player_config.get('options') or {}\n        metas = options.get('metas') or {}\n        title = metas.get('title') or video_info['title']\n        links = player_config.get('links') or {}\n        error = None\n        if not links:\n            links_url = player_config['linksurl']\n            links_data = self._download_json(urljoin(\n                self._BASE_URL, links_url), video_id)\n            links = links_data.get('links') or {}\n            error = links_data.get('error')\n\n        formats = []\n        for format_id, qualities in links.items():\n            if not isinstance(qualities, dict):\n                continue\n            for load_balancer_url in qualities.values():\n                load_balancer_data = self._download_json(\n                    load_balancer_url, video_id, fatal=False) or {}\n                m3u8_url = load_balancer_data.get('location')\n                if not m3u8_url:\n                    continue\n                m3u8_formats = self._extract_m3u8_formats(\n                    m3u8_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=format_id, fatal=False)\n                if format_id == 'vf':\n                    for f in m3u8_formats:\n                        f['language'] = 'fr'\n                formats.extend(m3u8_formats)\n        if not error:\n            error = options.get('error')\n        if not formats and error:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': strip_or_none(metas.get('summary') or video_info.get('resume')),\n            'thumbnail': video_info.get('image'),\n            'formats': formats,\n            'subtitles': self.extract_subtitles(player_config.get('subtitles'), video_id),\n            'episode': metas.get('subtitle') or video_info.get('videoTitle'),\n            'series': video_info.get('playlistTitle'),\n        }",
        "begin_line": 92,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobepass.AdobePassIE._download_webpage_handle#1327",
        "src_path": "youtube_dl/extractor/adobepass.py",
        "class_name": "youtube_dl.extractor.adobepass.AdobePassIE",
        "signature": "youtube_dl.extractor.adobepass.AdobePassIE._download_webpage_handle(self, *args, **kwargs)",
        "snippet": "    def _download_webpage_handle(self, *args, **kwargs):\n        headers = kwargs.get('headers', {})\n        headers.update(self.geo_verification_headers())\n        kwargs['headers'] = headers\n        return super(AdobePassIE, self)._download_webpage_handle(\n            *args, **compat_kwargs(kwargs))",
        "begin_line": 1327,
        "end_line": 1332,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobepass.AdobePassIE._get_mvpd_resource#1335",
        "src_path": "youtube_dl/extractor/adobepass.py",
        "class_name": "youtube_dl.extractor.adobepass.AdobePassIE",
        "signature": "youtube_dl.extractor.adobepass.AdobePassIE._get_mvpd_resource(provider_id, title, guid, rating)",
        "snippet": "    def _get_mvpd_resource(provider_id, title, guid, rating):\n        channel = etree.Element('channel')\n        channel_title = etree.SubElement(channel, 'title')\n        channel_title.text = provider_id\n        item = etree.SubElement(channel, 'item')\n        resource_title = etree.SubElement(item, 'title')\n        resource_title.text = title\n        resource_guid = etree.SubElement(item, 'guid')\n        resource_guid.text = guid\n        resource_rating = etree.SubElement(item, 'media:rating')\n        resource_rating.attrib = {'scheme': 'urn:v-chip'}\n        resource_rating.text = rating\n        return '<rss version=\"2.0\" xmlns:media=\"http://search.yahoo.com/mrss/\">' + etree.tostring(channel).decode() + '</rss>'",
        "begin_line": 1335,
        "end_line": 1347,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobepass.AdobePassIE._extract_mvpd_auth#1349",
        "src_path": "youtube_dl/extractor/adobepass.py",
        "class_name": "youtube_dl.extractor.adobepass.AdobePassIE",
        "signature": "youtube_dl.extractor.adobepass.AdobePassIE._extract_mvpd_auth(self, url, video_id, requestor_id, resource)",
        "snippet": "    def _extract_mvpd_auth(self, url, video_id, requestor_id, resource):\n        def xml_text(xml_str, tag):\n            return self._search_regex(\n                '<%s>(.+?)</%s>' % (tag, tag), xml_str, tag)\n\n        def is_expired(token, date_ele):\n            token_expires = unified_timestamp(re.sub(r'[_ ]GMT', '', xml_text(token, date_ele)))\n            return token_expires and token_expires <= int(time.time())\n\n        def post_form(form_page_res, note, data={}):\n            form_page, urlh = form_page_res\n            post_url = self._html_search_regex(r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', form_page, 'post url', group='url')\n            if not re.match(r'https?://', post_url):\n                post_url = compat_urlparse.urljoin(urlh.geturl(), post_url)\n            form_data = self._hidden_inputs(form_page)\n            form_data.update(data)\n            return self._download_webpage_handle(\n                post_url, video_id, note, data=urlencode_postdata(form_data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded',\n                })\n\n        def raise_mvpd_required():\n            raise ExtractorError(\n                'This video is only available for users of participating TV providers. '\n                'Use --ap-mso to specify Adobe Pass Multiple-system operator Identifier '\n                'and --ap-username and --ap-password or --netrc to provide account credentials.', expected=True)\n\n        def extract_redirect_url(html, url=None, fatal=False):\n            # TODO: eliminate code duplication with generic extractor and move\n            # redirection code into _download_webpage_handle\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            redirect_url = self._search_regex(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                html, 'meta refresh redirect',\n                default=NO_DEFAULT if fatal else None, fatal=fatal)\n            if not redirect_url:\n                return None\n            if url:\n                redirect_url = compat_urlparse.urljoin(url, unescapeHTML(redirect_url))\n            return redirect_url\n\n        mvpd_headers = {\n            'ap_42': 'anonymous',\n            'ap_11': 'Linux i686',\n            'ap_z': self._USER_AGENT,\n            'User-Agent': self._USER_AGENT,\n        }\n\n        guid = xml_text(resource, 'guid') if '<' in resource else resource\n        count = 0\n        while count < 2:\n            requestor_info = self._downloader.cache.load(self._MVPD_CACHE, requestor_id) or {}\n            authn_token = requestor_info.get('authn_token')\n            if authn_token and is_expired(authn_token, 'simpleTokenExpires'):\n                authn_token = None\n            if not authn_token:\n                # TODO add support for other TV Providers\n                mso_id = self._downloader.params.get('ap_mso')\n                if not mso_id:\n                    raise_mvpd_required()\n                username, password = self._get_login_info('ap_username', 'ap_password', mso_id)\n                if not username or not password:\n                    raise_mvpd_required()\n                mso_info = MSO_INFO[mso_id]\n\n                provider_redirect_page_res = self._download_webpage_handle(\n                    self._SERVICE_PROVIDER_TEMPLATE % 'authenticate/saml', video_id,\n                    'Downloading Provider Redirect Page', query={\n                        'noflash': 'true',\n                        'mso_id': mso_id,\n                        'requestor_id': requestor_id,\n                        'no_iframe': 'false',\n                        'domain_name': 'adobe.com',\n                        'redirect_url': url,\n                    })\n\n                if mso_id == 'Comcast_SSO':\n                    # Comcast page flow varies by video site and whether you\n                    # are on Comcast's network.\n                    provider_redirect_page, urlh = provider_redirect_page_res\n                    if 'automatically signing you in' in provider_redirect_page:\n                        oauth_redirect_url = self._html_search_regex(\n                            r'window\\.location\\s*=\\s*[\\'\"]([^\\'\"]+)',\n                            provider_redirect_page, 'oauth redirect')\n                        self._download_webpage(\n                            oauth_redirect_url, video_id, 'Confirming auto login')\n                    else:\n                        if '<form name=\"signin\"' in provider_redirect_page:\n                            provider_login_page_res = provider_redirect_page_res\n                        elif 'http-equiv=\"refresh\"' in provider_redirect_page:\n                            oauth_redirect_url = extract_redirect_url(\n                                provider_redirect_page, fatal=True)\n                            provider_login_page_res = self._download_webpage_handle(\n                                oauth_redirect_url, video_id,\n                                self._DOWNLOADING_LOGIN_PAGE)\n                        else:\n                            provider_login_page_res = post_form(\n                                provider_redirect_page_res,\n                                self._DOWNLOADING_LOGIN_PAGE)\n\n                        mvpd_confirm_page_res = post_form(\n                            provider_login_page_res, 'Logging in', {\n                                mso_info['username_field']: username,\n                                mso_info['password_field']: password,\n                            })\n                        mvpd_confirm_page, urlh = mvpd_confirm_page_res\n                        if '<button class=\"submit\" value=\"Resume\">Resume</button>' in mvpd_confirm_page:\n                            post_form(mvpd_confirm_page_res, 'Confirming Login')\n                elif mso_id == 'Verizon':\n                    # In general, if you're connecting from a Verizon-assigned IP,\n                    # you will not actually pass your credentials.\n                    provider_redirect_page, urlh = provider_redirect_page_res\n                    if 'Please wait ...' in provider_redirect_page:\n                        saml_redirect_url = self._html_search_regex(\n                            r'self\\.parent\\.location=([\"\\'])(?P<url>.+?)\\1',\n                            provider_redirect_page,\n                            'SAML Redirect URL', group='url')\n                        saml_login_page = self._download_webpage(\n                            saml_redirect_url, video_id,\n                            'Downloading SAML Login Page')\n                    else:\n                        saml_login_page_res = post_form(\n                            provider_redirect_page_res, 'Logging in', {\n                                mso_info['username_field']: username,\n                                mso_info['password_field']: password,\n                            })\n                        saml_login_page, urlh = saml_login_page_res\n                        if 'Please try again.' in saml_login_page:\n                            raise ExtractorError(\n                                'We\\'re sorry, but either the User ID or Password entered is not correct.')\n                    saml_login_url = self._search_regex(\n                        r'xmlHttp\\.open\\(\"POST\"\\s*,\\s*([\"\\'])(?P<url>.+?)\\1',\n                        saml_login_page, 'SAML Login URL', group='url')\n                    saml_response_json = self._download_json(\n                        saml_login_url, video_id, 'Downloading SAML Response',\n                        headers={'Content-Type': 'text/xml'})\n                    self._download_webpage(\n                        saml_response_json['targetValue'], video_id,\n                        'Confirming Login', data=urlencode_postdata({\n                            'SAMLResponse': saml_response_json['SAMLResponse'],\n                            'RelayState': saml_response_json['RelayState']\n                        }), headers={\n                            'Content-Type': 'application/x-www-form-urlencoded'\n                        })\n                else:\n                    # Some providers (e.g. DIRECTV NOW) have another meta refresh\n                    # based redirect that should be followed.\n                    provider_redirect_page, urlh = provider_redirect_page_res\n                    provider_refresh_redirect_url = extract_redirect_url(\n                        provider_redirect_page, url=urlh.geturl())\n                    if provider_refresh_redirect_url:\n                        provider_redirect_page_res = self._download_webpage_handle(\n                            provider_refresh_redirect_url, video_id,\n                            'Downloading Provider Redirect Page (meta refresh)')\n                    provider_login_page_res = post_form(\n                        provider_redirect_page_res, self._DOWNLOADING_LOGIN_PAGE)\n                    mvpd_confirm_page_res = post_form(provider_login_page_res, 'Logging in', {\n                        mso_info.get('username_field', 'username'): username,\n                        mso_info.get('password_field', 'password'): password,\n                    })\n                    if mso_id != 'Rogers':\n                        post_form(mvpd_confirm_page_res, 'Confirming Login')\n\n                session = self._download_webpage(\n                    self._SERVICE_PROVIDER_TEMPLATE % 'session', video_id,\n                    'Retrieving Session', data=urlencode_postdata({\n                        '_method': 'GET',\n                        'requestor_id': requestor_id,\n                    }), headers=mvpd_headers)\n                if '<pendingLogout' in session:\n                    self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})\n                    count += 1\n                    continue\n                authn_token = unescapeHTML(xml_text(session, 'authnToken'))\n                requestor_info['authn_token'] = authn_token\n                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, requestor_info)\n\n            authz_token = requestor_info.get(guid)\n            if authz_token and is_expired(authz_token, 'simpleTokenTTL'):\n                authz_token = None\n            if not authz_token:\n                authorize = self._download_webpage(\n                    self._SERVICE_PROVIDER_TEMPLATE % 'authorize', video_id,\n                    'Retrieving Authorization Token', data=urlencode_postdata({\n                        'resource_id': resource,\n                        'requestor_id': requestor_id,\n                        'authentication_token': authn_token,\n                        'mso_id': xml_text(authn_token, 'simpleTokenMsoID'),\n                        'userMeta': '1',\n                    }), headers=mvpd_headers)\n                if '<pendingLogout' in authorize:\n                    self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})\n                    count += 1\n                    continue\n                if '<error' in authorize:\n                    raise ExtractorError(xml_text(authorize, 'details'), expected=True)\n                authz_token = unescapeHTML(xml_text(authorize, 'authzToken'))\n                requestor_info[guid] = authz_token\n                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, requestor_info)\n\n            mvpd_headers.update({\n                'ap_19': xml_text(authn_token, 'simpleSamlNameID'),\n                'ap_23': xml_text(authn_token, 'simpleSamlSessionIndex'),\n            })\n\n            short_authorize = self._download_webpage(\n                self._SERVICE_PROVIDER_TEMPLATE % 'shortAuthorize',\n                video_id, 'Retrieving Media Token', data=urlencode_postdata({\n                    'authz_token': authz_token,\n                    'requestor_id': requestor_id,\n                    'session_guid': xml_text(authn_token, 'simpleTokenAuthenticationGuid'),\n                    'hashed_guid': 'false',\n                }), headers=mvpd_headers)\n            if '<pendingLogout' in short_authorize:\n                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})\n                count += 1\n                continue\n            return short_authorize",
        "begin_line": 1349,
        "end_line": 1567,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVIE._real_extract#40",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        language, show_urlname, urlname = re.match(self._VALID_URL, url).groups()\n        if not language:\n            language = 'en'\n\n        video_data = self._download_json(\n            self._API_BASE_URL + 'episode/get/?language=%s&show_urlname=%s&urlname=%s&disclosure=standard' % (language, show_urlname, urlname),\n            urlname)['data'][0]\n\n        formats = [{\n            'url': source['url'],\n            'format_id': source.get('quality_level') or source['url'].split('-')[-1].split('.')[0] or None,\n            'width': int_or_none(source.get('width')),\n            'height': int_or_none(source.get('height')),\n            'tbr': int_or_none(source.get('video_data_rate')),\n        } for source in video_data['videos']]\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(video_data['id']),\n            'title': video_data['title'],\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnail'),\n            'upload_date': unified_strdate(video_data.get('start_date')),\n            'duration': parse_duration(video_data.get('duration')),\n            'view_count': str_to_int(video_data.get('playcount')),\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE._parse_page_data#71",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE._parse_page_data(self, page_data)",
        "snippet": "    def _parse_page_data(self, page_data):\n        return [self.url_result(self._get_element_url(element_data)) for element_data in page_data]",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE._extract_playlist_entries#74",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVPlaylistBaseIE._extract_playlist_entries(self, url, display_id)",
        "snippet": "    def _extract_playlist_entries(self, url, display_id):\n        page = self._download_json(url, display_id)\n        entries = self._parse_page_data(page['data'])\n        for page_num in range(2, page['paging']['pages'] + 1):\n            entries.extend(self._parse_page_data(\n                self._download_json(url + '&page=%d' % page_num, display_id)['data']))\n        return entries",
        "begin_line": 74,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVShowIE._get_element_url#96",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVShowIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVShowIE._get_element_url(self, element_data)",
        "snippet": "    def _get_element_url(self, element_data):\n        return element_data['urls'][0]",
        "begin_line": 96,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVShowIE._real_extract#99",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVShowIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        language, show_urlname = re.match(self._VALID_URL, url).groups()\n        if not language:\n            language = 'en'\n        query = 'language=%s&show_urlname=%s' % (language, show_urlname)\n\n        show_data = self._download_json(self._API_BASE_URL + 'show/get/?%s' % query, show_urlname)['data'][0]\n\n        return self.playlist_result(\n            self._extract_playlist_entries(self._API_BASE_URL + 'episode/?%s' % query, show_urlname),\n            compat_str(show_data['id']),\n            show_data['show_name'],\n            show_data['show_description'])",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVChannelIE._get_element_url#125",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVChannelIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVChannelIE._get_element_url(self, element_data)",
        "snippet": "    def _get_element_url(self, element_data):\n        return element_data['url']",
        "begin_line": 125,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVChannelIE._real_extract#128",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVChannelIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        language, channel_urlname, category_urlname = re.match(self._VALID_URL, url).groups()\n        if not language:\n            language = 'en'\n        query = 'language=%s&channel_urlname=%s' % (language, channel_urlname)\n        if category_urlname:\n            query += '&category_urlname=%s' % category_urlname\n\n        return self.playlist_result(\n            self._extract_playlist_entries(self._API_BASE_URL + 'show/?%s' % query, channel_urlname),\n            channel_urlname)",
        "begin_line": 128,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract#157",
        "src_path": "youtube_dl/extractor/adobetv.py",
        "class_name": "youtube_dl.extractor.adobetv.AdobeTVVideoIE",
        "signature": "youtube_dl.extractor.adobetv.AdobeTVVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_data = self._parse_json(self._search_regex(\n            r'var\\s+bridge\\s*=\\s*([^;]+);', webpage, 'bridged data'), video_id)\n\n        formats = [{\n            'format_id': '%s-%s' % (determine_ext(source['src']), source.get('height')),\n            'url': source['src'],\n            'width': int_or_none(source.get('width')),\n            'height': int_or_none(source.get('height')),\n            'tbr': int_or_none(source.get('bitrate')),\n        } for source in video_data['sources']]\n        self._sort_formats(formats)\n\n        # For both metadata and downloaded files the duration varies among\n        # formats. I just pick the max one\n        duration = max(filter(None, [\n            float_or_none(source.get('duration'), scale=1000)\n            for source in video_data['sources']]))\n\n        subtitles = {}\n        for translation in video_data.get('translations', []):\n            lang_id = translation.get('language_w3c') or ISO639Utils.long2short(translation['language_medium'])\n            if lang_id not in subtitles:\n                subtitles[lang_id] = []\n            subtitles[lang_id].append({\n                'url': translation['vttPath'],\n                'ext': 'vtt',\n            })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_data['title'],\n            'description': video_data.get('description'),\n            'thumbnail': video_data['video'].get('poster'),\n            'duration': duration,\n            'subtitles': subtitles,\n        }",
        "begin_line": 157,
        "end_line": 197,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract#82",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_path, episode_path = re.match(self._VALID_URL, url).groups()\n        display_id = episode_path or show_path\n        webpage = self._download_webpage(url, display_id)\n        initial_data = self._parse_json(self._search_regex(\n            r'AS_INITIAL_DATA(?:__)?\\s*=\\s*({.+?});',\n            webpage, 'initial data'), display_id)\n\n        is_stream = show_path == 'streams'\n        if is_stream:\n            if not episode_path:\n                episode_path = 'live-stream'\n\n            video_data = next(stream for stream_path, stream in initial_data['streams'].items() if stream_path == episode_path)\n            video_id = video_data.get('stream')\n\n            if not video_id:\n                entries = []\n                for episode in video_data.get('archiveEpisodes', []):\n                    episode_url = episode.get('url')\n                    if not episode_url:\n                        continue\n                    entries.append(self.url_result(\n                        episode_url, 'AdultSwim', episode.get('id')))\n                return self.playlist_result(\n                    entries, video_data.get('id'), video_data.get('title'),\n                    strip_or_none(video_data.get('description')))\n        else:\n            show_data = initial_data['show']\n\n            if not episode_path:\n                entries = []\n                for video in show_data.get('videos', []):\n                    slug = video.get('slug')\n                    if not slug:\n                        continue\n                    entries.append(self.url_result(\n                        'http://adultswim.com/videos/%s/%s' % (show_path, slug),\n                        'AdultSwim', video.get('id')))\n                return self.playlist_result(\n                    entries, show_data.get('id'), show_data.get('title'),\n                    strip_or_none(show_data.get('metadata', {}).get('description')))\n\n            video_data = show_data['sluggedVideo']\n            video_id = video_data['id']\n\n        info = self._extract_cvp_info(\n            'http://www.adultswim.com/videos/api/v0/assets?platform=desktop&id=' + video_id,\n            video_id, {\n                'secure': {\n                    'media_src': 'http://androidhls-secure.cdn.turner.com/adultswim/big',\n                    'tokenizer_src': 'http://www.adultswim.com/astv/mvpd/processors/services/token_ipadAdobe.do',\n                },\n            }, {\n                'url': url,\n                'site_name': 'AdultSwim',\n                'auth_required': video_data.get('auth'),\n            })\n\n        info.update({\n            'id': video_id,\n            'display_id': display_id,\n            'description': info.get('description') or strip_or_none(video_data.get('description')),\n        })\n        if not is_stream:\n            info.update({\n                'duration': info.get('duration') or int_or_none(video_data.get('duration')),\n                'timestamp': info.get('timestamp') or int_or_none(video_data.get('launch_date')),\n                'season_number': info.get('season_number') or int_or_none(video_data.get('season_number')),\n                'episode': info['title'],\n                'episode_number': info.get('episode_number') or int_or_none(video_data.get('episode_number')),\n            })\n\n            info['series'] = video_data.get('collection_title') or info.get('series')\n            if info['series'] and info['series'] != info['title']:\n                info['title'] = '%s - %s' % (info['series'], info['title'])\n\n        return info",
        "begin_line": 82,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aenetworks.AENetworksIE._real_extract#92",
        "src_path": "youtube_dl/extractor/aenetworks.py",
        "class_name": "youtube_dl.extractor.aenetworks.AENetworksIE",
        "signature": "youtube_dl.extractor.aenetworks.AENetworksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, show_path, movie_display_id, special_display_id = re.match(self._VALID_URL, url).groups()\n        display_id = show_path or movie_display_id or special_display_id\n        webpage = self._download_webpage(url, display_id)\n        if show_path:\n            url_parts = show_path.split('/')\n            url_parts_len = len(url_parts)\n            if url_parts_len == 1:\n                entries = []\n                for season_url_path in re.findall(r'(?s)<li[^>]+data-href=\"(/shows/%s/season-\\d+)\"' % url_parts[0], webpage):\n                    entries.append(self.url_result(\n                        compat_urlparse.urljoin(url, season_url_path), 'AENetworks'))\n                if entries:\n                    return self.playlist_result(\n                        entries, self._html_search_meta('aetn:SeriesId', webpage),\n                        self._html_search_meta('aetn:SeriesTitle', webpage))\n                else:\n                    # single season\n                    url_parts_len = 2\n            if url_parts_len == 2:\n                entries = []\n                for episode_item in re.findall(r'(?s)<[^>]+class=\"[^\"]*(?:episode|program)-item[^\"]*\"[^>]*>', webpage):\n                    episode_attributes = extract_attributes(episode_item)\n                    episode_url = compat_urlparse.urljoin(\n                        url, episode_attributes['data-canonical'])\n                    entries.append(self.url_result(\n                        episode_url, 'AENetworks',\n                        episode_attributes.get('data-videoid') or episode_attributes.get('data-video-id')))\n                return self.playlist_result(\n                    entries, self._html_search_meta('aetn:SeasonId', webpage))\n\n        query = {\n            'mbr': 'true',\n            'assetTypes': 'high_video_s3'\n        }\n        video_id = self._html_search_meta('aetn:VideoID', webpage)\n        media_url = self._search_regex(\n            [r\"media_url\\s*=\\s*'(?P<url>[^']+)'\",\n             r'data-media-url=(?P<url>(?:https?:)?//[^\\s>]+)',\n             r'data-media-url=([\"\\'])(?P<url>(?:(?!\\1).)+?)\\1'],\n            webpage, 'video url', group='url')\n        theplatform_metadata = self._download_theplatform_metadata(self._search_regex(\n            r'https?://link.theplatform.com/s/([^?]+)', media_url, 'theplatform_path'), video_id)\n        info = self._parse_theplatform_metadata(theplatform_metadata)\n        if theplatform_metadata.get('AETN$isBehindWall'):\n            requestor_id = self._DOMAIN_TO_REQUESTOR_ID[domain]\n            resource = self._get_mvpd_resource(\n                requestor_id, theplatform_metadata['title'],\n                theplatform_metadata.get('AETN$PPL_pplProgramId') or theplatform_metadata.get('AETN$PPL_pplProgramId_OLD'),\n                theplatform_metadata['ratings'][0]['rating'])\n            query['auth'] = self._extract_mvpd_auth(\n                url, video_id, requestor_id, resource)\n        info.update(self._search_json_ld(webpage, video_id, fatal=False))\n        media_url = update_url_query(media_url, query)\n        media_url = self._sign_url(media_url, self._THEPLATFORM_KEY, self._THEPLATFORM_SECRET)\n        formats, subtitles = self._extract_theplatform_smil(media_url, video_id)\n        self._sort_formats(formats)\n        info.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': subtitles,\n        })\n        return info",
        "begin_line": 92,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aenetworks.HistoryTopicIE.theplatform_url_result#196",
        "src_path": "youtube_dl/extractor/aenetworks.py",
        "class_name": "youtube_dl.extractor.aenetworks.HistoryTopicIE",
        "signature": "youtube_dl.extractor.aenetworks.HistoryTopicIE.theplatform_url_result(self, theplatform_url, video_id, query)",
        "snippet": "    def theplatform_url_result(self, theplatform_url, video_id, query):\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': smuggle_url(\n                update_url_query(theplatform_url, query),\n                {\n                    'sig': {\n                        'key': self._THEPLATFORM_KEY,\n                        'secret': self._THEPLATFORM_SECRET,\n                    },\n                    'force_smil_url': True\n                }),\n            'ie_key': 'ThePlatform',\n        }",
        "begin_line": 196,
        "end_line": 210,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aenetworks.HistoryTopicIE._real_extract#212",
        "src_path": "youtube_dl/extractor/aenetworks.py",
        "class_name": "youtube_dl.extractor.aenetworks.HistoryTopicIE",
        "signature": "youtube_dl.extractor.aenetworks.HistoryTopicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        topic_id, video_display_id = re.match(self._VALID_URL, url).groups()\n        if video_display_id:\n            webpage = self._download_webpage(url, video_display_id)\n            release_url, video_id = re.search(r\"_videoPlayer.play\\('([^']+)'\\s*,\\s*'[^']+'\\s*,\\s*'(\\d+)'\\)\", webpage).groups()\n            release_url = unescapeHTML(release_url)\n\n            return self.theplatform_url_result(\n                release_url, video_id, {\n                    'mbr': 'true',\n                    'switch': 'hls',\n                    'assetTypes': 'high_video_ak',\n                })\n        else:\n            webpage = self._download_webpage(url, topic_id)\n            entries = []\n            for episode_item in re.findall(r'<a.+?data-release-url=\"[^\"]+\"[^>]*>', webpage):\n                video_attributes = extract_attributes(episode_item)\n                entries.append(self.theplatform_url_result(\n                    video_attributes['data-release-url'], video_attributes['data-id'], {\n                        'mbr': 'true',\n                        'switch': 'hls',\n                        'assetTypes': 'high_video_ak',\n                    }))\n            return self.playlist_result(entries, topic_id, get_element_by_attribute('class', 'show-title', webpage))",
        "begin_line": 212,
        "end_line": 236,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.afreecatv.AfreecaTVIE.parse_video_key#150",
        "src_path": "youtube_dl/extractor/afreecatv.py",
        "class_name": "youtube_dl.extractor.afreecatv.AfreecaTVIE",
        "signature": "youtube_dl.extractor.afreecatv.AfreecaTVIE.parse_video_key(key)",
        "snippet": "    def parse_video_key(key):\n        video_key = {}\n        m = re.match(r'^(?P<upload_date>\\d{8})_\\w+_(?P<part>\\d+)$', key)\n        if m:\n            video_key['upload_date'] = m.group('upload_date')\n            video_key['part'] = int(m.group('part'))\n        return video_key",
        "begin_line": 150,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.afreecatv.AfreecaTVIE._real_extract#158",
        "src_path": "youtube_dl/extractor/afreecatv.py",
        "class_name": "youtube_dl.extractor.afreecatv.AfreecaTVIE",
        "signature": "youtube_dl.extractor.afreecatv.AfreecaTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_xml = self._download_xml(\n            'http://afbbs.afreecatv.com:8080/api/video/get_video_info.php',\n            video_id, query={'nTitleNo': video_id})\n\n        video_element = video_xml.findall(compat_xpath('./track/video'))[1]\n        if video_element is None or video_element.text is None:\n            raise ExtractorError('Specified AfreecaTV video does not exist',\n                                 expected=True)\n\n        video_url = video_element.text.strip()\n\n        title = xpath_text(video_xml, './track/title', 'title', fatal=True)\n\n        uploader = xpath_text(video_xml, './track/nickname', 'uploader')\n        uploader_id = xpath_text(video_xml, './track/bj_id', 'uploader id')\n        duration = int_or_none(xpath_text(\n            video_xml, './track/duration', 'duration'))\n        thumbnail = xpath_text(video_xml, './track/titleImage', 'thumbnail')\n\n        common_entry = {\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n        }\n\n        info = common_entry.copy()\n        info.update({\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n        })\n\n        if not video_url:\n            entries = []\n            file_elements = video_element.findall(compat_xpath('./file'))\n            one = len(file_elements) == 1\n            for file_num, file_element in enumerate(file_elements, start=1):\n                file_url = file_element.text\n                if not file_url:\n                    continue\n                key = file_element.get('key', '')\n                upload_date = self._search_regex(\n                    r'^(\\d{8})_', key, 'upload date', default=None)\n                file_duration = int_or_none(file_element.get('duration'))\n                format_id = key if key else '%s_%s' % (video_id, file_num)\n                formats = self._extract_m3u8_formats(\n                    file_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls',\n                    note='Downloading part %d m3u8 information' % file_num)\n                file_info = common_entry.copy()\n                file_info.update({\n                    'id': format_id,\n                    'title': title if one else '%s (part %d)' % (title, file_num),\n                    'upload_date': upload_date,\n                    'duration': file_duration,\n                    'formats': formats,\n                })\n                entries.append(file_info)\n            entries_info = info.copy()\n            entries_info.update({\n                '_type': 'multi_video',\n                'entries': entries,\n            })\n            return entries_info\n\n        info = {\n            'id': video_id,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }\n\n        if determine_ext(video_url) == 'm3u8':\n            info['formats'] = self._extract_m3u8_formats(\n                video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls')\n        else:\n            app, playpath = video_url.split('mp4:')\n            info.update({\n                'url': app,\n                'ext': 'flv',\n                'play_path': 'mp4:' + playpath,\n                'rtmp_live': True,  # downloading won't end without this\n            })\n\n        return info",
        "begin_line": 158,
        "end_line": 248,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.afreecatv.AfreecaTVGlobalIE._real_extract#265",
        "src_path": "youtube_dl/extractor/afreecatv.py",
        "class_name": "youtube_dl.extractor.afreecatv.AfreecaTVGlobalIE",
        "signature": "youtube_dl.extractor.afreecatv.AfreecaTVGlobalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id, video_id = re.match(self._VALID_URL, url).groups()\n        video_type = 'video' if video_id else 'live'\n        query = {\n            'pt': 'view',\n            'bid': channel_id,\n        }\n        if video_id:\n            query['vno'] = video_id\n        video_data = self._download_json(\n            'http://api.afreeca.tv/%s/view_%s.php' % (video_type, video_type),\n            video_id or channel_id, query=query)['channel']\n\n        if video_data.get('result') != 1:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, video_data['remsg']))\n\n        title = video_data['title']\n\n        info = {\n            'thumbnail': video_data.get('thumb'),\n            'view_count': int_or_none(video_data.get('vcnt')),\n            'age_limit': int_or_none(video_data.get('grade')),\n            'uploader_id': channel_id,\n            'uploader': video_data.get('cname'),\n        }\n\n        if video_id:\n            entries = []\n            for i, f in enumerate(video_data.get('flist', [])):\n                video_key = self.parse_video_key(f.get('key', ''))\n                f_url = f.get('file')\n                if not video_key or not f_url:\n                    continue\n                entries.append({\n                    'id': '%s_%s' % (video_id, video_key.get('part', i + 1)),\n                    'title': title,\n                    'upload_date': video_key.get('upload_date'),\n                    'duration': int_or_none(f.get('length')),\n                    'url': f_url,\n                    'protocol': 'm3u8_native',\n                    'ext': 'mp4',\n                })\n\n            info.update({\n                'id': video_id,\n                'title': title,\n                'duration': int_or_none(video_data.get('length')),\n            })\n            if len(entries) > 1:\n                info['_type'] = 'multi_video'\n                info['entries'] = entries\n            elif len(entries) == 1:\n                i = entries[0].copy()\n                i.update(info)\n                info = i\n        else:\n            formats = []\n            for s in video_data.get('strm', []):\n                s_url = s.get('purl')\n                if not s_url:\n                    continue\n                stype = s.get('stype')\n                if stype == 'HLS':\n                    formats.extend(self._extract_m3u8_formats(\n                        s_url, channel_id, 'mp4', m3u8_id=stype, fatal=False))\n                elif stype == 'RTMP':\n                    format_id = [stype]\n                    label = s.get('label')\n                    if label:\n                        format_id.append(label)\n                    formats.append({\n                        'format_id': '-'.join(format_id),\n                        'url': s_url,\n                        'tbr': int_or_none(s.get('bps')),\n                        'height': int_or_none(s.get('brt')),\n                        'ext': 'flv',\n                        'rtmp_live': True,\n                    })\n            self._sort_formats(formats)\n\n            info.update({\n                'id': channel_id,\n                'title': self._live_title(title),\n                'is_live': True,\n                'formats': formats,\n            })\n\n        return info",
        "begin_line": 265,
        "end_line": 352,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.airmozilla.AirMozillaIE._real_extract#34",
        "src_path": "youtube_dl/extractor/airmozilla.py",
        "class_name": "youtube_dl.extractor.airmozilla.AirMozillaIE",
        "signature": "youtube_dl.extractor.airmozilla.AirMozillaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_id = self._html_search_regex(r'//vid\\.ly/(.*?)/embed', webpage, 'id')\n\n        embed_script = self._download_webpage('https://vid.ly/{0}/embed'.format(video_id), video_id)\n        jwconfig = self._parse_json(self._search_regex(\n            r'initCallback\\((.*)\\);', embed_script, 'metadata'), video_id)['config']\n\n        info_dict = self._parse_jwplayer_data(jwconfig, video_id)\n        view_count = int_or_none(self._html_search_regex(\n            r'Views since archived: ([0-9]+)',\n            webpage, 'view count', fatal=False))\n        timestamp = parse_iso8601(self._html_search_regex(\n            r'<time datetime=\"(.*?)\"', webpage, 'timestamp', fatal=False))\n        duration = parse_duration(self._search_regex(\n            r'Duration:\\s*(\\d+\\s*hours?\\s*\\d+\\s*minutes?)',\n            webpage, 'duration', fatal=False))\n\n        info_dict.update({\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': self._og_search_url(webpage),\n            'display_id': display_id,\n            'description': self._og_search_description(webpage),\n            'timestamp': timestamp,\n            'location': self._html_search_regex(r'Location: (.*)', webpage, 'location', default=None),\n            'duration': duration,\n            'view_count': view_count,\n            'categories': re.findall(r'<a href=\".*?\" class=\"channel\">(.*?)</a>', webpage),\n        })\n\n        return info_dict",
        "begin_line": 34,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aljazeera.AlJazeeraIE._real_extract#28",
        "src_path": "youtube_dl/extractor/aljazeera.py",
        "class_name": "youtube_dl.extractor.aljazeera.AlJazeeraIE",
        "signature": "youtube_dl.extractor.aljazeera.AlJazeeraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        program_name = self._match_id(url)\n        webpage = self._download_webpage(url, program_name)\n        brightcove_id = self._search_regex(\n            r'RenderPagesVideo\\(\\'(.+?)\\'', webpage, 'brightcove id')\n        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)",
        "begin_line": 28,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.allocine.AllocineIE._real_extract#76",
        "src_path": "youtube_dl/extractor/allocine.py",
        "class_name": "youtube_dl.extractor.allocine.AllocineIE",
        "signature": "youtube_dl.extractor.allocine.AllocineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        formats = []\n        quality = qualities(['ld', 'md', 'hd'])\n\n        model = self._html_search_regex(\n            r'data-model=\"([^\"]+)\"', webpage, 'data model', default=None)\n        if model:\n            model_data = self._parse_json(model, display_id)\n            video = model_data['videos'][0]\n            title = video['title']\n            for video_url in video['sources'].values():\n                video_id, format_id = url_basename(video_url).split('_')[:2]\n                formats.append({\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                    'url': video_url,\n                })\n            duration = int_or_none(video.get('duration'))\n            view_count = int_or_none(video.get('view_count'))\n            timestamp = unified_timestamp(try_get(\n                video, lambda x: x['added_at']['date'], compat_str))\n        else:\n            video_id = display_id\n            media_data = self._download_json(\n                'http://www.allocine.fr/ws/AcVisiondataV5.ashx?media=%s' % video_id, display_id)\n            title = remove_end(\n                self._html_search_regex(\n                    r'(?s)<title>(.+?)</title>', webpage, 'title').strip(),\n                ' - AlloCin\u00e9')\n            for key, value in media_data['video'].items():\n                if not key.endswith('Path'):\n                    continue\n                format_id = key[:-len('Path')]\n                formats.append({\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                    'url': value,\n                })\n            duration, view_count, timestamp = [None] * 3\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 76,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.alphaporno.AlphaPornoIE._real_extract#33",
        "src_path": "youtube_dl/extractor/alphaporno.py",
        "class_name": "youtube_dl.extractor.alphaporno.AlphaPornoIE",
        "signature": "youtube_dl.extractor.alphaporno.AlphaPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r\"video_id\\s*:\\s*'([^']+)'\", webpage, 'video id', default=None)\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video url')\n        ext = self._html_search_meta(\n            'encodingFormat', webpage, 'ext', default='.mp4')[1:]\n\n        title = self._search_regex(\n            [r'<meta content=\"([^\"]+)\" itemprop=\"description\">',\n             r'class=\"title\" itemprop=\"name\">([^<]+)<'],\n            webpage, 'title')\n        thumbnail = self._html_search_meta('thumbnail', webpage, 'thumbnail')\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date'))\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration'))\n        filesize_approx = parse_filesize(self._html_search_meta(\n            'contentSize', webpage, 'file size'))\n        bitrate = int_or_none(self._html_search_meta(\n            'bitrate', webpage, 'bitrate'))\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'ext': ext,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n            'tbr': bitrate,\n            'categories': categories,\n            'age_limit': age_limit,\n        }",
        "begin_line": 33,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.amcnetworks.AMCNetworksIE._real_extract#56",
        "src_path": "youtube_dl/extractor/amcnetworks.py",
        "class_name": "youtube_dl.extractor.amcnetworks.AMCNetworksIE",
        "signature": "youtube_dl.extractor.amcnetworks.AMCNetworksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        query = {\n            'mbr': 'true',\n            'manifest': 'm3u',\n        }\n        media_url = self._search_regex(\n            r'window\\.platformLinkURL\\s*=\\s*[\\'\"]([^\\'\"]+)',\n            webpage, 'media url')\n        theplatform_metadata = self._download_theplatform_metadata(self._search_regex(\n            r'link\\.theplatform\\.com/s/([^?]+)',\n            media_url, 'theplatform_path'), display_id)\n        info = self._parse_theplatform_metadata(theplatform_metadata)\n        video_id = theplatform_metadata['pid']\n        title = theplatform_metadata['title']\n        rating = try_get(\n            theplatform_metadata, lambda x: x['ratings'][0]['rating'])\n        auth_required = self._search_regex(\n            r'window\\.authRequired\\s*=\\s*(true|false);',\n            webpage, 'auth required')\n        if auth_required == 'true':\n            requestor_id = self._search_regex(\n                r'window\\.requestor_id\\s*=\\s*[\\'\"]([^\\'\"]+)',\n                webpage, 'requestor id')\n            resource = self._get_mvpd_resource(\n                requestor_id, title, video_id, rating)\n            query['auth'] = self._extract_mvpd_auth(\n                url, video_id, requestor_id, resource)\n        media_url = update_url_query(media_url, query)\n        formats, subtitles = self._extract_theplatform_smil(\n            media_url, video_id)\n        self._sort_formats(formats)\n        info.update({\n            'id': video_id,\n            'subtitles': subtitles,\n            'formats': formats,\n            'age_limit': parse_age_limit(parse_age_limit(rating)),\n        })\n        ns_keys = theplatform_metadata.get('$xmlns', {}).keys()\n        if ns_keys:\n            ns = list(ns_keys)[0]\n            series = theplatform_metadata.get(ns + '$show')\n            season_number = int_or_none(\n                theplatform_metadata.get(ns + '$season'))\n            episode = theplatform_metadata.get(ns + '$episodeTitle')\n            episode_number = int_or_none(\n                theplatform_metadata.get(ns + '$episode'))\n            if season_number:\n                title = 'Season %d - %s' % (season_number, title)\n            if series:\n                title = '%s - %s' % (series, title)\n            info.update({\n                'title': title,\n                'series': series,\n                'season_number': season_number,\n                'episode': episode,\n                'episode_number': episode_number,\n            })\n        return info",
        "begin_line": 56,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.amp.AMPIE._extract_feed_info#16",
        "src_path": "youtube_dl/extractor/amp.py",
        "class_name": "youtube_dl.extractor.amp.AMPIE",
        "signature": "youtube_dl.extractor.amp.AMPIE._extract_feed_info(self, url)",
        "snippet": "    def _extract_feed_info(self, url):\n        feed = self._download_json(\n            url, None, 'Downloading Akamai AMP feed',\n            'Unable to download Akamai AMP feed')\n        item = feed.get('channel', {}).get('item')\n        if not item:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, feed['error']))\n\n        video_id = item['guid']\n\n        def get_media_node(name, default=None):\n            media_name = 'media-%s' % name\n            media_group = item.get('media-group') or item\n            return media_group.get(media_name) or item.get(media_name) or item.get(name, default)\n\n        thumbnails = []\n        media_thumbnail = get_media_node('thumbnail')\n        if media_thumbnail:\n            if isinstance(media_thumbnail, dict):\n                media_thumbnail = [media_thumbnail]\n            for thumbnail_data in media_thumbnail:\n                thumbnail = thumbnail_data.get('@attributes', {})\n                thumbnail_url = thumbnail.get('url')\n                if not thumbnail_url:\n                    continue\n                thumbnails.append({\n                    'url': self._proto_relative_url(thumbnail_url, 'http:'),\n                    'width': int_or_none(thumbnail.get('width')),\n                    'height': int_or_none(thumbnail.get('height')),\n                })\n\n        subtitles = {}\n        media_subtitle = get_media_node('subTitle')\n        if media_subtitle:\n            if isinstance(media_subtitle, dict):\n                media_subtitle = [media_subtitle]\n            for subtitle_data in media_subtitle:\n                subtitle = subtitle_data.get('@attributes', {})\n                subtitle_href = subtitle.get('href')\n                if not subtitle_href:\n                    continue\n                subtitles.setdefault(subtitle.get('lang') or 'en', []).append({\n                    'url': subtitle_href,\n                    'ext': mimetype2ext(subtitle.get('type')) or determine_ext(subtitle_href),\n                })\n\n        formats = []\n        media_content = get_media_node('content')\n        if isinstance(media_content, dict):\n            media_content = [media_content]\n        for media_data in media_content:\n            media = media_data.get('@attributes', {})\n            media_url = media.get('url')\n            if not media_url:\n                continue\n            ext = mimetype2ext(media.get('type')) or determine_ext(media_url)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    media_url + '?hdcore=3.4.0&plugin=aasp-3.4.0.132.124',\n                    video_id, f4m_id='hds', fatal=False))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'format_id': media_data.get('media-category', {}).get('@attributes', {}).get('label'),\n                    'url': media['url'],\n                    'tbr': int_or_none(media.get('bitrate')),\n                    'filesize': int_or_none(media.get('fileSize')),\n                    'ext': ext,\n                })\n\n        self._sort_formats(formats)\n\n        timestamp = parse_iso8601(item.get('pubDate'), ' ') or parse_iso8601(item.get('dc-date'))\n\n        return {\n            'id': video_id,\n            'title': get_media_node('title'),\n            'description': get_media_node('description'),\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'duration': int_or_none(media_content[0].get('@attributes', {}).get('duration')),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 16,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._login#51",
        "src_path": "youtube_dl/extractor/animeondemand.py",
        "class_name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE",
        "signature": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        if '>Our licensing terms allow the distribution of animes only to German-speaking countries of Europe' in login_page:\n            self.raise_geo_restricted(\n                '%s is only available in German-speaking countries of Europe' % self.IE_NAME)\n\n        login_form = self._form_hidden_inputs('new_user', login_page)\n\n        login_form.update({\n            'user[login]': username,\n            'user[password]': password,\n        })\n\n        post_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', login_page,\n            'post url', default=self._LOGIN_URL, group='url')\n\n        if not post_url.startswith('http'):\n            post_url = compat_urlparse.urljoin(self._LOGIN_URL, post_url)\n\n        request = sanitized_Request(\n            post_url, urlencode_postdata(login_form))\n        request.add_header('Referer', self._LOGIN_URL)\n\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if all(p not in response for p in ('>Logout<', 'href=\"/users/sign_out\"')):\n            error = self._search_regex(\n                r'<p class=\"alert alert-danger\">(.+?)</p>',\n                response, 'error', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 51,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._real_initialize#92",
        "src_path": "youtube_dl/extractor/animeondemand.py",
        "class_name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE",
        "signature": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._real_extract#95",
        "src_path": "youtube_dl/extractor/animeondemand.py",
        "class_name": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE",
        "signature": "youtube_dl.extractor.animeondemand.AnimeOnDemandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        anime_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, anime_id)\n\n        if 'data-playlist=' not in webpage:\n            self._download_webpage(\n                self._APPLY_HTML5_URL, anime_id,\n                'Activating HTML5 beta', 'Unable to apply HTML5 beta')\n            webpage = self._download_webpage(url, anime_id)\n\n        csrf_token = self._html_search_meta(\n            'csrf-token', webpage, 'csrf token', fatal=True)\n\n        anime_title = self._html_search_regex(\n            r'(?s)<h1[^>]+itemprop=\"name\"[^>]*>(.+?)</h1>',\n            webpage, 'anime name')\n        anime_description = self._html_search_regex(\n            r'(?s)<div[^>]+itemprop=\"description\"[^>]*>(.+?)</div>',\n            webpage, 'anime description', default=None)\n\n        entries = []\n\n        def extract_info(html, video_id, num=None):\n            title, description = [None] * 2\n            formats = []\n\n            for input_ in re.findall(\n                    r'<input[^>]+class=[\"\\'].*?streamstarter_html5[^>]+>', html):\n                attributes = extract_attributes(input_)\n                playlist_urls = []\n                for playlist_key in ('data-playlist', 'data-otherplaylist'):\n                    playlist_url = attributes.get(playlist_key)\n                    if isinstance(playlist_url, compat_str) and re.match(\n                            r'/?[\\da-zA-Z]+', playlist_url):\n                        playlist_urls.append(attributes[playlist_key])\n                if not playlist_urls:\n                    continue\n\n                lang = attributes.get('data-lang')\n                lang_note = attributes.get('value')\n\n                for playlist_url in playlist_urls:\n                    kind = self._search_regex(\n                        r'videomaterialurl/\\d+/([^/]+)/',\n                        playlist_url, 'media kind', default=None)\n                    format_id_list = []\n                    if lang:\n                        format_id_list.append(lang)\n                    if kind:\n                        format_id_list.append(kind)\n                    if not format_id_list and num is not None:\n                        format_id_list.append(compat_str(num))\n                    format_id = '-'.join(format_id_list)\n                    format_note = ', '.join(filter(None, (kind, lang_note)))\n                    request = sanitized_Request(\n                        compat_urlparse.urljoin(url, playlist_url),\n                        headers={\n                            'X-Requested-With': 'XMLHttpRequest',\n                            'X-CSRF-Token': csrf_token,\n                            'Referer': url,\n                            'Accept': 'application/json, text/javascript, */*; q=0.01',\n                        })\n                    playlist = self._download_json(\n                        request, video_id, 'Downloading %s playlist JSON' % format_id,\n                        fatal=False)\n                    if not playlist:\n                        continue\n                    start_video = playlist.get('startvideo', 0)\n                    playlist = playlist.get('playlist')\n                    if not playlist or not isinstance(playlist, list):\n                        continue\n                    playlist = playlist[start_video]\n                    title = playlist.get('title')\n                    if not title:\n                        continue\n                    description = playlist.get('description')\n                    for source in playlist.get('sources', []):\n                        file_ = source.get('file')\n                        if not file_:\n                            continue\n                        ext = determine_ext(file_)\n                        format_id_list = [lang, kind]\n                        if ext == 'm3u8':\n                            format_id_list.append('hls')\n                        elif source.get('type') == 'video/dash' or ext == 'mpd':\n                            format_id_list.append('dash')\n                        format_id = '-'.join(filter(None, format_id_list))\n                        if ext == 'm3u8':\n                            file_formats = self._extract_m3u8_formats(\n                                file_, video_id, 'mp4',\n                                entry_protocol='m3u8_native', m3u8_id=format_id, fatal=False)\n                        elif source.get('type') == 'video/dash' or ext == 'mpd':\n                            continue\n                            file_formats = self._extract_mpd_formats(\n                                file_, video_id, mpd_id=format_id, fatal=False)\n                        else:\n                            continue\n                        for f in file_formats:\n                            f.update({\n                                'language': lang,\n                                'format_note': format_note,\n                            })\n                        formats.extend(file_formats)\n\n            return {\n                'title': title,\n                'description': description,\n                'formats': formats,\n            }\n\n        def extract_entries(html, video_id, common_info, num=None):\n            info = extract_info(html, video_id, num)\n\n            if info['formats']:\n                self._sort_formats(info['formats'])\n                f = common_info.copy()\n                f.update(info)\n                entries.append(f)\n\n            # Extract teaser/trailer only when full episode is not available\n            if not info['formats']:\n                m = re.search(\n                    r'data-dialog-header=([\"\\'])(?P<title>.+?)\\1[^>]+href=([\"\\'])(?P<href>.+?)\\3[^>]*>(?P<kind>Teaser|Trailer)<',\n                    html)\n                if m:\n                    f = common_info.copy()\n                    f.update({\n                        'id': '%s-%s' % (f['id'], m.group('kind').lower()),\n                        'title': m.group('title'),\n                        'url': compat_urlparse.urljoin(url, m.group('href')),\n                    })\n                    entries.append(f)\n\n        def extract_episodes(html):\n            for num, episode_html in enumerate(re.findall(\n                    r'(?s)<h3[^>]+class=\"episodebox-title\".+?>Episodeninhalt<', html), 1):\n                episodebox_title = self._search_regex(\n                    (r'class=\"episodebox-title\"[^>]+title=([\"\\'])(?P<title>.+?)\\1',\n                     r'class=\"episodebox-title\"[^>]+>(?P<title>.+?)<'),\n                    episode_html, 'episodebox title', default=None, group='title')\n                if not episodebox_title:\n                    continue\n\n                episode_number = int(self._search_regex(\n                    r'(?:Episode|Film)\\s*(\\d+)',\n                    episodebox_title, 'episode number', default=num))\n                episode_title = self._search_regex(\n                    r'(?:Episode|Film)\\s*\\d+\\s*-\\s*(.+)',\n                    episodebox_title, 'episode title', default=None)\n\n                video_id = 'episode-%d' % episode_number\n\n                common_info = {\n                    'id': video_id,\n                    'series': anime_title,\n                    'episode': episode_title,\n                    'episode_number': episode_number,\n                }\n\n                extract_entries(episode_html, video_id, common_info)\n\n        def extract_film(html, video_id):\n            common_info = {\n                'id': anime_id,\n                'title': anime_title,\n                'description': anime_description,\n            }\n            extract_entries(html, video_id, common_info)\n\n        extract_episodes(webpage)\n\n        if not entries:\n            extract_film(webpage, anime_id)\n\n        return self.playlist_result(entries, anime_id, anime_title, anime_description)",
        "begin_line": 95,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anitube.AnitubeIE._real_extract#22",
        "src_path": "youtube_dl/extractor/anitube.py",
        "class_name": "youtube_dl.extractor.anitube.AnitubeIE",
        "signature": "youtube_dl.extractor.anitube.AnitubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        key = self._search_regex(\n            r'src=[\"\\']https?://[^/]+/embed/([A-Za-z0-9_-]+)', webpage, 'key')\n\n        return self._extract_nuevo(\n            'http://www.anitube.se/nuevo/econfig.php?key=%s' % key, video_id)",
        "begin_line": 22,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.md5_text#24",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato",
        "signature": "youtube_dl.extractor.anvato.md5_text(s)",
        "snippet": "def md5_text(s):\n    if not isinstance(s, compat_str):\n        s = compat_str(s)\n    return hashlib.md5(s.encode('utf-8')).hexdigest()",
        "begin_line": 24,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE.__init__#139",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(AnvatoIE, self).__init__(*args, **kwargs)\n        self.__server_time = None",
        "begin_line": 139,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._server_time#143",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._server_time(self, access_key, video_id)",
        "snippet": "    def _server_time(self, access_key, video_id):\n        if self.__server_time is not None:\n            return self.__server_time\n\n        self.__server_time = int(self._download_json(\n            self._api_prefix(access_key) + 'server_time?anvack=' + access_key, video_id,\n            note='Fetching server time')['server_time'])\n\n        return self.__server_time",
        "begin_line": 143,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._api_prefix#153",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._api_prefix(self, access_key)",
        "snippet": "    def _api_prefix(self, access_key):\n        return 'https://tkx2-%s.anvato.net/rest/v2/' % ('prod' if 'prod' in access_key else 'stage')",
        "begin_line": 153,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._get_video_json#156",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._get_video_json(self, access_key, video_id)",
        "snippet": "    def _get_video_json(self, access_key, video_id):\n        # See et() in anvplayer.min.js, which is an alias of getVideoJSON()\n        video_data_url = self._api_prefix(access_key) + 'mcp/video/%s?anvack=%s' % (video_id, access_key)\n        server_time = self._server_time(access_key, video_id)\n        input_data = '%d~%s~%s' % (server_time, md5_text(video_data_url), md5_text(server_time))\n\n        auth_secret = intlist_to_bytes(aes_encrypt(\n            bytes_to_intlist(input_data[:64]), bytes_to_intlist(self._AUTH_KEY)))\n\n        video_data_url += '&X-Anvato-Adst-Auth=' + base64.b64encode(auth_secret).decode('ascii')\n        anvrid = md5_text(time.time() * 1000 * random.random())[:30]\n        payload = {\n            'api': {\n                'anvrid': anvrid,\n                'anvstk': md5_text('%s|%s|%d|%s' % (\n                    access_key, anvrid, server_time, self._ANVACK_TABLE[access_key])),\n                'anvts': server_time,\n            },\n        }\n\n        return self._download_json(\n            video_data_url, video_id, transform_source=strip_jsonp,\n            data=json.dumps(payload).encode('utf-8'))",
        "begin_line": 156,
        "end_line": 178,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._get_anvato_videos#180",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._get_anvato_videos(self, access_key, video_id)",
        "snippet": "    def _get_anvato_videos(self, access_key, video_id):\n        video_data = self._get_video_json(access_key, video_id)\n\n        formats = []\n        for published_url in video_data['published_urls']:\n            video_url = published_url['embed_url']\n            media_format = published_url.get('format')\n            ext = determine_ext(video_url)\n\n            if ext == 'smil' or media_format == 'smil':\n                formats.extend(self._extract_smil_formats(video_url, video_id))\n                continue\n\n            tbr = int_or_none(published_url.get('kbps'))\n            a_format = {\n                'url': video_url,\n                'format_id': ('-'.join(filter(None, ['http', published_url.get('cdn_name')]))).lower(),\n                'tbr': tbr if tbr != 0 else None,\n            }\n\n            if ext == 'm3u8' or media_format in ('m3u8', 'm3u8-variant'):\n                if tbr is not None:\n                    a_format.update({\n                        'format_id': '-'.join(filter(None, ['hls', compat_str(tbr)])),\n                        'ext': 'mp4',\n                    })\n            elif ext == 'mp3' or media_format == 'mp3':\n                a_format['vcodec'] = 'none'\n            else:\n                a_format.update({\n                    'width': int_or_none(published_url.get('width')),\n                    'height': int_or_none(published_url.get('height')),\n                })\n            formats.append(a_format)\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for caption in video_data.get('captions', []):\n            a_caption = {\n                'url': caption['url'],\n                'ext': 'tt' if caption.get('format') == 'SMPTE-TT' else None\n            }\n            subtitles.setdefault(caption['language'], []).append(a_caption)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_data.get('def_title'),\n            'description': video_data.get('def_description'),\n            'tags': video_data.get('def_tags', '').split(','),\n            'categories': video_data.get('categories'),\n            'thumbnail': video_data.get('thumbnail'),\n            'timestamp': int_or_none(video_data.get(\n                'ts_published') or video_data.get('ts_added')),\n            'uploader': video_data.get('mcp_id'),\n            'duration': int_or_none(video_data.get('duration')),\n            'subtitles': subtitles,\n        }",
        "begin_line": 180,
        "end_line": 238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._extract_urls#241",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._extract_urls(ie, webpage, video_id)",
        "snippet": "    def _extract_urls(ie, webpage, video_id):\n        entries = []\n        for mobj in re.finditer(AnvatoIE._ANVP_RE, webpage):\n            anvplayer_data = ie._parse_json(\n                mobj.group('anvp'), video_id, transform_source=unescapeHTML,\n                fatal=False)\n            if not anvplayer_data:\n                continue\n            video = anvplayer_data.get('video')\n            if not isinstance(video, compat_str) or not video.isdigit():\n                continue\n            access_key = anvplayer_data.get('accessKey')\n            if not access_key:\n                mcp = anvplayer_data.get('mcp')\n                if mcp:\n                    access_key = AnvatoIE._MCP_TO_ACCESS_KEY_TABLE.get(\n                        mcp.lower())\n            if not access_key:\n                continue\n            entries.append(ie.url_result(\n                'anvato:%s:%s' % (access_key, video), ie=AnvatoIE.ie_key(),\n                video_id=video))\n        return entries",
        "begin_line": 241,
        "end_line": 263,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._extract_anvato_videos#265",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._extract_anvato_videos(self, webpage, video_id)",
        "snippet": "    def _extract_anvato_videos(self, webpage, video_id):\n        anvplayer_data = self._parse_json(\n            self._html_search_regex(\n                self._ANVP_RE, webpage, 'Anvato player data', group='anvp'),\n            video_id)\n        return self._get_anvato_videos(\n            anvplayer_data['accessKey'], anvplayer_data['video'])",
        "begin_line": 265,
        "end_line": 271,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anvato.AnvatoIE._real_extract#273",
        "src_path": "youtube_dl/extractor/anvato.py",
        "class_name": "youtube_dl.extractor.anvato.AnvatoIE",
        "signature": "youtube_dl.extractor.anvato.AnvatoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        access_key, video_id = mobj.group('access_key_or_mcp', 'id')\n        if access_key not in self._ANVACK_TABLE:\n            access_key = self._MCP_TO_ACCESS_KEY_TABLE[access_key]\n        return self._get_anvato_videos(access_key, video_id)",
        "begin_line": 273,
        "end_line": 278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.anysex.AnySexIE._real_extract#28",
        "src_path": "youtube_dl/extractor/anysex.py",
        "class_name": "youtube_dl.extractor.anysex.AnySexIE",
        "signature": "youtube_dl.extractor.anysex.AnySexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video URL')\n\n        title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"description\"[^>]*>([^<]+)</div>', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'preview_url\\s*:\\s*\\'(.*?)\\'', webpage, 'thumbnail', fatal=False)\n\n        categories = re.findall(\n            r'<a href=\"http://anysex\\.com/categories/[^\"]+\" title=\"[^\"]*\">([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'<b>Duration:</b> (?:<q itemprop=\"duration\">)?(\\d+:\\d+)', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<b>Views:</b> (\\d+)', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aol.AolIE._real_extract#64",
        "src_path": "youtube_dl/extractor/aol.py",
        "class_name": "youtube_dl.extractor.aol.AolIE",
        "signature": "youtube_dl.extractor.aol.AolIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        response = self._download_json(\n            'https://feedapi.b2c.on.aol.com/v1.0/app/videos/aolon/%s/details' % video_id,\n            video_id)['response']\n        if response['statusText'] != 'Ok':\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, response['statusText']), expected=True)\n\n        video_data = response['data']\n        formats = []\n        m3u8_url = video_data.get('videoMasterPlaylist')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n        for rendition in video_data.get('renditions', []):\n            video_url = rendition.get('url')\n            if not video_url:\n                continue\n            ext = rendition.get('format')\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n            else:\n                f = {\n                    'url': video_url,\n                    'format_id': rendition.get('quality'),\n                }\n                mobj = re.search(r'(\\d+)x(\\d+)', video_url)\n                if mobj:\n                    f.update({\n                        'width': int(mobj.group(1)),\n                        'height': int(mobj.group(2)),\n                    })\n                formats.append(f)\n        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))\n\n        return {\n            'id': video_id,\n            'title': video_data['title'],\n            'duration': int_or_none(video_data.get('duration')),\n            'timestamp': int_or_none(video_data.get('publishDate')),\n            'view_count': int_or_none(video_data.get('views')),\n            'description': video_data.get('description'),\n            'uploader': video_data.get('videoOwner'),\n            'formats': formats,\n        }",
        "begin_line": 64,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.aparat.AparatIE._real_extract#26",
        "src_path": "youtube_dl/extractor/aparat.py",
        "class_name": "youtube_dl.extractor.aparat.AparatIE",
        "signature": "youtube_dl.extractor.aparat.AparatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Note: There is an easier-to-parse configuration at\n        # http://www.aparat.com/video/video/config/videohash/%video_id\n        # but the URL in there does not work\n        webpage = self._download_webpage(\n            'http://www.aparat.com/video/video/embed/vt/frame/showvideo/yes/videohash/' + video_id,\n            video_id)\n\n        title = self._search_regex(r'\\s+title:\\s*\"([^\"]+)\"', webpage, 'title')\n\n        file_list = self._parse_json(\n            self._search_regex(\n                r'fileList\\s*=\\s*JSON\\.parse\\(\\'([^\\']+)\\'\\)', webpage,\n                'file list'),\n            video_id)\n\n        formats = []\n        for item in file_list[0]:\n            file_url = item.get('file')\n            if not file_url:\n                continue\n            ext = mimetype2ext(item.get('type'))\n            label = item.get('label')\n            formats.append({\n                'url': file_url,\n                'ext': ext,\n                'format_id': label or ext,\n                'height': int_or_none(self._search_regex(\n                    r'(\\d+)[pP]', label or '', 'height', default=None)),\n            })\n        self._sort_formats(formats)\n\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': self._family_friendly_search(webpage),\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.appleconnect.AppleConnectIE._real_extract#27",
        "src_path": "youtube_dl/extractor/appleconnect.py",
        "class_name": "youtube_dl.extractor.appleconnect.AppleConnectIE",
        "signature": "youtube_dl.extractor.appleconnect.AppleConnectIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        try:\n            video_json = self._html_search_regex(\n                r'class=\"auc-video-data\">(\\{.*?\\})', webpage, 'json')\n        except ExtractorError:\n            raise ExtractorError('This post doesn\\'t contain a video', expected=True)\n\n        video_data = self._parse_json(video_json, video_id)\n        timestamp = str_to_int(self._html_search_regex(r'data-timestamp=\"(\\d+)\"', webpage, 'timestamp'))\n        like_count = str_to_int(self._html_search_regex(r'(\\d+) Loves', webpage, 'like count'))\n\n        return {\n            'id': video_id,\n            'url': video_data['sslSrc'],\n            'title': video_data['title'],\n            'description': video_data['description'],\n            'uploader': video_data['artistName'],\n            'thumbnail': video_data['artworkUrl'],\n            'timestamp': timestamp,\n            'like_count': like_count,\n        }",
        "begin_line": 27,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract#96",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie = mobj.group('movie')\n        uploader_id = mobj.group('company')\n\n        webpage = self._download_webpage(url, movie)\n        film_id = self._search_regex(r\"FilmId\\s*=\\s*'(\\d+)'\", webpage, 'film id')\n        film_data = self._download_json(\n            'http://trailers.apple.com/trailers/feeds/data/%s.json' % film_id,\n            film_id, fatal=False)\n\n        if film_data:\n            entries = []\n            for clip in film_data.get('clips', []):\n                clip_title = clip['title']\n\n                formats = []\n                for version, version_data in clip.get('versions', {}).items():\n                    for size, size_data in version_data.get('sizes', {}).items():\n                        src = size_data.get('src')\n                        if not src:\n                            continue\n                        formats.append({\n                            'format_id': '%s-%s' % (version, size),\n                            'url': re.sub(r'_(\\d+p.mov)', r'_h\\1', src),\n                            'width': int_or_none(size_data.get('width')),\n                            'height': int_or_none(size_data.get('height')),\n                            'language': version[:2],\n                        })\n                self._sort_formats(formats)\n\n                entries.append({\n                    'id': movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', clip_title).lower(),\n                    'formats': formats,\n                    'title': clip_title,\n                    'thumbnail': clip.get('screen') or clip.get('thumb'),\n                    'duration': parse_duration(clip.get('runtime') or clip.get('faded')),\n                    'upload_date': unified_strdate(clip.get('posted')),\n                    'uploader_id': uploader_id,\n                })\n\n            page_data = film_data.get('page', {})\n            return self.playlist_result(entries, film_id, page_data.get('movie_title'))\n\n        playlist_url = compat_urlparse.urljoin(url, 'includes/playlists/itunes.inc')\n\n        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)\n            s = re.sub(r'<img ([^<]*?)/?>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n\n            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = '<html>%s</html>' % s\n            return s\n        doc = self._download_xml(playlist_url, movie, transform_source=fix_html)\n\n        playlist = []\n        for li in doc.findall('./div/ul/li'):\n            on_click = li.find('.//a').attrib['onClick']\n            trailer_info_json = self._search_regex(self._JSON_RE,\n                                                   on_click, 'trailer info')\n            trailer_info = json.loads(trailer_info_json)\n            first_url = trailer_info.get('url')\n            if not first_url:\n                continue\n            title = trailer_info['title']\n            video_id = movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', title).lower()\n            thumbnail = li.find('.//img').attrib['src']\n            upload_date = trailer_info['posted'].replace('-', '')\n\n            runtime = trailer_info['runtime']\n            m = re.search(r'(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime)\n            duration = None\n            if m:\n                duration = 60 * int(m.group('minutes')) + int(m.group('seconds'))\n\n            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()\n            settings_json_url = compat_urlparse.urljoin(url, 'includes/settings/%s.json' % trailer_id)\n            settings = self._download_json(settings_json_url, trailer_id, 'Downloading settings json')\n\n            formats = []\n            for format in settings['metadata']['sizes']:\n                # The src is a file pointing to the real video file\n                format_url = re.sub(r'_(\\d*p.mov)', r'_h\\1', format['src'])\n                formats.append({\n                    'url': format_url,\n                    'format': format['type'],\n                    'width': int_or_none(format['width']),\n                    'height': int_or_none(format['height']),\n                })\n\n            self._sort_formats(formats)\n\n            playlist.append({\n                '_type': 'video',\n                'id': video_id,\n                'formats': formats,\n                'title': title,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'upload_date': upload_date,\n                'uploader_id': uploader_id,\n                'http_headers': {\n                    'User-Agent': 'QuickTime compatible (youtube-dl)',\n                },\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': movie,\n            'entries': playlist,\n        }",
        "begin_line": 96,
        "end_line": 210,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersSectionIE._real_extract#275",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersSectionIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersSectionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        section = self._match_id(url)\n        section_data = self._download_json(\n            'http://trailers.apple.com/trailers/home/feeds/%s.json' % self._SECTIONS[section]['feed_path'],\n            section)\n        entries = [\n            self.url_result('http://trailers.apple.com' + e['location'])\n            for e in section_data]\n        return self.playlist_result(entries, section, self._SECTIONS[section]['title'])",
        "begin_line": 275,
        "end_line": 283,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract#39",
        "src_path": "youtube_dl/extractor/archiveorg.py",
        "class_name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE",
        "signature": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://archive.org/embed/' + video_id, video_id)\n        jwplayer_playlist = self._parse_json(self._search_regex(\n            r\"(?s)Play\\('[^']+'\\s*,\\s*(\\[.+\\])\\s*,\\s*{.*?}\\);\",\n            webpage, 'jwplayer playlist'), video_id)\n        info = self._parse_jwplayer_data(\n            {'playlist': jwplayer_playlist}, video_id, base_url=url)\n\n        def get_optional(metadata, field):\n            return metadata.get(field, [None])[0]\n\n        metadata = self._download_json(\n            'http://archive.org/details/' + video_id, video_id, query={\n                'output': 'json',\n            })['metadata']\n        info.update({\n            'title': get_optional(metadata, 'title') or info.get('title'),\n            'description': clean_html(get_optional(metadata, 'description')),\n        })\n        if info.get('_type') != 'playlist':\n            info.update({\n                'uploader': get_optional(metadata, 'creator'),\n                'upload_date': unified_strdate(get_optional(metadata, 'date')),\n            })\n        return info",
        "begin_line": 39,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._extract_media_info#79",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._extract_media_info(self, media_info_url, webpage, video_id)",
        "snippet": "    def _extract_media_info(self, media_info_url, webpage, video_id):\n        media_info = self._download_json(\n            media_info_url, video_id, 'Downloading media JSON')\n\n        formats = self._extract_formats(media_info, video_id)\n\n        if not formats:\n            if '\"fsk\"' in webpage:\n                raise ExtractorError(\n                    'This video is only available after 20:00', expected=True)\n            elif media_info.get('_geoblocked'):\n                raise ExtractorError('This video is not available due to geo restriction', expected=True)\n\n        self._sort_formats(formats)\n\n        duration = int_or_none(media_info.get('_duration'))\n        thumbnail = media_info.get('_previewImage')\n        is_live = media_info.get('_isLive') is True\n\n        subtitles = {}\n        subtitle_url = media_info.get('_subtitleUrl')\n        if subtitle_url:\n            subtitles['de'] = [{\n                'ext': 'ttml',\n                'url': subtitle_url,\n            }]\n\n        return {\n            'id': video_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'is_live': is_live,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 79,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._extract_formats#115",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._extract_formats(self, media_info, video_id)",
        "snippet": "    def _extract_formats(self, media_info, video_id):\n        type_ = media_info.get('_type')\n        media_array = media_info.get('_mediaArray', [])\n        formats = []\n        for num, media in enumerate(media_array):\n            for stream in media.get('_mediaStreamArray', []):\n                stream_urls = stream.get('_stream')\n                if not stream_urls:\n                    continue\n                if not isinstance(stream_urls, list):\n                    stream_urls = [stream_urls]\n                quality = stream.get('_quality')\n                server = stream.get('_server')\n                for stream_url in stream_urls:\n                    ext = determine_ext(stream_url)\n                    if quality != 'auto' and ext in ('f4m', 'm3u8'):\n                        continue\n                    if ext == 'f4m':\n                        formats.extend(self._extract_f4m_formats(\n                            update_url_query(stream_url, {\n                                'hdcore': '3.1.1',\n                                'plugin': 'aasp-3.1.1.69.124'\n                            }),\n                            video_id, f4m_id='hds', fatal=False))\n                    elif ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            stream_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n                    else:\n                        if server and server.startswith('rtmp'):\n                            f = {\n                                'url': server,\n                                'play_path': stream_url,\n                                'format_id': 'a%s-rtmp-%s' % (num, quality),\n                            }\n                        elif stream_url.startswith('http'):\n                            f = {\n                                'url': stream_url,\n                                'format_id': 'a%s-%s-%s' % (num, ext, quality)\n                            }\n                        else:\n                            continue\n                        m = re.search(r'_(?P<width>\\d+)x(?P<height>\\d+)\\.mp4$', stream_url)\n                        if m:\n                            f.update({\n                                'width': int(m.group('width')),\n                                'height': int(m.group('height')),\n                            })\n                        if type_ == 'audio':\n                            f['vcodec'] = 'none'\n                        formats.append(f)\n        return formats",
        "begin_line": 115,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract#167",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # determine video id from url\n        m = re.match(self._VALID_URL, url)\n\n        document_id = None\n\n        numid = re.search(r'documentId=([0-9]+)', url)\n        if numid:\n            document_id = video_id = numid.group(1)\n        else:\n            video_id = m.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        ERRORS = (\n            ('>Leider liegt eine St\u00f6rung vor.', 'Video %s is unavailable'),\n            ('>Der gew\u00fcnschte Beitrag ist nicht mehr verf\u00fcgbar.<',\n             'Video %s is no longer available'),\n        )\n\n        for pattern, message in ERRORS:\n            if pattern in webpage:\n                raise ExtractorError(message % video_id, expected=True)\n\n        if re.search(r'[\\?&]rss($|[=&])', url):\n            doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                return GenericIE()._extract_rss(url, video_id, doc)\n\n        title = self._html_search_regex(\n            [r'<h1(?:\\s+class=\"boxTopHeadline\")?>(.*?)</h1>',\n             r'<meta name=\"dcterms.title\" content=\"(.*?)\"/>',\n             r'<h4 class=\"headline\">(.*?)</h4>'],\n            webpage, 'title')\n        description = self._html_search_meta(\n            'dcterms.abstract', webpage, 'description', default=None)\n        if description is None:\n            description = self._html_search_meta(\n                'description', webpage, 'meta description')\n\n        # Thumbnail is sometimes not present.\n        # It is in the mobile version, but that seems to use a different URL\n        # structure altogether.\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        media_streams = re.findall(r'''(?x)\n            mediaCollection\\.addMediaStream\\([0-9]+,\\s*[0-9]+,\\s*\"[^\"]*\",\\s*\n            \"([^\"]+)\"''', webpage)\n\n        if media_streams:\n            QUALITIES = qualities(['lo', 'hi', 'hq'])\n            formats = []\n            for furl in set(media_streams):\n                if furl.endswith('.f4m'):\n                    fid = 'f4m'\n                else:\n                    fid_m = re.match(r'.*\\.([^.]+)\\.[^.]+$', furl)\n                    fid = fid_m.group(1) if fid_m else None\n                formats.append({\n                    'quality': QUALITIES(fid),\n                    'format_id': fid,\n                    'url': furl,\n                })\n            self._sort_formats(formats)\n            info = {\n                'formats': formats,\n            }\n        else:  # request JSON file\n            if not document_id:\n                video_id = self._search_regex(\n                    r'/play/(?:config|media)/(\\d+)', webpage, 'media id')\n            info = self._extract_media_info(\n                'http://www.ardmediathek.de/play/media/%s' % video_id,\n                webpage, video_id)\n\n        info.update({\n            'id': video_id,\n            'title': self._live_title(title) if info.get('is_live') else title,\n            'description': description,\n            'thumbnail': thumbnail,\n        })\n\n        return info",
        "begin_line": 167,
        "end_line": 249,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ard.ARDIE._real_extract#269",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDIE",
        "signature": "youtube_dl.extractor.ard.ARDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        player_url = mobj.group('mainurl') + '~playerXml.xml'\n        doc = self._download_xml(player_url, display_id)\n        video_node = doc.find('./video')\n        upload_date = unified_strdate(xpath_text(\n            video_node, './broadcastDate'))\n        thumbnail = xpath_text(video_node, './/teaserImage//variant/url')\n\n        formats = []\n        for a in video_node.findall('.//asset'):\n            f = {\n                'format_id': a.attrib['type'],\n                'width': int_or_none(a.find('./frameWidth').text),\n                'height': int_or_none(a.find('./frameHeight').text),\n                'vbr': int_or_none(a.find('./bitrateVideo').text),\n                'abr': int_or_none(a.find('./bitrateAudio').text),\n                'vcodec': a.find('./codecVideo').text,\n                'tbr': int_or_none(a.find('./totalBitrate').text),\n            }\n            if a.find('./serverPrefix').text:\n                f['url'] = a.find('./serverPrefix').text\n                f['playpath'] = a.find('./fileName').text\n            else:\n                f['url'] = a.find('./fileName').text\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': mobj.group('id'),\n            'formats': formats,\n            'display_id': display_id,\n            'title': video_node.find('./title').text,\n            'duration': parse_duration(video_node.find('./duration').text),\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 269,
        "end_line": 307,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arkena.ArkenaIE._extract_url#54",
        "src_path": "youtube_dl/extractor/arkena.py",
        "class_name": "youtube_dl.extractor.arkena.ArkenaIE",
        "signature": "youtube_dl.extractor.arkena.ArkenaIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        # See https://support.arkena.com/display/PLAY/Ways+to+embed+your+video\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//play\\.arkena\\.com/embed/avp/.+?)\\1',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 54,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arkena.ArkenaIE._real_extract#62",
        "src_path": "youtube_dl/extractor/arkena.py",
        "class_name": "youtube_dl.extractor.arkena.ArkenaIE",
        "signature": "youtube_dl.extractor.arkena.ArkenaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        account_id = mobj.group('account_id')\n\n        # Handle http://video.arkena.com/play2/embed/player URL\n        if not video_id:\n            qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n            video_id = qs.get('mediaId', [None])[0]\n            account_id = qs.get('accountId', [None])[0]\n            if not video_id or not account_id:\n                raise ExtractorError('Invalid URL', expected=True)\n\n        playlist = self._download_json(\n            'https://play.arkena.com/config/avp/v2/player/media/%s/0/%s/?callbackMethod=_'\n            % (video_id, account_id),\n            video_id, transform_source=strip_jsonp)['Playlist'][0]\n\n        media_info = playlist['MediaInfo']\n        title = media_info['Title']\n        media_files = playlist['MediaFiles']\n\n        is_live = False\n        formats = []\n        for kind_case, kind_formats in media_files.items():\n            kind = kind_case.lower()\n            for f in kind_formats:\n                f_url = f.get('Url')\n                if not f_url:\n                    continue\n                is_live = f.get('Live') == 'true'\n                exts = (mimetype2ext(f.get('Type')), determine_ext(f_url, None))\n                if kind == 'm3u8' or 'm3u8' in exts:\n                    formats.extend(self._extract_m3u8_formats(\n                        f_url, video_id, 'mp4', 'm3u8_native',\n                        m3u8_id=kind, fatal=False, live=is_live))\n                elif kind == 'flash' or 'f4m' in exts:\n                    formats.extend(self._extract_f4m_formats(\n                        f_url, video_id, f4m_id=kind, fatal=False))\n                elif kind == 'dash' or 'mpd' in exts:\n                    formats.extend(self._extract_mpd_formats(\n                        f_url, video_id, mpd_id=kind, fatal=False))\n                elif kind == 'silverlight':\n                    # TODO: process when ism is supported (see\n                    # https://github.com/rg3/youtube-dl/issues/8118)\n                    continue\n                else:\n                    tbr = float_or_none(f.get('Bitrate'), 1000)\n                    formats.append({\n                        'url': f_url,\n                        'format_id': '%s-%d' % (kind, tbr) if tbr else kind,\n                        'tbr': tbr,\n                    })\n        self._sort_formats(formats)\n\n        description = media_info.get('Description')\n        video_id = media_info.get('VideoId') or video_id\n        timestamp = parse_iso8601(media_info.get('PublishDate'))\n        thumbnails = [{\n            'url': thumbnail['Url'],\n            'width': int_or_none(thumbnail.get('Size')),\n        } for thumbnail in (media_info.get('Poster') or []) if thumbnail.get('Url')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'is_live': is_live,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 62,
        "end_line": 133,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._real_extract#30",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lang = mobj.group('lang')\n        video_id = mobj.group('id')\n\n        ref_xml_url = url.replace('/videos/', '/do_delegate/videos/')\n        ref_xml_url = ref_xml_url.replace('.html', ',view,asPlayerXml.xml')\n        ref_xml_doc = self._download_xml(\n            ref_xml_url, video_id, note='Downloading metadata')\n        config_node = find_xpath_attr(ref_xml_doc, './/video', 'lang', lang)\n        config_xml_url = config_node.attrib['ref']\n        config = self._download_xml(\n            config_xml_url, video_id, note='Downloading configuration')\n\n        formats = [{\n            'format_id': q.attrib['quality'],\n            # The playpath starts at 'mp4:', if we don't manually\n            # split the url, rtmpdump will incorrectly parse them\n            'url': q.text.split('mp4:', 1)[0],\n            'play_path': 'mp4:' + q.text.split('mp4:', 1)[1],\n            'ext': 'flv',\n            'quality': 2 if q.attrib['quality'] == 'hd' else 1,\n        } for q in config.findall('./urls/url')]\n        self._sort_formats(formats)\n\n        title = config.find('.//name').text\n        thumbnail = config.find('.//firstThumbnailUrl').text\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVBaseIE._extract_url_info#67",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVBaseIE",
        "signature": "youtube_dl.extractor.arte.ArteTVBaseIE._extract_url_info(cls, url)",
        "snippet": "    def _extract_url_info(cls, url):\n        mobj = re.match(cls._VALID_URL, url)\n        lang = mobj.group('lang')\n        query = compat_parse_qs(compat_urllib_parse_urlparse(url).query)\n        if 'vid' in query:\n            video_id = query['vid'][0]\n        else:\n            # This is not a real id, it can be for example AJT for the news\n            # http://www.arte.tv/guide/fr/emissions/AJT/arte-journal\n            video_id = mobj.group('id')\n        return video_id, lang",
        "begin_line": 67,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVBaseIE._extract_from_json_url#79",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVBaseIE",
        "signature": "youtube_dl.extractor.arte.ArteTVBaseIE._extract_from_json_url(self, json_url, video_id, lang, title=None)",
        "snippet": "    def _extract_from_json_url(self, json_url, video_id, lang, title=None):\n        info = self._download_json(json_url, video_id)\n        player_info = info['videoJsonPlayer']\n\n        vsr = player_info['VSR']\n\n        if not vsr and not player_info.get('VRU'):\n            raise ExtractorError(\n                'Video %s is not available' % player_info.get('VID') or video_id,\n                expected=True)\n\n        upload_date_str = player_info.get('shootingDate')\n        if not upload_date_str:\n            upload_date_str = (player_info.get('VRA') or player_info.get('VDA') or '').split(' ')[0]\n\n        title = (player_info.get('VTI') or title or player_info['VID']).strip()\n        subtitle = player_info.get('VSU', '').strip()\n        if subtitle:\n            title += ' - %s' % subtitle\n\n        info_dict = {\n            'id': player_info['VID'],\n            'title': title,\n            'description': player_info.get('VDE'),\n            'upload_date': unified_strdate(upload_date_str),\n            'thumbnail': player_info.get('programImage') or player_info.get('VTU', {}).get('IUR'),\n        }\n        qfunc = qualities(['HQ', 'MQ', 'EQ', 'SQ'])\n\n        LANGS = {\n            'fr': 'F',\n            'de': 'A',\n            'en': 'E[ANG]',\n            'es': 'E[ESP]',\n        }\n\n        langcode = LANGS.get(lang, lang)\n\n        formats = []\n        for format_id, format_dict in vsr.items():\n            f = dict(format_dict)\n            versionCode = f.get('versionCode')\n            l = re.escape(langcode)\n\n            # Language preference from most to least priority\n            # Reference: section 5.6.3 of\n            # http://www.arte.tv/sites/en/corporate/files/complete-technical-guidelines-arte-geie-v1-05.pdf\n            PREFERENCES = (\n                # original version in requested language, without subtitles\n                r'VO{0}$'.format(l),\n                # original version in requested language, with partial subtitles in requested language\n                r'VO{0}-ST{0}$'.format(l),\n                # original version in requested language, with subtitles for the deaf and hard-of-hearing in requested language\n                r'VO{0}-STM{0}$'.format(l),\n                # non-original (dubbed) version in requested language, without subtitles\n                r'V{0}$'.format(l),\n                # non-original (dubbed) version in requested language, with subtitles partial subtitles in requested language\n                r'V{0}-ST{0}$'.format(l),\n                # non-original (dubbed) version in requested language, with subtitles for the deaf and hard-of-hearing in requested language\n                r'V{0}-STM{0}$'.format(l),\n                # original version in requested language, with partial subtitles in different language\n                r'VO{0}-ST(?!{0}).+?$'.format(l),\n                # original version in requested language, with subtitles for the deaf and hard-of-hearing in different language\n                r'VO{0}-STM(?!{0}).+?$'.format(l),\n                # original version in different language, with partial subtitles in requested language\n                r'VO(?:(?!{0}).+?)?-ST{0}$'.format(l),\n                # original version in different language, with subtitles for the deaf and hard-of-hearing in requested language\n                r'VO(?:(?!{0}).+?)?-STM{0}$'.format(l),\n                # original version in different language, without subtitles\n                r'VO(?:(?!{0}))?$'.format(l),\n                # original version in different language, with partial subtitles in different language\n                r'VO(?:(?!{0}).+?)?-ST(?!{0}).+?$'.format(l),\n                # original version in different language, with subtitles for the deaf and hard-of-hearing in different language\n                r'VO(?:(?!{0}).+?)?-STM(?!{0}).+?$'.format(l),\n            )\n\n            for pref, p in enumerate(PREFERENCES):\n                if re.match(p, versionCode):\n                    lang_pref = len(PREFERENCES) - pref\n                    break\n            else:\n                lang_pref = -1\n\n            format = {\n                'format_id': format_id,\n                'preference': -10 if f.get('videoFormat') == 'M3U8' else None,\n                'language_preference': lang_pref,\n                'format_note': '%s, %s' % (f.get('versionCode'), f.get('versionLibelle')),\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'tbr': int_or_none(f.get('bitrate')),\n                'quality': qfunc(f.get('quality')),\n            }\n\n            if f.get('mediaType') == 'rtmp':\n                format['url'] = f['streamer']\n                format['play_path'] = 'mp4:' + f['url']\n                format['ext'] = 'flv'\n            else:\n                format['url'] = f['url']\n\n            formats.append(format)\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        info_dict['formats'] = formats\n        return info_dict",
        "begin_line": 79,
        "end_line": 186,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE.suitable#205",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if ArteTVPlaylistIE.suitable(url) else super(ArteTVPlus7IE, cls).suitable(url)",
        "begin_line": 205,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract#208",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, video_id)\n        return self._extract_from_webpage(webpage, video_id, lang)",
        "begin_line": 208,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage#213",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage(self, webpage, video_id, lang)",
        "snippet": "    def _extract_from_webpage(self, webpage, video_id, lang):\n        patterns_templates = (r'arte_vp_url=[\"\\'](.*?%s.*?)[\"\\']', r'data-url=[\"\\']([^\"]+%s[^\"]+)[\"\\']')\n        ids = (video_id, '')\n        # some pages contain multiple videos (like\n        # http://www.arte.tv/guide/de/sendungen/XEN/xenius/?vid=055918-015_PLUS7-D),\n        # so we first try to look for json URLs that contain the video id from\n        # the 'vid' parameter.\n        patterns = [t % re.escape(_id) for _id in ids for t in patterns_templates]\n        json_url = self._html_search_regex(\n            patterns, webpage, 'json vp url', default=None)\n        if not json_url:\n            def find_iframe_url(webpage, default=NO_DEFAULT):\n                return self._html_search_regex(\n                    r'<iframe[^>]+src=([\"\\'])(?P<url>.+\\bjson_url=.+?)\\1',\n                    webpage, 'iframe url', group='url', default=default)\n\n            iframe_url = find_iframe_url(webpage, None)\n            if not iframe_url:\n                embed_url = self._html_search_regex(\n                    r'arte_vp_url_oembed=\\'([^\\']+?)\\'', webpage, 'embed url', default=None)\n                if embed_url:\n                    player = self._download_json(\n                        embed_url, video_id, 'Downloading player page')\n                    iframe_url = find_iframe_url(player['html'])\n            # en and es URLs produce react-based pages with different layout (e.g.\n            # http://www.arte.tv/guide/en/053330-002-A/carnival-italy?zone=world)\n            if not iframe_url:\n                program = self._search_regex(\n                    r'program\\s*:\\s*({.+?[\"\\']embed_html[\"\\'].+?}),?\\s*\\n',\n                    webpage, 'program', default=None)\n                if program:\n                    embed_html = self._parse_json(program, video_id)\n                    if embed_html:\n                        iframe_url = find_iframe_url(embed_html['embed_html'])\n            if iframe_url:\n                json_url = compat_parse_qs(\n                    compat_urllib_parse_urlparse(iframe_url).query)['json_url'][0]\n        if json_url:\n            title = self._search_regex(\n                r'<h3[^>]+title=([\"\\'])(?P<title>.+?)\\1',\n                webpage, 'title', default=None, group='title')\n            return self._extract_from_json_url(json_url, video_id, lang, title=title)\n        # Different kind of embed URL (e.g.\n        # http://www.arte.tv/magazine/trepalium/fr/episode-0406-replay-trepalium)\n        entries = [\n            self.url_result(url)\n            for _, url in re.findall(r'<iframe[^>]+src=([\"\\'])(?P<url>.+?)\\1', webpage)]\n        return self.playlist_result(entries)",
        "begin_line": 213,
        "end_line": 260,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract#325",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVDDCIE",
        "signature": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        if lang == 'folge':\n            lang = 'de'\n        elif lang == 'emission':\n            lang = 'fr'\n        webpage = self._download_webpage(url, video_id)\n        scriptElement = get_element_by_attribute('class', 'visu_video_block', webpage)\n        script_url = self._html_search_regex(r'src=\"(.*?)\"', scriptElement, 'script url')\n        javascriptPlayerGenerator = self._download_webpage(script_url, video_id, 'Download javascript player generator')\n        json_url = self._search_regex(r\"json_url=(.*)&rendering_place.*\", javascriptPlayerGenerator, 'json url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 325,
        "end_line": 336,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract#416",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVEmbedIE",
        "signature": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        lang = mobj.group('lang')\n        json_url = mobj.group('json_url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 416,
        "end_line": 421,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlaylistIE._real_extract#457",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlaylistIE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id, lang = self._extract_url_info(url)\n        collection = self._download_json(\n            'https://api.arte.tv/api/player/v1/collectionData/%s/%s?source=videos'\n            % (lang, playlist_id), playlist_id)\n        title = collection.get('title')\n        description = collection.get('shortDescription') or collection.get('teaserText')\n        entries = [\n            self._extract_from_json_url(\n                video['jsonUrl'], video.get('programId') or playlist_id, lang)\n            for video in collection['videos'] if video.get('jsonUrl')]\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 457,
        "end_line": 468,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.asiancrush.AsianCrushIE._real_extract#34",
        "src_path": "youtube_dl/extractor/asiancrush.py",
        "class_name": "youtube_dl.extractor.asiancrush.AsianCrushIE",
        "signature": "youtube_dl.extractor.asiancrush.AsianCrushIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'https://www.asiancrush.com/wp-admin/admin-ajax.php', video_id,\n            data=urlencode_postdata({\n                'postid': video_id,\n                'action': 'get_channel_kaltura_vars',\n            }))\n\n        entry_id = data['entry_id']\n\n        return self.url_result(\n            'kaltura:%s:%s' % (data['partner_id'], entry_id),\n            ie=KalturaIE.ie_key(), video_id=entry_id,\n            video_title=data.get('vid_label'))",
        "begin_line": 34,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.asiancrush.AsianCrushPlaylistIE._real_extract#64",
        "src_path": "youtube_dl/extractor/asiancrush.py",
        "class_name": "youtube_dl.extractor.asiancrush.AsianCrushPlaylistIE",
        "signature": "youtube_dl.extractor.asiancrush.AsianCrushPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = []\n\n        for mobj in re.finditer(\n                r'<a[^>]+href=([\"\\'])(?P<url>%s.*?)\\1[^>]*>' % AsianCrushIE._VALID_URL,\n                webpage):\n            attrs = extract_attributes(mobj.group(0))\n            if attrs.get('class') == 'clearfix':\n                entries.append(self.url_result(\n                    mobj.group('url'), ie=AsianCrushIE.ie_key()))\n\n        title = remove_end(\n            self._html_search_regex(\n                r'(?s)<h1\\b[^>]\\bid=[\"\\']movieTitle[^>]+>(.+?)</h1>', webpage,\n                'title', default=None) or self._og_search_title(\n                webpage, default=None) or self._html_search_meta(\n                'twitter:title', webpage, 'title',\n                default=None) or self._search_regex(\n                r'<title>([^<]+)</title>', webpage, 'title', fatal=False),\n            ' | AsianCrush')\n\n        description = self._og_search_description(\n            webpage, default=None) or self._html_search_meta(\n            'twitter:description', webpage, 'description', fatal=False)\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 64,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_initialize#73",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 73,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._login#76",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'j_username': username,\n            'j_password': password,\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        error = self._html_search_regex(\n            r'(?s)<ul[^>]+class=\"[^\"]*\\blist_error\\b[^\"]*\">(.+?)</ul>',\n            response, 'error', default=None)\n        if error:\n            raise ExtractorError(\n                'Unable to login: %s' % error, expected=True)",
        "begin_line": 76,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_extract#99",
        "src_path": "youtube_dl/extractor/atresplayer.py",
        "class_name": "youtube_dl.extractor.atresplayer.AtresPlayerIE",
        "signature": "youtube_dl.extractor.atresplayer.AtresPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        episode_id = self._search_regex(\n            r'episode=\"([^\"]+)\"', webpage, 'episode id')\n\n        request = sanitized_Request(\n            self._PLAYER_URL_TEMPLATE % episode_id,\n            headers={'User-Agent': self._USER_AGENT})\n        player = self._download_json(request, episode_id, 'Downloading player JSON')\n\n        episode_type = player.get('typeOfEpisode')\n        error_message = self._ERRORS.get(episode_type)\n        if error_message:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_message), expected=True)\n\n        formats = []\n        video_url = player.get('urlVideo')\n        if video_url:\n            format_info = {\n                'url': video_url,\n                'format_id': 'http',\n            }\n            mobj = re.search(r'(?P<bitrate>\\d+)K_(?P<width>\\d+)x(?P<height>\\d+)', video_url)\n            if mobj:\n                format_info.update({\n                    'width': int_or_none(mobj.group('width')),\n                    'height': int_or_none(mobj.group('height')),\n                    'tbr': int_or_none(mobj.group('bitrate')),\n                })\n            formats.append(format_info)\n\n        timestamp = int_or_none(self._download_webpage(\n            self._TIME_API_URL,\n            video_id, 'Downloading timestamp', fatal=False), 1000, time.time())\n        timestamp_shifted = compat_str(timestamp + self._TIMESTAMP_SHIFT)\n        token = hmac.new(\n            self._MAGIC.encode('ascii'),\n            (episode_id + timestamp_shifted).encode('utf-8'), hashlib.md5\n        ).hexdigest()\n\n        request = sanitized_Request(\n            self._URL_VIDEO_TEMPLATE.format('windows', episode_id, timestamp_shifted, token),\n            headers={'User-Agent': self._USER_AGENT})\n\n        fmt_json = self._download_json(\n            request, video_id, 'Downloading windows video JSON')\n\n        result = fmt_json.get('resultDes')\n        if result.lower() != 'ok':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, result), expected=True)\n\n        for format_id, video_url in fmt_json['resultObject'].items():\n            if format_id == 'token' or not video_url.startswith('http'):\n                continue\n            if 'geodeswowsmpra3player' in video_url:\n                # f4m_path = video_url.split('smil:', 1)[-1].split('free_', 1)[0]\n                # f4m_url = 'http://drg.antena3.com/{0}hds/es/sd.f4m'.format(f4m_path)\n                # this videos are protected by DRM, the f4m downloader doesn't support them\n                continue\n            video_url_hd = video_url.replace('free_es', 'es')\n            formats.extend(self._extract_f4m_formats(\n                video_url_hd[:-9] + '/manifest.f4m', video_id, f4m_id='hds',\n                fatal=False))\n            formats.extend(self._extract_mpd_formats(\n                video_url_hd[:-9] + '/manifest.mpd', video_id, mpd_id='dash',\n                fatal=False))\n        self._sort_formats(formats)\n\n        path_data = player.get('pathData')\n\n        episode = self._download_xml(\n            self._EPISODE_URL_TEMPLATE % path_data, video_id,\n            'Downloading episode XML')\n\n        duration = float_or_none(xpath_text(\n            episode, './media/asset/info/technical/contentDuration', 'duration'))\n\n        art = episode.find('./media/asset/info/art')\n        title = xpath_text(art, './name', 'title')\n        description = xpath_text(art, './description', 'description')\n        thumbnail = xpath_text(episode, './media/asset/files/background', 'thumbnail')\n\n        subtitles = {}\n        subtitle_url = xpath_text(episode, './media/asset/files/subtitle', 'subtitle')\n        if subtitle_url:\n            subtitles['es'] = [{\n                'ext': 'srt',\n                'url': subtitle_url,\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 99,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/atttechchannel.py",
        "class_name": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE",
        "signature": "youtube_dl.extractor.atttechchannel.ATTTechChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r\"url\\s*:\\s*'(rtmp://[^']+)'\",\n            webpage, 'video URL')\n\n        video_id = self._search_regex(\n            r'mediaid\\s*=\\s*(\\d+)',\n            webpage, 'video id', fatal=False)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'[Rr]elease\\s+date:\\s*(\\d{1,2}/\\d{1,2}/\\d{4})',\n            webpage, 'upload date', fatal=False), False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 26,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.atvat.ATVAtIE._real_extract#27",
        "src_path": "youtube_dl/extractor/atvat.py",
        "class_name": "youtube_dl.extractor.atvat.ATVAtIE",
        "signature": "youtube_dl.extractor.atvat.ATVAtIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_data = self._parse_json(unescapeHTML(self._search_regex(\n            r'class=\"[^\"]*jsb_video/FlashPlayer[^\"]*\"[^>]+data-jsb=\"([^\"]+)\"',\n            webpage, 'player data')), display_id)['config']['initial_video']\n\n        video_id = video_data['id']\n        video_title = video_data['title']\n\n        parts = []\n        for part in video_data.get('parts', []):\n            part_id = part['id']\n            part_title = part['title']\n\n            formats = []\n            for source in part.get('sources', []):\n                source_url = source.get('src')\n                if not source_url:\n                    continue\n                ext = determine_ext(source_url)\n                if ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        source_url, part_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n                else:\n                    formats.append({\n                        'format_id': source.get('delivery'),\n                        'url': source_url,\n                    })\n            self._sort_formats(formats)\n\n            parts.append({\n                'id': part_id,\n                'title': part_title,\n                'thumbnail': part.get('preview_image_url'),\n                'duration': int_or_none(part.get('duration')),\n                'is_live': part.get('is_livestream'),\n                'formats': formats,\n            })\n\n        return {\n            '_type': 'multi_video',\n            'id': video_id,\n            'title': video_title,\n            'entries': parts,\n        }",
        "begin_line": 27,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.audimedia.AudiMediaIE._real_extract#31",
        "src_path": "youtube_dl/extractor/audimedia.py",
        "class_name": "youtube_dl.extractor.audimedia.AudiMediaIE",
        "signature": "youtube_dl.extractor.audimedia.AudiMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        raw_payload = self._search_regex([\n            r'class=\"amtv-embed\"[^>]+id=\"([^\"]+)\"',\n            r'class=\\\\\"amtv-embed\\\\\"[^>]+id=\\\\\"([^\"]+)\\\\\"',\n        ], webpage, 'raw payload')\n        _, stage_mode, video_id, lang = raw_payload.split('-')\n\n        # TODO: handle s and e stage_mode (live streams and ended live streams)\n        if stage_mode not in ('s', 'e'):\n            request = sanitized_Request(\n                'https://audimedia.tv/api/video/v1/videos/%s?embed[]=video_versions&embed[]=thumbnail_image&where[content_language_iso]=%s' % (video_id, lang),\n                headers={'X-Auth-Token': self._AUTH_TOKEN})\n            json_data = self._download_json(request, video_id)['results']\n            formats = []\n\n            stream_url_hls = json_data.get('stream_url_hls')\n            if stream_url_hls:\n                formats.extend(self._extract_m3u8_formats(\n                    stream_url_hls, video_id, 'mp4',\n                    entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n\n            stream_url_hds = json_data.get('stream_url_hds')\n            if stream_url_hds:\n                formats.extend(self._extract_f4m_formats(\n                    stream_url_hds + '?hdcore=3.4.0',\n                    video_id, f4m_id='hds', fatal=False))\n\n            for video_version in json_data.get('video_versions'):\n                video_version_url = video_version.get('download_url') or video_version.get('stream_url')\n                if not video_version_url:\n                    continue\n                f = {\n                    'url': video_version_url,\n                    'width': int_or_none(video_version.get('width')),\n                    'height': int_or_none(video_version.get('height')),\n                    'abr': int_or_none(video_version.get('audio_bitrate')),\n                    'vbr': int_or_none(video_version.get('video_bitrate')),\n                }\n                bitrate = self._search_regex(r'(\\d+)k', video_version_url, 'bitrate', default=None)\n                if bitrate:\n                    f.update({\n                        'format_id': 'http-%s' % bitrate,\n                    })\n                formats.append(f)\n            self._sort_formats(formats)\n\n            return {\n                'id': video_id,\n                'title': json_data['title'],\n                'description': json_data.get('subtitle'),\n                'thumbnail': json_data.get('thumbnail_image', {}).get('file'),\n                'timestamp': parse_iso8601(json_data.get('publication_date')),\n                'duration': int_or_none(json_data.get('duration')),\n                'view_count': int_or_none(json_data.get('view_count')),\n                'formats': formats,\n            }",
        "begin_line": 31,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.audioboom.AudioBoomIE._real_extract#27",
        "src_path": "youtube_dl/extractor/audioboom.py",
        "class_name": "youtube_dl.extractor.audioboom.AudioBoomIE",
        "signature": "youtube_dl.extractor.audioboom.AudioBoomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        clip = None\n\n        clip_store = self._parse_json(\n            self._search_regex(\n                r'data-new-clip-store=([\"\\'])(?P<json>{.*?\"clipId\"\\s*:\\s*%s.*?})\\1' % video_id,\n                webpage, 'clip store', default='{}', group='json'),\n            video_id, fatal=False)\n        if clip_store:\n            clips = clip_store.get('clips')\n            if clips and isinstance(clips, list) and isinstance(clips[0], dict):\n                clip = clips[0]\n\n        def from_clip(field):\n            if clip:\n                return clip.get(field)\n\n        audio_url = from_clip('clipURLPriorToLoading') or self._og_search_property(\n            'audio', webpage, 'audio url')\n        title = from_clip('title') or self._og_search_title(webpage)\n        description = from_clip('description') or self._og_search_description(webpage)\n\n        duration = float_or_none(from_clip('duration') or self._html_search_meta(\n            'weibo:audio:duration', webpage))\n\n        uploader = from_clip('author') or self._og_search_property(\n            'audio:artist', webpage, 'uploader', fatal=False)\n        uploader_url = from_clip('author_url') or self._html_search_meta(\n            'audioboo:channel', webpage, 'uploader url')\n\n        return {\n            'id': video_id,\n            'url': audio_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_url': uploader_url,\n        }",
        "begin_line": 27,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.audiomack.AudiomackIE._real_extract#46",
        "src_path": "youtube_dl/extractor/audiomack.py",
        "class_name": "youtube_dl.extractor.audiomack.AudiomackIE",
        "signature": "youtube_dl.extractor.audiomack.AudiomackIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # URLs end with [uploader name]/[uploader title]\n        # this title is whatever the user types in, and is rarely\n        # the proper song title.  Real metadata is in the api response\n        album_url_tag = self._match_id(url)\n\n        # Request the extended version of the api for extra fields like artist and title\n        api_response = self._download_json(\n            'http://www.audiomack.com/api/music/url/song/%s?extended=1&_=%d' % (\n                album_url_tag, time.time()),\n            album_url_tag)\n\n        # API is inconsistent with errors\n        if 'url' not in api_response or not api_response['url'] or 'error' in api_response:\n            raise ExtractorError('Invalid url %s' % url)\n\n        # Audiomack wraps a lot of soundcloud tracks in their branded wrapper\n        # if so, pass the work off to the soundcloud extractor\n        if SoundcloudIE.suitable(api_response['url']):\n            return {'_type': 'url', 'url': api_response['url'], 'ie_key': 'Soundcloud'}\n\n        return {\n            'id': api_response.get('id', album_url_tag),\n            'uploader': api_response.get('artist'),\n            'title': api_response.get('title'),\n            'url': api_response['url'],\n        }",
        "begin_line": 46,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.audiomack.AudiomackAlbumIE._real_extract#111",
        "src_path": "youtube_dl/extractor/audiomack.py",
        "class_name": "youtube_dl.extractor.audiomack.AudiomackAlbumIE",
        "signature": "youtube_dl.extractor.audiomack.AudiomackAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # URLs end with [uploader name]/[uploader title]\n        # this title is whatever the user types in, and is rarely\n        # the proper song title.  Real metadata is in the api response\n        album_url_tag = self._match_id(url)\n        result = {'_type': 'playlist', 'entries': []}\n        # There is no one endpoint for album metadata - instead it is included/repeated in each song's metadata\n        # Therefore we don't know how many songs the album has and must infi-loop until failure\n        for track_no in itertools.count():\n            # Get song's metadata\n            api_response = self._download_json(\n                'http://www.audiomack.com/api/music/url/album/%s/%d?extended=1&_=%d'\n                % (album_url_tag, track_no, time.time()), album_url_tag,\n                note='Querying song information (%d)' % (track_no + 1))\n\n            # Total failure, only occurs when url is totally wrong\n            # Won't happen in middle of valid playlist (next case)\n            if 'url' not in api_response or 'error' in api_response:\n                raise ExtractorError('Invalid url for track %d of album url %s' % (track_no, url))\n            # URL is good but song id doesn't exist - usually means end of playlist\n            elif not api_response['url']:\n                break\n            else:\n                # Pull out the album metadata and add to result (if it exists)\n                for resultkey, apikey in [('id', 'album_id'), ('title', 'album_title')]:\n                    if apikey in api_response and resultkey not in result:\n                        result[resultkey] = api_response[apikey]\n                song_id = url_basename(api_response['url']).rpartition('.')[0]\n                result['entries'].append({\n                    'id': compat_str(api_response.get('id', song_id)),\n                    'uploader': api_response.get('artist'),\n                    'title': api_response.get('title', song_id),\n                    'url': api_response['url'],\n                })\n        return result",
        "begin_line": 111,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.awaan.AWAANIE._real_extract#24",
        "src_path": "youtube_dl/extractor/awaan.py",
        "class_name": "youtube_dl.extractor.awaan.AWAANIE",
        "signature": "youtube_dl.extractor.awaan.AWAANIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id, video_id, season_id = re.match(self._VALID_URL, url).groups()\n        if video_id and int(video_id) > 0:\n            return self.url_result(\n                'http://awaan.ae/media/%s' % video_id, 'AWAANVideo')\n        elif season_id and int(season_id) > 0:\n            return self.url_result(smuggle_url(\n                'http://awaan.ae/program/season/%s' % season_id,\n                {'show_id': show_id}), 'AWAANSeason')\n        else:\n            return self.url_result(\n                'http://awaan.ae/program/%s' % show_id, 'AWAANSeason')",
        "begin_line": 24,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.awaan.AWAANBaseIE._parse_video_data#39",
        "src_path": "youtube_dl/extractor/awaan.py",
        "class_name": "youtube_dl.extractor.awaan.AWAANBaseIE",
        "signature": "youtube_dl.extractor.awaan.AWAANBaseIE._parse_video_data(self, video_data, video_id, is_live)",
        "snippet": "    def _parse_video_data(self, video_data, video_id, is_live):\n        title = video_data.get('title_en') or video_data['title_ar']\n        img = video_data.get('img')\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': video_data.get('description_en') or video_data.get('description_ar'),\n            'thumbnail': 'http://admin.mangomolo.com/analytics/%s' % img if img else None,\n            'duration': int_or_none(video_data.get('duration')),\n            'timestamp': parse_iso8601(video_data.get('create_time'), ' '),\n            'is_live': is_live,\n        }",
        "begin_line": 39,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.awaan.AWAANVideoIE._real_extract#76",
        "src_path": "youtube_dl/extractor/awaan.py",
        "class_name": "youtube_dl.extractor.awaan.AWAANVideoIE",
        "signature": "youtube_dl.extractor.awaan.AWAANVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_data = self._download_json(\n            'http://admin.mangomolo.com/analytics/index.php/plus/video?id=%s' % video_id,\n            video_id, headers={'Origin': 'http://awaan.ae'})\n        info = self._parse_video_data(video_data, video_id, False)\n\n        embed_url = 'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?' + compat_urllib_parse_urlencode({\n            'id': video_data['id'],\n            'user_id': video_data['user_id'],\n            'signature': video_data['signature'],\n            'countries': 'Q0M=',\n            'filter': 'DENY',\n        })\n        info.update({\n            '_type': 'url_transparent',\n            'url': embed_url,\n            'ie_key': 'MangomoloVideo',\n        })\n        return info",
        "begin_line": 76,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.awaan.AWAANLiveIE._real_extract#117",
        "src_path": "youtube_dl/extractor/awaan.py",
        "class_name": "youtube_dl.extractor.awaan.AWAANLiveIE",
        "signature": "youtube_dl.extractor.awaan.AWAANLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        channel_data = self._download_json(\n            'http://admin.mangomolo.com/analytics/index.php/plus/getchanneldetails?channel_id=%s' % channel_id,\n            channel_id, headers={'Origin': 'http://awaan.ae'})\n        info = self._parse_video_data(channel_data, channel_id, True)\n\n        embed_url = 'http://admin.mangomolo.com/analytics/index.php/customers/embed/index?' + compat_urllib_parse_urlencode({\n            'id': base64.b64encode(channel_data['user_id'].encode()).decode(),\n            'channelid': base64.b64encode(channel_data['id'].encode()).decode(),\n            'signature': channel_data['signature'],\n            'countries': 'Q0M=',\n            'filter': 'DENY',\n        })\n        info.update({\n            '_type': 'url_transparent',\n            'url': embed_url,\n            'ie_key': 'MangomoloLive',\n        })\n        return info",
        "begin_line": 117,
        "end_line": 137,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.awaan.AWAANSeasonIE._real_extract#153",
        "src_path": "youtube_dl/extractor/awaan.py",
        "class_name": "youtube_dl.extractor.awaan.AWAANSeasonIE",
        "signature": "youtube_dl.extractor.awaan.AWAANSeasonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        show_id, season_id = re.match(self._VALID_URL, url).groups()\n\n        data = {}\n        if season_id:\n            data['season'] = season_id\n            show_id = smuggled_data.get('show_id')\n            if show_id is None:\n                season = self._download_json(\n                    'http://admin.mangomolo.com/analytics/index.php/plus/season_info?id=%s' % season_id,\n                    season_id, headers={'Origin': 'http://awaan.ae'})\n                show_id = season['id']\n        data['show_id'] = show_id\n        show = self._download_json(\n            'http://admin.mangomolo.com/analytics/index.php/plus/show',\n            show_id, data=urlencode_postdata(data), headers={\n                'Origin': 'http://awaan.ae',\n                'Content-Type': 'application/x-www-form-urlencoded'\n            })\n        if not season_id:\n            season_id = show['default_season']\n        for season in show['seasons']:\n            if season['id'] == season_id:\n                title = season.get('title_en') or season['title_ar']\n\n                entries = []\n                for video in show['videos']:\n                    video_id = compat_str(video['id'])\n                    entries.append(self.url_result(\n                        'http://awaan.ae/media/%s' % video_id, 'AWAANVideo', video_id))\n\n                return self.playlist_result(entries, season_id, title)",
        "begin_line": 153,
        "end_line": 185,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.azmedien.AZMedienBaseIE._kaltura_video#17",
        "src_path": "youtube_dl/extractor/azmedien.py",
        "class_name": "youtube_dl.extractor.azmedien.AZMedienBaseIE",
        "signature": "youtube_dl.extractor.azmedien.AZMedienBaseIE._kaltura_video(self, partner_id, entry_id)",
        "snippet": "    def _kaltura_video(self, partner_id, entry_id):\n        return self.url_result(\n            'kaltura:%s:%s' % (partner_id, entry_id), ie=KalturaIE.ie_key(),\n            video_id=entry_id)",
        "begin_line": 17,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.azmedien.AZMedienIE._real_extract#74",
        "src_path": "youtube_dl/extractor/azmedien.py",
        "class_name": "youtube_dl.extractor.azmedien.AZMedienIE",
        "signature": "youtube_dl.extractor.azmedien.AZMedienIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        partner_id = self._search_regex(\n            r'<script[^>]+src=[\"\\'](?:https?:)?//(?:[^/]+\\.)?kaltura\\.com(?:/[^/]+)*/(?:p|partner_id)/([0-9]+)',\n            webpage, 'kaltura partner id')\n        entry_id = self._html_search_regex(\n            r'<a[^>]+data-id=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1[^>]+data-slug=[\"\\']%s'\n            % re.escape(video_id), webpage, 'kaltura entry id', group='id')\n\n        return self._kaltura_video(partner_id, entry_id)",
        "begin_line": 74,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.azmedien.AZMedienPlaylistIE._real_extract#137",
        "src_path": "youtube_dl/extractor/azmedien.py",
        "class_name": "youtube_dl.extractor.azmedien.AZMedienPlaylistIE",
        "signature": "youtube_dl.extractor.azmedien.AZMedienPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n        webpage = self._download_webpage(url, show_id)\n\n        entries = []\n\n        partner_id = self._search_regex(\n            r'src=[\"\\'](?:https?:)?//(?:[^/]+\\.)kaltura\\.com/(?:[^/]+/)*(?:p|partner_id)/(\\d+)',\n            webpage, 'kaltura partner id', default=None)\n\n        if partner_id:\n            entries = [\n                self._kaltura_video(partner_id, m.group('id'))\n                for m in re.finditer(\n                    r'data-id=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1', webpage)]\n\n        if not entries:\n            entries = [\n                self.url_result(m.group('url'), ie=AZMedienIE.ie_key())\n                for m in re.finditer(\n                    r'<a[^>]+data-real=([\"\\'])(?P<url>http.+?)\\1', webpage)]\n\n        if not entries:\n            entries = [\n                # May contain nested playlists (e.g. [1]) thus no explicit\n                # ie_key\n                # 1. http://www.telezueri.ch/219-topic-aera-trump-hat-offiziell-begonnen)\n                self.url_result(urljoin(url, m.group('url')))\n                for m in re.finditer(\n                    r'<a[^>]+name=[^>]+href=([\"\\'])(?P<url>/.+?)\\1', webpage)]\n\n        title = self._search_regex(\n            r'episodeShareTitle\\s*=\\s*([\"\\'])(?P<title>(?:(?!\\1).)+)\\1',\n            webpage, 'title',\n            default=strip_or_none(get_element_by_id(\n                'video-title', webpage)), group='title')\n\n        return self.playlist_result(entries, show_id, title)",
        "begin_line": 137,
        "end_line": 174,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.azmedien.AZMedienShowPlaylistIE._real_extract#204",
        "src_path": "youtube_dl/extractor/azmedien.py",
        "class_name": "youtube_dl.extractor.azmedien.AZMedienShowPlaylistIE",
        "signature": "youtube_dl.extractor.azmedien.AZMedienShowPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n        episodes = get_element_by_class('search-mobile-box', webpage)\n        entries = [self.url_result(\n            urljoin(url, m.group('url'))) for m in re.finditer(\n                r'<a[^>]+href=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', episodes)]\n        title = self._og_search_title(webpage, fatal=False)\n        description = self._og_search_description(webpage)\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 204,
        "end_line": 213,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.baidu.BaiduVideoIE._call_api#31",
        "src_path": "youtube_dl/extractor/baidu.py",
        "class_name": "youtube_dl.extractor.baidu.BaiduVideoIE",
        "signature": "youtube_dl.extractor.baidu.BaiduVideoIE._call_api(self, path, category, playlist_id, note)",
        "snippet": "    def _call_api(self, path, category, playlist_id, note):\n        return self._download_json('http://app.video.baidu.com/%s/?worktype=adnative%s&id=%s' % (\n            path, category, playlist_id), playlist_id, note)",
        "begin_line": 31,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.baidu.BaiduVideoIE._real_extract#35",
        "src_path": "youtube_dl/extractor/baidu.py",
        "class_name": "youtube_dl.extractor.baidu.BaiduVideoIE",
        "signature": "youtube_dl.extractor.baidu.BaiduVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        category, playlist_id = re.match(self._VALID_URL, url).groups()\n        if category == 'show':\n            category = 'tvshow'\n        if category == 'tv':\n            category = 'tvplay'\n\n        playlist_detail = self._call_api(\n            'xqinfo', category, playlist_id, 'Download playlist JSON metadata')\n\n        playlist_title = playlist_detail['title']\n        playlist_description = unescapeHTML(playlist_detail.get('intro'))\n\n        episodes_detail = self._call_api(\n            'xqsingle', category, playlist_id, 'Download episodes JSON metadata')\n\n        entries = [self.url_result(\n            episode['url'], video_title=episode['title']\n        ) for episode in episodes_detail['videos']]\n\n        return self.playlist_result(\n            entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 35,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._login#46",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'form_id': 'user_login',\n            'op': 'Log in',\n            'name': username,\n            'pass': password,\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form))\n        request.add_header('Referer', self._LOGIN_URL)\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        login_error = self._html_search_regex(\n            r'(?s)<div class=\"messages error\">(.+?)</div>',\n            response, 'login error', default=None)\n        if login_error:\n            raise ExtractorError(\n                'Unable to login: %s' % login_error, expected=True)",
        "begin_line": 46,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_initialize#71",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_extract#74",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://player-c.api.bambuser.com/getVideo.json?api_key=%s&vid=%s'\n            % (self._API_KEY, video_id), video_id)\n\n        error = info.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        result = info['result']\n\n        return {\n            'id': video_id,\n            'title': result['title'],\n            'url': result['url'],\n            'thumbnail': result.get('preview'),\n            'duration': int_or_none(result.get('length')),\n            'uploader': result.get('username'),\n            'uploader_id': compat_str(result.get('owner', {}).get('uid')),\n            'timestamp': int_or_none(result.get('created')),\n            'fps': float_or_none(result.get('framerate')),\n            'view_count': int_or_none(result.get('views_total')),\n            'comment_count': int_or_none(result.get('comment_count')),\n        }",
        "begin_line": 74,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract#116",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserChannelIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        urls = []\n        last_id = ''\n        for i in itertools.count(1):\n            req_url = (\n                'http://bambuser.com/xhr-api/index.php?username={user}'\n                '&sort=created&access_mode=0%2C1%2C2&limit={count}'\n                '&method=broadcast&format=json&vid_older_than={last}'\n            ).format(user=user, count=self._STEP, last=last_id)\n            req = sanitized_Request(req_url)\n            # Without setting this header, we wouldn't get any result\n            req.add_header('Referer', 'http://bambuser.com/channel/%s' % user)\n            data = self._download_json(\n                req, user, 'Downloading page %d' % i)\n            results = data['result']\n            if not results:\n                break\n            last_id = results[-1]['vid']\n            urls.extend(self.url_result(v['page'], 'Bambuser') for v in results)\n\n        return {\n            '_type': 'playlist',\n            'title': user,\n            'entries': urls,\n        }",
        "begin_line": 116,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract#48",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        thumbnail = self._html_search_meta('og:image', webpage, default=None)\n        m_download = re.search(r'freeDownloadPage: \"(.*?)\"', webpage)\n        if not m_download:\n            m_trackinfo = re.search(r'trackinfo: (.+),\\s*?\\n', webpage)\n            if m_trackinfo:\n                json_code = m_trackinfo.group(1)\n                data = json.loads(json_code)[0]\n                track_id = compat_str(data['id'])\n\n                if not data.get('file'):\n                    raise ExtractorError('Not streamable', video_id=track_id, expected=True)\n\n                formats = []\n                for format_id, format_url in data['file'].items():\n                    ext, abr_str = format_id.split('-', 1)\n                    formats.append({\n                        'format_id': format_id,\n                        'url': self._proto_relative_url(format_url, 'http:'),\n                        'ext': ext,\n                        'vcodec': 'none',\n                        'acodec': ext,\n                        'abr': int_or_none(abr_str),\n                    })\n\n                self._sort_formats(formats)\n\n                return {\n                    'id': track_id,\n                    'title': data['title'],\n                    'thumbnail': thumbnail,\n                    'formats': formats,\n                    'duration': float_or_none(data.get('duration')),\n                }\n            else:\n                raise ExtractorError('No free songs found')\n\n        download_link = m_download.group(1)\n        video_id = self._search_regex(\n            r'(?ms)var TralbumData = .*?[{,]\\s*id: (?P<id>\\d+),?$',\n            webpage, 'video id')\n\n        download_webpage = self._download_webpage(\n            download_link, video_id, 'Downloading free downloads page')\n\n        blob = self._parse_json(\n            self._search_regex(\n                r'data-blob=([\"\\'])(?P<blob>{.+?})\\1', download_webpage,\n                'blob', group='blob'),\n            video_id, transform_source=unescapeHTML)\n\n        info = blob['digital_items'][0]\n\n        downloads = info['downloads']\n        track = info['title']\n\n        artist = info.get('artist')\n        title = '%s - %s' % (artist, track) if artist else track\n\n        download_formats = {}\n        for f in blob['download_formats']:\n            name, ext = f.get('name'), f.get('file_extension')\n            if all(isinstance(x, compat_str) for x in (name, ext)):\n                download_formats[name] = ext.strip('.')\n\n        formats = []\n        for format_id, f in downloads.items():\n            format_url = f.get('url')\n            if not format_url:\n                continue\n            # Stat URL generation algorithm is reverse engineered from\n            # download_*_bundle_*.js\n            stat_url = update_url_query(\n                format_url.replace('/download/', '/statdownload/'), {\n                    '.rand': int(time.time() * 1000 * random.random()),\n                })\n            format_id = f.get('encoding_name') or format_id\n            stat = self._download_json(\n                stat_url, video_id, 'Downloading %s JSON' % format_id,\n                transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1],\n                fatal=False)\n            if not stat:\n                continue\n            retry_url = stat.get('retry_url')\n            if not isinstance(retry_url, compat_str):\n                continue\n            formats.append({\n                'url': self._proto_relative_url(retry_url, 'http:'),\n                'ext': download_formats.get(format_id),\n                'format_id': format_id,\n                'format_note': f.get('description'),\n                'filesize': parse_filesize(f.get('size_mb')),\n                'vcodec': 'none',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': info.get('thumb_url') or thumbnail,\n            'uploader': info.get('artist'),\n            'artist': artist,\n            'track': track,\n            'formats': formats,\n        }",
        "begin_line": 48,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE.suitable#228",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return (False\n                if BandcampWeeklyIE.suitable(url) or BandcampIE.suitable(url)\n                else super(BandcampAlbumIE, cls).suitable(url))",
        "begin_line": 228,
        "end_line": 231,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract#233",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('subdomain')\n        album_id = mobj.group('album_id')\n        playlist_id = album_id or uploader_id\n        webpage = self._download_webpage(url, playlist_id)\n        track_elements = re.findall(\n            r'(?s)<div[^>]*>(.*?<a[^>]+href=\"([^\"]+?)\"[^>]+itemprop=\"url\"[^>]*>.*?)</div>', webpage)\n        if not track_elements:\n            raise ExtractorError('The page doesn\\'t contain any tracks')\n        # Only tracks with duration info have songs\n        entries = [\n            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())\n            for elem_content, t_path in track_elements\n            if self._html_search_meta('duration', elem_content, default=None)]\n\n        title = self._html_search_regex(\n            r'album_title\\s*:\\s*\"((?:\\\\.|[^\"\\\\])+?)\"',\n            webpage, 'title', fatal=False)\n        if title:\n            title = title.replace(r'\\\"', '\"')\n        return {\n            '_type': 'playlist',\n            'uploader_id': uploader_id,\n            'id': playlist_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 233,
        "end_line": 260,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampWeeklyIE._real_extract#286",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampWeeklyIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampWeeklyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        blob = self._parse_json(\n            self._search_regex(\n                r'data-blob=([\"\\'])(?P<blob>{.+?})\\1', webpage,\n                'blob', group='blob'),\n            video_id, transform_source=unescapeHTML)\n\n        show = blob['bcw_show']\n\n        # This is desired because any invalid show id redirects to `bandcamp.com`\n        # which happens to expose the latest Bandcamp Weekly episode.\n        show_id = int_or_none(show.get('show_id')) or int_or_none(video_id)\n\n        formats = []\n        for format_id, format_url in show['audio_stream'].items():\n            if not isinstance(format_url, compat_str):\n                continue\n            for known_ext in KNOWN_EXTENSIONS:\n                if known_ext in format_id:\n                    ext = known_ext\n                    break\n            else:\n                ext = None\n            formats.append({\n                'format_id': format_id,\n                'url': format_url,\n                'ext': ext,\n                'vcodec': 'none',\n            })\n        self._sort_formats(formats)\n\n        title = show.get('audio_title') or 'Bandcamp Weekly'\n        subtitle = show.get('subtitle')\n        if subtitle:\n            title += ' - %s' % subtitle\n\n        episode_number = None\n        seq = blob.get('bcw_seq')\n\n        if seq and isinstance(seq, list):\n            try:\n                episode_number = next(\n                    int_or_none(e.get('episode_number'))\n                    for e in seq\n                    if isinstance(e, dict) and int_or_none(e.get('id')) == show_id)\n            except StopIteration:\n                pass\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': show.get('desc') or show.get('short_desc'),\n            'duration': float_or_none(show.get('audio_duration')),\n            'is_live': False,\n            'release_date': unified_strdate(show.get('published_date')),\n            'series': 'Bandcamp Weekly',\n            'episode': show.get('subtitle'),\n            'episode_number': episode_number,\n            'episode_id': compat_str(video_id),\n            'formats': formats\n        }",
        "begin_line": 286,
        "end_line": 349,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._login#239",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._login(self)",
        "snippet": "    def _login(self):\n        username, password = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading signin page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'username': username,\n            'password': password,\n        })\n\n        post_url = urljoin(self._LOGIN_URL, self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', login_page,\n            'post url', default=self._LOGIN_URL, group='url'))\n\n        response, urlh = self._download_webpage_handle(\n            post_url, None, 'Logging in', data=urlencode_postdata(login_form),\n            headers={'Referer': self._LOGIN_URL})\n\n        if self._LOGIN_URL in urlh.geturl():\n            error = clean_html(get_element_by_class('form-message', response))\n            if error:\n                raise ExtractorError(\n                    'Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 239,
        "end_line": 267,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._real_initialize#269",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 269,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.MediaSelectionError.__init__#273",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.MediaSelectionError",
        "signature": "youtube_dl.extractor.bbc.MediaSelectionError.__init__(self, id)",
        "snippet": "        def __init__(self, id):\n            self.id = id",
        "begin_line": 273,
        "end_line": 274,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_asx_playlist#276",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_asx_playlist(self, connection, programme_id)",
        "snippet": "    def _extract_asx_playlist(self, connection, programme_id):\n        asx = self._download_xml(connection.get('href'), programme_id, 'Downloading ASX playlist')\n        return [ref.get('href') for ref in asx.findall('./Entry/ref')]",
        "begin_line": 276,
        "end_line": 278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_items#280",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_items(self, playlist)",
        "snippet": "    def _extract_items(self, playlist):\n        return playlist.findall('./{%s}item' % self._EMP_PLAYLIST_NS)",
        "begin_line": 280,
        "end_line": 281,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._findall_ns#283",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._findall_ns(self, element, xpath)",
        "snippet": "    def _findall_ns(self, element, xpath):\n        elements = []\n        for ns in self._NAMESPACES:\n            elements.extend(element.findall(xpath % ns))\n        return elements",
        "begin_line": 283,
        "end_line": 287,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_medias#289",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_medias(self, media_selection)",
        "snippet": "    def _extract_medias(self, media_selection):\n        error = media_selection.find('./{%s}error' % self._MEDIASELECTION_NS)\n        if error is None:\n            media_selection.find('./{%s}error' % self._EMP_PLAYLIST_NS)\n        if error is not None:\n            raise BBCCoUkIE.MediaSelectionError(error.get('id'))\n        return self._findall_ns(media_selection, './{%s}media')",
        "begin_line": 289,
        "end_line": 295,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connections#297",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_connections(self, media)",
        "snippet": "    def _extract_connections(self, media):\n        return self._findall_ns(media, './{%s}connection')",
        "begin_line": 297,
        "end_line": 298,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._get_subtitles#300",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._get_subtitles(self, media, programme_id)",
        "snippet": "    def _get_subtitles(self, media, programme_id):\n        subtitles = {}\n        for connection in self._extract_connections(media):\n            captions = self._download_xml(connection.get('href'), programme_id, 'Downloading captions')\n            lang = captions.get('{http://www.w3.org/XML/1998/namespace}lang', 'en')\n            subtitles[lang] = [\n                {\n                    'url': connection.get('href'),\n                    'ext': 'ttml',\n                },\n            ]\n        return subtitles",
        "begin_line": 300,
        "end_line": 311,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._raise_extractor_error#313",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._raise_extractor_error(self, media_selection_error)",
        "snippet": "    def _raise_extractor_error(self, media_selection_error):\n        raise ExtractorError(\n            '%s returned error: %s' % (self.IE_NAME, media_selection_error.id),\n            expected=True)",
        "begin_line": 313,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector#318",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector(self, programme_id)",
        "snippet": "    def _download_media_selector(self, programme_id):\n        last_exception = None\n        for mediaselector_url in self._MEDIASELECTOR_URLS:\n            try:\n                return self._download_media_selector_url(\n                    mediaselector_url % programme_id, programme_id)\n            except BBCCoUkIE.MediaSelectionError as e:\n                if e.id in ('notukerror', 'geolocation', 'selectionunavailable'):\n                    last_exception = e\n                    continue\n                self._raise_extractor_error(e)\n        self._raise_extractor_error(last_exception)",
        "begin_line": 318,
        "end_line": 329,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector_url#331",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_media_selector_url(self, url, programme_id=None)",
        "snippet": "    def _download_media_selector_url(self, url, programme_id=None):\n        try:\n            media_selection = self._download_xml(\n                url, programme_id, 'Downloading media selection XML')\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code in (403, 404):\n                media_selection = compat_etree_fromstring(ee.cause.read().decode('utf-8'))\n            else:\n                raise\n        return self._process_media_selector(media_selection, programme_id)",
        "begin_line": 331,
        "end_line": 340,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_media_selector#342",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_media_selector(self, media_selection, programme_id)",
        "snippet": "    def _process_media_selector(self, media_selection, programme_id):\n        formats = []\n        subtitles = None\n        urls = []\n\n        for media in self._extract_medias(media_selection):\n            kind = media.get('kind')\n            if kind in ('video', 'audio'):\n                bitrate = int_or_none(media.get('bitrate'))\n                encoding = media.get('encoding')\n                service = media.get('service')\n                width = int_or_none(media.get('width'))\n                height = int_or_none(media.get('height'))\n                file_size = int_or_none(media.get('media_file_size'))\n                for connection in self._extract_connections(media):\n                    href = connection.get('href')\n                    if href in urls:\n                        continue\n                    if href:\n                        urls.append(href)\n                    conn_kind = connection.get('kind')\n                    protocol = connection.get('protocol')\n                    supplier = connection.get('supplier')\n                    transfer_format = connection.get('transferFormat')\n                    format_id = supplier or conn_kind or protocol\n                    if service:\n                        format_id = '%s_%s' % (service, format_id)\n                    # ASX playlist\n                    if supplier == 'asx':\n                        for i, ref in enumerate(self._extract_asx_playlist(connection, programme_id)):\n                            formats.append({\n                                'url': ref,\n                                'format_id': 'ref%s_%s' % (i, format_id),\n                            })\n                    elif transfer_format == 'dash':\n                        formats.extend(self._extract_mpd_formats(\n                            href, programme_id, mpd_id=format_id, fatal=False))\n                    elif transfer_format == 'hls':\n                        formats.extend(self._extract_m3u8_formats(\n                            href, programme_id, ext='mp4', entry_protocol='m3u8_native',\n                            m3u8_id=format_id, fatal=False))\n                        if re.search(self._USP_RE, href):\n                            usp_formats = self._extract_m3u8_formats(\n                                re.sub(self._USP_RE, r'/\\1.ism/\\1.m3u8', href),\n                                programme_id, ext='mp4', entry_protocol='m3u8_native',\n                                m3u8_id=format_id, fatal=False)\n                            for f in usp_formats:\n                                if f.get('height') and f['height'] > 720:\n                                    continue\n                                formats.append(f)\n                    elif transfer_format == 'hds':\n                        formats.extend(self._extract_f4m_formats(\n                            href, programme_id, f4m_id=format_id, fatal=False))\n                    else:\n                        if not service and not supplier and bitrate:\n                            format_id += '-%d' % bitrate\n                        fmt = {\n                            'format_id': format_id,\n                            'filesize': file_size,\n                        }\n                        if kind == 'video':\n                            fmt.update({\n                                'width': width,\n                                'height': height,\n                                'tbr': bitrate,\n                                'vcodec': encoding,\n                            })\n                        else:\n                            fmt.update({\n                                'abr': bitrate,\n                                'acodec': encoding,\n                                'vcodec': 'none',\n                            })\n                        if protocol in ('http', 'https'):\n                            # Direct link\n                            fmt.update({\n                                'url': href,\n                            })\n                        elif protocol == 'rtmp':\n                            application = connection.get('application', 'ondemand')\n                            auth_string = connection.get('authString')\n                            identifier = connection.get('identifier')\n                            server = connection.get('server')\n                            fmt.update({\n                                'url': '%s://%s/%s?%s' % (protocol, server, application, auth_string),\n                                'play_path': identifier,\n                                'app': '%s?%s' % (application, auth_string),\n                                'page_url': 'http://www.bbc.co.uk',\n                                'player_url': 'http://www.bbc.co.uk/emp/releases/iplayer/revisions/617463_618125_4/617463_618125_4_emp.swf',\n                                'rtmp_live': False,\n                                'ext': 'flv',\n                            })\n                        else:\n                            continue\n                        formats.append(fmt)\n            elif kind == 'captions':\n                subtitles = self.extract_subtitles(media, programme_id)\n        return formats, subtitles",
        "begin_line": 342,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_playlist#441",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_playlist(self, playlist_id)",
        "snippet": "    def _download_playlist(self, playlist_id):\n        try:\n            playlist = self._download_json(\n                'http://www.bbc.co.uk/programmes/%s/playlist.json' % playlist_id,\n                playlist_id, 'Downloading playlist JSON')\n\n            version = playlist.get('defaultAvailableVersion')\n            if version:\n                smp_config = version['smpConfig']\n                title = smp_config['title']\n                description = smp_config['summary']\n                for item in smp_config['items']:\n                    kind = item['kind']\n                    if kind not in ('programme', 'radioProgramme'):\n                        continue\n                    programme_id = item.get('vpid')\n                    duration = int_or_none(item.get('duration'))\n                    formats, subtitles = self._download_media_selector(programme_id)\n                return programme_id, title, description, duration, formats, subtitles\n        except ExtractorError as ee:\n            if not (isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404):\n                raise\n\n        # fallback to legacy playlist\n        return self._process_legacy_playlist(playlist_id)",
        "begin_line": 441,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist_url#467",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist_url(self, url, display_id)",
        "snippet": "    def _process_legacy_playlist_url(self, url, display_id):\n        playlist = self._download_legacy_playlist_url(url, display_id)\n        return self._extract_from_legacy_playlist(playlist, display_id)",
        "begin_line": 467,
        "end_line": 469,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist#471",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._process_legacy_playlist(self, playlist_id)",
        "snippet": "    def _process_legacy_playlist(self, playlist_id):\n        return self._process_legacy_playlist_url(\n            'http://www.bbc.co.uk/iplayer/playlist/%s' % playlist_id, playlist_id)",
        "begin_line": 471,
        "end_line": 473,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._download_legacy_playlist_url#475",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._download_legacy_playlist_url(self, url, playlist_id=None)",
        "snippet": "    def _download_legacy_playlist_url(self, url, playlist_id=None):\n        return self._download_xml(\n            url, playlist_id, 'Downloading legacy playlist XML')",
        "begin_line": 475,
        "end_line": 477,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_from_legacy_playlist#479",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._extract_from_legacy_playlist(self, playlist, playlist_id)",
        "snippet": "    def _extract_from_legacy_playlist(self, playlist, playlist_id):\n        no_items = playlist.find('./{%s}noItems' % self._EMP_PLAYLIST_NS)\n        if no_items is not None:\n            reason = no_items.get('reason')\n            if reason == 'preAvailability':\n                msg = 'Episode %s is not yet available' % playlist_id\n            elif reason == 'postAvailability':\n                msg = 'Episode %s is no longer available' % playlist_id\n            elif reason == 'noMedia':\n                msg = 'Episode %s is not currently available' % playlist_id\n            else:\n                msg = 'Episode %s is not available: %s' % (playlist_id, reason)\n            raise ExtractorError(msg, expected=True)\n\n        for item in self._extract_items(playlist):\n            kind = item.get('kind')\n            if kind not in ('programme', 'radioProgramme'):\n                continue\n            title = playlist.find('./{%s}title' % self._EMP_PLAYLIST_NS).text\n            description_el = playlist.find('./{%s}summary' % self._EMP_PLAYLIST_NS)\n            description = description_el.text if description_el is not None else None\n\n            def get_programme_id(item):\n                def get_from_attributes(item):\n                    for p in('identifier', 'group'):\n                        value = item.get(p)\n                        if value and re.match(r'^[pb][\\da-z]{7}$', value):\n                            return value\n                get_from_attributes(item)\n                mediator = item.find('./{%s}mediator' % self._EMP_PLAYLIST_NS)\n                if mediator is not None:\n                    return get_from_attributes(mediator)\n\n            programme_id = get_programme_id(item)\n            duration = int_or_none(item.get('duration'))\n\n            if programme_id:\n                formats, subtitles = self._download_media_selector(programme_id)\n            else:\n                formats, subtitles = self._process_media_selector(item, playlist_id)\n                programme_id = playlist_id\n\n        return programme_id, title, description, duration, formats, subtitles",
        "begin_line": 479,
        "end_line": 521,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIE._real_extract#523",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        group_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, group_id, 'Downloading video page')\n\n        error = self._search_regex(\n            r'<div\\b[^>]+\\bclass=[\"\\']smp__message delta[\"\\'][^>]*>([^<]+)<',\n            webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(error, expected=True)\n\n        programme_id = None\n        duration = None\n\n        tviplayer = self._search_regex(\n            r'mediator\\.bind\\(({.+?})\\s*,\\s*document\\.getElementById',\n            webpage, 'player', default=None)\n\n        if tviplayer:\n            player = self._parse_json(tviplayer, group_id).get('player', {})\n            duration = int_or_none(player.get('duration'))\n            programme_id = player.get('vpid')\n\n        if not programme_id:\n            programme_id = self._search_regex(\n                r'\"vpid\"\\s*:\\s*\"(%s)\"' % self._ID_REGEX, webpage, 'vpid', fatal=False, default=None)\n\n        if programme_id:\n            formats, subtitles = self._download_media_selector(programme_id)\n            title = self._og_search_title(webpage, default=None) or self._html_search_regex(\n                (r'<h2[^>]+id=\"parent-title\"[^>]*>(.+?)</h2>',\n                 r'<div[^>]+class=\"info\"[^>]*>\\s*<h1>(.+?)</h1>'), webpage, 'title')\n            description = self._search_regex(\n                (r'<p class=\"[^\"]*medium-description[^\"]*\">([^<]+)</p>',\n                 r'<div[^>]+class=\"info_+synopsis\"[^>]*>([^<]+)</div>'),\n                webpage, 'description', default=None)\n            if not description:\n                description = self._html_search_meta('description', webpage)\n        else:\n            programme_id, title, description, duration, formats, subtitles = self._download_playlist(group_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 523,
        "end_line": 574,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE.suitable#774",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        EXCLUDE_IE = (BBCCoUkIE, BBCCoUkArticleIE, BBCCoUkIPlayerPlaylistIE, BBCCoUkPlaylistIE)\n        return (False if any(ie.suitable(url) for ie in EXCLUDE_IE)\n                else super(BBCIE, cls).suitable(url))",
        "begin_line": 774,
        "end_line": 777,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._extract_from_media_meta#779",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._extract_from_media_meta(self, media_meta, video_id)",
        "snippet": "    def _extract_from_media_meta(self, media_meta, video_id):\n        # Direct links to media in media metadata (e.g.\n        # http://www.bbc.com/turkce/haberler/2015/06/150615_telabyad_kentin_cogu)\n        # TODO: there are also f4m and m3u8 streams incorporated in playlist.sxml\n        source_files = media_meta.get('sourceFiles')\n        if source_files:\n            return [{\n                'url': f['url'],\n                'format_id': format_id,\n                'ext': f.get('encoding'),\n                'tbr': float_or_none(f.get('bitrate'), 1000),\n                'filesize': int_or_none(f.get('filesize')),\n            } for format_id, f in source_files.items() if f.get('url')], []\n\n        programme_id = media_meta.get('externalId')\n        if programme_id:\n            return self._download_media_selector(programme_id)\n\n        # Process playlist.sxml as legacy playlist\n        href = media_meta.get('href')\n        if href:\n            playlist = self._download_legacy_playlist_url(href)\n            _, _, _, _, formats, subtitles = self._extract_from_legacy_playlist(playlist, video_id)\n            return formats, subtitles\n\n        return [], []",
        "begin_line": 779,
        "end_line": 804,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._extract_from_playlist_sxml#806",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._extract_from_playlist_sxml(self, url, playlist_id, timestamp)",
        "snippet": "    def _extract_from_playlist_sxml(self, url, playlist_id, timestamp):\n        programme_id, title, description, duration, formats, subtitles = \\\n            self._process_legacy_playlist_url(url, playlist_id)\n        self._sort_formats(formats)\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 806,
        "end_line": 818,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCIE._real_extract#820",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCIE",
        "signature": "youtube_dl.extractor.bbc.BBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        json_ld_info = self._search_json_ld(webpage, playlist_id, default={})\n        timestamp = json_ld_info.get('timestamp')\n\n        playlist_title = json_ld_info.get('title')\n        if not playlist_title:\n            playlist_title = self._og_search_title(\n                webpage, default=None) or self._html_search_regex(\n                r'<title>(.+?)</title>', webpage, 'playlist title', default=None)\n            if playlist_title:\n                playlist_title = re.sub(r'(.+)\\s*-\\s*BBC.*?$', r'\\1', playlist_title).strip()\n\n        playlist_description = json_ld_info.get(\n            'description') or self._og_search_description(webpage, default=None)\n\n        if not timestamp:\n            timestamp = parse_iso8601(self._search_regex(\n                [r'<meta[^>]+property=\"article:published_time\"[^>]+content=\"([^\"]+)\"',\n                 r'itemprop=\"datePublished\"[^>]+datetime=\"([^\"]+)\"',\n                 r'\"datePublished\":\\s*\"([^\"]+)'],\n                webpage, 'date', default=None))\n\n        entries = []\n\n        # article with multiple videos embedded with playlist.sxml (e.g.\n        # http://www.bbc.com/sport/0/football/34475836)\n        playlists = re.findall(r'<param[^>]+name=\"playlist\"[^>]+value=\"([^\"]+)\"', webpage)\n        playlists.extend(re.findall(r'data-media-id=\"([^\"]+/playlist\\.sxml)\"', webpage))\n        if playlists:\n            entries = [\n                self._extract_from_playlist_sxml(playlist_url, playlist_id, timestamp)\n                for playlist_url in playlists]\n\n        # news article with multiple videos embedded with data-playable\n        data_playables = re.findall(r'data-playable=([\"\\'])({.+?})\\1', webpage)\n        if data_playables:\n            for _, data_playable_json in data_playables:\n                data_playable = self._parse_json(\n                    unescapeHTML(data_playable_json), playlist_id, fatal=False)\n                if not data_playable:\n                    continue\n                settings = data_playable.get('settings', {})\n                if settings:\n                    # data-playable with video vpid in settings.playlistObject.items (e.g.\n                    # http://www.bbc.com/news/world-us-canada-34473351)\n                    playlist_object = settings.get('playlistObject', {})\n                    if playlist_object:\n                        items = playlist_object.get('items')\n                        if items and isinstance(items, list):\n                            title = playlist_object['title']\n                            description = playlist_object.get('summary')\n                            duration = int_or_none(items[0].get('duration'))\n                            programme_id = items[0].get('vpid')\n                            formats, subtitles = self._download_media_selector(programme_id)\n                            self._sort_formats(formats)\n                            entries.append({\n                                'id': programme_id,\n                                'title': title,\n                                'description': description,\n                                'timestamp': timestamp,\n                                'duration': duration,\n                                'formats': formats,\n                                'subtitles': subtitles,\n                            })\n                    else:\n                        # data-playable without vpid but with a playlist.sxml URLs\n                        # in otherSettings.playlist (e.g.\n                        # http://www.bbc.com/turkce/multimedya/2015/10/151010_vid_ankara_patlama_ani)\n                        playlist = data_playable.get('otherSettings', {}).get('playlist', {})\n                        if playlist:\n                            entry = None\n                            for key in ('streaming', 'progressiveDownload'):\n                                playlist_url = playlist.get('%sUrl' % key)\n                                if not playlist_url:\n                                    continue\n                                try:\n                                    info = self._extract_from_playlist_sxml(\n                                        playlist_url, playlist_id, timestamp)\n                                    if not entry:\n                                        entry = info\n                                    else:\n                                        entry['title'] = info['title']\n                                        entry['formats'].extend(info['formats'])\n                                except Exception as e:\n                                    # Some playlist URL may fail with 500, at the same time\n                                    # the other one may work fine (e.g.\n                                    # http://www.bbc.com/turkce/haberler/2015/06/150615_telabyad_kentin_cogu)\n                                    if isinstance(e.cause, compat_HTTPError) and e.cause.code == 500:\n                                        continue\n                                    raise\n                            if entry:\n                                self._sort_formats(entry['formats'])\n                                entries.append(entry)\n\n        if entries:\n            return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)\n\n        # single video story (e.g. http://www.bbc.com/travel/story/20150625-sri-lankas-spicy-secret)\n        programme_id = self._search_regex(\n            [r'data-(?:video-player|media)-vpid=\"(%s)\"' % self._ID_REGEX,\n             r'<param[^>]+name=\"externalIdentifier\"[^>]+value=\"(%s)\"' % self._ID_REGEX,\n             r'videoId\\s*:\\s*[\"\\'](%s)[\"\\']' % self._ID_REGEX],\n            webpage, 'vpid', default=None)\n\n        if programme_id:\n            formats, subtitles = self._download_media_selector(programme_id)\n            self._sort_formats(formats)\n            # digitalData may be missing (e.g. http://www.bbc.com/autos/story/20130513-hyundais-rock-star)\n            digital_data = self._parse_json(\n                self._search_regex(\n                    r'var\\s+digitalData\\s*=\\s*({.+?});?\\n', webpage, 'digital data', default='{}'),\n                programme_id, fatal=False)\n            page_info = digital_data.get('page', {}).get('pageInfo', {})\n            title = page_info.get('pageName') or self._og_search_title(webpage)\n            description = page_info.get('description') or self._og_search_description(webpage)\n            timestamp = parse_iso8601(page_info.get('publicationDate')) or timestamp\n            return {\n                'id': programme_id,\n                'title': title,\n                'description': description,\n                'timestamp': timestamp,\n                'formats': formats,\n                'subtitles': subtitles,\n            }\n\n        # Morph based embed (e.g. http://www.bbc.co.uk/sport/live/olympics/36895975)\n        # There are several setPayload calls may be present but the video\n        # seems to be always related to the first one\n        morph_payload = self._parse_json(\n            self._search_regex(\n                r'Morph\\.setPayload\\([^,]+,\\s*({.+?})\\);',\n                webpage, 'morph payload', default='{}'),\n            playlist_id, fatal=False)\n        if morph_payload:\n            components = try_get(morph_payload, lambda x: x['body']['components'], list) or []\n            for component in components:\n                if not isinstance(component, dict):\n                    continue\n                lead_media = try_get(component, lambda x: x['props']['leadMedia'], dict)\n                if not lead_media:\n                    continue\n                identifiers = lead_media.get('identifiers')\n                if not identifiers or not isinstance(identifiers, dict):\n                    continue\n                programme_id = identifiers.get('vpid') or identifiers.get('playablePid')\n                if not programme_id:\n                    continue\n                title = lead_media.get('title') or self._og_search_title(webpage)\n                formats, subtitles = self._download_media_selector(programme_id)\n                self._sort_formats(formats)\n                description = lead_media.get('summary')\n                uploader = lead_media.get('masterBrand')\n                uploader_id = lead_media.get('mid')\n                duration = None\n                duration_d = lead_media.get('duration')\n                if isinstance(duration_d, dict):\n                    duration = parse_duration(dict_get(\n                        duration_d, ('rawDuration', 'formattedDuration', 'spokenDuration')))\n                return {\n                    'id': programme_id,\n                    'title': title,\n                    'description': description,\n                    'duration': duration,\n                    'uploader': uploader,\n                    'uploader_id': uploader_id,\n                    'formats': formats,\n                    'subtitles': subtitles,\n                }\n\n        def extract_all(pattern):\n            return list(filter(None, map(\n                lambda s: self._parse_json(s, playlist_id, fatal=False),\n                re.findall(pattern, webpage))))\n\n        # Multiple video article (e.g.\n        # http://www.bbc.co.uk/blogs/adamcurtis/entries/3662a707-0af9-3149-963f-47bea720b460)\n        EMBED_URL = r'https?://(?:www\\.)?bbc\\.co\\.uk/(?:[^/]+/)+%s(?:\\b[^\"]+)?' % self._ID_REGEX\n        entries = []\n        for match in extract_all(r'new\\s+SMP\\(({.+?})\\)'):\n            embed_url = match.get('playerSettings', {}).get('externalEmbedUrl')\n            if embed_url and re.match(EMBED_URL, embed_url):\n                entries.append(embed_url)\n        entries.extend(re.findall(\n            r'setPlaylist\\(\"(%s)\"\\)' % EMBED_URL, webpage))\n        if entries:\n            return self.playlist_result(\n                [self.url_result(entry_, 'BBCCoUk') for entry_ in entries],\n                playlist_id, playlist_title, playlist_description)\n\n        # Multiple video article (e.g. http://www.bbc.com/news/world-europe-32668511)\n        medias = extract_all(r\"data-media-meta='({[^']+})'\")\n\n        if not medias:\n            # Single video article (e.g. http://www.bbc.com/news/video_and_audio/international)\n            media_asset = self._search_regex(\n                r'mediaAssetPage\\.init\\(\\s*({.+?}), \"/',\n                webpage, 'media asset', default=None)\n            if media_asset:\n                media_asset_page = self._parse_json(media_asset, playlist_id, fatal=False)\n                medias = []\n                for video in media_asset_page.get('videos', {}).values():\n                    medias.extend(video.values())\n\n        if not medias:\n            # Multiple video playlist with single `now playing` entry (e.g.\n            # http://www.bbc.com/news/video_and_audio/must_see/33767813)\n            vxp_playlist = self._parse_json(\n                self._search_regex(\n                    r'<script[^>]+class=\"vxp-playlist-data\"[^>]+type=\"application/json\"[^>]*>([^<]+)</script>',\n                    webpage, 'playlist data'),\n                playlist_id)\n            playlist_medias = []\n            for item in vxp_playlist:\n                media = item.get('media')\n                if not media:\n                    continue\n                playlist_medias.append(media)\n                # Download single video if found media with asset id matching the video id from URL\n                if item.get('advert', {}).get('assetId') == playlist_id:\n                    medias = [media]\n                    break\n            # Fallback to the whole playlist\n            if not medias:\n                medias = playlist_medias\n\n        entries = []\n        for num, media_meta in enumerate(medias, start=1):\n            formats, subtitles = self._extract_from_media_meta(media_meta, playlist_id)\n            if not formats:\n                continue\n            self._sort_formats(formats)\n\n            video_id = media_meta.get('externalId')\n            if not video_id:\n                video_id = playlist_id if len(medias) == 1 else '%s-%s' % (playlist_id, num)\n\n            title = media_meta.get('caption')\n            if not title:\n                title = playlist_title if len(medias) == 1 else '%s - Video %s' % (playlist_title, num)\n\n            duration = int_or_none(media_meta.get('durationInSeconds')) or parse_duration(media_meta.get('duration'))\n\n            images = []\n            for image in media_meta.get('images', {}).values():\n                images.extend(image.values())\n            if 'image' in media_meta:\n                images.append(media_meta['image'])\n\n            thumbnails = [{\n                'url': image.get('href'),\n                'width': int_or_none(image.get('width')),\n                'height': int_or_none(image.get('height')),\n            } for image in images]\n\n            entries.append({\n                'id': video_id,\n                'title': title,\n                'thumbnails': thumbnails,\n                'duration': duration,\n                'timestamp': timestamp,\n                'formats': formats,\n                'subtitles': subtitles,\n            })\n\n        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 820,
        "end_line": 1088,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkArticleIE._real_extract#1107",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkArticleIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage).strip()\n\n        entries = [self.url_result(programme_url) for programme_url in re.findall(\n            r'<div[^>]+typeof=\"Clip\"[^>]+resource=\"([^\"]+)\"', webpage)]\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 1107,
        "end_line": 1118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE._entries#1122",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE._entries(self, webpage, url, playlist_id)",
        "snippet": "    def _entries(self, webpage, url, playlist_id):\n        single_page = 'page' in compat_urlparse.parse_qs(\n            compat_urlparse.urlparse(url).query)\n        for page_num in itertools.count(2):\n            for video_id in re.findall(\n                    self._VIDEO_ID_TEMPLATE % BBCCoUkIE._ID_REGEX, webpage):\n                yield self.url_result(\n                    self._URL_TEMPLATE % video_id, BBCCoUkIE.ie_key())\n            if single_page:\n                return\n            next_page = self._search_regex(\n                r'<li[^>]+class=([\"\\'])pagination_+next\\1[^>]*><a[^>]+href=([\"\\'])(?P<url>(?:(?!\\2).)+)\\2',\n                webpage, 'next page url', default=None, group='url')\n            if not next_page:\n                break\n            webpage = self._download_webpage(\n                compat_urlparse.urljoin(url, next_page), playlist_id,\n                'Downloading page %d' % page_num, page_num)",
        "begin_line": 1122,
        "end_line": 1139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE._real_extract#1141",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        title, description = self._extract_title_and_description(webpage)\n\n        return self.playlist_result(\n            self._entries(webpage, url, playlist_id),\n            playlist_id, title, description)",
        "begin_line": 1141,
        "end_line": 1150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkIPlayerPlaylistIE._extract_title_and_description#1178",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkIPlayerPlaylistIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkIPlayerPlaylistIE._extract_title_and_description(self, webpage)",
        "snippet": "    def _extract_title_and_description(self, webpage):\n        title = self._search_regex(r'<h1>([^<]+)</h1>', webpage, 'title', fatal=False)\n        description = self._search_regex(\n            r'<p[^>]+class=([\"\\'])subtitle\\1[^>]*>(?P<value>[^<]+)</p>',\n            webpage, 'description', fatal=False, group='value')\n        return title, description",
        "begin_line": 1178,
        "end_line": 1183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistIE._extract_title_and_description#1228",
        "src_path": "youtube_dl/extractor/bbc.py",
        "class_name": "youtube_dl.extractor.bbc.BBCCoUkPlaylistIE",
        "signature": "youtube_dl.extractor.bbc.BBCCoUkPlaylistIE._extract_title_and_description(self, webpage)",
        "snippet": "    def _extract_title_and_description(self, webpage):\n        title = self._og_search_title(webpage, fatal=False)\n        description = self._og_search_description(webpage)\n        return title, description",
        "begin_line": 1228,
        "end_line": 1231,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beampro.BeamProBaseIE._extract_channel_info#21",
        "src_path": "youtube_dl/extractor/beampro.py",
        "class_name": "youtube_dl.extractor.beampro.BeamProBaseIE",
        "signature": "youtube_dl.extractor.beampro.BeamProBaseIE._extract_channel_info(self, chan)",
        "snippet": "    def _extract_channel_info(self, chan):\n        user_id = chan.get('userId') or try_get(chan, lambda x: x['user']['id'])\n        return {\n            'uploader': chan.get('token') or try_get(\n                chan, lambda x: x['user']['username'], compat_str),\n            'uploader_id': compat_str(user_id) if user_id else None,\n            'age_limit': self._RATINGS.get(chan.get('audience')),\n        }",
        "begin_line": 21,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beampro.BeamProLiveIE.suitable#59",
        "src_path": "youtube_dl/extractor/beampro.py",
        "class_name": "youtube_dl.extractor.beampro.BeamProLiveIE",
        "signature": "youtube_dl.extractor.beampro.BeamProLiveIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if BeamProVodIE.suitable(url) else super(BeamProLiveIE, cls).suitable(url)",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beampro.BeamProLiveIE._real_extract#62",
        "src_path": "youtube_dl/extractor/beampro.py",
        "class_name": "youtube_dl.extractor.beampro.BeamProLiveIE",
        "signature": "youtube_dl.extractor.beampro.BeamProLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_name = self._match_id(url)\n\n        chan = self._download_json(\n            '%s/channels/%s' % (self._API_BASE, channel_name), channel_name)\n\n        if chan.get('online') is False:\n            raise ExtractorError(\n                '{0} is offline'.format(channel_name), expected=True)\n\n        channel_id = chan['id']\n\n        def manifest_url(kind):\n            return self._MANIFEST_URL_TEMPLATE % (channel_id, kind)\n\n        formats = self._extract_m3u8_formats(\n            manifest_url('m3u8'), channel_name, ext='mp4', m3u8_id='hls',\n            fatal=False)\n        formats.extend(self._extract_smil_formats(\n            manifest_url('smil'), channel_name, fatal=False))\n        self._sort_formats(formats)\n\n        info = {\n            'id': compat_str(chan.get('id') or channel_name),\n            'title': self._live_title(chan.get('name') or channel_name),\n            'description': clean_html(chan.get('description')),\n            'thumbnail': try_get(\n                chan, lambda x: x['thumbnail']['url'], compat_str),\n            'timestamp': parse_iso8601(chan.get('updatedAt')),\n            'is_live': True,\n            'view_count': int_or_none(chan.get('viewersTotal')),\n            'formats': formats,\n        }\n        info.update(self._extract_channel_info(chan))\n\n        return info",
        "begin_line": 62,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beampro.BeamProVodIE._extract_format#125",
        "src_path": "youtube_dl/extractor/beampro.py",
        "class_name": "youtube_dl.extractor.beampro.BeamProVodIE",
        "signature": "youtube_dl.extractor.beampro.BeamProVodIE._extract_format(vod, vod_type)",
        "snippet": "    def _extract_format(vod, vod_type):\n        if not vod.get('baseUrl'):\n            return []\n\n        if vod_type == 'hls':\n            filename, protocol = 'manifest.m3u8', 'm3u8_native'\n        elif vod_type == 'raw':\n            filename, protocol = 'source.mp4', 'https'\n        else:\n            assert False\n\n        data = vod.get('data') if isinstance(vod.get('data'), dict) else {}\n\n        format_id = [vod_type]\n        if isinstance(data.get('Height'), compat_str):\n            format_id.append('%sp' % data['Height'])\n\n        return [{\n            'url': urljoin(vod['baseUrl'], filename),\n            'format_id': '-'.join(format_id),\n            'ext': 'mp4',\n            'protocol': protocol,\n            'width': int_or_none(data.get('Width')),\n            'height': int_or_none(data.get('Height')),\n            'fps': int_or_none(data.get('Fps')),\n            'tbr': int_or_none(data.get('Bitrate'), 1000),\n        }]",
        "begin_line": 125,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beampro.BeamProVodIE._real_extract#153",
        "src_path": "youtube_dl/extractor/beampro.py",
        "class_name": "youtube_dl.extractor.beampro.BeamProVodIE",
        "signature": "youtube_dl.extractor.beampro.BeamProVodIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        vod_id = self._match_id(url)\n\n        vod_info = self._download_json(\n            '%s/recordings/%s' % (self._API_BASE, vod_id), vod_id)\n\n        state = vod_info.get('state')\n        if state != 'AVAILABLE':\n            raise ExtractorError(\n                'VOD %s is not available (state: %s)' % (vod_id, state),\n                expected=True)\n\n        formats = []\n        thumbnail_url = None\n\n        for vod in vod_info['vods']:\n            vod_type = vod.get('format')\n            if vod_type in ('hls', 'raw'):\n                formats.extend(self._extract_format(vod, vod_type))\n            elif vod_type == 'thumbnail':\n                thumbnail_url = urljoin(vod.get('baseUrl'), 'source.png')\n\n        self._sort_formats(formats)\n\n        info = {\n            'id': vod_id,\n            'title': vod_info.get('name') or vod_id,\n            'duration': float_or_none(vod_info.get('duration')),\n            'thumbnail': thumbnail_url,\n            'timestamp': parse_iso8601(vod_info.get('createdAt')),\n            'view_count': int_or_none(vod_info.get('viewsTotal')),\n            'formats': formats,\n        }\n        info.update(self._extract_channel_info(vod_info.get('channel') or {}))\n\n        return info",
        "begin_line": 153,
        "end_line": 188,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beatport.BeatportIE._real_extract#42",
        "src_path": "youtube_dl/extractor/beatport.py",
        "class_name": "youtube_dl.extractor.beatport.BeatportIE",
        "signature": "youtube_dl.extractor.beatport.BeatportIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        track_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        playables = self._parse_json(\n            self._search_regex(\n                r'window\\.Playables\\s*=\\s*({.+?});', webpage,\n                'playables info', flags=re.DOTALL),\n            track_id)\n\n        track = next(t for t in playables['tracks'] if t['id'] == int(track_id))\n\n        title = ', '.join((a['name'] for a in track['artists'])) + ' - ' + track['name']\n        if track['mix']:\n            title += ' (' + track['mix'] + ')'\n\n        formats = []\n        for ext, info in track['preview'].items():\n            if not info['url']:\n                continue\n            fmt = {\n                'url': info['url'],\n                'ext': ext,\n                'format_id': ext,\n                'vcodec': 'none',\n            }\n            if ext == 'mp3':\n                fmt['preference'] = 0\n                fmt['acodec'] = 'mp3'\n                fmt['abr'] = 96\n                fmt['asr'] = 44100\n            elif ext == 'mp4':\n                fmt['preference'] = 1\n                fmt['acodec'] = 'aac'\n                fmt['abr'] = 96\n                fmt['asr'] = 44100\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        images = []\n        for name, info in track['images'].items():\n            image_url = info.get('url')\n            if name == 'dynamic' or not image_url:\n                continue\n            image = {\n                'id': name,\n                'url': image_url,\n                'height': int_or_none(info.get('height')),\n                'width': int_or_none(info.get('width')),\n            }\n            images.append(image)\n\n        return {\n            'id': compat_str(track.get('id')) or track_id,\n            'display_id': track.get('slug') or display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnails': images,\n        }",
        "begin_line": 42,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.beeg.BeegIE._real_extract#33",
        "src_path": "youtube_dl/extractor/beeg.py",
        "class_name": "youtube_dl.extractor.beeg.BeegIE",
        "signature": "youtube_dl.extractor.beeg.BeegIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        cpl_url = self._search_regex(\n            r'<script[^>]+src=([\"\\'])(?P<url>(?:https?:)?//static\\.beeg\\.com/cpl/\\d+\\.js.*?)\\1',\n            webpage, 'cpl', default=None, group='url')\n\n        beeg_version, beeg_salt = [None] * 2\n\n        if cpl_url:\n            cpl = self._download_webpage(\n                self._proto_relative_url(cpl_url), video_id,\n                'Downloading cpl JS', fatal=False)\n            if cpl:\n                beeg_version = int_or_none(self._search_regex(\n                    r'beeg_version\\s*=\\s*([^\\b]+)', cpl,\n                    'beeg version', default=None)) or self._search_regex(\n                    r'/(\\d+)\\.js', cpl_url, 'beeg version', default=None)\n                beeg_salt = self._search_regex(\n                    r'beeg_salt\\s*=\\s*([\"\\'])(?P<beeg_salt>.+?)\\1', cpl, 'beeg salt',\n                    default=None, group='beeg_salt')\n\n        beeg_version = beeg_version or '2000'\n        beeg_salt = beeg_salt or 'pmweAkq8lAYKdfWcFCUj0yoVgoPlinamH5UE1CB3H'\n\n        video = self._download_json(\n            'https://api.beeg.com/api/v6/%s/video/%s' % (beeg_version, video_id),\n            video_id)\n\n        def split(o, e):\n            def cut(s, x):\n                n.append(s[:x])\n                return s[x:]\n            n = []\n            r = len(o) % e\n            if r > 0:\n                o = cut(o, r)\n            while len(o) > e:\n                o = cut(o, e)\n            n.append(o)\n            return n\n\n        def decrypt_key(key):\n            # Reverse engineered from http://static.beeg.com/cpl/1738.js\n            a = beeg_salt\n            e = compat_urllib_parse_unquote(key)\n            o = ''.join([\n                compat_chr(compat_ord(e[n]) - compat_ord(a[n % len(a)]) % 21)\n                for n in range(len(e))])\n            return ''.join(split(o, 3)[::-1])\n\n        def decrypt_url(encrypted_url):\n            encrypted_url = self._proto_relative_url(\n                encrypted_url.replace('{DATA_MARKERS}', ''), 'https:')\n            key = self._search_regex(\n                r'/key=(.*?)%2Cend=', encrypted_url, 'key', default=None)\n            if not key:\n                return encrypted_url\n            return encrypted_url.replace(key, decrypt_key(key))\n\n        formats = []\n        for format_id, video_url in video.items():\n            if not video_url:\n                continue\n            height = self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None)\n            if not height:\n                continue\n            formats.append({\n                'url': decrypt_url(video_url),\n                'format_id': format_id,\n                'height': int(height),\n            })\n        self._sort_formats(formats)\n\n        title = video['title']\n        video_id = video.get('id') or video_id\n        display_id = video.get('code')\n        description = video.get('desc')\n\n        timestamp = parse_iso8601(video.get('date'), ' ')\n        duration = int_or_none(video.get('duration'))\n\n        tags = [tag.strip() for tag in video['tags'].split(',')] if video.get('tags') else None\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'tags': tags,\n            'formats': formats,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 33,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.behindkink.BehindKinkIE._real_extract#26",
        "src_path": "youtube_dl/extractor/behindkink.py",
        "class_name": "youtube_dl.extractor.behindkink.BehindKinkIE",
        "signature": "youtube_dl.extractor.behindkink.BehindKinkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r'<source src=\"([^\"]+)\"', webpage, 'video URL')\n        video_id = url_basename(video_url).split('_')[0]\n        upload_date = mobj.group('year') + mobj.group('month') + mobj.group('day')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'upload_date': upload_date,\n            'age_limit': 18,\n        }",
        "begin_line": 26,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bellmedia.BellMediaIE._real_extract#75",
        "src_path": "youtube_dl/extractor/bellmedia.py",
        "class_name": "youtube_dl.extractor.bellmedia.BellMediaIE",
        "signature": "youtube_dl.extractor.bellmedia.BellMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, video_id = re.match(self._VALID_URL, url).groups()\n        domain = domain.split('.')[0]\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': '9c9media:%s_web:%s' % (self._DOMAINS.get(domain, domain), video_id),\n            'ie_key': 'NineCNineMedia',\n        }",
        "begin_line": 75,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bet.BetIE._get_feed_query#54",
        "src_path": "youtube_dl/extractor/bet.py",
        "class_name": "youtube_dl.extractor.bet.BetIE",
        "signature": "youtube_dl.extractor.bet.BetIE._get_feed_query(self, uri)",
        "snippet": "    def _get_feed_query(self, uri):\n        return {\n            'uuid': uri,\n        }",
        "begin_line": 54,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bet.BetIE._extract_mgid#59",
        "src_path": "youtube_dl/extractor/bet.py",
        "class_name": "youtube_dl.extractor.bet.BetIE",
        "signature": "youtube_dl.extractor.bet.BetIE._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        return self._search_regex(r'data-uri=\"([^\"]+)', webpage, 'mgid')",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bet.BetIE._real_extract#62",
        "src_path": "youtube_dl/extractor/bet.py",
        "class_name": "youtube_dl.extractor.bet.BetIE",
        "signature": "youtube_dl.extractor.bet.BetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n        mgid = self._extract_mgid(webpage)\n        videos_info = self._get_videos_info(mgid)\n\n        info_dict = videos_info['entries'][0]\n\n        upload_date = unified_strdate(self._html_search_meta('date', webpage))\n        description = self._html_search_meta('description', webpage)\n\n        info_dict.update({\n            'display_id': display_id,\n            'description': description,\n            'upload_date': upload_date,\n        })\n\n        return info_dict",
        "begin_line": 62,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bigflix.BigflixIE._real_extract#32",
        "src_path": "youtube_dl/extractor/bigflix.py",
        "class_name": "youtube_dl.extractor.bigflix.BigflixIE",
        "signature": "youtube_dl.extractor.bigflix.BigflixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<div[^>]+class=[\"\\']pagetitle[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'title')\n\n        def decode_url(quoted_b64_url):\n            return base64.b64decode(compat_urllib_parse_unquote(\n                quoted_b64_url).encode('ascii')).decode('utf-8')\n\n        formats = []\n        for height, encoded_url in re.findall(\n                r'ContentURL_(\\d{3,4})[pP][^=]+=([^&]+)', webpage):\n            video_url = decode_url(encoded_url)\n            f = {\n                'url': video_url,\n                'format_id': '%sp' % height,\n                'height': int(height),\n            }\n            if video_url.startswith('rtmp'):\n                f['ext'] = 'flv'\n            formats.append(f)\n\n        file_url = self._search_regex(\n            r'file=([^&]+)', webpage, 'video url', default=None)\n        if file_url:\n            video_url = decode_url(file_url)\n            if all(f['url'] != video_url for f in formats):\n                formats.append({\n                    'url': decode_url(file_url),\n                })\n\n        self._sort_formats(formats)\n\n        description = self._html_search_meta('description', webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats\n        }",
        "begin_line": 32,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bild.BildIE._real_extract#27",
        "src_path": "youtube_dl/extractor/bild.py",
        "class_name": "youtube_dl.extractor.bild.BildIE",
        "signature": "youtube_dl.extractor.bild.BildIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_data = self._download_json(\n            url.split('.bild.html')[0] + ',view=json.bild.html', video_id)\n\n        return {\n            'id': video_id,\n            'title': unescapeHTML(video_data['title']).strip(),\n            'description': unescapeHTML(video_data.get('description')),\n            'url': video_data['clipList'][0]['srces'][0]['src'],\n            'thumbnail': video_data.get('poster'),\n            'duration': int_or_none(video_data.get('durationSec')),\n        }",
        "begin_line": 27,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliIE._report_error#78",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliIE._report_error(self, result)",
        "snippet": "    def _report_error(self, result):\n        if 'message' in result:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, result['message']), expected=True)\n        elif 'code' in result:\n            raise ExtractorError('%s returns error %d' % (self.IE_NAME, result['code']), expected=True)\n        else:\n            raise ExtractorError('Can\\'t extract Bangumi episode ID')",
        "begin_line": 78,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract#86",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        anime_id = mobj.group('anime_id')\n        webpage = self._download_webpage(url, video_id)\n\n        if 'anime/' not in url:\n            cid = compat_parse_qs(self._search_regex(\n                [r'EmbedPlayer\\([^)]+,\\s*\"([^\"]+)\"\\)',\n                 r'<iframe[^>]+src=\"https://secure\\.bilibili\\.com/secure,([^\"]+)\"'],\n                webpage, 'player parameters'))['cid'][0]\n        else:\n            if 'no_bangumi_tip' not in smuggled_data:\n                self.to_screen('Downloading episode %s. To download all videos in anime %s, re-run youtube-dl with %s' % (\n                    video_id, anime_id, compat_urlparse.urljoin(url, '//bangumi.bilibili.com/anime/%s' % anime_id)))\n            headers = {\n                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n            }\n            headers.update(self.geo_verification_headers())\n\n            js = self._download_json(\n                'http://bangumi.bilibili.com/web_api/get_source', video_id,\n                data=urlencode_postdata({'episode_id': video_id}),\n                headers=headers)\n            if 'result' not in js:\n                self._report_error(js)\n            cid = js['result']['cid']\n\n        payload = 'appkey=%s&cid=%s&otype=json&quality=2&type=mp4' % (self._APP_KEY, cid)\n        sign = hashlib.md5((payload + self._BILIBILI_KEY).encode('utf-8')).hexdigest()\n\n        video_info = self._download_json(\n            'http://interface.bilibili.com/playurl?%s&sign=%s' % (payload, sign),\n            video_id, note='Downloading video info page',\n            headers=self.geo_verification_headers())\n\n        if 'durl' not in video_info:\n            self._report_error(video_info)\n\n        entries = []\n\n        for idx, durl in enumerate(video_info['durl']):\n            formats = [{\n                'url': durl['url'],\n                'filesize': int_or_none(durl['size']),\n            }]\n            for backup_url in durl.get('backup_url', []):\n                formats.append({\n                    'url': backup_url,\n                    # backup URLs have lower priorities\n                    'preference': -2 if 'hd.mp4' in backup_url else -3,\n                })\n\n            for a_format in formats:\n                a_format.setdefault('http_headers', {}).update({\n                    'Referer': url,\n                })\n\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': '%s_part%s' % (video_id, idx),\n                'duration': float_or_none(durl.get('length'), 1000),\n                'formats': formats,\n            })\n\n        title = self._html_search_regex('<h1[^>]*>([^<]+)</h1>', webpage, 'title')\n        description = self._html_search_meta('description', webpage)\n        timestamp = unified_timestamp(self._html_search_regex(\n            r'<time[^>]+datetime=\"([^\"]+)\"', webpage, 'upload time', default=None))\n        thumbnail = self._html_search_meta(['og:image', 'thumbnailUrl'], webpage)\n\n        # TODO 'view_count' requires deobfuscating Javascript\n        info = {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'thumbnail': thumbnail,\n            'duration': float_or_none(video_info.get('timelength'), scale=1000),\n        }\n\n        uploader_mobj = re.search(\n            r'<a[^>]+href=\"(?:https?:)?//space\\.bilibili\\.com/(?P<id>\\d+)\"[^>]+title=\"(?P<name>[^\"]+)\"',\n            webpage)\n        if uploader_mobj:\n            info.update({\n                'uploader': uploader_mobj.group('name'),\n                'uploader_id': uploader_mobj.group('id'),\n            })\n\n        for entry in entries:\n            entry.update(info)\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            for idx, entry in enumerate(entries):\n                entry['id'] = '%s_part%d' % (video_id, (idx + 1))\n\n            return {\n                '_type': 'multi_video',\n                'id': video_id,\n                'title': title,\n                'description': description,\n                'entries': entries,\n            }",
        "begin_line": 86,
        "end_line": 194,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE.suitable#237",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if BiliBiliIE.suitable(url) else super(BiliBiliBangumiIE, cls).suitable(url)",
        "begin_line": 237,
        "end_line": 238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE._real_extract#240",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliBangumiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        bangumi_id = self._match_id(url)\n\n        # Sometimes this API returns a JSONP response\n        season_info = self._download_json(\n            'http://bangumi.bilibili.com/jsonp/seasoninfo/%s.ver' % bangumi_id,\n            bangumi_id, transform_source=strip_jsonp)['result']\n\n        entries = [{\n            '_type': 'url_transparent',\n            'url': smuggle_url(episode['webplay_url'], {'no_bangumi_tip': 1}),\n            'ie_key': BiliBiliIE.ie_key(),\n            'timestamp': parse_iso8601(episode.get('update_time'), delimiter=' '),\n            'episode': episode.get('index_title'),\n            'episode_number': int_or_none(episode.get('index')),\n        } for episode in season_info['episodes']]\n\n        entries = sorted(entries, key=lambda entry: entry.get('episode_number'))\n\n        return self.playlist_result(\n            entries, bangumi_id,\n            season_info.get('bangumi_title'), season_info.get('evaluate'))",
        "begin_line": 240,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.biobiochiletv.BioBioChileTVIE._real_extract#58",
        "src_path": "youtube_dl/extractor/biobiochiletv.py",
        "class_name": "youtube_dl.extractor.biobiochiletv.BioBioChileTVIE",
        "signature": "youtube_dl.extractor.biobiochiletv.BioBioChileTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        rudo_url = RudoIE._extract_url(webpage)\n        if not rudo_url:\n            raise ExtractorError('No videos found')\n\n        title = remove_end(self._og_search_title(webpage), ' - BioBioChile TV')\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._html_search_regex(\n            r'<a[^>]+href=[\"\\']https?://(?:busca|www)\\.biobiochile\\.cl/(?:lista/)?(?:author|autor)[^>]+>(.+?)</a>',\n            webpage, 'uploader', fatal=False)\n\n        return {\n            '_type': 'url_transparent',\n            'url': rudo_url,\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n        }",
        "begin_line": 58,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.biqle.BIQLEIE._real_extract#31",
        "src_path": "youtube_dl/extractor/biqle.py",
        "class_name": "youtube_dl.extractor.biqle.BIQLEIE",
        "signature": "youtube_dl.extractor.biqle.BIQLEIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        embed_url = self._proto_relative_url(self._search_regex(\n            r'<iframe.+?src=\"((?:http:)?//daxab\\.com/[^\"]+)\".*?></iframe>', webpage, 'embed url'))\n\n        return {\n            '_type': 'url_transparent',\n            'url': embed_url,\n        }",
        "begin_line": 31,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bleacherreport.BleacherReportIE._real_extract#45",
        "src_path": "youtube_dl/extractor/bleacherreport.py",
        "class_name": "youtube_dl.extractor.bleacherreport.BleacherReportIE",
        "signature": "youtube_dl.extractor.bleacherreport.BleacherReportIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        article_id = self._match_id(url)\n\n        article_data = self._download_json('http://api.bleacherreport.com/api/v1/articles/%s' % article_id, article_id)['article']\n\n        thumbnails = []\n        primary_photo = article_data.get('primaryPhoto')\n        if primary_photo:\n            thumbnails = [{\n                'url': primary_photo['url'],\n                'width': primary_photo.get('width'),\n                'height': primary_photo.get('height'),\n            }]\n\n        info = {\n            '_type': 'url_transparent',\n            'id': article_id,\n            'title': article_data['title'],\n            'uploader': article_data.get('author', {}).get('name'),\n            'uploader_id': article_data.get('authorId'),\n            'timestamp': parse_iso8601(article_data.get('createdAt')),\n            'thumbnails': thumbnails,\n            'comment_count': int_or_none(article_data.get('commentsCount')),\n            'view_count': int_or_none(article_data.get('hitCount')),\n        }\n\n        video = article_data.get('video')\n        if video:\n            video_type = video['type']\n            if video_type == 'cms.bleacherreport.com':\n                info['url'] = 'http://bleacherreport.com/video_embed?id=%s' % video['id']\n            elif video_type == 'ooyala.com':\n                info['url'] = 'ooyala:%s' % video['id']\n            elif video_type == 'youtube.com':\n                info['url'] = video['id']\n            elif video_type == 'vine.co':\n                info['url'] = 'https://vine.co/v/%s' % video['id']\n            else:\n                info['url'] = video_type + video['id']\n            return info\n        else:\n            raise ExtractorError('no video in the article', expected=True)",
        "begin_line": 45,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bleacherreport.BleacherReportCMSIE._real_extract#102",
        "src_path": "youtube_dl/extractor/bleacherreport.py",
        "class_name": "youtube_dl.extractor.bleacherreport.BleacherReportCMSIE",
        "signature": "youtube_dl.extractor.bleacherreport.BleacherReportCMSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        info = self._extract_feed_info('http://cms.bleacherreport.com/media/items/%s/akamai.json' % video_id)\n        info['id'] = video_id\n        return info",
        "begin_line": 102,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract#31",
        "src_path": "youtube_dl/extractor/blinkx.py",
        "class_name": "youtube_dl.extractor.blinkx.BlinkxIE",
        "signature": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        display_id = video_id[:8]\n\n        api_url = ('https://apib4.blinkx.com/api.php?action=play_video&' +\n                   'video=%s' % video_id)\n        data_json = self._download_webpage(api_url, display_id)\n        data = json.loads(data_json)['api']['results'][0]\n        duration = None\n        thumbnails = []\n        formats = []\n        for m in data['media']:\n            if m['type'] == 'jpg':\n                thumbnails.append({\n                    'url': m['link'],\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n            elif m['type'] == 'original':\n                duration = float(m['d'])\n            elif m['type'] == 'youtube':\n                yt_id = m['link']\n                self.to_screen('Youtube video detected: %s' % yt_id)\n                return self.url_result(yt_id, 'Youtube', video_id=yt_id)\n            elif m['type'] in ('flv', 'mp4'):\n                vcodec = remove_start(m['vcodec'], 'ff')\n                acodec = remove_start(m['acodec'], 'ff')\n                vbr = int_or_none(m.get('vbr') or m.get('vbitrate'), 1000)\n                abr = int_or_none(m.get('abr') or m.get('abitrate'), 1000)\n                tbr = vbr + abr if vbr and abr else None\n                format_id = '%s-%sk-%s' % (vcodec, tbr, m['w'])\n                formats.append({\n                    'format_id': format_id,\n                    'url': m['link'],\n                    'vcodec': vcodec,\n                    'acodec': acodec,\n                    'abr': abr,\n                    'vbr': vbr,\n                    'tbr': tbr,\n                    'width': int_or_none(m.get('w')),\n                    'height': int_or_none(m.get('h')),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'fullid': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'uploader': data['channel_name'],\n            'timestamp': data['pubdate_epoch'],\n            'description': data.get('description'),\n            'thumbnails': thumbnails,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract#48",
        "src_path": "youtube_dl/extractor/bloomberg.py",
        "class_name": "youtube_dl.extractor.bloomberg.BloombergIE",
        "signature": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        name = self._match_id(url)\n        webpage = self._download_webpage(url, name)\n        video_id = self._search_regex(\n            (r'[\"\\']bmmrId[\"\\']\\s*:\\s*([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n             r'videoId\\s*:\\s*([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n             r'data-bmmrid=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1'),\n            webpage, 'id', group='id', default=None)\n        if not video_id:\n            bplayer_data = self._parse_json(self._search_regex(\n                r'BPlayer\\(null,\\s*({[^;]+})\\);', webpage, 'id'), name)\n            video_id = bplayer_data['id']\n        title = re.sub(': Video$', '', self._og_search_title(webpage))\n\n        embed_info = self._download_json(\n            'http://www.bloomberg.com/api/embed?id=%s' % video_id, video_id)\n        formats = []\n        for stream in embed_info['streams']:\n            stream_url = stream.get('url')\n            if not stream_url:\n                continue\n            if stream['muxing_format'] == 'TS':\n                formats.extend(self._extract_m3u8_formats(\n                    stream_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n            else:\n                formats.extend(self._extract_f4m_formats(\n                    stream_url, video_id, f4m_id='hds', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 48,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bokecc.BokeCCBaseIE._extract_bokecc_formats#12",
        "src_path": "youtube_dl/extractor/bokecc.py",
        "class_name": "youtube_dl.extractor.bokecc.BokeCCBaseIE",
        "signature": "youtube_dl.extractor.bokecc.BokeCCBaseIE._extract_bokecc_formats(self, webpage, video_id, format_id=None)",
        "snippet": "    def _extract_bokecc_formats(self, webpage, video_id, format_id=None):\n        player_params_str = self._html_search_regex(\n            r'<(?:script|embed)[^>]+src=\"http://p\\.bokecc\\.com/player\\?([^\"]+)',\n            webpage, 'player params')\n\n        player_params = compat_parse_qs(player_params_str)\n\n        info_xml = self._download_xml(\n            'http://p.bokecc.com/servlet/playinfo?uid=%s&vid=%s&m=1' % (\n                player_params['siteid'][0], player_params['vid'][0]), video_id)\n\n        formats = [{\n            'format_id': format_id,\n            'url': quality.find('./copy').attrib['playurl'],\n            'preference': int(quality.attrib['value']),\n        } for quality in info_xml.findall('./video/quality')]\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 12,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bokecc.BokeCCIE._real_extract#47",
        "src_path": "youtube_dl/extractor/bokecc.py",
        "class_name": "youtube_dl.extractor.bokecc.BokeCCIE",
        "signature": "youtube_dl.extractor.bokecc.BokeCCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        qs = compat_parse_qs(re.match(self._VALID_URL, url).group('query'))\n        if not qs.get('vid') or not qs.get('uid'):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        video_id = '%s_%s' % (qs['uid'][0], qs['vid'][0])\n\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            'id': video_id,\n            'title': 'BokeCC Video',  # no title provided in the webpage\n            'formats': self._extract_bokecc_formats(webpage, video_id),\n        }",
        "begin_line": 47,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bostonglobe.BostonGlobeIE._real_extract#46",
        "src_path": "youtube_dl/extractor/bostonglobe.py",
        "class_name": "youtube_dl.extractor.bostonglobe.BostonGlobeIE",
        "signature": "youtube_dl.extractor.bostonglobe.BostonGlobeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n\n        page_title = self._og_search_title(webpage, default=None)\n\n        # <video data-brightcove-video-id=\"5320421710001\" data-account=\"245991542\" data-player=\"SJWAiyYWg\" data-embed=\"default\" class=\"video-js\" controls itemscope itemtype=\"http://schema.org/VideoObject\">\n        entries = []\n        for video in re.findall(r'(?i)(<video[^>]+>)', webpage):\n            attrs = extract_attributes(video)\n\n            video_id = attrs.get('data-brightcove-video-id')\n            account_id = attrs.get('data-account')\n            player_id = attrs.get('data-player')\n            embed = attrs.get('data-embed')\n\n            if video_id and account_id and player_id and embed:\n                entries.append(\n                    'http://players.brightcove.net/%s/%s_%s/index.html?videoId=%s'\n                    % (account_id, player_id, embed, video_id))\n\n        if len(entries) == 0:\n            return self.url_result(url, 'Generic')\n        elif len(entries) == 1:\n            return self.url_result(entries[0], 'BrightcoveNew')\n        else:\n            return self.playlist_from_matches(entries, page_id, page_title, ie='BrightcoveNew')",
        "begin_line": 46,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bpb.BpbIE._real_extract#29",
        "src_path": "youtube_dl/extractor/bpb.py",
        "class_name": "youtube_dl.extractor.bpb.BpbIE",
        "signature": "youtube_dl.extractor.bpb.BpbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2 class=\"white\">(.*?)</h2>', webpage, 'title')\n        video_info_dicts = re.findall(\n            r\"({\\s*src:\\s*'http://film\\.bpb\\.de/[^}]+})\", webpage)\n\n        formats = []\n        for video_info in video_info_dicts:\n            video_info = self._parse_json(video_info, video_id, transform_source=js_to_json)\n            quality = video_info['quality']\n            video_url = video_info['src']\n            formats.append({\n                'url': video_url,\n                'preference': 10 if quality == 'high' else 0,\n                'format_note': quality,\n                'format_id': '%s-%s' % (quality, determine_ext(video_url)),\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 29,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._real_extract#85",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        base_url, display_id = re.search(self._VALID_URL, url).groups()\n        page = self._download_webpage(url, display_id)\n        xml_url = self._search_regex(\n            r\"return BRavFramework\\.register\\(BRavFramework\\('avPlayer_(?:[a-f0-9-]{36})'\\)\\.setup\\({dataURL:'(/(?:[a-z0-9\\-]+/)+[a-z0-9/~_.-]+)'}\\)\\);\", page, 'XMLURL')\n        xml = self._download_xml(base_url + xml_url, display_id)\n\n        medias = []\n\n        for xml_media in xml.findall('video') + xml.findall('audio'):\n            media_id = xml_media.get('externalId')\n            media = {\n                'id': media_id,\n                'title': xpath_text(xml_media, 'title', 'title', True),\n                'duration': parse_duration(xpath_text(xml_media, 'duration')),\n                'formats': self._extract_formats(xpath_element(\n                    xml_media, 'assets'), media_id),\n                'thumbnails': self._extract_thumbnails(xpath_element(\n                    xml_media, 'teaserImage/variants'), base_url),\n                'description': xpath_text(xml_media, 'desc'),\n                'webpage_url': xpath_text(xml_media, 'permalink'),\n                'uploader': xpath_text(xml_media, 'author'),\n            }\n            broadcast_date = xpath_text(xml_media, 'broadcastDate')\n            if broadcast_date:\n                media['upload_date'] = ''.join(reversed(broadcast_date.split('.')))\n            medias.append(media)\n\n        if len(medias) > 1:\n            self._downloader.report_warning(\n                'found multiple medias; please '\n                'report this with the video URL to http://yt-dl.org/bug')\n        if not medias:\n            raise ExtractorError('No media entries found')\n        return medias[0]",
        "begin_line": 85,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_formats#121",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_formats(self, assets, media_id)",
        "snippet": "    def _extract_formats(self, assets, media_id):\n        formats = []\n        for asset in assets.findall('asset'):\n            format_url = xpath_text(asset, ['downloadUrl', 'url'])\n            asset_type = asset.get('type')\n            if asset_type == 'HDS':\n                formats.extend(self._extract_f4m_formats(\n                    format_url + '?hdcore=3.2.0', media_id, f4m_id='hds', fatal=False))\n            elif asset_type == 'HLS':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, media_id, 'mp4', 'm3u8_native', m3u8_id='hds', fatal=False))\n            else:\n                format_info = {\n                    'ext': xpath_text(asset, 'mediaType'),\n                    'width': int_or_none(xpath_text(asset, 'frameWidth')),\n                    'height': int_or_none(xpath_text(asset, 'frameHeight')),\n                    'tbr': int_or_none(xpath_text(asset, 'bitrateVideo')),\n                    'abr': int_or_none(xpath_text(asset, 'bitrateAudio')),\n                    'vcodec': xpath_text(asset, 'codecVideo'),\n                    'acodec': xpath_text(asset, 'codecAudio'),\n                    'container': xpath_text(asset, 'mediaType'),\n                    'filesize': int_or_none(xpath_text(asset, 'size')),\n                }\n                format_url = self._proto_relative_url(format_url)\n                if format_url:\n                    http_format_info = format_info.copy()\n                    http_format_info.update({\n                        'url': format_url,\n                        'format_id': 'http-%s' % asset_type,\n                    })\n                    formats.append(http_format_info)\n                server_prefix = xpath_text(asset, 'serverPrefix')\n                if server_prefix:\n                    rtmp_format_info = format_info.copy()\n                    rtmp_format_info.update({\n                        'url': server_prefix,\n                        'play_path': xpath_text(asset, 'fileName'),\n                        'format_id': 'rtmp-%s' % asset_type,\n                    })\n                    formats.append(rtmp_format_info)\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 121,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_thumbnails#164",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_thumbnails(self, variants, base_url)",
        "snippet": "    def _extract_thumbnails(self, variants, base_url):\n        thumbnails = [{\n            'url': base_url + xpath_text(variant, 'url'),\n            'width': int_or_none(xpath_text(variant, 'width')),\n            'height': int_or_none(xpath_text(variant, 'height')),\n        } for variant in variants.findall('variant') if xpath_text(variant, 'url')]\n        thumbnails.sort(key=lambda x: x['width'] * x['height'], reverse=True)\n        return thumbnails",
        "begin_line": 164,
        "end_line": 171,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.bravotv.BravoTVIE._real_extract#31",
        "src_path": "youtube_dl/extractor/bravotv.py",
        "class_name": "youtube_dl.extractor.bravotv.BravoTVIE",
        "signature": "youtube_dl.extractor.bravotv.BravoTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        settings = self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);', webpage, 'drupal settings'),\n            display_id)\n        info = {}\n        query = {\n            'mbr': 'true',\n        }\n        account_pid, release_pid = [None] * 2\n        tve = settings.get('sharedTVE')\n        if tve:\n            query['manifest'] = 'm3u'\n            account_pid = 'HNK2IC'\n            release_pid = tve['release_pid']\n            if tve.get('entitlement') == 'auth':\n                adobe_pass = settings.get('adobePass', {})\n                resource = self._get_mvpd_resource(\n                    adobe_pass.get('adobePassResourceId', 'bravo'),\n                    tve['title'], release_pid, tve.get('rating'))\n                query['auth'] = self._extract_mvpd_auth(\n                    url, release_pid, adobe_pass.get('adobePassRequestorId', 'bravo'), resource)\n        else:\n            shared_playlist = settings['shared_playlist']\n            account_pid = shared_playlist['account_pid']\n            metadata = shared_playlist['video_metadata'][shared_playlist['default_clip']]\n            release_pid = metadata['release_pid']\n            info.update({\n                'title': metadata['title'],\n                'description': metadata.get('description'),\n                'season_number': int_or_none(metadata.get('season_num')),\n                'episode_number': int_or_none(metadata.get('episode_num')),\n            })\n            query['switch'] = 'progressive'\n        info.update({\n            '_type': 'url_transparent',\n            'id': release_pid,\n            'url': smuggle_url(update_url_query(\n                'http://link.theplatform.com/s/%s/%s' % (account_pid, release_pid),\n                query), {'force_smil_url': True}),\n            'ie_key': 'ThePlatform',\n        })\n        return info",
        "begin_line": 31,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.breakcom.BreakIE._real_extract#67",
        "src_path": "youtube_dl/extractor/breakcom.py",
        "class_name": "youtube_dl.extractor.breakcom.BreakIE",
        "signature": "youtube_dl.extractor.breakcom.BreakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        site, display_id, video_id = re.match(self._VALID_URL, url).groups()\n\n        if not video_id:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._search_regex(\n                (r'src=[\"\\']/embed/(\\d+)', r'data-video-content-id=[\"\\'](\\d+)'),\n                webpage, 'video id')\n\n        webpage = self._download_webpage(\n            'http://www.%s.com/embed/%s' % (site, video_id),\n            display_id, 'Downloading video embed page')\n        embed_vars = self._parse_json(\n            self._search_regex(\n                r'(?s)embedVars\\s*=\\s*({.+?})\\s*</script>', webpage, 'embed vars'),\n            display_id)\n\n        youtube_id = embed_vars.get('youtubeId')\n        if youtube_id:\n            return self.url_result(youtube_id, 'Youtube')\n\n        title = embed_vars['contentName']\n\n        formats = []\n        bitrates = []\n        for f in embed_vars.get('media', []):\n            if not f.get('uri') or f.get('mediaPurpose') != 'play':\n                continue\n            bitrate = int_or_none(f.get('bitRate'))\n            if bitrate:\n                bitrates.append(bitrate)\n            formats.append({\n                'url': f['uri'],\n                'format_id': 'http-%d' % bitrate if bitrate else 'http',\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'tbr': bitrate,\n                'format': 'mp4',\n            })\n\n        if not bitrates:\n            # When subscriptionLevel > 0, i.e. plus subscription is required\n            # media list will be empty. However, hds and hls uris are still\n            # available. We can grab them assuming bitrates to be default.\n            bitrates = self._DEFAULT_BITRATES\n\n        auth_token = embed_vars.get('AuthToken')\n\n        def construct_manifest_url(base_url, ext):\n            pieces = [base_url]\n            pieces.extend([compat_str(b) for b in bitrates])\n            pieces.append('_kbps.mp4.%s?%s' % (ext, auth_token))\n            return ','.join(pieces)\n\n        if bitrates and auth_token:\n            hds_url = embed_vars.get('hdsUri')\n            if hds_url:\n                formats.extend(self._extract_f4m_formats(\n                    construct_manifest_url(hds_url, 'f4m'),\n                    display_id, f4m_id='hds', fatal=False))\n            hls_url = embed_vars.get('hlsUri')\n            if hls_url:\n                formats.extend(self._extract_m3u8_formats(\n                    construct_manifest_url(hls_url, 'm3u8'),\n                    display_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': embed_vars.get('thumbUri'),\n            'duration': int_or_none(embed_vars.get('videoLengthInSeconds')) or None,\n            'age_limit': parse_age_limit(embed_vars.get('audienceRating')),\n            'tags': embed_vars.get('tags', '').split(','),\n            'formats': formats,\n        }",
        "begin_line": 67,
        "end_line": 143,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._build_brighcove_url#150",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._build_brighcove_url(cls, object_str)",
        "snippet": "    def _build_brighcove_url(cls, object_str):\n        \"\"\"\n        Build a Brightcove url from a xml string containing\n        <object class=\"BrightcoveExperience\">{params}</object>\n        \"\"\"\n\n        # Fix up some stupid HTML, see https://github.com/rg3/youtube-dl/issues/1553\n        object_str = re.sub(r'(<param(?:\\s+[a-zA-Z0-9_]+=\"[^\"]*\")*)>',\n                            lambda m: m.group(1) + '/>', object_str)\n        # Fix up some stupid XML, see https://github.com/rg3/youtube-dl/issues/1608\n        object_str = object_str.replace('<--', '<!--')\n        # remove namespace to simplify extraction\n        object_str = re.sub(r'(<object[^>]*)(xmlns=\".*?\")', r'\\1', object_str)\n        object_str = fix_xml_ampersands(object_str)\n\n        try:\n            object_doc = compat_etree_fromstring(object_str.encode('utf-8'))\n        except compat_xml_parse_error:\n            return\n\n        fv_el = find_xpath_attr(object_doc, './param', 'name', 'flashVars')\n        if fv_el is not None:\n            flashvars = dict(\n                (k, v[0])\n                for k, v in compat_parse_qs(fv_el.attrib['value']).items())\n        else:\n            flashvars = {}\n\n        data_url = object_doc.attrib.get('data', '')\n        data_url_params = compat_parse_qs(compat_urllib_parse_urlparse(data_url).query)\n\n        def find_param(name):\n            if name in flashvars:\n                return flashvars[name]\n            node = find_xpath_attr(object_doc, './param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n            return data_url_params.get(name)\n\n        params = {}\n\n        playerID = find_param('playerID') or find_param('playerId')\n        if playerID is None:\n            raise ExtractorError('Cannot find player ID')\n        params['playerID'] = playerID\n\n        playerKey = find_param('playerKey')\n        # Not all pages define this value\n        if playerKey is not None:\n            params['playerKey'] = playerKey\n        # These fields hold the id of the video\n        videoPlayer = find_param('@videoPlayer') or find_param('videoId') or find_param('videoID') or find_param('@videoList')\n        if videoPlayer is not None:\n            if isinstance(videoPlayer, list):\n                videoPlayer = videoPlayer[0]\n            videoPlayer = videoPlayer.strip()\n            # UUID is also possible for videoPlayer (e.g.\n            # http://www.popcornflix.com/hoodies-vs-hooligans/7f2d2b87-bbf2-4623-acfb-ea942b4f01dd\n            # or http://www8.hp.com/cn/zh/home.html)\n            if not (re.match(\n                    r'^(?:\\d+|[\\da-fA-F]{8}-?[\\da-fA-F]{4}-?[\\da-fA-F]{4}-?[\\da-fA-F]{4}-?[\\da-fA-F]{12})$',\n                    videoPlayer) or videoPlayer.startswith('ref:')):\n                return None\n            params['@videoPlayer'] = videoPlayer\n        linkBase = find_param('linkBaseURL')\n        if linkBase is not None:\n            params['linkBaseURL'] = linkBase\n        return cls._make_brightcove_url(params)",
        "begin_line": 150,
        "end_line": 217,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._build_brighcove_url_from_js#220",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._build_brighcove_url_from_js(cls, object_js)",
        "snippet": "    def _build_brighcove_url_from_js(cls, object_js):\n        # The layout of JS is as follows:\n        # customBC.createVideo = function (width, height, playerID, playerKey, videoPlayer, VideoRandomID) {\n        #   // build Brightcove <object /> XML\n        # }\n        m = re.search(\n            r'''(?x)customBC\\.createVideo\\(\n                .*?                                                  # skipping width and height\n                [\"\\'](?P<playerID>\\d+)[\"\\']\\s*,\\s*                   # playerID\n                [\"\\'](?P<playerKey>AQ[^\"\\']{48})[^\"\\']*[\"\\']\\s*,\\s*  # playerKey begins with AQ and is 50 characters\n                                                                     # in length, however it's appended to itself\n                                                                     # in places, so truncate\n                [\"\\'](?P<videoID>\\d+)[\"\\']                           # @videoPlayer\n            ''', object_js)\n        if m:\n            return cls._make_brightcove_url(m.groupdict())",
        "begin_line": 220,
        "end_line": 235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._make_brightcove_url#238",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._make_brightcove_url(cls, params)",
        "snippet": "    def _make_brightcove_url(cls, params):\n        return update_url_query(cls._FEDERATED_URL, params)",
        "begin_line": 238,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_brightcove_url#242",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_brightcove_url(cls, webpage)",
        "snippet": "    def _extract_brightcove_url(cls, webpage):\n        \"\"\"Try to extract the brightcove url from the webpage, returns None\n        if it can't be found\n        \"\"\"\n        urls = cls._extract_brightcove_urls(webpage)\n        return urls[0] if urls else None",
        "begin_line": 242,
        "end_line": 247,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_brightcove_urls#250",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_brightcove_urls(cls, webpage)",
        "snippet": "    def _extract_brightcove_urls(cls, webpage):\n        \"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"\n\n        url_m = re.search(\n            r'''(?x)\n                <meta\\s+\n                    (?:property|itemprop)=([\\'\"])(?:og:video|embedURL)\\1[^>]+\n                    content=([\\'\"])(?P<url>https?://(?:secure|c)\\.brightcove.com/(?:(?!\\2).)+)\\2\n            ''', webpage)\n        if url_m:\n            url = unescapeHTML(url_m.group('url'))\n            # Some sites don't add it, we can't download with this url, for example:\n            # http://www.ktvu.com/videos/news/raw-video-caltrain-releases-video-of-man-almost/vCTZdY/\n            if 'playerKey' in url or 'videoId' in url or 'idVideo' in url:\n                return [url]\n\n        matches = re.findall(\n            r'''(?sx)<object\n            (?:\n                [^>]+?class=[\\'\"][^>]*?BrightcoveExperience.*?[\\'\"] |\n                [^>]*?>\\s*<param\\s+name=\"movie\"\\s+value=\"https?://[^/]*brightcove\\.com/\n            ).+?>\\s*</object>''',\n            webpage)\n        if matches:\n            return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))\n\n        matches = re.findall(r'(customBC\\.createVideo\\(.+?\\);)', webpage)\n        if matches:\n            return list(filter(None, [\n                cls._build_brighcove_url_from_js(custom_bc)\n                for custom_bc in matches]))\n        return [src for _, src in re.findall(\n            r'<iframe[^>]+src=([\\'\"])((?:https?:)?//link\\.brightcove\\.com/services/player/(?!\\1).+)\\1', webpage)]",
        "begin_line": 250,
        "end_line": 282,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._real_extract#284",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        # Change the 'videoId' and others field to '@videoPlayer'\n        url = re.sub(r'(?<=[?&])(videoI(d|D)|idVideo|bctid)', '%40videoPlayer', url)\n        # Change bckey (used by bcove.me urls) to playerKey\n        url = re.sub(r'(?<=[?&])bckey', 'playerKey', url)\n        mobj = re.match(self._VALID_URL, url)\n        query_str = mobj.group('query')\n        query = compat_urlparse.parse_qs(query_str)\n\n        videoPlayer = query.get('@videoPlayer')\n        if videoPlayer:\n            # We set the original url as the default 'Referer' header\n            referer = smuggled_data.get('Referer', url)\n            if 'playerID' not in query:\n                mobj = re.search(r'/bcpid(\\d+)', url)\n                if mobj is not None:\n                    query['playerID'] = [mobj.group(1)]\n            return self._get_video_info(\n                videoPlayer[0], query, referer=referer)\n        elif 'playerKey' in query:\n            player_key = query['playerKey']\n            return self._get_playlist_info(player_key[0])\n        else:\n            raise ExtractorError(\n                'Cannot find playerKey= variable. Did you forget quotes in a shell invocation?',\n                expected=True)",
        "begin_line": 284,
        "end_line": 311,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._get_video_info#313",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._get_video_info(self, video_id, query, referer=None)",
        "snippet": "    def _get_video_info(self, video_id, query, referer=None):\n        headers = {}\n        linkBase = query.get('linkBaseURL')\n        if linkBase is not None:\n            referer = linkBase[0]\n        if referer is not None:\n            headers['Referer'] = referer\n        webpage = self._download_webpage(self._FEDERATED_URL, video_id, headers=headers, query=query)\n\n        error_msg = self._html_search_regex(\n            r\"<h1>We're sorry.</h1>([\\s\\n]*<p>.*?</p>)+\", webpage,\n            'error message', default=None)\n        if error_msg is not None:\n            raise ExtractorError(\n                'brightcove said: %s' % error_msg, expected=True)\n\n        self.report_extraction(video_id)\n        info = self._search_regex(r'var experienceJSON = ({.*});', webpage, 'json')\n        info = json.loads(info)['data']\n        video_info = info['programmedContent']['videoPlayer']['mediaDTO']\n        video_info['_youtubedl_adServerURL'] = info.get('adServerURL')\n\n        return self._extract_video_info(video_info)",
        "begin_line": 313,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._get_playlist_info#337",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._get_playlist_info(self, player_key)",
        "snippet": "    def _get_playlist_info(self, player_key):\n        info_url = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s' % player_key\n        playlist_info = self._download_webpage(\n            info_url, player_key, 'Downloading playlist information')\n\n        json_data = json.loads(playlist_info)\n        if 'videoList' in json_data:\n            playlist_info = json_data['videoList']\n            playlist_dto = playlist_info['mediaCollectionDTO']\n        elif 'playlistTabs' in json_data:\n            playlist_info = json_data['playlistTabs']\n            playlist_dto = playlist_info['lineupListDTO']['playlistDTOs'][0]\n        else:\n            raise ExtractorError('Empty playlist')\n\n        videos = [self._extract_video_info(video_info) for video_info in playlist_dto['videoDTOs']]\n\n        return self.playlist_result(videos, playlist_id='%s' % playlist_info['id'],\n                                    playlist_title=playlist_dto['displayName'])",
        "begin_line": 337,
        "end_line": 355,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_video_info#357",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveLegacyIE._extract_video_info(self, video_info)",
        "snippet": "    def _extract_video_info(self, video_info):\n        video_id = compat_str(video_info['id'])\n        publisher_id = video_info.get('publisherId')\n        info = {\n            'id': video_id,\n            'title': video_info['displayName'].strip(),\n            'description': video_info.get('shortDescription'),\n            'thumbnail': video_info.get('videoStillURL') or video_info.get('thumbnailURL'),\n            'uploader': video_info.get('publisherName'),\n            'uploader_id': compat_str(publisher_id) if publisher_id else None,\n            'duration': float_or_none(video_info.get('length'), 1000),\n            'timestamp': int_or_none(video_info.get('creationDate'), 1000),\n        }\n\n        renditions = video_info.get('renditions', []) + video_info.get('IOSRenditions', [])\n        if renditions:\n            formats = []\n            for rend in renditions:\n                url = rend['defaultURL']\n                if not url:\n                    continue\n                ext = None\n                if rend['remote']:\n                    url_comp = compat_urllib_parse_urlparse(url)\n                    if url_comp.path.endswith('.m3u8'):\n                        formats.extend(\n                            self._extract_m3u8_formats(\n                                url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n                        continue\n                    elif 'akamaihd.net' in url_comp.netloc:\n                        # This type of renditions are served through\n                        # akamaihd.net, but they don't use f4m manifests\n                        url = url.replace('control/', '') + '?&v=3.3.0&fp=13&r=FEEFJ&g=RTSJIMBMPFPB'\n                        ext = 'flv'\n                if ext is None:\n                    ext = determine_ext(url)\n                tbr = int_or_none(rend.get('encodingRate'), 1000)\n                a_format = {\n                    'format_id': 'http%s' % ('-%s' % tbr if tbr else ''),\n                    'url': url,\n                    'ext': ext,\n                    'filesize': int_or_none(rend.get('size')) or None,\n                    'tbr': tbr,\n                }\n                if rend.get('audioOnly'):\n                    a_format.update({\n                        'vcodec': 'none',\n                    })\n                else:\n                    a_format.update({\n                        'height': int_or_none(rend.get('frameHeight')),\n                        'width': int_or_none(rend.get('frameWidth')),\n                        'vcodec': rend.get('videoCodec'),\n                    })\n\n                # m3u8 manifests with remote == false are media playlists\n                # Not calling _extract_m3u8_formats here to save network traffic\n                if ext == 'm3u8':\n                    a_format.update({\n                        'format_id': 'hls%s' % ('-%s' % tbr if tbr else ''),\n                        'ext': 'mp4',\n                        'protocol': 'm3u8_native',\n                    })\n\n                formats.append(a_format)\n            self._sort_formats(formats)\n            info['formats'] = formats\n        elif video_info.get('FLVFullLengthURL') is not None:\n            info.update({\n                'url': video_info['FLVFullLengthURL'],\n                'vcodec': self.FLV_VCODECS.get(video_info.get('FLVFullCodec')),\n                'filesize': int_or_none(video_info.get('FLVFullSize')),\n            })\n\n        if self._downloader.params.get('include_ads', False):\n            adServerURL = video_info.get('_youtubedl_adServerURL')\n            if adServerURL:\n                ad_info = {\n                    '_type': 'url',\n                    'url': adServerURL,\n                }\n                if 'url' in info:\n                    return {\n                        '_type': 'playlist',\n                        'title': info['title'],\n                        'entries': [ad_info, info],\n                    }\n                else:\n                    return ad_info\n\n        if 'url' not in info and not info.get('formats'):\n            raise ExtractorError('Unable to extract video url for %s' % video_id)\n        return info",
        "begin_line": 357,
        "end_line": 449,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveNewIE._extract_url#502",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveNewIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveNewIE._extract_url(ie, webpage)",
        "snippet": "    def _extract_url(ie, webpage):\n        urls = BrightcoveNewIE._extract_urls(ie, webpage)\n        return urls[0] if urls else None",
        "begin_line": 502,
        "end_line": 504,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveNewIE._extract_urls#507",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveNewIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveNewIE._extract_urls(ie, webpage)",
        "snippet": "    def _extract_urls(ie, webpage):\n        # Reference:\n        # 1. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#setvideoiniframe\n        # 2. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#tag\n        # 3. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#setvideousingjavascript\n        # 4. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/in-page-embed-player-implementation.html\n        # 5. https://support.brightcove.com/en/video-cloud/docs/dynamically-assigning-videos-player\n\n        entries = []\n\n        # Look for iframe embeds [1]\n        for _, url in re.findall(\n                r'<iframe[^>]+src=([\"\\'])((?:https?:)?//players\\.brightcove\\.net/\\d+/[^/]+/index\\.html.+?)\\1', webpage):\n            entries.append(url if url.startswith('http') else 'http:' + url)\n\n        # Look for <video> tags [2] and embed_in_page embeds [3]\n        # [2] looks like:\n        for video, script_tag, account_id, player_id, embed in re.findall(\n                r'''(?isx)\n                    (<video\\s+[^>]*\\bdata-video-id\\s*=\\s*['\"]?[^>]+>)\n                    (?:.*?\n                        (<script[^>]+\n                            src=[\"\\'](?:https?:)?//players\\.brightcove\\.net/\n                            (\\d+)/([^/]+)_([^/]+)/index(?:\\.min)?\\.js\n                        )\n                    )?\n                ''', webpage):\n            attrs = extract_attributes(video)\n\n            # According to examples from [4] it's unclear whether video id\n            # may be optional and what to do when it is\n            video_id = attrs.get('data-video-id')\n            if not video_id:\n                continue\n\n            account_id = account_id or attrs.get('data-account')\n            if not account_id:\n                continue\n\n            player_id = player_id or attrs.get('data-player') or 'default'\n            embed = embed or attrs.get('data-embed') or 'default'\n\n            bc_url = 'http://players.brightcove.net/%s/%s_%s/index.html?videoId=%s' % (\n                account_id, player_id, embed, video_id)\n\n            # Some brightcove videos may be embedded with video tag only and\n            # without script tag or any mentioning of brightcove at all. Such\n            # embeds are considered ambiguous since they are matched based only\n            # on data-video-id and data-account attributes and in the wild may\n            # not be brightcove embeds at all. Let's check reconstructed\n            # brightcove URLs in case of such embeds and only process valid\n            # ones. By this we ensure there is indeed a brightcove embed.\n            if not script_tag and not ie._is_valid_url(\n                    bc_url, video_id, 'possible brightcove video'):\n                continue\n\n            entries.append(bc_url)\n\n        return entries",
        "begin_line": 507,
        "end_line": 565,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveNewIE._real_extract#567",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveNewIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveNewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        self._initialize_geo_bypass(smuggled_data.get('geo_countries'))\n\n        account_id, player_id, embed, video_id = re.match(self._VALID_URL, url).groups()\n\n        webpage = self._download_webpage(\n            'http://players.brightcove.net/%s/%s_%s/index.min.js'\n            % (account_id, player_id, embed), video_id)\n\n        policy_key = None\n\n        catalog = self._search_regex(\n            r'catalog\\(({.+?})\\);', webpage, 'catalog', default=None)\n        if catalog:\n            catalog = self._parse_json(\n                js_to_json(catalog), video_id, fatal=False)\n            if catalog:\n                policy_key = catalog.get('policyKey')\n\n        if not policy_key:\n            policy_key = self._search_regex(\n                r'policyKey\\s*:\\s*([\"\\'])(?P<pk>.+?)\\1',\n                webpage, 'policy key', group='pk')\n\n        api_url = 'https://edge.api.brightcove.com/playback/v1/accounts/%s/videos/%s' % (account_id, video_id)\n        try:\n            json_data = self._download_json(api_url, video_id, headers={\n                'Accept': 'application/json;pk=%s' % policy_key\n            })\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403:\n                json_data = self._parse_json(e.cause.read().decode(), video_id)[0]\n                message = json_data.get('message') or json_data['error_code']\n                if json_data.get('error_subcode') == 'CLIENT_GEO':\n                    self.raise_geo_restricted(msg=message)\n                raise ExtractorError(message, expected=True)\n            raise\n\n        errors = json_data.get('errors')\n        if errors and errors[0].get('error_subcode') == 'TVE_AUTH':\n            custom_fields = json_data['custom_fields']\n            tve_token = self._extract_mvpd_auth(\n                smuggled_data['source_url'], video_id,\n                custom_fields['bcadobepassrequestorid'],\n                custom_fields['bcadobepassresourceid'])\n            json_data = self._download_json(\n                api_url, video_id, headers={\n                    'Accept': 'application/json;pk=%s' % policy_key\n                }, query={\n                    'tveToken': tve_token,\n                })\n\n        title = json_data['name'].strip()\n\n        formats = []\n        for source in json_data.get('sources', []):\n            container = source.get('container')\n            ext = mimetype2ext(source.get('type'))\n            src = source.get('src')\n            if ext == 'ism' or container == 'WVM':\n                continue\n            elif ext == 'm3u8' or container == 'M2TS':\n                if not src:\n                    continue\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n            elif ext == 'mpd':\n                if not src:\n                    continue\n                formats.extend(self._extract_mpd_formats(src, video_id, 'dash', fatal=False))\n            else:\n                streaming_src = source.get('streaming_src')\n                stream_name, app_name = source.get('stream_name'), source.get('app_name')\n                if not src and not streaming_src and (not stream_name or not app_name):\n                    continue\n                tbr = float_or_none(source.get('avg_bitrate'), 1000)\n                height = int_or_none(source.get('height'))\n                width = int_or_none(source.get('width'))\n                f = {\n                    'tbr': tbr,\n                    'filesize': int_or_none(source.get('size')),\n                    'container': container,\n                    'ext': ext or container.lower(),\n                }\n                if width == 0 and height == 0:\n                    f.update({\n                        'vcodec': 'none',\n                    })\n                else:\n                    f.update({\n                        'width': width,\n                        'height': height,\n                        'vcodec': source.get('codec'),\n                    })\n\n                def build_format_id(kind):\n                    format_id = kind\n                    if tbr:\n                        format_id += '-%dk' % int(tbr)\n                    if height:\n                        format_id += '-%dp' % height\n                    return format_id\n\n                if src or streaming_src:\n                    f.update({\n                        'url': src or streaming_src,\n                        'format_id': build_format_id('http' if src else 'http-streaming'),\n                        'source_preference': 0 if src else -1,\n                    })\n                else:\n                    f.update({\n                        'url': app_name,\n                        'play_path': stream_name,\n                        'format_id': build_format_id('rtmp'),\n                    })\n                formats.append(f)\n\n        if not formats and errors:\n            error = errors[0]\n            raise ExtractorError(\n                error.get('message') or error.get('error_subcode') or error['error_code'], expected=True)\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for text_track in json_data.get('text_tracks', []):\n            if text_track.get('src'):\n                subtitles.setdefault(text_track.get('srclang'), []).append({\n                    'url': text_track['src'],\n                })\n\n        is_live = False\n        duration = float_or_none(json_data.get('duration'), 1000)\n        if duration is not None and duration <= 0:\n            is_live = True\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': clean_html(json_data.get('description')),\n            'thumbnail': json_data.get('thumbnail') or json_data.get('poster'),\n            'duration': duration,\n            'timestamp': parse_iso8601(json_data.get('published_at')),\n            'uploader_id': account_id,\n            'formats': formats,\n            'subtitles': subtitles,\n            'tags': json_data.get('tags', []),\n            'is_live': is_live,\n        }",
        "begin_line": 567,
        "end_line": 716,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.buzzfeed.BuzzFeedIE._real_extract#71",
        "src_path": "youtube_dl/extractor/buzzfeed.py",
        "class_name": "youtube_dl.extractor.buzzfeed.BuzzFeedIE",
        "signature": "youtube_dl.extractor.buzzfeed.BuzzFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        all_buckets = re.findall(\n            r'(?s)<div class=\"video-embed[^\"]*\"..*?rel:bf_bucket_data=\\'([^\\']+)\\'',\n            webpage)\n\n        entries = []\n        for bd_json in all_buckets:\n            bd = json.loads(bd_json)\n            video = bd.get('video') or bd.get('progload_video')\n            if not video:\n                continue\n            entries.append(self.url_result(video['url']))\n\n        facebook_urls = FacebookIE._extract_urls(webpage)\n        entries.extend([\n            self.url_result(facebook_url)\n            for facebook_url in facebook_urls])\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'entries': entries,\n        }",
        "begin_line": 71,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.byutv.BYUtvIE._real_extract#31",
        "src_path": "youtube_dl/extractor/byutv.py",
        "class_name": "youtube_dl.extractor.byutv.BYUtvIE",
        "signature": "youtube_dl.extractor.byutv.BYUtvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n        episode_code = self._search_regex(\n            r'(?s)episode:(.*?\\}),\\s*\\n', webpage, 'episode information')\n\n        ep = self._parse_json(\n            episode_code, display_id, transform_source=lambda s:\n            re.sub(r'(\\n\\s+)([a-zA-Z]+):\\s+\\'(.*?)\\'', r'\\1\"\\2\": \"\\3\"', s))\n\n        if ep['providerType'] != 'Ooyala':\n            raise ExtractorError('Unsupported provider %s' % ep['provider'])\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Ooyala',\n            'url': 'ooyala:%s' % ep['providerId'],\n            'id': video_id,\n            'display_id': display_id,\n            'title': ep['title'],\n            'description': ep.get('description'),\n            'thumbnail': ep.get('imageThumbnail'),\n        }",
        "begin_line": 31,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.byutv.BYUtvEventIE._real_extract#74",
        "src_path": "youtube_dl/extractor/byutv.py",
        "class_name": "youtube_dl.extractor.byutv.BYUtvEventIE",
        "signature": "youtube_dl.extractor.byutv.BYUtvEventIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        ooyala_id = self._search_regex(\n            r'providerId\\s*:\\s*([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'ooyala id', group='id')\n\n        title = self._search_regex(\n            r'class=[\"\\']description[\"\\'][^>]*>\\s*<h1>([^<]+)</h1>', webpage,\n            'title').strip()\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Ooyala',\n            'url': 'ooyala:%s' % ooyala_id,\n            'id': video_id,\n            'title': title,\n        }",
        "begin_line": 74,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.c56.C56IE._real_extract#33",
        "src_path": "youtube_dl/extractor/c56.py",
        "class_name": "youtube_dl.extractor.c56.C56IE",
        "signature": "youtube_dl.extractor.c56.C56IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        text_id = mobj.group('textid')\n\n        webpage = self._download_webpage(url, text_id)\n        sohu_video_info_str = self._search_regex(\n            r'var\\s+sohuVideoInfo\\s*=\\s*({[^}]+});', webpage, 'Sohu video info', default=None)\n        if sohu_video_info_str:\n            sohu_video_info = self._parse_json(\n                sohu_video_info_str, text_id, transform_source=js_to_json)\n            return self.url_result(sohu_video_info['url'], 'Sohu')\n\n        page = self._download_json(\n            'http://vxml.56.com/json/%s/' % text_id, text_id, 'Downloading video info')\n\n        info = page['info']\n\n        formats = [\n            {\n                'format_id': f['type'],\n                'filesize': int(f['filesize']),\n                'url': f['url']\n            } for f in info['rfiles']\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': info['vid'],\n            'title': info['Subject'],\n            'duration': int(info['duration']) / 1000.0,\n            'formats': formats,\n            'thumbnail': info.get('bimg') or info.get('img'),\n        }",
        "begin_line": 33,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.camdemy.CamdemyIE._real_extract#66",
        "src_path": "youtube_dl/extractor/camdemy.py",
        "class_name": "youtube_dl.extractor.camdemy.CamdemyIE",
        "signature": "youtube_dl.extractor.camdemy.CamdemyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        src_from = self._html_search_regex(\n            r\"class=['\\\"]srcFrom['\\\"][^>]*>Sources?(?:\\s+from)?\\s*:\\s*<a[^>]+(?:href|title)=(['\\\"])(?P<url>(?:(?!\\1).)+)\\1\",\n            webpage, 'external source', default=None, group='url')\n        if src_from:\n            return self.url_result(src_from)\n\n        oembed_obj = self._download_json(\n            'http://www.camdemy.com/oembed/?format=json&url=' + url, video_id)\n\n        title = oembed_obj['title']\n        thumb_url = oembed_obj['thumbnail_url']\n        video_folder = compat_urlparse.urljoin(thumb_url, 'video/')\n        file_list_doc = self._download_xml(\n            compat_urlparse.urljoin(video_folder, 'fileList.xml'),\n            video_id, 'Downloading filelist XML')\n        file_name = file_list_doc.find('./video/item/fileName').text\n        video_url = compat_urlparse.urljoin(video_folder, file_name)\n\n        # Some URLs return \"No permission or not login\" in a webpage despite being\n        # freely available via oembed JSON URL (e.g. http://www.camdemy.com/media/13885)\n        upload_date = unified_strdate(self._search_regex(\n            r'>published on ([^<]+)<', webpage,\n            'upload date', default=None))\n        view_count = str_to_int(self._search_regex(\n            r'role=[\"\\']viewCnt[\"\\'][^>]*>([\\d,.]+) views',\n            webpage, 'view count', default=None))\n        description = self._html_search_meta(\n            'description', webpage, default=None) or clean_html(\n            oembed_obj.get('description'))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumb_url,\n            'description': description,\n            'creator': oembed_obj.get('author_name'),\n            'duration': parse_duration(oembed_obj.get('duration')),\n            'upload_date': upload_date,\n            'view_count': view_count,\n        }",
        "begin_line": 66,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.camdemy.CamdemyFolderIE._real_extract#143",
        "src_path": "youtube_dl/extractor/camdemy.py",
        "class_name": "youtube_dl.extractor.camdemy.CamdemyFolderIE",
        "signature": "youtube_dl.extractor.camdemy.CamdemyFolderIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        folder_id = self._match_id(url)\n\n        # Add displayMode=list so that all links are displayed in a single page\n        parsed_url = list(compat_urlparse.urlparse(url))\n        query = dict(compat_urlparse.parse_qsl(parsed_url[4]))\n        query.update({'displayMode': 'list'})\n        parsed_url[4] = compat_urllib_parse_urlencode(query)\n        final_url = compat_urlparse.urlunparse(parsed_url)\n\n        page = self._download_webpage(final_url, folder_id)\n        matches = re.findall(r\"href='(/media/\\d+/?)'\", page)\n\n        entries = [self.url_result('http://www.camdemy.com' + media_path)\n                   for media_path in matches]\n\n        folder_title = self._html_search_meta('keywords', page)\n\n        return self.playlist_result(entries, folder_id, folder_title)",
        "begin_line": 143,
        "end_line": 161,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.camwithher.CamWithHerIE._real_extract#43",
        "src_path": "youtube_dl/extractor/camwithher.py",
        "class_name": "youtube_dl.extractor.camwithher.CamWithHerIE",
        "signature": "youtube_dl.extractor.camwithher.CamWithHerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        flv_id = self._html_search_regex(\n            r'<a[^>]+href=[\"\\']/download/\\?v=(\\d+)', webpage, 'video id')\n\n        # Video URL construction algorithm is reverse-engineered from cwhplayer.swf\n        rtmp_url = 'rtmp://camwithher.tv/clipshare/%s' % (\n            ('mp4:%s.mp4' % flv_id) if int(flv_id) > 2010 else flv_id)\n\n        title = self._html_search_regex(\n            r'<div[^>]+style=\"float:left\"[^>]*>\\s*<h2>(.+?)</h2>', webpage, 'title')\n        description = self._html_search_regex(\n            r'>Description:</span>(.+?)</div>', webpage, 'description', default=None)\n\n        runtime = self._search_regex(\n            r'Runtime\\s*:\\s*(.+?) \\|', webpage, 'duration', default=None)\n        if runtime:\n            runtime = re.sub(r'[\\s-]', '', runtime)\n        duration = parse_duration(runtime)\n        view_count = int_or_none(self._search_regex(\n            r'Views\\s*:\\s*(\\d+)', webpage, 'view count', default=None))\n        comment_count = int_or_none(self._search_regex(\n            r'Comments\\s*:\\s*(\\d+)', webpage, 'comment count', default=None))\n\n        uploader = self._search_regex(\n            r'Added by\\s*:\\s*<a[^>]+>([^<]+)</a>', webpage, 'uploader', default=None)\n        upload_date = unified_strdate(self._search_regex(\n            r'Added on\\s*:\\s*([\\d-]+)', webpage, 'upload date', default=None))\n\n        return {\n            'id': flv_id,\n            'url': rtmp_url,\n            'ext': 'flv',\n            'no_resume': True,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'uploader': uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 43,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract#28",
        "src_path": "youtube_dl/extractor/canalc2.py",
        "class_name": "youtube_dl.extractor.canalc2.Canalc2IE",
        "signature": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.canalc2.tv/video/%s' % video_id, video_id)\n\n        formats = []\n        for _, video_url in re.findall(r'file\\s*=\\s*([\"\\'])(.+?)\\1', webpage):\n            if video_url.startswith('rtmp://'):\n                rtmp = re.search(\n                    r'^(?P<url>rtmp://[^/]+/(?P<app>.+/))(?P<play_path>mp4:.+)$', video_url)\n                formats.append({\n                    'url': rtmp.group('url'),\n                    'format_id': 'rtmp',\n                    'ext': 'flv',\n                    'app': rtmp.group('app'),\n                    'play_path': rtmp.group('play_path'),\n                    'page_url': url,\n                })\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'http',\n                })\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'(?s)class=\"[^\"]*col_description[^\"]*\">.*?<h3>(.*?)</h3>', webpage, 'title')\n        duration = parse_duration(self._search_regex(\n            r'id=[\"\\']video_duree[\"\\'][^>]*>([^<]+)',\n            webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract#117",
        "src_path": "youtube_dl/extractor/canalplus.py",
        "class_name": "youtube_dl.extractor.canalplus.CanalplusIE",
        "signature": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        site_id = self._SITE_ID_MAP[compat_urllib_parse_urlparse(url).netloc.rsplit('.', 2)[-2]]\n\n        # Beware, some subclasses do not define an id group\n        display_id = remove_end(dict_get(mobj.groupdict(), ('display_id', 'id', 'vid')), '.html')\n\n        webpage = self._download_webpage(url, display_id)\n        video_id = self._search_regex(\n            [r'<canal:player[^>]+?videoId=([\"\\'])(?P<id>\\d+)',\n             r'id=[\"\\']canal_video_player(?P<id>\\d+)',\n             r'data-video=[\"\\'](?P<id>\\d+)'],\n            webpage, 'video id', default=mobj.group('vid'), group='id')\n\n        info_url = self._VIDEO_INFO_TEMPLATE % (site_id, video_id)\n        video_data = self._download_json(info_url, video_id, 'Downloading video JSON')\n\n        if isinstance(video_data, list):\n            video_data = [video for video in video_data if video.get('ID') == video_id][0]\n        media = video_data['MEDIA']\n        infos = video_data['INFOS']\n\n        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD'])\n\n        # _, fmt_url = next(iter(media['VIDEOS'].items()))\n        # if '/geo' in fmt_url.lower():\n        #     response = self._request_webpage(\n        #         HEADRequest(fmt_url), video_id,\n        #         'Checking if the video is georestricted')\n        #     if '/blocage' in response.geturl():\n        #         raise ExtractorError(\n        #             'The video is not available in your country',\n        #             expected=True)\n\n        formats = []\n        for format_id, format_url in media['VIDEOS'].items():\n            if not format_url:\n                continue\n            if format_id == 'HLS':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', 'm3u8_native', m3u8_id=format_id, fatal=False))\n            elif format_id == 'HDS':\n                formats.extend(self._extract_f4m_formats(\n                    format_url + '?hdcore=2.11.3', video_id, f4m_id=format_id, fatal=False))\n            else:\n                formats.append({\n                    # the secret extracted ya function in http://player.canalplus.fr/common/js/canalPlayer.js\n                    'url': format_url + '?secret=pqzerjlsmdkjfoiuerhsdlfknaes',\n                    'format_id': format_id,\n                    'preference': preference(format_id),\n                })\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'id': image_id,\n            'url': image_url,\n        } for image_id, image_url in media.get('images', {}).items()]\n\n        titrage = infos['TITRAGE']\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': '%s - %s' % (titrage['TITRE'],\n                                  titrage['SOUS_TITRE']),\n            'upload_date': unified_strdate(infos.get('PUBLICATION', {}).get('DATE')),\n            'thumbnails': thumbnails,\n            'description': infos.get('DESCRIPTION'),\n            'duration': int_or_none(infos.get('DURATION')),\n            'view_count': int_or_none(infos.get('NB_VUES')),\n            'like_count': int_or_none(infos.get('NB_LIKES')),\n            'comment_count': int_or_none(infos.get('NB_COMMENTS')),\n            'formats': formats,\n        }",
        "begin_line": 117,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.canvas.CanvasIE._real_extract#63",
        "src_path": "youtube_dl/extractor/canvas.py",
        "class_name": "youtube_dl.extractor.canvas.CanvasIE",
        "signature": "youtube_dl.extractor.canvas.CanvasIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        site_id, display_id = mobj.group('site_id'), mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = (self._search_regex(\n            r'<h1[^>]+class=\"video__body__header__title\"[^>]*>(.+?)</h1>',\n            webpage, 'title', default=None) or self._og_search_title(\n            webpage)).strip()\n\n        video_id = self._html_search_regex(\n            r'data-video=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1', webpage, 'video id', group='id')\n\n        data = self._download_json(\n            'https://mediazone.vrt.be/api/v1/%s/assets/%s'\n            % (site_id, video_id), display_id)\n\n        formats = []\n        for target in data['targetUrls']:\n            format_url, format_type = target.get('url'), target.get('type')\n            if not format_url or not format_type:\n                continue\n            if format_type == 'HLS':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, display_id, entry_protocol='m3u8_native',\n                    ext='mp4', preference=0, fatal=False, m3u8_id=format_type))\n            elif format_type == 'HDS':\n                formats.extend(self._extract_f4m_formats(\n                    format_url, display_id, f4m_id=format_type, fatal=False))\n            elif format_type == 'MPEG_DASH':\n                formats.extend(self._extract_mpd_formats(\n                    format_url, display_id, mpd_id=format_type, fatal=False))\n            else:\n                formats.append({\n                    'format_id': format_type,\n                    'url': format_url,\n                })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        subtitle_urls = data.get('subtitleUrls')\n        if isinstance(subtitle_urls, list):\n            for subtitle in subtitle_urls:\n                subtitle_url = subtitle.get('url')\n                if subtitle_url and subtitle.get('type') == 'CLOSED':\n                    subtitles.setdefault('nl', []).append({'url': subtitle_url})\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'formats': formats,\n            'duration': float_or_none(data.get('duration'), 1000),\n            'thumbnail': data.get('posterImageUrl'),\n            'subtitles': subtitles,\n        }",
        "begin_line": 63,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.carambatv.CarambaTVIE._real_extract#32",
        "src_path": "youtube_dl/extractor/carambatv.py",
        "class_name": "youtube_dl.extractor.carambatv.CarambaTVIE",
        "signature": "youtube_dl.extractor.carambatv.CarambaTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://video1.carambatv.ru/v/%s/videoinfo.js' % video_id,\n            video_id)\n\n        title = video['title']\n\n        base_url = video.get('video') or 'http://video1.carambatv.ru/v/%s/' % video_id\n\n        formats = [{\n            'url': base_url + f['fn'],\n            'height': int_or_none(f.get('height')),\n            'format_id': '%sp' % f['height'] if f.get('height') else None,\n        } for f in video['qualities'] if f.get('fn')]\n        self._sort_formats(formats)\n\n        thumbnail = video.get('splash')\n        duration = float_or_none(try_get(\n            video, lambda x: x['annotations'][0]['end_time'], compat_str))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.carambatv.CarambaTVPageIE._real_extract#79",
        "src_path": "youtube_dl/extractor/carambatv.py",
        "class_name": "youtube_dl.extractor.carambatv.CarambaTVPageIE",
        "signature": "youtube_dl.extractor.carambatv.CarambaTVPageIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        videomore_url = VideomoreIE._extract_url(webpage)\n        if videomore_url:\n            title = self._og_search_title(webpage)\n            return {\n                '_type': 'url_transparent',\n                'url': videomore_url,\n                'ie_key': VideomoreIE.ie_key(),\n                'title': title,\n            }\n\n        video_url = self._og_search_property('video:iframe', webpage, default=None)\n\n        if not video_url:\n            video_id = self._search_regex(\n                r'(?:video_id|crmb_vuid)\\s*[:=]\\s*[\"\\']?(\\d+)',\n                webpage, 'video id')\n            video_url = 'carambatv:%s' % video_id\n\n        return self.url_result(video_url, CarambaTVIE.ie_key())",
        "begin_line": 79,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cartoonnetwork.CartoonNetworkIE._real_extract#25",
        "src_path": "youtube_dl/extractor/cartoonnetwork.py",
        "class_name": "youtube_dl.extractor.cartoonnetwork.CartoonNetworkIE",
        "signature": "youtube_dl.extractor.cartoonnetwork.CartoonNetworkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        id_type, video_id = re.search(r\"_cnglobal\\.cvp(Video|Title)Id\\s*=\\s*'([^']+)';\", webpage).groups()\n        query = ('id' if id_type == 'Video' else 'titleId') + '=' + video_id\n        return self._extract_cvp_info(\n            'http://www.cartoonnetwork.com/video-seo-svc/episodeservices/getCvpPlaylist?networkName=CN2&' + query, video_id, {\n                'secure': {\n                    'media_src': 'http://androidhls-secure.cdn.turner.com/toon/big',\n                    'tokenizer_src': 'http://www.cartoonnetwork.com/cntv/mvpd/processors/services/token_ipadAdobe.do',\n                },\n            }, {\n                'url': url,\n                'site_name': 'CartoonNetwork',\n                'auth_required': self._search_regex(\n                    r'_cnglobal\\.cvpFullOrPreviewAuth\\s*=\\s*(true|false);',\n                    webpage, 'auth required', default='false') == 'true',\n            })",
        "begin_line": 25,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCIE.suitable#105",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCIE",
        "signature": "youtube_dl.extractor.cbc.CBCIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if CBCPlayerIE.suitable(url) else super(CBCIE, cls).suitable(url)",
        "begin_line": 105,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCIE._extract_player_init#108",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCIE",
        "signature": "youtube_dl.extractor.cbc.CBCIE._extract_player_init(self, player_init, display_id)",
        "snippet": "    def _extract_player_init(self, player_init, display_id):\n        player_info = self._parse_json(player_init, display_id, js_to_json)\n        media_id = player_info.get('mediaId')\n        if not media_id:\n            clip_id = player_info['clipId']\n            feed = self._download_json(\n                'http://tpfeed.cbc.ca/f/ExhSPC/vms_5akSXx4Ng_Zn?byCustomValue={:mpsReleases}{%s}' % clip_id,\n                clip_id, fatal=False)\n            if feed:\n                media_id = try_get(feed, lambda x: x['entries'][0]['guid'], compat_str)\n            if not media_id:\n                media_id = self._download_json(\n                    'http://feed.theplatform.com/f/h9dtGB/punlNGjMlc1F?fields=id&byContent=byReleases%3DbyId%253D' + clip_id,\n                    clip_id)['entries'][0]['id'].split('/')[-1]\n        return self.url_result('cbcplayer:%s' % media_id, 'CBCPlayer', media_id)",
        "begin_line": 108,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCIE._real_extract#124",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCIE",
        "signature": "youtube_dl.extractor.cbc.CBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        entries = [\n            self._extract_player_init(player_init, display_id)\n            for player_init in re.findall(r'CBC\\.APP\\.Caffeine\\.initInstance\\(({.+?})\\);', webpage)]\n        entries.extend([\n            self.url_result('cbcplayer:%s' % media_id, 'CBCPlayer', media_id)\n            for media_id in re.findall(r'<iframe[^>]+src=\"[^\"]+?mediaId=(\\d+)\"', webpage)])\n        return self.playlist_result(\n            entries, display_id,\n            self._og_search_title(webpage, fatal=False),\n            self._og_search_description(webpage))",
        "begin_line": 124,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCPlayerIE._real_extract#182",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCPlayerIE",
        "signature": "youtube_dl.extractor.cbc.CBCPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(\n                'http://link.theplatform.com/s/ExhSPC/media/guid/2655402169/%s?mbr=true&formats=MPEG4,FLV,MP3' % video_id, {\n                    'force_smil_url': True\n                }),\n            'id': video_id,\n        }",
        "begin_line": 182,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCWatchBaseIE._call_api#204",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCWatchBaseIE",
        "signature": "youtube_dl.extractor.cbc.CBCWatchBaseIE._call_api(self, path, video_id)",
        "snippet": "    def _call_api(self, path, video_id):\n        url = path if path.startswith('http') else self._API_BASE_URL + path\n        result = self._download_xml(url, video_id, headers={\n            'X-Clearleap-DeviceId': self._device_id,\n            'X-Clearleap-DeviceToken': self._device_token,\n        })\n        error_message = xpath_text(result, 'userMessage') or xpath_text(result, 'systemMessage')\n        if error_message:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error_message))\n        return result",
        "begin_line": 204,
        "end_line": 213,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCWatchBaseIE._real_initialize#215",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCWatchBaseIE",
        "signature": "youtube_dl.extractor.cbc.CBCWatchBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if not self._device_id or not self._device_token:\n            device = self._downloader.cache.load('cbcwatch', 'device') or {}\n            self._device_id, self._device_token = device.get('id'), device.get('token')\n            if not self._device_id or not self._device_token:\n                result = self._download_xml(\n                    self._API_BASE_URL + 'device/register',\n                    None, data=b'<device><type>web</type></device>')\n                self._device_id = xpath_text(result, 'deviceId', fatal=True)\n                self._device_token = xpath_text(result, 'deviceToken', fatal=True)\n                self._downloader.cache.store(\n                    'cbcwatch', 'device', {\n                        'id': self._device_id,\n                        'token': self._device_token,\n                    })",
        "begin_line": 215,
        "end_line": 229,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCWatchBaseIE._parse_rss_feed#231",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCWatchBaseIE",
        "signature": "youtube_dl.extractor.cbc.CBCWatchBaseIE._parse_rss_feed(self, rss)",
        "snippet": "    def _parse_rss_feed(self, rss):\n        channel = xpath_element(rss, 'channel', fatal=True)\n\n        def _add_ns(path):\n            return xpath_with_ns(path, self._NS_MAP)\n\n        entries = []\n        for item in channel.findall('item'):\n            guid = xpath_text(item, 'guid', fatal=True)\n            title = xpath_text(item, 'title', fatal=True)\n\n            media_group = xpath_element(item, _add_ns('media:group'), fatal=True)\n            content = xpath_element(media_group, _add_ns('media:content'), fatal=True)\n            content_url = content.attrib['url']\n\n            thumbnails = []\n            for thumbnail in media_group.findall(_add_ns('media:thumbnail')):\n                thumbnail_url = thumbnail.get('url')\n                if not thumbnail_url:\n                    continue\n                thumbnails.append({\n                    'id': thumbnail.get('profile'),\n                    'url': thumbnail_url,\n                    'width': int_or_none(thumbnail.get('width')),\n                    'height': int_or_none(thumbnail.get('height')),\n                })\n\n            timestamp = None\n            release_date = find_xpath_attr(\n                item, _add_ns('media:credit'), 'role', 'releaseDate')\n            if release_date is not None:\n                timestamp = parse_iso8601(release_date.text)\n\n            entries.append({\n                '_type': 'url_transparent',\n                'url': content_url,\n                'id': guid,\n                'title': title,\n                'description': xpath_text(item, 'description'),\n                'timestamp': timestamp,\n                'duration': int_or_none(content.get('duration')),\n                'age_limit': parse_age_limit(xpath_text(item, _add_ns('media:rating'))),\n                'episode': xpath_text(item, _add_ns('clearleap:episode')),\n                'episode_number': int_or_none(xpath_text(item, _add_ns('clearleap:episodeInSeason'))),\n                'series': xpath_text(item, _add_ns('clearleap:series')),\n                'season_number': int_or_none(xpath_text(item, _add_ns('clearleap:season'))),\n                'thumbnails': thumbnails,\n                'ie_key': 'CBCWatchVideo',\n            })\n\n        return self.playlist_result(\n            entries, xpath_text(channel, 'guid'),\n            xpath_text(channel, 'title'),\n            xpath_text(channel, 'description'))",
        "begin_line": 231,
        "end_line": 284,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCWatchVideoIE._real_extract#291",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCWatchVideoIE",
        "signature": "youtube_dl.extractor.cbc.CBCWatchVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        result = self._call_api(url, video_id)\n\n        m3u8_url = xpath_text(result, 'url', fatal=True)\n        formats = self._extract_m3u8_formats(re.sub(r'/([^/]+)/[^/?]+\\.m3u8', r'/\\1/\\1.m3u8', m3u8_url), video_id, 'mp4', fatal=False)\n        if len(formats) < 2:\n            formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')\n        for f in formats:\n            format_id = f.get('format_id')\n            if format_id.startswith('AAC'):\n                f['acodec'] = 'aac'\n            elif format_id.startswith('AC3'):\n                f['acodec'] = 'ac-3'\n        self._sort_formats(formats)\n\n        info = {\n            'id': video_id,\n            'title': video_id,\n            'formats': formats,\n        }\n\n        rss = xpath_element(result, 'rss')\n        if rss:\n            info.update(self._parse_rss_feed(rss)['entries'][0])\n            del info['url']\n            del info['_type']\n            del info['ie_key']\n        return info",
        "begin_line": 291,
        "end_line": 319,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbc.CBCWatchIE._real_extract#352",
        "src_path": "youtube_dl/extractor/cbc.py",
        "class_name": "youtube_dl.extractor.cbc.CBCWatchIE",
        "signature": "youtube_dl.extractor.cbc.CBCWatchIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        rss = self._call_api('web/browse/' + video_id, video_id)\n        return self._parse_rss_feed(rss)",
        "begin_line": 352,
        "end_line": 355,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSBaseIE._parse_smil_subtitles#14",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSBaseIE",
        "signature": "youtube_dl.extractor.cbs.CBSBaseIE._parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en')",
        "snippet": "    def _parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en'):\n        closed_caption_e = find_xpath_attr(smil, self._xpath_ns('.//param', namespace), 'name', 'ClosedCaptionURL')\n        return {\n            'en': [{\n                'ext': 'ttml',\n                'url': closed_caption_e.attrib['value'],\n            }]\n        } if closed_caption_e is not None and closed_caption_e.attrib.get('value') else []",
        "begin_line": 14,
        "end_line": 21,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSIE._extract_video_info#52",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSIE",
        "signature": "youtube_dl.extractor.cbs.CBSIE._extract_video_info(self, content_id, site='cbs', mpx_acc=2198311517)",
        "snippet": "    def _extract_video_info(self, content_id, site='cbs', mpx_acc=2198311517):\n        items_data = self._download_xml(\n            'http://can.cbs.com/thunder/player/videoPlayerService.php',\n            content_id, query={'partner': site, 'contentId': content_id})\n        video_data = xpath_element(items_data, './/item')\n        title = xpath_text(video_data, 'videoTitle', 'title', True)\n        tp_path = 'dJ5BDC/media/guid/%d/%s' % (mpx_acc, content_id)\n        tp_release_url = 'http://link.theplatform.com/s/' + tp_path\n\n        asset_types = []\n        subtitles = {}\n        formats = []\n        for item in items_data.findall('.//item'):\n            asset_type = xpath_text(item, 'assetType')\n            if not asset_type or asset_type in asset_types:\n                continue\n            asset_types.append(asset_type)\n            query = {\n                'mbr': 'true',\n                'assetTypes': asset_type,\n            }\n            if asset_type.startswith('HLS') or asset_type in ('OnceURL', 'StreamPack'):\n                query['formats'] = 'MPEG4,M3U'\n            elif asset_type in ('RTMP', 'WIFI', '3G'):\n                query['formats'] = 'MPEG4,FLV'\n            tp_formats, tp_subtitles = self._extract_theplatform_smil(\n                update_url_query(tp_release_url, query), content_id,\n                'Downloading %s SMIL data' % asset_type)\n            formats.extend(tp_formats)\n            subtitles = self._merge_subtitles(subtitles, tp_subtitles)\n        self._sort_formats(formats)\n\n        info = self._extract_theplatform_metadata(tp_path, content_id)\n        info.update({\n            'id': content_id,\n            'title': title,\n            'series': xpath_text(video_data, 'seriesTitle'),\n            'season_number': int_or_none(xpath_text(video_data, 'seasonNumber')),\n            'episode_number': int_or_none(xpath_text(video_data, 'episodeNumber')),\n            'duration': int_or_none(xpath_text(video_data, 'videoLength'), 1000),\n            'thumbnail': xpath_text(video_data, 'previewImageURL'),\n            'formats': formats,\n            'subtitles': subtitles,\n        })\n        return info",
        "begin_line": 52,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSIE._real_extract#98",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSIE",
        "signature": "youtube_dl.extractor.cbs.CBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        content_id = self._match_id(url)\n        return self._extract_video_info(content_id)",
        "begin_line": 98,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbsinteractive.CBSInteractiveIE._real_extract#73",
        "src_path": "youtube_dl/extractor/cbsinteractive.py",
        "class_name": "youtube_dl.extractor.cbsinteractive.CBSInteractiveIE",
        "signature": "youtube_dl.extractor.cbsinteractive.CBSInteractiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        site, display_id = re.match(self._VALID_URL, url).groups()\n        webpage = self._download_webpage(url, display_id)\n\n        data_json = self._html_search_regex(\n            r\"data-(?:cnet|zdnet)-video(?:-uvp(?:js)?)?-options='([^']+)'\",\n            webpage, 'data json')\n        data = self._parse_json(data_json, display_id)\n        vdata = data.get('video') or data['videos'][0]\n\n        video_id = vdata['mpxRefId']\n\n        title = vdata['title']\n        author = vdata.get('author')\n        if author:\n            uploader = '%s %s' % (author['firstName'], author['lastName'])\n            uploader_id = author.get('id')\n        else:\n            uploader = None\n            uploader_id = None\n\n        info = self._extract_video_info(video_id, site, self.MPX_ACCOUNTS[site])\n        info.update({\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'duration': int_or_none(vdata.get('duration')),\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n        })\n        return info",
        "begin_line": 73,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbslocal.CBSLocalIE._real_extract#82",
        "src_path": "youtube_dl/extractor/cbslocal.py",
        "class_name": "youtube_dl.extractor.cbslocal.CBSLocalIE",
        "signature": "youtube_dl.extractor.cbslocal.CBSLocalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        sendtonews_url = SendtoNewsIE._extract_url(webpage)\n        if sendtonews_url:\n            return self.url_result(\n                compat_urlparse.urljoin(url, sendtonews_url),\n                ie=SendtoNewsIE.ie_key())\n\n        info_dict = self._extract_anvato_videos(webpage, display_id)\n\n        time_str = self._html_search_regex(\n            r'class=\"entry-date\">([^<]+)<', webpage, 'released date', default=None)\n        if time_str:\n            timestamp = unified_timestamp(time_str)\n        else:\n            timestamp = parse_iso8601(self._html_search_meta('uploadDate', webpage))\n\n        info_dict.update({\n            'display_id': display_id,\n            'timestamp': timestamp,\n        })\n\n        return info_dict",
        "begin_line": 82,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract#77",
        "src_path": "youtube_dl/extractor/cbsnews.py",
        "class_name": "youtube_dl.extractor.cbsnews.CBSNewsIE",
        "signature": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_info = self._parse_json(self._html_search_regex(\n            r'(?:<ul class=\"media-list items\" id=\"media-related-items\"[^>]*><li data-video-info|<div id=\"cbsNewsVideoPlayer\" data-video-player-options)=\\'({.+?})\\'',\n            webpage, 'video JSON info', default='{}'), video_id, fatal=False)\n\n        if video_info:\n            item = video_info['item'] if 'item' in video_info else video_info\n        else:\n            state = self._parse_json(self._search_regex(\n                r'data-cbsvideoui-options=([\"\\'])(?P<json>{.+?})\\1', webpage,\n                'playlist JSON info', group='json'), video_id)['state']\n            item = state['playlist'][state['pid']]\n\n        return self._extract_video_info(item['mpxRefId'], 'cbsnews')",
        "begin_line": 77,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbsnews.CBSNewsLiveVideoIE._real_extract#114",
        "src_path": "youtube_dl/extractor/cbsnews.py",
        "class_name": "youtube_dl.extractor.cbsnews.CBSNewsLiveVideoIE",
        "signature": "youtube_dl.extractor.cbsnews.CBSNewsLiveVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        video_info = self._download_json(\n            'http://feeds.cbsn.cbsnews.com/rundown/story', display_id, query={\n                'device': 'desktop',\n                'dvr_slug': display_id,\n            })\n\n        formats = self._extract_akamai_formats(video_info['url'], display_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'display_id': display_id,\n            'title': video_info['headline'],\n            'thumbnail': video_info.get('thumbnail_url_hd') or video_info.get('thumbnail_url_sd'),\n            'duration': parse_duration(video_info.get('segmentDur')),\n            'formats': formats,\n        }",
        "begin_line": 114,
        "end_line": 133,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbssports.CBSSportsIE._extract_video_info#26",
        "src_path": "youtube_dl/extractor/cbssports.py",
        "class_name": "youtube_dl.extractor.cbssports.CBSSportsIE",
        "signature": "youtube_dl.extractor.cbssports.CBSSportsIE._extract_video_info(self, filter_query, video_id)",
        "snippet": "    def _extract_video_info(self, filter_query, video_id):\n        return self._extract_feed_info('dJ5BDC', 'VxxJg8Ymh8sE', filter_query, video_id)",
        "begin_line": 26,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cbssports.CBSSportsIE._real_extract#29",
        "src_path": "youtube_dl/extractor/cbssports.py",
        "class_name": "youtube_dl.extractor.cbssports.CBSSportsIE",
        "signature": "youtube_dl.extractor.cbssports.CBSSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._extract_video_info('byId=%s' % video_id, video_id)",
        "begin_line": 29,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ccc.CCCIE._real_extract#32",
        "src_path": "youtube_dl/extractor/ccc.py",
        "class_name": "youtube_dl.extractor.ccc.CCCIE",
        "signature": "youtube_dl.extractor.ccc.CCCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        event_id = self._search_regex(r\"data-id='(\\d+)'\", webpage, 'event id')\n        event_data = self._download_json('https://media.ccc.de/public/events/%s' % event_id, event_id)\n\n        formats = []\n        for recording in event_data.get('recordings', []):\n            recording_url = recording.get('recording_url')\n            if not recording_url:\n                continue\n            language = recording.get('language')\n            folder = recording.get('folder')\n            format_id = None\n            if language:\n                format_id = language\n            if folder:\n                if language:\n                    format_id += '-' + folder\n                else:\n                    format_id = folder\n            vcodec = 'h264' if 'h264' in folder else (\n                'none' if folder in ('mp3', 'opus') else None\n            )\n            formats.append({\n                'format_id': format_id,\n                'url': recording_url,\n                'width': int_or_none(recording.get('width')),\n                'height': int_or_none(recording.get('height')),\n                'filesize': int_or_none(recording.get('size'), invscale=1024 * 1024),\n                'language': language,\n                'vcodec': vcodec,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': event_id,\n            'display_id': display_id,\n            'title': event_data['title'],\n            'description': event_data.get('description'),\n            'thumbnail': event_data.get('thumb_url'),\n            'timestamp': parse_iso8601(event_data.get('date')),\n            'duration': int_or_none(event_data.get('length')),\n            'tags': event_data.get('tags'),\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ccma.CCMAIE._real_extract#41",
        "src_path": "youtube_dl/extractor/ccma.py",
        "class_name": "youtube_dl.extractor.ccma.CCMAIE",
        "signature": "youtube_dl.extractor.ccma.CCMAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_type, media_id = re.match(self._VALID_URL, url).groups()\n        media_data = {}\n        formats = []\n        profiles = ['pc'] if media_type == 'audio' else ['mobil', 'pc']\n        for i, profile in enumerate(profiles):\n            md = self._download_json('http://dinamics.ccma.cat/pvideo/media.jsp', media_id, query={\n                'media': media_type,\n                'idint': media_id,\n                'profile': profile,\n            }, fatal=False)\n            if md:\n                media_data = md\n                media_url = media_data.get('media', {}).get('url')\n                if media_url:\n                    formats.append({\n                        'format_id': profile,\n                        'url': media_url,\n                        'quality': i,\n                    })\n        self._sort_formats(formats)\n\n        informacio = media_data['informacio']\n        title = informacio['titol']\n        durada = informacio.get('durada', {})\n        duration = int_or_none(durada.get('milisegons'), 1000) or parse_duration(durada.get('text'))\n        timestamp = parse_iso8601(informacio.get('data_emissio', {}).get('utc'))\n\n        subtitles = {}\n        subtitols = media_data.get('subtitols', {})\n        if subtitols:\n            sub_url = subtitols.get('url')\n            if sub_url:\n                subtitles.setdefault(\n                    subtitols.get('iso') or subtitols.get('text') or 'ca', []).append({\n                        'url': sub_url,\n                    })\n\n        thumbnails = []\n        imatges = media_data.get('imatges', {})\n        if imatges:\n            thumbnail_url = imatges.get('url')\n            if thumbnail_url:\n                thumbnails = [{\n                    'url': thumbnail_url,\n                    'width': int_or_none(imatges.get('amplada')),\n                    'height': int_or_none(imatges.get('alcada')),\n                }]\n\n        return {\n            'id': media_id,\n            'title': title,\n            'description': clean_html(informacio.get('descripcio')),\n            'duration': duration,\n            'timestamp': timestamp,\n            'thumnails': thumbnails,\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 41,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cctv.CCTVIE._real_extract#128",
        "src_path": "youtube_dl/extractor/cctv.py",
        "class_name": "youtube_dl.extractor.cctv.CCTVIE",
        "signature": "youtube_dl.extractor.cctv.CCTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(\n            [r'var\\s+guid\\s*=\\s*[\"\\']([\\da-fA-F]+)',\n             r'videoCenterId[\"\\']\\s*,\\s*[\"\\']([\\da-fA-F]+)',\n             r'changePlayer\\s*\\(\\s*[\"\\']([\\da-fA-F]+)',\n             r'load[Vv]ideo\\s*\\(\\s*[\"\\']([\\da-fA-F]+)',\n             r'var\\s+initMyAray\\s*=\\s*[\"\\']([\\da-fA-F]+)',\n             r'var\\s+ids\\s*=\\s*\\[[\"\\']([\\da-fA-F]+)'],\n            webpage, 'video id')\n\n        data = self._download_json(\n            'http://vdn.apps.cntv.cn/api/getHttpVideoInfo.do', video_id,\n            query={\n                'pid': video_id,\n                'url': url,\n                'idl': 32,\n                'idlr': 32,\n                'modifyed': 'false',\n            })\n\n        title = data['title']\n\n        formats = []\n\n        video = data.get('video')\n        if isinstance(video, dict):\n            for quality, chapters_key in enumerate(('lowChapters', 'chapters')):\n                video_url = try_get(\n                    video, lambda x: x[chapters_key][0]['url'], compat_str)\n                if video_url:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': 'http',\n                        'quality': quality,\n                        'preference': -1,\n                    })\n\n        hls_url = try_get(data, lambda x: x['hls_url'], compat_str)\n        if hls_url:\n            hls_url = re.sub(r'maxbr=\\d+&?', '', hls_url)\n            formats.extend(self._extract_m3u8_formats(\n                hls_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        self._sort_formats(formats)\n\n        uploader = data.get('editer_name')\n        description = self._html_search_meta(\n            'description', webpage, default=None)\n        timestamp = unified_timestamp(data.get('f_pgmtime'))\n        duration = float_or_none(try_get(video, lambda x: x['totalLength']))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 128,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cda.CDAIE._download_age_confirm_page#72",
        "src_path": "youtube_dl/extractor/cda.py",
        "class_name": "youtube_dl.extractor.cda.CDAIE",
        "signature": "youtube_dl.extractor.cda.CDAIE._download_age_confirm_page(self, url, video_id, *args, **kwargs)",
        "snippet": "    def _download_age_confirm_page(self, url, video_id, *args, **kwargs):\n        form_data = random_birthday('rok', 'miesiac', 'dzien')\n        form_data.update({'return': url, 'module': 'video', 'module_id': video_id})\n        data, content_type = multipart_encode(form_data)\n        return self._download_webpage(\n            urljoin(url, '/a/validatebirth'), video_id, *args,\n            data=data, headers={\n                'Referer': url,\n                'Content-Type': content_type,\n            }, **kwargs)",
        "begin_line": 72,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cda.CDAIE._real_extract#83",
        "src_path": "youtube_dl/extractor/cda.py",
        "class_name": "youtube_dl.extractor.cda.CDAIE",
        "signature": "youtube_dl.extractor.cda.CDAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        self._set_cookie('cda.pl', 'cda.player', 'html5')\n        webpage = self._download_webpage(\n            self._BASE_URL + '/video/' + video_id, video_id)\n\n        if 'Ten film jest dost\u0119pny dla u\u017cytkownik\u00f3w premium' in webpage:\n            raise ExtractorError('This video is only available for premium users.', expected=True)\n\n        need_confirm_age = False\n        if self._html_search_regex(r'(<form[^>]+action=\"/a/validatebirth\")',\n                                   webpage, 'birthday validate form', default=None):\n            webpage = self._download_age_confirm_page(\n                url, video_id, note='Confirming age')\n            need_confirm_age = True\n\n        formats = []\n\n        uploader = self._search_regex(r'''(?x)\n            <(span|meta)[^>]+itemprop=([\"\\'])author\\2[^>]*>\n            (?:<\\1[^>]*>[^<]*</\\1>|(?!</\\1>)(?:.|\\n))*?\n            <(span|meta)[^>]+itemprop=([\"\\'])name\\4[^>]*>(?P<uploader>[^<]+)</\\3>\n        ''', webpage, 'uploader', default=None, group='uploader')\n        view_count = self._search_regex(\n            r'Ods\u0142ony:(?:\\s|&nbsp;)*([0-9]+)', webpage,\n            'view_count', default=None)\n        average_rating = self._search_regex(\n            r'<(?:span|meta)[^>]+itemprop=([\"\\'])ratingValue\\1[^>]*>(?P<rating_value>[0-9.]+)',\n            webpage, 'rating', fatal=False, group='rating_value')\n\n        info_dict = {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'uploader': uploader,\n            'view_count': int_or_none(view_count),\n            'average_rating': float_or_none(average_rating),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'duration': None,\n            'age_limit': 18 if need_confirm_age else 0,\n        }\n\n        def extract_format(page, version):\n            json_str = self._search_regex(\n                r'player_data=(\\\\?[\"\\'])(?P<player_data>.+?)\\1', page,\n                '%s player_json' % version, fatal=False, group='player_data')\n            if not json_str:\n                return\n            player_data = self._parse_json(\n                json_str, '%s player_data' % version, fatal=False)\n            if not player_data:\n                return\n            video = player_data.get('video')\n            if not video or 'file' not in video:\n                self.report_warning('Unable to extract %s version information' % version)\n                return\n            if video['file'].startswith('uggc'):\n                video['file'] = codecs.decode(video['file'], 'rot_13')\n                if video['file'].endswith('adc.mp4'):\n                    video['file'] = video['file'].replace('adc.mp4', '.mp4')\n            f = {\n                'url': video['file'],\n            }\n            m = re.search(\n                r'<a[^>]+data-quality=\"(?P<format_id>[^\"]+)\"[^>]+href=\"[^\"]+\"[^>]+class=\"[^\"]*quality-btn-active[^\"]*\">(?P<height>[0-9]+)p',\n                page)\n            if m:\n                f.update({\n                    'format_id': m.group('format_id'),\n                    'height': int(m.group('height')),\n                })\n            info_dict['formats'].append(f)\n            if not info_dict['duration']:\n                info_dict['duration'] = parse_duration(video.get('duration'))\n\n        extract_format(webpage, 'default')\n\n        for href, resolution in re.findall(\n                r'<a[^>]+data-quality=\"[^\"]+\"[^>]+href=\"([^\"]+)\"[^>]+class=\"quality-btn\"[^>]*>([0-9]+p)',\n                webpage):\n            if need_confirm_age:\n                handler = self._download_age_confirm_page\n            else:\n                handler = self._download_webpage\n\n            webpage = handler(\n                self._BASE_URL + href, video_id,\n                'Downloading %s version information' % resolution, fatal=False)\n            if not webpage:\n                # Manually report warning because empty page is returned when\n                # invalid version is requested.\n                self.report_warning('Unable to download %s version information' % resolution)\n                continue\n\n            extract_format(webpage, resolution)\n\n        self._sort_formats(formats)\n\n        return info_dict",
        "begin_line": 83,
        "end_line": 182,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract#70",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'\n        if '%s</p>' % NOT_AVAILABLE_STRING in webpage:\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        type_ = None\n        episode_id = None\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'getPlaylistUrl\\(\\[({.+?})\\]', webpage, 'playlist',\n                default='{}'), playlist_id)\n        if playlist:\n            type_ = playlist.get('type')\n            episode_id = playlist.get('id')\n\n        if not type_:\n            type_ = self._html_search_regex(\n                r'getPlaylistUrl\\(\\[\\{\"type\":\"(.+?)\",\"id\":\".+?\"\\}\\],',\n                webpage, 'type')\n        if not episode_id:\n            episode_id = self._html_search_regex(\n                r'getPlaylistUrl\\(\\[\\{\"type\":\".+?\",\"id\":\"(.+?)\"\\}\\],',\n                webpage, 'episode_id')\n\n        data = {\n            'playlist[0][type]': type_,\n            'playlist[0][id]': episode_id,\n            'requestUrl': compat_urllib_parse_urlparse(url).path,\n            'requestSource': 'iVysilani',\n        }\n\n        entries = []\n\n        for user_agent in (None, USER_AGENTS['Safari']):\n            req = sanitized_Request(\n                'http://www.ceskatelevize.cz/ivysilani/ajax/get-client-playlist',\n                data=urlencode_postdata(data))\n\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n            req.add_header('x-addr', '127.0.0.1')\n            req.add_header('X-Requested-With', 'XMLHttpRequest')\n            if user_agent:\n                req.add_header('User-Agent', user_agent)\n            req.add_header('Referer', url)\n\n            playlistpage = self._download_json(req, playlist_id, fatal=False)\n\n            if not playlistpage:\n                continue\n\n            playlist_url = playlistpage['url']\n            if playlist_url == 'error_region':\n                raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n            req = sanitized_Request(compat_urllib_parse_unquote(playlist_url))\n            req.add_header('Referer', url)\n\n            playlist_title = self._og_search_title(webpage, default=None)\n            playlist_description = self._og_search_description(webpage, default=None)\n\n            playlist = self._download_json(req, playlist_id, fatal=False)\n            if not playlist:\n                continue\n\n            playlist = playlist.get('playlist')\n            if not isinstance(playlist, list):\n                continue\n\n            playlist_len = len(playlist)\n\n            for num, item in enumerate(playlist):\n                is_live = item.get('type') == 'LIVE'\n                formats = []\n                for format_id, stream_url in item.get('streamUrls', {}).items():\n                    if 'playerType=flash' in stream_url:\n                        stream_formats = self._extract_m3u8_formats(\n                            stream_url, playlist_id, 'mp4', 'm3u8_native',\n                            m3u8_id='hls-%s' % format_id, fatal=False)\n                    else:\n                        stream_formats = self._extract_mpd_formats(\n                            stream_url, playlist_id,\n                            mpd_id='dash-%s' % format_id, fatal=False)\n                    # See https://github.com/rg3/youtube-dl/issues/12119#issuecomment-280037031\n                    if format_id == 'audioDescription':\n                        for f in stream_formats:\n                            f['source_preference'] = -10\n                    formats.extend(stream_formats)\n\n                if user_agent and len(entries) == playlist_len:\n                    entries[num]['formats'].extend(formats)\n                    continue\n\n                item_id = item.get('id') or item['assetId']\n                title = item['title']\n\n                duration = float_or_none(item.get('duration'))\n                thumbnail = item.get('previewImageUrl')\n\n                subtitles = {}\n                if item.get('type') == 'VOD':\n                    subs = item.get('subtitles')\n                    if subs:\n                        subtitles = self.extract_subtitles(episode_id, subs)\n\n                if playlist_len == 1:\n                    final_title = playlist_title or title\n                    if is_live:\n                        final_title = self._live_title(final_title)\n                else:\n                    final_title = '%s (%s)' % (playlist_title, title)\n\n                entries.append({\n                    'id': item_id,\n                    'title': final_title,\n                    'description': playlist_description if playlist_len == 1 else None,\n                    'thumbnail': thumbnail,\n                    'duration': duration,\n                    'formats': formats,\n                    'subtitles': subtitles,\n                    'is_live': is_live,\n                })\n\n        for e in entries:\n            self._sort_formats(e['formats'])\n\n        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 70,
        "end_line": 200,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._get_subtitles#202",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._get_subtitles(self, episode_id, subs)",
        "snippet": "    def _get_subtitles(self, episode_id, subs):\n        original_subtitles = self._download_webpage(\n            subs[0]['url'], episode_id, 'Downloading subtitles')\n        srt_subs = self._fix_subtitles(original_subtitles)\n        return {\n            'cs': [{\n                'ext': 'srt',\n                'data': srt_subs,\n            }]\n        }",
        "begin_line": 202,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._fix_subtitles#214",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._fix_subtitles(subtitles)",
        "snippet": "    def _fix_subtitles(subtitles):\n        \"\"\" Convert millisecond-based subtitles to SRT \"\"\"\n\n        def _msectotimecode(msec):\n            \"\"\" Helper utility to convert milliseconds to timecode \"\"\"\n            components = []\n            for divider in [1000, 60, 60, 100]:\n                components.append(msec % divider)\n                msec //= divider\n            return '{3:02}:{2:02}:{1:02},{0:03}'.format(*components)\n\n        def _fix_subtitle(subtitle):\n            for line in subtitle.splitlines():\n                m = re.match(r'^\\s*([0-9]+);\\s*([0-9]+)\\s+([0-9]+)\\s*$', line)\n                if m:\n                    yield m.group(1)\n                    start, stop = (_msectotimecode(int(t)) for t in m.groups()[1:])\n                    yield '{0} --> {1}'.format(start, stop)\n                else:\n                    yield line\n\n        return '\\r\\n'.join(_fix_subtitle(subtitles))",
        "begin_line": 214,
        "end_line": 235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizePoradyIE._real_extract#270",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizePoradyIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizePoradyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        data_url = unescapeHTML(self._search_regex(\n            r'<span[^>]*\\bdata-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'iframe player url', group='url'))\n\n        return self.url_result(data_url, ie=CeskaTelevizeIE.ie_key())",
        "begin_line": 270,
        "end_line": 279,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_list#84",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_list(self, video_id, rss_url=None)",
        "snippet": "    def _extract_list(self, video_id, rss_url=None):\n        if not rss_url:\n            rss_url = self._RSS_URL % video_id\n        rss = self._download_xml(rss_url, video_id, 'Downloading RSS')\n        entries = [self.url_result(session_url.text, 'Channel9')\n                   for session_url in rss.findall('./channel/item/link')]\n        title_text = rss.find('./channel/title').text\n        return self.playlist_result(entries, video_id, title_text)",
        "begin_line": 84,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._real_extract#93",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        content_path, rss = re.match(self._VALID_URL, url).groups()\n\n        if rss:\n            return self._extract_list(content_path, url)\n\n        webpage = self._download_webpage(\n            url, content_path, 'Downloading web page')\n\n        episode_data = self._search_regex(\n            r\"data-episode='([^']+)'\", webpage, 'episode data', default=None)\n        if episode_data:\n            episode_data = self._parse_json(unescapeHTML(\n                episode_data), content_path)\n            content_id = episode_data['contentId']\n            is_session = '/Sessions(' in episode_data['api']\n            content_url = 'https://channel9.msdn.com/odata' + episode_data['api']\n            if is_session:\n                content_url += '?$expand=Speakers'\n            else:\n                content_url += '?$expand=Authors'\n            content_data = self._download_json(content_url, content_id)\n            title = content_data['Title']\n\n            QUALITIES = (\n                'mp3',\n                'wmv', 'mp4',\n                'wmv-low', 'mp4-low',\n                'wmv-mid', 'mp4-mid',\n                'wmv-high', 'mp4-high',\n            )\n\n            quality_key = qualities(QUALITIES)\n\n            def quality(quality_id, format_url):\n                return (len(QUALITIES) if '_Source.' in format_url\n                        else quality_key(quality_id))\n\n            formats = []\n            urls = set()\n\n            SITE_QUALITIES = {\n                'MP3': 'mp3',\n                'MP4': 'mp4',\n                'Low Quality WMV': 'wmv-low',\n                'Low Quality MP4': 'mp4-low',\n                'Mid Quality WMV': 'wmv-mid',\n                'Mid Quality MP4': 'mp4-mid',\n                'High Quality WMV': 'wmv-high',\n                'High Quality MP4': 'mp4-high',\n            }\n\n            formats_select = self._search_regex(\n                r'(?s)<select[^>]+name=[\"\\']format[^>]+>(.+?)</select', webpage,\n                'formats select', default=None)\n            if formats_select:\n                for mobj in re.finditer(\n                        r'<option\\b[^>]+\\bvalue=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1[^>]*>\\s*(?P<format>[^<]+?)\\s*<',\n                        formats_select):\n                    format_url = mobj.group('url')\n                    if format_url in urls:\n                        continue\n                    urls.add(format_url)\n                    format_id = mobj.group('format')\n                    quality_id = SITE_QUALITIES.get(format_id, format_id)\n                    formats.append({\n                        'url': format_url,\n                        'format_id': quality_id,\n                        'quality': quality(quality_id, format_url),\n                        'vcodec': 'none' if quality_id == 'mp3' else None,\n                    })\n\n            API_QUALITIES = {\n                'VideoMP4Low': 'mp4-low',\n                'VideoWMV': 'wmv-mid',\n                'VideoMP4Medium': 'mp4-mid',\n                'VideoMP4High': 'mp4-high',\n                'VideoWMVHQ': 'wmv-hq',\n            }\n\n            for format_id, q in API_QUALITIES.items():\n                q_url = content_data.get(format_id)\n                if not q_url or q_url in urls:\n                    continue\n                urls.add(q_url)\n                formats.append({\n                    'url': q_url,\n                    'format_id': q,\n                    'quality': quality(q, q_url),\n                })\n\n            self._sort_formats(formats)\n\n            slides = content_data.get('Slides')\n            zip_file = content_data.get('ZipFile')\n\n            if not formats and not slides and not zip_file:\n                raise ExtractorError(\n                    'None of recording, slides or zip are available for %s' % content_path)\n\n            subtitles = {}\n            for caption in content_data.get('Captions', []):\n                caption_url = caption.get('Url')\n                if not caption_url:\n                    continue\n                subtitles.setdefault(caption.get('Language', 'en'), []).append({\n                    'url': caption_url,\n                    'ext': 'vtt',\n                })\n\n            common = {\n                'id': content_id,\n                'title': title,\n                'description': clean_html(content_data.get('Description') or content_data.get('Body')),\n                'thumbnail': content_data.get('Thumbnail') or content_data.get('VideoPlayerPreviewImage'),\n                'duration': int_or_none(content_data.get('MediaLengthInSeconds')),\n                'timestamp': parse_iso8601(content_data.get('PublishedDate')),\n                'avg_rating': int_or_none(content_data.get('Rating')),\n                'rating_count': int_or_none(content_data.get('RatingCount')),\n                'view_count': int_or_none(content_data.get('Views')),\n                'comment_count': int_or_none(content_data.get('CommentCount')),\n                'subtitles': subtitles,\n            }\n            if is_session:\n                speakers = []\n                for s in content_data.get('Speakers', []):\n                    speaker_name = s.get('FullName')\n                    if not speaker_name:\n                        continue\n                    speakers.append(speaker_name)\n\n                common.update({\n                    'session_code': content_data.get('Code'),\n                    'session_room': content_data.get('Room'),\n                    'session_speakers': speakers,\n                })\n            else:\n                authors = []\n                for a in content_data.get('Authors', []):\n                    author_name = a.get('DisplayName')\n                    if not author_name:\n                        continue\n                    authors.append(author_name)\n                common['authors'] = authors\n\n            contents = []\n\n            if slides:\n                d = common.copy()\n                d.update({'title': title + '-Slides', 'url': slides})\n                contents.append(d)\n\n            if zip_file:\n                d = common.copy()\n                d.update({'title': title + '-Zip', 'url': zip_file})\n                contents.append(d)\n\n            if formats:\n                d = common.copy()\n                d.update({'title': title, 'formats': formats})\n                contents.append(d)\n            return self.playlist_result(contents)\n        else:\n            return self._extract_list(content_path)",
        "begin_line": 93,
        "end_line": 256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.charlierose.CharlieRoseIE._real_extract#31",
        "src_path": "youtube_dl/extractor/charlierose.py",
        "class_name": "youtube_dl.extractor.charlierose.CharlieRoseIE",
        "signature": "youtube_dl.extractor.charlierose.CharlieRoseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(self._PLAYER_BASE % video_id, video_id)\n\n        title = remove_end(self._og_search_title(webpage), ' - Charlie Rose')\n\n        info_dict = self._parse_html5_media_entries(\n            self._PLAYER_BASE % video_id, webpage, video_id,\n            m3u8_entry_protocol='m3u8_native')[0]\n\n        self._sort_formats(info_dict['formats'])\n        self._remove_duplicate_formats(info_dict['formats'])\n\n        info_dict.update({\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        })\n\n        return info_dict",
        "begin_line": 31,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.chaturbate.ChaturbateIE._real_extract#31",
        "src_path": "youtube_dl/extractor/chaturbate.py",
        "class_name": "youtube_dl.extractor.chaturbate.ChaturbateIE",
        "signature": "youtube_dl.extractor.chaturbate.ChaturbateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        m3u8_urls = []\n\n        for m in re.finditer(\n                r'([\"\\'])(?P<url>http.+?\\.m3u8.*?)\\1', webpage):\n            m3u8_fast_url, m3u8_no_fast_url = m.group('url'), m.group(\n                'url').replace('_fast', '')\n            for m3u8_url in (m3u8_fast_url, m3u8_no_fast_url):\n                if m3u8_url not in m3u8_urls:\n                    m3u8_urls.append(m3u8_url)\n\n        if not m3u8_urls:\n            error = self._search_regex(\n                [r'<span[^>]+class=([\"\\'])desc_span\\1[^>]*>(?P<error>[^<]+)</span>',\n                 r'<div[^>]+id=([\"\\'])defchat\\1[^>]*>\\s*<p><strong>(?P<error>[^<]+)<'],\n                webpage, 'error', group='error', default=None)\n            if not error:\n                if any(p in webpage for p in (\n                        self._ROOM_OFFLINE, 'offline_tipping', 'tip_offline')):\n                    error = self._ROOM_OFFLINE\n            if error:\n                raise ExtractorError(error, expected=True)\n            raise ExtractorError('Unable to find stream URL')\n\n        formats = []\n        for m3u8_url in m3u8_urls:\n            m3u8_id = 'fast' if '_fast' in m3u8_url else 'slow'\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, ext='mp4',\n                # ffmpeg skips segments for fast m3u8\n                preference=-10 if m3u8_id == 'fast' else None,\n                m3u8_id=m3u8_id, fatal=False, live=True))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._live_title(video_id),\n            'thumbnail': 'https://roomimg.stream.highwebmedia.com/ri/%s.jpg' % video_id,\n            'age_limit': self._rta_search(webpage),\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract#52",
        "src_path": "youtube_dl/extractor/chilloutzone.py",
        "class_name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE",
        "signature": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        base64_video_info = self._html_search_regex(\n            r'var cozVidData = \"(.+?)\";', webpage, 'video data')\n        decoded_video_info = base64.b64decode(base64_video_info.encode('utf-8')).decode('utf-8')\n        video_info_dict = json.loads(decoded_video_info)\n\n        # get video information from dict\n        video_url = video_info_dict['mediaUrl']\n        description = clean_html(video_info_dict.get('description'))\n        title = video_info_dict['title']\n        native_platform = video_info_dict['nativePlatform']\n        native_video_id = video_info_dict['nativeVideoId']\n        source_priority = video_info_dict['sourcePriority']\n\n        # If nativePlatform is None a fallback mechanism is used (i.e. youtube embed)\n        if native_platform is None:\n            youtube_url = self._html_search_regex(\n                r'<iframe.* src=\"((?:https?:)?//(?:[^.]+\\.)?youtube\\.com/.+?)\"',\n                webpage, 'fallback video URL', default=None)\n            if youtube_url is not None:\n                return self.url_result(youtube_url, ie='Youtube')\n\n        # Non Fallback: Decide to use native source (e.g. youtube or vimeo) or\n        # the own CDN\n        if source_priority == 'native':\n            if native_platform == 'youtube':\n                return self.url_result(native_video_id, ie='Youtube')\n            if native_platform == 'vimeo':\n                return self.url_result(\n                    'http://vimeo.com/' + native_video_id, ie='Vimeo')\n\n        if not video_url:\n            raise ExtractorError('No video found')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 52,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.chirbit.ChirbitIE._real_extract#35",
        "src_path": "youtube_dl/extractor/chirbit.py",
        "class_name": "youtube_dl.extractor.chirbit.ChirbitIE",
        "signature": "youtube_dl.extractor.chirbit.ChirbitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://chirb.it/%s' % audio_id, audio_id)\n\n        data_fd = self._search_regex(\n            r'data-fd=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'data fd', group='url')\n\n        # Reverse engineered from https://chirb.it/js/chirbit.player.js (look\n        # for soundURL)\n        audio_url = base64.b64decode(\n            data_fd[::-1].encode('ascii')).decode('utf-8')\n\n        title = self._search_regex(\n            r'class=[\"\\']chirbit-title[\"\\'][^>]*>([^<]+)', webpage, 'title')\n        description = self._search_regex(\n            r'<h3>Description</h3>\\s*<pre[^>]*>([^<]+)</pre>',\n            webpage, 'description', default=None)\n        duration = parse_duration(self._search_regex(\n            r'class=[\"\\']c-length[\"\\'][^>]*>([^<]+)',\n            webpage, 'duration', fatal=False))\n        uploader = self._search_regex(\n            r'id=[\"\\']chirbit-username[\"\\'][^>]*>([^<]+)',\n            webpage, 'uploader', fatal=False)\n\n        return {\n            'id': audio_id,\n            'url': audio_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'uploader': uploader,\n        }",
        "begin_line": 35,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.chirbit.ChirbitProfileIE._real_extract#83",
        "src_path": "youtube_dl/extractor/chirbit.py",
        "class_name": "youtube_dl.extractor.chirbit.ChirbitProfileIE",
        "signature": "youtube_dl.extractor.chirbit.ChirbitProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        profile_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, profile_id)\n\n        entries = [\n            self.url_result(self._proto_relative_url('//chirb.it/' + video_id))\n            for _, video_id in re.findall(r'<input[^>]+id=([\\'\"])copy-btn-(?P<id>[0-9a-zA-Z]+)\\1', webpage)]\n\n        return self.playlist_result(entries, profile_id)",
        "begin_line": 83,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cinchcast.CinchcastIE._real_extract#27",
        "src_path": "youtube_dl/extractor/cinchcast.py",
        "class_name": "youtube_dl.extractor.cinchcast.CinchcastIE",
        "signature": "youtube_dl.extractor.cinchcast.CinchcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        doc = self._download_xml(\n            'http://www.blogtalkradio.com/playerasset/mrss?assetType=single&assetId=%s' % video_id,\n            video_id)\n\n        item = doc.find('.//item')\n        title = xpath_text(item, './title', fatal=True)\n        date_str = xpath_text(\n            item, './{http://developer.longtailvideo.com/trac/}date')\n        upload_date = unified_strdate(date_str, day_first=False)\n        # duration is present but wrong\n        formats = [{\n            'format_id': 'main',\n            'url': item.find('./{http://search.yahoo.com/mrss/}content').attrib['url'],\n        }]\n        backup_url = xpath_text(\n            item, './{http://developer.longtailvideo.com/trac/}backupContent')\n        if backup_url:\n            formats.append({\n                'preference': 2,  # seems to be more reliable\n                'format_id': 'backup',\n                'url': backup_url,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cjsw.CJSWIE._real_extract#32",
        "src_path": "youtube_dl/extractor/cjsw.py",
        "class_name": "youtube_dl.extractor.cjsw.CJSWIE",
        "signature": "youtube_dl.extractor.cjsw.CJSWIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        program, episode_id = mobj.group('program', 'id')\n        audio_id = '%s/%s' % (program, episode_id)\n\n        webpage = self._download_webpage(url, episode_id)\n\n        title = unescapeHTML(self._search_regex(\n            (r'<h1[^>]+class=[\"\\']episode-header__title[\"\\'][^>]*>(?P<title>[^<]+)',\n             r'data-audio-title=([\"\\'])(?P<title>(?:(?!\\1).)+)\\1'),\n            webpage, 'title', group='title'))\n\n        audio_url = self._search_regex(\n            r'<button[^>]+data-audio-src=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'audio url', group='url')\n\n        audio_id = self._search_regex(\n            r'/([\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})\\.mp3',\n            audio_url, 'audio id', default=audio_id)\n\n        formats = [{\n            'url': audio_url,\n            'ext': determine_ext(audio_url, 'mp3'),\n            'vcodec': 'none',\n        }]\n\n        description = self._html_search_regex(\n            r'<p>(?P<description>.+?)</p>', webpage, 'description',\n            default=None)\n        series = self._search_regex(\n            r'data-showname=([\"\\'])(?P<name>(?:(?!\\1).)+)\\1', webpage,\n            'series', default=program, group='name')\n\n        return {\n            'id': audio_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'series': series,\n            'episode_id': episode_id,\n        }",
        "begin_line": 32,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cliphunter._decode#15",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter",
        "signature": "youtube_dl.extractor.cliphunter._decode(s)",
        "snippet": "def _decode(s):\n    return ''.join(_translation_table.get(c, c) for c in s)",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract#49",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter.CliphunterIE",
        "signature": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._search_regex(\n            r'mediaTitle = \"([^\"]+)\"', webpage, 'title')\n\n        gexo_files = self._parse_json(\n            self._search_regex(\n                r'var\\s+gexoFiles\\s*=\\s*({.+?});', webpage, 'gexo files'),\n            video_id)\n\n        formats = []\n        for format_id, f in gexo_files.items():\n            video_url = f.get('url')\n            if not video_url:\n                continue\n            fmt = f.get('fmt')\n            height = f.get('h')\n            format_id = '%s_%sp' % (fmt, height) if fmt and height else format_id\n            formats.append({\n                'url': _decode(video_url),\n                'format_id': format_id,\n                'width': int_or_none(f.get('w')),\n                'height': int_or_none(height),\n                'tbr': int_or_none(f.get('br')),\n            })\n        self._sort_formats(formats)\n\n        thumbnail = self._search_regex(\n            r\"var\\s+mov_thumb\\s*=\\s*'([^']+)';\",\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'age_limit': self._rta_search(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 49,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.clippit.ClippitIE._real_extract#33",
        "src_path": "youtube_dl/extractor/clippit.py",
        "class_name": "youtube_dl.extractor.clippit.ClippitIE",
        "signature": "youtube_dl.extractor.clippit.ClippitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<title.*>(.+?)</title>', webpage, 'title')\n\n        FORMATS = ('sd', 'hd')\n        quality = qualities(FORMATS)\n        formats = []\n        for format_id in FORMATS:\n            url = self._html_search_regex(r'data-%s-file=\"(.+?)\"' % format_id,\n                                          webpage, 'url', fatal=False)\n            if not url:\n                continue\n            match = re.search(r'/(?P<height>\\d+)\\.mp4', url)\n            formats.append({\n                'url': url,\n                'format_id': format_id,\n                'quality': quality(format_id),\n                'height': int(match.group('height')) if match else None,\n            })\n\n        uploader = self._html_search_regex(r'class=\"username\".*>\\s+(.+?)\\n',\n                                           webpage, 'uploader', fatal=False)\n        uploader_url = ('https://www.clippituser.tv/p/' + uploader\n                        if uploader else None)\n\n        timestamp = self._html_search_regex(r'datetime=\"(.+?)\"',\n                                            webpage, 'date', fatal=False)\n        thumbnail = self._html_search_regex(r'data-image=\"(.+?)\"',\n                                            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'uploader': uploader,\n            'uploader_url': uploader_url,\n            'timestamp': parse_iso8601(timestamp),\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 33,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cliprs.ClipRsIE._real_extract#23",
        "src_path": "youtube_dl/extractor/cliprs.py",
        "class_name": "youtube_dl.extractor.cliprs.ClipRsIE",
        "signature": "youtube_dl.extractor.cliprs.ClipRsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        mvp_id = self._search_mvp_id(webpage)\n\n        info_dict = self._extract_from_id(mvp_id, webpage)\n        info_dict['display_id'] = display_id\n\n        return info_dict",
        "begin_line": 23,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract#28",
        "src_path": "youtube_dl/extractor/clipsyndicate.py",
        "class_name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE",
        "signature": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        js_player = self._download_webpage(\n            'http://eplayer.clipsyndicate.com/embed/player.js?va_id=%s' % video_id,\n            video_id, 'Downlaoding player')\n        # it includes a required token\n        flvars = self._search_regex(r'flvars: \"(.*?)\"', js_player, 'flvars')\n\n        pdoc = self._download_xml(\n            'http://eplayer.clipsyndicate.com/osmf/playlist?%s' % flvars,\n            video_id, 'Downloading video info',\n            transform_source=fix_xml_ampersands)\n\n        track_doc = pdoc.find('trackList/track')\n\n        def find_param(name):\n            node = find_xpath_attr(track_doc, './/param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n\n        return {\n            'id': video_id,\n            'title': find_param('title'),\n            'url': track_doc.find('location').text,\n            'thumbnail': find_param('thumbnail'),\n            'duration': int(find_param('duration')),\n        }",
        "begin_line": 28,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.closertotruth.CloserToTruthIE._real_extract#48",
        "src_path": "youtube_dl/extractor/closertotruth.py",
        "class_name": "youtube_dl.extractor.closertotruth.CloserToTruthIE",
        "signature": "youtube_dl.extractor.closertotruth.CloserToTruthIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        partner_id = self._search_regex(\n            r'<script[^>]+src=[\"\\'].*?\\b(?:partner_id|p)/(\\d+)',\n            webpage, 'kaltura partner_id')\n\n        title = self._search_regex(\n            r'<title>(.+?)\\s*\\|\\s*.+?</title>', webpage, 'video title')\n\n        select = self._search_regex(\n            r'(?s)<select[^>]+id=\"select-version\"[^>]*>(.+?)</select>',\n            webpage, 'select version', default=None)\n        if select:\n            entry_ids = set()\n            entries = []\n            for mobj in re.finditer(\n                    r'<option[^>]+value=([\"\\'])(?P<id>[0-9a-z_]+)(?:#.+?)?\\1[^>]*>(?P<title>[^<]+)',\n                    webpage):\n                entry_id = mobj.group('id')\n                if entry_id in entry_ids:\n                    continue\n                entry_ids.add(entry_id)\n                entries.append({\n                    '_type': 'url_transparent',\n                    'url': 'kaltura:%s:%s' % (partner_id, entry_id),\n                    'ie_key': 'Kaltura',\n                    'title': mobj.group('title'),\n                })\n            if entries:\n                return self.playlist_result(entries, display_id, title)\n\n        entry_id = self._search_regex(\n            r'<a[^>]+id=([\"\\'])embed-kaltura\\1[^>]+data-kaltura=([\"\\'])(?P<id>[0-9a-z_]+)\\2',\n            webpage, 'kaltura entry_id', group='id')\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'url': 'kaltura:%s:%s' % (partner_id, entry_id),\n            'ie_key': 'Kaltura',\n            'title': title\n        }",
        "begin_line": 48,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._real_extract#29",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://www.cloudy.ec/embed.php', video_id, query={\n                'id': video_id,\n                'playerPage': 1,\n                'autoplay': 1,\n            })\n\n        info = self._parse_html5_media_entries(url, webpage, video_id)[0]\n\n        webpage = self._download_webpage(\n            'https://www.cloudy.ec/v/%s' % video_id, video_id, fatal=False)\n\n        if webpage:\n            info.update({\n                'title': self._search_regex(\n                    r'<h\\d[^>]*>([^<]+)<', webpage, 'title'),\n                'upload_date': unified_strdate(self._search_regex(\n                    r'>Published at (\\d{4}-\\d{1,2}-\\d{1,2})', webpage,\n                    'upload date', fatal=False)),\n                'view_count': str_to_int(self._search_regex(\n                    r'([\\d,.]+) views<', webpage, 'view count', fatal=False)),\n            })\n\n        if not info.get('title'):\n            info['title'] = video_id\n\n        info['id'] = video_id\n\n        return info",
        "begin_line": 29,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.clubic.ClubicIE._real_extract#29",
        "src_path": "youtube_dl/extractor/clubic.py",
        "class_name": "youtube_dl.extractor.clubic.ClubicIE",
        "signature": "youtube_dl.extractor.clubic.ClubicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_url = 'http://player.m6web.fr/v1/player/clubic/%s.html' % video_id\n        player_page = self._download_webpage(player_url, video_id)\n\n        config = self._parse_json(self._search_regex(\n            r'(?m)M6\\.Player\\.config\\s*=\\s*(\\{.+?\\});$', player_page,\n            'configuration'), video_id)\n\n        video_info = config['videoInfo']\n        sources = config['sources']\n        quality_order = qualities(['sd', 'hq'])\n\n        formats = [{\n            'format_id': src['streamQuality'],\n            'url': src['src'],\n            'quality': quality_order(src['streamQuality']),\n        } for src in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'description': clean_html(video_info.get('description')),\n            'thumbnail': config.get('poster'),\n        }",
        "begin_line": 29,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.clyp.ClypIE._real_extract#26",
        "src_path": "youtube_dl/extractor/clyp.py",
        "class_name": "youtube_dl.extractor.clyp.ClypIE",
        "signature": "youtube_dl.extractor.clyp.ClypIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        metadata = self._download_json(\n            'https://api.clyp.it/%s' % audio_id, audio_id)\n\n        formats = []\n        for secure in ('', 'Secure'):\n            for ext in ('Ogg', 'Mp3'):\n                format_id = '%s%s' % (secure, ext)\n                format_url = metadata.get('%sUrl' % format_id)\n                if format_url:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                        'vcodec': 'none',\n                    })\n        self._sort_formats(formats)\n\n        title = metadata['Title']\n        description = metadata.get('Description')\n        duration = float_or_none(metadata.get('Duration'))\n        timestamp = parse_iso8601(metadata.get('DateCreated'))\n\n        return {\n            'id': audio_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cmt.CMTIE._extract_mgid#42",
        "src_path": "youtube_dl/extractor/cmt.py",
        "class_name": "youtube_dl.extractor.cmt.CMTIE",
        "signature": "youtube_dl.extractor.cmt.CMTIE._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        mgid = self._search_regex(\n            r'MTVN\\.VIDEO\\.contentUri\\s*=\\s*([\\'\"])(?P<mgid>.+?)\\1',\n            webpage, 'mgid', group='mgid', default=None)\n        if not mgid:\n            mgid = self._extract_triforce_mgid(webpage)\n        return mgid",
        "begin_line": 42,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cmt.CMTIE._real_extract#50",
        "src_path": "youtube_dl/extractor/cmt.py",
        "class_name": "youtube_dl.extractor.cmt.CMTIE",
        "signature": "youtube_dl.extractor.cmt.CMTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        mgid = self._extract_mgid(webpage)\n        return self.url_result('http://media.mtvnservices.com/embed/%s' % mgid)",
        "begin_line": 50,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cnbc.CNBCIE._real_extract#27",
        "src_path": "youtube_dl/extractor/cnbc.py",
        "class_name": "youtube_dl.extractor.cnbc.CNBCIE",
        "signature": "youtube_dl.extractor.cnbc.CNBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(\n                'http://link.theplatform.com/s/gZWlPC/media/guid/2408950221/%s?mbr=true&manifest=m3u' % video_id,\n                {'force_smil_url': True}),\n            'id': video_id,\n        }",
        "begin_line": 27,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNIE._extract_timestamp#86",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNIE",
        "signature": "youtube_dl.extractor.cnn.CNNIE._extract_timestamp(self, video_data)",
        "snippet": "    def _extract_timestamp(self, video_data):\n        # TODO: fix timestamp extraction\n        return None",
        "begin_line": 86,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNIE._real_extract#90",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNIE",
        "signature": "youtube_dl.extractor.cnn.CNNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        sub_domain, path, page_title = re.match(self._VALID_URL, url).groups()\n        if sub_domain not in ('money', 'edition'):\n            sub_domain = 'edition'\n        config = self._CONFIG[sub_domain]\n        return self._extract_cvp_info(\n            config['data_src'] % path, page_title, {\n                'default': {\n                    'media_src': config['media_src'],\n                }\n            })",
        "begin_line": 90,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract#119",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNBlogsIE",
        "signature": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r'data-url=\"(.+?)\"', webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 119,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNArticleIE._real_extract#145",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNArticleIE",
        "signature": "youtube_dl.extractor.cnn.CNNArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r\"video:\\s*'([^']+)'\", webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': 'http://cnn.com/video/?/video/' + cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 145,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.collegerama.CollegeRamaIE._real_extract#46",
        "src_path": "youtube_dl/extractor/collegerama.py",
        "class_name": "youtube_dl.extractor.collegerama.CollegeRamaIE",
        "signature": "youtube_dl.extractor.collegerama.CollegeRamaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_options_request = {\n            'getPlayerOptionsRequest': {\n                'ResourceId': video_id,\n                'QueryString': '',\n            }\n        }\n\n        request = sanitized_Request(\n            'http://collegerama.tudelft.nl/Mediasite/PlayerService/PlayerService.svc/json/GetPlayerOptions',\n            json.dumps(player_options_request))\n        request.add_header('Content-Type', 'application/json')\n\n        player_options = self._download_json(request, video_id)\n\n        presentation = player_options['d']['Presentation']\n        title = presentation['Title']\n        description = presentation.get('Description')\n        thumbnail = None\n        duration = float_or_none(presentation.get('Duration'), 1000)\n        timestamp = int_or_none(presentation.get('UnixTime'), 1000)\n\n        formats = []\n        for stream in presentation['Streams']:\n            for video in stream['VideoUrls']:\n                thumbnail_url = stream.get('ThumbnailUrl')\n                if thumbnail_url:\n                    thumbnail = 'http://collegerama.tudelft.nl' + thumbnail_url\n                format_id = video['MediaType']\n                if format_id == 'SS':\n                    continue\n                formats.append({\n                    'url': video['Location'],\n                    'format_id': format_id,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.comcarcoff.ComCarCoffIE._real_extract#31",
        "src_path": "youtube_dl/extractor/comcarcoff.py",
        "class_name": "youtube_dl.extractor.comcarcoff.ComCarCoffIE",
        "signature": "youtube_dl.extractor.comcarcoff.ComCarCoffIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        if not display_id:\n            display_id = 'comediansincarsgettingcoffee.com'\n        webpage = self._download_webpage(url, display_id)\n\n        full_data = self._parse_json(\n            self._search_regex(\n                r'window\\.app\\s*=\\s*({.+?});\\n', webpage, 'full data json'),\n            display_id)['videoData']\n\n        display_id = full_data['activeVideo']['video']\n        video_data = full_data.get('videos', {}).get(display_id) or full_data['singleshots'][display_id]\n\n        video_id = compat_str(video_data['mediaId'])\n        title = video_data['title']\n        formats = self._extract_m3u8_formats(\n            video_data['mediaUrl'], video_id, 'mp4')\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': video_data['images']['thumb'],\n        }, {\n            'url': video_data['images']['poster'],\n        }]\n\n        timestamp = int_or_none(video_data.get('pubDateTime')) or parse_iso8601(\n            video_data.get('pubDate'))\n        duration = int_or_none(video_data.get('durationSeconds')) or parse_duration(\n            video_data.get('duration'))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'timestamp': timestamp,\n            'duration': duration,\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'season_number': int_or_none(video_data.get('season')),\n            'episode_number': int_or_none(video_data.get('episode')),\n            'webpage_url': 'http://comediansincarsgettingcoffee.com/%s' % (video_data.get('urlSlug', video_data.get('slug'))),\n        }",
        "begin_line": 31,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralFullEpisodesIE._real_extract#48",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralFullEpisodesIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralFullEpisodesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n        mgid = self._extract_triforce_mgid(webpage, data_zone='t2_lc_promo1')\n        videos_info = self._get_videos_info(mgid)\n        return videos_info",
        "begin_line": 48,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralTVIE._real_extract#110",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralTVIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        mrss_url = self._search_regex(\n            r'data-mrss=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'mrss url', group='url')\n\n        return self._get_videos_info_from_url(mrss_url, video_id)",
        "begin_line": 110,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralShortnameIE._real_extract#132",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralShortnameIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralShortnameIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        shortcut_map = {\n            'tds': 'http://www.cc.com/shows/the-daily-show-with-trevor-noah/full-episodes',\n            'thedailyshow': 'http://www.cc.com/shows/the-daily-show-with-trevor-noah/full-episodes',\n        }\n        return self.url_result(shortcut_map[video_id])",
        "begin_line": 132,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__init__#356",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        \"\"\"Constructor. Receives an optional downloader.\"\"\"\n        self._ready = False\n        self._x_forwarded_for_ip = None\n        self.set_downloader(downloader)",
        "begin_line": 356,
        "end_line": 360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.suitable#363",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n\n        # This does not use has/getattr intentionally - we want to know whether\n        # we have cached the regexp for *this* class, whereas getattr would also\n        # match the superclass\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        return cls._VALID_URL_RE.match(url) is not None",
        "begin_line": 363,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._match_id#374",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._match_id(cls, url)",
        "snippet": "    def _match_id(cls, url):\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        m = cls._VALID_URL_RE.match(url)\n        assert m\n        return compat_str(m.group('id'))",
        "begin_line": 374,
        "end_line": 379,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.working#382",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.working(cls)",
        "snippet": "    def working(cls):\n        \"\"\"Getter method for _WORKING.\"\"\"\n        return cls._WORKING",
        "begin_line": 382,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.initialize#386",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.initialize(self)",
        "snippet": "    def initialize(self):\n        \"\"\"Initializes an instance (authentication, etc).\"\"\"\n        self._initialize_geo_bypass(self._GEO_COUNTRIES)\n        if not self._ready:\n            self._real_initialize()\n            self._ready = True",
        "begin_line": 386,
        "end_line": 391,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._initialize_geo_bypass#393",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._initialize_geo_bypass(self, countries)",
        "snippet": "    def _initialize_geo_bypass(self, countries):\n        \"\"\"\n        Initialize geo restriction bypass mechanism.\n\n        This method is used to initialize geo bypass mechanism based on faking\n        X-Forwarded-For HTTP header. A random country from provided country list\n        is selected and a random IP belonging to this country is generated. This\n        IP will be passed as X-Forwarded-For HTTP header in all subsequent\n        HTTP requests.\n\n        This method will be used for initial geo bypass mechanism initialization\n        during the instance initialization with _GEO_COUNTRIES.\n\n        You may also manually call it from extractor's code if geo countries\n        information is not available beforehand (e.g. obtained during\n        extraction) or due to some another reason.\n        \"\"\"\n        if not self._x_forwarded_for_ip:\n            country_code = self._downloader.params.get('geo_bypass_country', None)\n            # If there is no explicit country for geo bypass specified and\n            # the extractor is known to be geo restricted let's fake IP\n            # as X-Forwarded-For right away.\n            if (not country_code and\n                    self._GEO_BYPASS and\n                    self._downloader.params.get('geo_bypass', True) and\n                    countries):\n                country_code = random.choice(countries)\n            if country_code:\n                self._x_forwarded_for_ip = GeoUtils.random_ipv4(country_code)\n                if self._downloader.params.get('verbose', False):\n                    self._downloader.to_screen(\n                        '[debug] Using fake IP %s (%s) as X-Forwarded-For.'\n                        % (self._x_forwarded_for_ip, country_code.upper()))",
        "begin_line": 393,
        "end_line": 425,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract#427",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract(self, url)",
        "snippet": "    def extract(self, url):\n        \"\"\"Extracts URL information and returns it in list of dicts.\"\"\"\n        try:\n            for _ in range(2):\n                try:\n                    self.initialize()\n                    ie_result = self._real_extract(url)\n                    if self._x_forwarded_for_ip:\n                        ie_result['__x_forwarded_for_ip'] = self._x_forwarded_for_ip\n                    return ie_result\n                except GeoRestrictedError as e:\n                    if self.__maybe_fake_ip_and_retry(e.countries):\n                        continue\n                    raise\n        except ExtractorError:\n            raise\n        except compat_http_client.IncompleteRead as e:\n            raise ExtractorError('A network error has occurred.', cause=e, expected=True)\n        except (KeyError, StopIteration) as e:\n            raise ExtractorError('An extractor error has occurred.', cause=e)",
        "begin_line": 427,
        "end_line": 446,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__maybe_fake_ip_and_retry#448",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__maybe_fake_ip_and_retry(self, countries)",
        "snippet": "    def __maybe_fake_ip_and_retry(self, countries):\n        if (not self._downloader.params.get('geo_bypass_country', None) and\n                self._GEO_BYPASS and\n                self._downloader.params.get('geo_bypass', True) and\n                not self._x_forwarded_for_ip and\n                countries):\n            country_code = random.choice(countries)\n            self._x_forwarded_for_ip = GeoUtils.random_ipv4(country_code)\n            if self._x_forwarded_for_ip:\n                self.report_warning(\n                    'Video is geo restricted. Retrying extraction with fake IP %s (%s) as X-Forwarded-For.'\n                    % (self._x_forwarded_for_ip, country_code.upper()))\n                return True\n        return False",
        "begin_line": 448,
        "end_line": 461,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.set_downloader#463",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this IE.\"\"\"\n        self._downloader = downloader",
        "begin_line": 463,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_initialize#467",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 467,
        "end_line": 469,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_extract#471",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 471,
        "end_line": 473,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.ie_key#476",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.ie_key(cls)",
        "snippet": "    def ie_key(cls):\n        \"\"\"A string for getting the InfoExtractor with get_info_extractor\"\"\"\n        return compat_str(cls.__name__[:-2])",
        "begin_line": 476,
        "end_line": 478,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.IE_NAME#481",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return compat_str(type(self).__name__[:-2])",
        "begin_line": 481,
        "end_line": 482,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._request_webpage#484",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={})",
        "snippet": "    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={}):\n        \"\"\" Returns the response handle \"\"\"\n        if note is None:\n            self.report_download_webpage(video_id)\n        elif note is not False:\n            if video_id is None:\n                self.to_screen('%s' % (note,))\n            else:\n                self.to_screen('%s: %s' % (video_id, note))\n        if isinstance(url_or_request, compat_urllib_request.Request):\n            url_or_request = update_Request(\n                url_or_request, data=data, headers=headers, query=query)\n        else:\n            if query:\n                url_or_request = update_url_query(url_or_request, query)\n            if data is not None or headers:\n                url_or_request = sanitized_Request(url_or_request, data, headers)\n        try:\n            return self._downloader.urlopen(url_or_request)\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            if errnote is False:\n                return False\n            if errnote is None:\n                errnote = 'Unable to download webpage'\n\n            errmsg = '%s: %s' % (errnote, error_to_compat_str(err))\n            if fatal:\n                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n            else:\n                self._downloader.report_warning(errmsg)\n                return False",
        "begin_line": 484,
        "end_line": 514,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle#516",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={})",
        "snippet": "    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={}):\n        \"\"\" Returns a tuple (page content as string, URL handle) \"\"\"\n        # Strip hashes from the URL (#1038)\n        if isinstance(url_or_request, (compat_str, str)):\n            url_or_request = url_or_request.partition('#')[0]\n\n        # Some sites check X-Forwarded-For HTTP header in order to figure out\n        # the origin of the client behind proxy. This allows bypassing geo\n        # restriction by faking this header's value to IP that belongs to some\n        # geo unrestricted country. We will do so once we encounter any\n        # geo restriction error.\n        if self._x_forwarded_for_ip:\n            if 'X-Forwarded-For' not in headers:\n                headers['X-Forwarded-For'] = self._x_forwarded_for_ip\n\n        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal, data=data, headers=headers, query=query)\n        if urlh is False:\n            assert not fatal\n            return False\n        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal, encoding=encoding)\n        return (content, urlh)",
        "begin_line": 516,
        "end_line": 536,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content#539",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._guess_encoding_from_content(content_type, webpage_bytes)",
        "snippet": "    def _guess_encoding_from_content(content_type, webpage_bytes):\n        m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\\s*;\\s*charset=(.+)', content_type)\n        if m:\n            encoding = m.group(1)\n        else:\n            m = re.search(br'<meta[^>]+charset=[\\'\"]?([^\\'\")]+)[ /\\'\">]',\n                          webpage_bytes[:1024])\n            if m:\n                encoding = m.group(1).decode('ascii')\n            elif webpage_bytes.startswith(b'\\xff\\xfe'):\n                encoding = 'utf-16'\n            else:\n                encoding = 'utf-8'\n\n        return encoding",
        "begin_line": 539,
        "end_line": 553,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__check_blocked#555",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__check_blocked(self, content)",
        "snippet": "    def __check_blocked(self, content):\n        first_block = content[:512]\n        if ('<title>Access to this site is blocked</title>' in content and\n                'Websense' in first_block):\n            msg = 'Access to this webpage has been blocked by Websense filtering software in your network.'\n            blocked_iframe = self._html_search_regex(\n                r'<iframe src=\"([^\"]+)\"', content,\n                'Websense information URL', default=None)\n            if blocked_iframe:\n                msg += ' Visit %s for more details' % blocked_iframe\n            raise ExtractorError(msg, expected=True)\n        if '<title>The URL you requested has been blocked</title>' in first_block:\n            msg = (\n                'Access to this webpage has been blocked by Indian censorship. '\n                'Use a VPN or proxy server (with --proxy) to route around it.')\n            block_msg = self._html_search_regex(\n                r'</h1><p>(.*?)</p>',\n                content, 'block message', default=None)\n            if block_msg:\n                msg += ' (Message: \"%s\")' % block_msg.replace('\\n', ' ')\n            raise ExtractorError(msg, expected=True)\n        if ('<title>TTK :: \u0414\u043e\u0441\u0442\u0443\u043f \u043a \u0440\u0435\u0441\u0443\u0440\u0441\u0443 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d</title>' in content and\n                'blocklist.rkn.gov.ru' in content):\n            raise ExtractorError(\n                'Access to this webpage has been blocked by decision of the Russian government. '\n                'Visit http://blocklist.rkn.gov.ru/ for a block reason.',\n                expected=True)",
        "begin_line": 555,
        "end_line": 581,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content#583",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None)",
        "snippet": "    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):\n        content_type = urlh.headers.get('Content-Type', '')\n        webpage_bytes = urlh.read()\n        if prefix is not None:\n            webpage_bytes = prefix + webpage_bytes\n        if not encoding:\n            encoding = self._guess_encoding_from_content(content_type, webpage_bytes)\n        if self._downloader.params.get('dump_intermediate_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            self.to_screen('Dumping request to ' + url)\n            dump = base64.b64encode(webpage_bytes).decode('ascii')\n            self._downloader.to_screen(dump)\n        if self._downloader.params.get('write_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            basen = '%s_%s' % (video_id, url)\n            if len(basen) > 240:\n                h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                basen = basen[:240 - len(h)] + h\n            raw_filename = basen + '.dump'\n            filename = sanitize_filename(raw_filename, restricted=True)\n            self.to_screen('Saving request to ' + filename)\n            # Working around MAX_PATH limitation on Windows (see\n            # http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx)\n            if compat_os_name == 'nt':\n                absfilepath = os.path.abspath(filename)\n                if len(absfilepath) > 259:\n                    filename = '\\\\\\\\?\\\\' + absfilepath\n            with open(filename, 'wb') as outf:\n                outf.write(webpage_bytes)\n\n        try:\n            content = webpage_bytes.decode(encoding, 'replace')\n        except LookupError:\n            content = webpage_bytes.decode('utf-8', 'replace')\n\n        self.__check_blocked(content)\n\n        return content",
        "begin_line": 583,
        "end_line": 626,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage#628",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None, data=None, headers={}, query={})",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None, data=None, headers={}, query={}):\n        \"\"\" Returns the data of the page as a string \"\"\"\n        success = False\n        try_count = 0\n        while success is False:\n            try:\n                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding, data=data, headers=headers, query=query)\n                success = True\n            except compat_http_client.IncompleteRead as e:\n                try_count += 1\n                if try_count >= tries:\n                    raise e\n                self._sleep(timeout, video_id)\n        if res is False:\n            return res\n        else:\n            content, _ = res\n            return content",
        "begin_line": 628,
        "end_line": 645,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_xml#647",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_xml(self, url_or_request, video_id, note='Downloading XML', errnote='Unable to download XML', transform_source=None, fatal=True, encoding=None, data=None, headers={}, query={})",
        "snippet": "    def _download_xml(self, url_or_request, video_id,\n                      note='Downloading XML', errnote='Unable to download XML',\n                      transform_source=None, fatal=True, encoding=None, data=None, headers={}, query={}):\n        \"\"\"Return the xml as an xml.etree.ElementTree.Element\"\"\"\n        xml_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding, data=data, headers=headers, query=query)\n        if xml_string is False:\n            return xml_string\n        if transform_source:\n            xml_string = transform_source(xml_string)\n        return compat_etree_fromstring(xml_string.encode('utf-8'))",
        "begin_line": 647,
        "end_line": 657,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_json#659",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_json(self, url_or_request, video_id, note='Downloading JSON metadata', errnote='Unable to download JSON metadata', transform_source=None, fatal=True, encoding=None, data=None, headers={}, query={})",
        "snippet": "    def _download_json(self, url_or_request, video_id,\n                       note='Downloading JSON metadata',\n                       errnote='Unable to download JSON metadata',\n                       transform_source=None,\n                       fatal=True, encoding=None, data=None, headers={}, query={}):\n        json_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal,\n            encoding=encoding, data=data, headers=headers, query=query)\n        if (not fatal) and json_string is False:\n            return None\n        return self._parse_json(\n            json_string, video_id, transform_source=transform_source, fatal=fatal)",
        "begin_line": 659,
        "end_line": 670,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_json#672",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_json(self, json_string, video_id, transform_source=None, fatal=True)",
        "snippet": "    def _parse_json(self, json_string, video_id, transform_source=None, fatal=True):\n        if transform_source:\n            json_string = transform_source(json_string)\n        try:\n            return json.loads(json_string)\n        except ValueError as ve:\n            errmsg = '%s: Failed to parse JSON ' % video_id\n            if fatal:\n                raise ExtractorError(errmsg, cause=ve)\n            else:\n                self.report_warning(errmsg + str(ve))",
        "begin_line": 672,
        "end_line": 682,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_warning#684",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_warning(self, msg, video_id=None)",
        "snippet": "    def report_warning(self, msg, video_id=None):\n        idstr = '' if video_id is None else '%s: ' % video_id\n        self._downloader.report_warning(\n            '[%s] %s%s' % (self.IE_NAME, idstr, msg))",
        "begin_line": 684,
        "end_line": 687,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.to_screen#689",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.to_screen(self, msg)",
        "snippet": "    def to_screen(self, msg):\n        \"\"\"Print msg to screen, prefixing it with '[ie_name]'\"\"\"\n        self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))",
        "begin_line": 689,
        "end_line": 691,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_extraction#693",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_extraction(self, id_or_name)",
        "snippet": "    def report_extraction(self, id_or_name):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Extracting information' % id_or_name)",
        "begin_line": 693,
        "end_line": 695,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage#697",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        self.to_screen('%s: Downloading webpage' % video_id)",
        "begin_line": 697,
        "end_line": 699,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation#701",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation(self)",
        "snippet": "    def report_age_confirmation(self):\n        \"\"\"Report attempt to confirm age.\"\"\"\n        self.to_screen('Confirming age')",
        "begin_line": 701,
        "end_line": 703,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_login#705",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_login(self)",
        "snippet": "    def report_login(self):\n        \"\"\"Report attempt to log in.\"\"\"\n        self.to_screen('Logging in')",
        "begin_line": 705,
        "end_line": 707,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.raise_login_required#710",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.raise_login_required(msg='This video is only available for registered users')",
        "snippet": "    def raise_login_required(msg='This video is only available for registered users'):\n        raise ExtractorError(\n            '%s. Use --username and --password or --netrc to provide account credentials.' % msg,\n            expected=True)",
        "begin_line": 710,
        "end_line": 713,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.raise_geo_restricted#716",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.raise_geo_restricted(msg='This video is not available from your location due to geo restriction', countries=None)",
        "snippet": "    def raise_geo_restricted(msg='This video is not available from your location due to geo restriction', countries=None):\n        raise GeoRestrictedError(msg, countries=countries)",
        "begin_line": 716,
        "end_line": 717,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.url_result#721",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.url_result(url, ie=None, video_id=None, video_title=None)",
        "snippet": "    def url_result(url, ie=None, video_id=None, video_title=None):\n        \"\"\"Returns a URL that points to a page that should be processed\"\"\"\n        # TODO: ie should be the class used for getting the info\n        video_info = {'_type': 'url',\n                      'url': url,\n                      'ie_key': ie}\n        if video_id is not None:\n            video_info['id'] = video_id\n        if video_title is not None:\n            video_info['title'] = video_title\n        return video_info",
        "begin_line": 721,
        "end_line": 731,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_from_matches#733",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_from_matches(self, matches, playlist_id=None, playlist_title=None, getter=None, ie=None)",
        "snippet": "    def playlist_from_matches(self, matches, playlist_id=None, playlist_title=None, getter=None, ie=None):\n        urls = orderedSet(\n            self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)\n            for m in matches)\n        return self.playlist_result(\n            urls, playlist_id=playlist_id, playlist_title=playlist_title)",
        "begin_line": 733,
        "end_line": 738,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_result#741",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None)",
        "snippet": "    def playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None):\n        \"\"\"Returns a playlist\"\"\"\n        video_info = {'_type': 'playlist',\n                      'entries': entries}\n        if playlist_id:\n            video_info['id'] = playlist_id\n        if playlist_title:\n            video_info['title'] = playlist_title\n        if playlist_description:\n            video_info['description'] = playlist_description\n        return video_info",
        "begin_line": 741,
        "end_line": 751,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_regex#753",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Perform a regex search on the given string, using a single or a list of\n        patterns returning the first matching group.\n        In case of failure return a default value or raise a WARNING or a\n        RegexNotFoundError, depending on fatal, specifying the field name.\n        \"\"\"\n        if isinstance(pattern, (str, compat_str, compiled_regex_type)):\n            mobj = re.search(pattern, string, flags)\n        else:\n            for p in pattern:\n                mobj = re.search(p, string, flags)\n                if mobj:\n                    break\n\n        if not self._downloader.params.get('no_color') and compat_os_name != 'nt' and sys.stderr.isatty():\n            _name = '\\033[0;34m%s\\033[0m' % name\n        else:\n            _name = name\n\n        if mobj:\n            if group is None:\n                # return the first matching group\n                return next(g for g in mobj.groups() if g is not None)\n            else:\n                return mobj.group(group)\n        elif default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            raise RegexNotFoundError('Unable to extract %s' % _name)\n        else:\n            self._downloader.report_warning('unable to extract %s' % _name + bug_reports_message())\n            return None",
        "begin_line": 753,
        "end_line": 785,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_regex#787",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None)",
        "snippet": "    def _html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):\n        \"\"\"\n        Like _search_regex, but strips HTML tags and unescapes entities.\n        \"\"\"\n        res = self._search_regex(pattern, string, name, default, fatal, flags, group)\n        if res:\n            return clean_html(res).strip()\n        else:\n            return res",
        "begin_line": 787,
        "end_line": 795,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_netrc_login_info#797",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_netrc_login_info(self, netrc_machine=None)",
        "snippet": "    def _get_netrc_login_info(self, netrc_machine=None):\n        username = None\n        password = None\n        netrc_machine = netrc_machine or self._NETRC_MACHINE\n\n        if self._downloader.params.get('usenetrc', False):\n            try:\n                info = netrc.netrc().authenticators(netrc_machine)\n                if info is not None:\n                    username = info[0]\n                    password = info[2]\n                else:\n                    raise netrc.NetrcParseError(\n                        'No authenticators for %s' % netrc_machine)\n            except (IOError, netrc.NetrcParseError) as err:\n                self._downloader.report_warning(\n                    'parsing .netrc: %s' % error_to_compat_str(err))\n\n        return username, password",
        "begin_line": 797,
        "end_line": 815,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_login_info#817",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_login_info(self, username_option='username', password_option='password', netrc_machine=None)",
        "snippet": "    def _get_login_info(self, username_option='username', password_option='password', netrc_machine=None):\n        \"\"\"\n        Get the login info as (username, password)\n        First look for the manually specified credentials using username_option\n        and password_option as keys in params dictionary. If no such credentials\n        available look in the netrc file using the netrc_machine or _NETRC_MACHINE\n        value.\n        If there's no info available, return (None, None)\n        \"\"\"\n        if self._downloader is None:\n            return (None, None)\n\n        downloader_params = self._downloader.params\n\n        # Attempt to use provided username and password or .netrc data\n        if downloader_params.get(username_option) is not None:\n            username = downloader_params[username_option]\n            password = downloader_params[password_option]\n        else:\n            username, password = self._get_netrc_login_info(netrc_machine)\n\n        return username, password",
        "begin_line": 817,
        "end_line": 838,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info#840",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info(self, note='two-factor verification code')",
        "snippet": "    def _get_tfa_info(self, note='two-factor verification code'):\n        \"\"\"\n        Get the two-factor authentication info\n        TODO - asking the user will be required for sms/phone verify\n        currently just uses the command line option\n        If there's no info available, return None\n        \"\"\"\n        if self._downloader is None:\n            return None\n        downloader_params = self._downloader.params\n\n        if downloader_params.get('twofactor') is not None:\n            return downloader_params['twofactor']\n\n        return compat_getpass('Type %s and press [Return]: ' % note)",
        "begin_line": 840,
        "end_line": 854,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_regexes#858",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_regexes(prop)",
        "snippet": "    def _og_regexes(prop):\n        content_re = r'content=(?:\"([^\"]+?)\"|\\'([^\\']+?)\\'|\\s*([^\\s\"\\'=<>`]+?))'\n        property_re = (r'(?:name|property)=(?:\\'og:%(prop)s\\'|\"og:%(prop)s\"|\\s*og:%(prop)s\\b)'\n                       % {'prop': re.escape(prop)})\n        template = r'<meta[^>]+?%s[^>]+?%s'\n        return [\n            template % (property_re, content_re),\n            template % (content_re, property_re),\n        ]",
        "begin_line": 858,
        "end_line": 866,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._meta_regex#869",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._meta_regex(prop)",
        "snippet": "    def _meta_regex(prop):\n        return r'''(?isx)<meta\n                    (?=[^>]+(?:itemprop|name|property|id|http-equiv)=([\"\\']?)%s\\1)\n                    [^>]+?content=([\"\\'])(?P<content>.*?)\\2''' % re.escape(prop)",
        "begin_line": 869,
        "end_line": 872,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_property#874",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_property(self, prop, html, name=None, **kargs)",
        "snippet": "    def _og_search_property(self, prop, html, name=None, **kargs):\n        if not isinstance(prop, (list, tuple)):\n            prop = [prop]\n        if name is None:\n            name = 'OpenGraph %s' % prop[0]\n        og_regexes = []\n        for p in prop:\n            og_regexes.extend(self._og_regexes(p))\n        escaped = self._search_regex(og_regexes, html, name, flags=re.DOTALL, **kargs)\n        if escaped is None:\n            return None\n        return unescapeHTML(escaped)",
        "begin_line": 874,
        "end_line": 885,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail#887",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail(self, html, **kargs)",
        "snippet": "    def _og_search_thumbnail(self, html, **kargs):\n        return self._og_search_property('image', html, 'thumbnail URL', fatal=False, **kargs)",
        "begin_line": 887,
        "end_line": 888,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_description#890",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_description(self, html, **kargs)",
        "snippet": "    def _og_search_description(self, html, **kargs):\n        return self._og_search_property('description', html, fatal=False, **kargs)",
        "begin_line": 890,
        "end_line": 891,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_title#893",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_title(self, html, **kargs)",
        "snippet": "    def _og_search_title(self, html, **kargs):\n        return self._og_search_property('title', html, **kargs)",
        "begin_line": 893,
        "end_line": 894,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url#896",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url(self, html, name='video url', secure=True, **kargs)",
        "snippet": "    def _og_search_video_url(self, html, name='video url', secure=True, **kargs):\n        regexes = self._og_regexes('video') + self._og_regexes('video:url')\n        if secure:\n            regexes = self._og_regexes('video:secure_url') + regexes\n        return self._html_search_regex(regexes, html, name, **kargs)",
        "begin_line": 896,
        "end_line": 900,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_url#902",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_url(self, html, **kargs)",
        "snippet": "    def _og_search_url(self, html, **kargs):\n        return self._og_search_property('url', html, **kargs)",
        "begin_line": 902,
        "end_line": 903,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_meta#905",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs)",
        "snippet": "    def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):\n        if not isinstance(name, (list, tuple)):\n            name = [name]\n        if display_name is None:\n            display_name = name[0]\n        return self._html_search_regex(\n            [self._meta_regex(n) for n in name],\n            html, display_name, fatal=fatal, group='content', **kwargs)",
        "begin_line": 905,
        "end_line": 912,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader#914",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader(self, html)",
        "snippet": "    def _dc_search_uploader(self, html):\n        return self._html_search_meta('dc.creator', html, 'uploader')",
        "begin_line": 914,
        "end_line": 915,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._rta_search#917",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._rta_search(self, html)",
        "snippet": "    def _rta_search(self, html):\n        # See http://www.rtalabel.org/index.php?content=howtofaq#single\n        if re.search(r'(?ix)<meta\\s+name=\"rating\"\\s+'\n                     r'     content=\"RTA-5042-1996-1400-1577-RTA\"',\n                     html):\n            return 18\n        return 0",
        "begin_line": 917,
        "end_line": 923,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._media_rating_search#925",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._media_rating_search(self, html)",
        "snippet": "    def _media_rating_search(self, html):\n        # See http://www.tjg-designs.com/WP/metadata-code-examples-adding-metadata-to-your-web-pages/\n        rating = self._html_search_meta('rating', html)\n\n        if not rating:\n            return None\n\n        RATING_TABLE = {\n            'safe for kids': 0,\n            'general': 8,\n            '14 years': 14,\n            'mature': 17,\n            'restricted': 19,\n        }\n        return RATING_TABLE.get(rating.lower())",
        "begin_line": 925,
        "end_line": 939,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._family_friendly_search#941",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._family_friendly_search(self, html)",
        "snippet": "    def _family_friendly_search(self, html):\n        # See http://schema.org/VideoObject\n        family_friendly = self._html_search_meta(\n            'isFamilyFriendly', html, default=None)\n\n        if not family_friendly:\n            return None\n\n        RATING_TABLE = {\n            '1': 0,\n            'true': 0,\n            '0': 18,\n            'false': 18,\n        }\n        return RATING_TABLE.get(family_friendly.lower())",
        "begin_line": 941,
        "end_line": 955,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player#957",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player(self, html)",
        "snippet": "    def _twitter_search_player(self, html):\n        return self._html_search_meta('twitter:player', html,\n                                      'twitter card player')",
        "begin_line": 957,
        "end_line": 959,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_json_ld#961",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_json_ld(self, html, video_id, expected_type=None, **kwargs)",
        "snippet": "    def _search_json_ld(self, html, video_id, expected_type=None, **kwargs):\n        json_ld = self._search_regex(\n            r'(?s)<script[^>]+type=([\"\\'])application/ld\\+json\\1[^>]*>(?P<json_ld>.+?)</script>',\n            html, 'JSON-LD', group='json_ld', **kwargs)\n        default = kwargs.get('default', NO_DEFAULT)\n        if not json_ld:\n            return default if default is not NO_DEFAULT else {}\n        # JSON-LD may be malformed and thus `fatal` should be respected.\n        # At the same time `default` may be passed that assumes `fatal=False`\n        # for _search_regex. Let's simulate the same behavior here as well.\n        fatal = kwargs.get('fatal', True) if default == NO_DEFAULT else False\n        return self._json_ld(json_ld, video_id, fatal=fatal, expected_type=expected_type)",
        "begin_line": 961,
        "end_line": 972,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._json_ld#974",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._json_ld(self, json_ld, video_id, fatal=True, expected_type=None)",
        "snippet": "    def _json_ld(self, json_ld, video_id, fatal=True, expected_type=None):\n        if isinstance(json_ld, compat_str):\n            json_ld = self._parse_json(json_ld, video_id, fatal=fatal)\n        if not json_ld:\n            return {}\n        info = {}\n        if not isinstance(json_ld, (list, tuple, dict)):\n            return info\n        if isinstance(json_ld, dict):\n            json_ld = [json_ld]\n\n        def extract_video_object(e):\n            assert e['@type'] == 'VideoObject'\n            info.update({\n                'url': e.get('contentUrl'),\n                'title': unescapeHTML(e.get('name')),\n                'description': unescapeHTML(e.get('description')),\n                'thumbnail': e.get('thumbnailUrl') or e.get('thumbnailURL'),\n                'duration': parse_duration(e.get('duration')),\n                'timestamp': unified_timestamp(e.get('uploadDate')),\n                'filesize': float_or_none(e.get('contentSize')),\n                'tbr': int_or_none(e.get('bitrate')),\n                'width': int_or_none(e.get('width')),\n                'height': int_or_none(e.get('height')),\n                'view_count': int_or_none(e.get('interactionCount')),\n            })\n\n        for e in json_ld:\n            if e.get('@context') == 'http://schema.org':\n                item_type = e.get('@type')\n                if expected_type is not None and expected_type != item_type:\n                    return info\n                if item_type in ('TVEpisode', 'Episode'):\n                    info.update({\n                        'episode': unescapeHTML(e.get('name')),\n                        'episode_number': int_or_none(e.get('episodeNumber')),\n                        'description': unescapeHTML(e.get('description')),\n                    })\n                    part_of_season = e.get('partOfSeason')\n                    if isinstance(part_of_season, dict) and part_of_season.get('@type') in ('TVSeason', 'Season', 'CreativeWorkSeason'):\n                        info['season_number'] = int_or_none(part_of_season.get('seasonNumber'))\n                    part_of_series = e.get('partOfSeries') or e.get('partOfTVSeries')\n                    if isinstance(part_of_series, dict) and part_of_series.get('@type') in ('TVSeries', 'Series', 'CreativeWorkSeries'):\n                        info['series'] = unescapeHTML(part_of_series.get('name'))\n                elif item_type == 'Article':\n                    info.update({\n                        'timestamp': parse_iso8601(e.get('datePublished')),\n                        'title': unescapeHTML(e.get('headline')),\n                        'description': unescapeHTML(e.get('articleBody')),\n                    })\n                elif item_type == 'VideoObject':\n                    extract_video_object(e)\n                    continue\n                video = e.get('video')\n                if isinstance(video, dict) and video.get('@type') == 'VideoObject':\n                    extract_video_object(video)\n                break\n        return dict((k, v) for k, v in info.items() if v is not None)",
        "begin_line": 974,
        "end_line": 1031,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._hidden_inputs#1034",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._hidden_inputs(html)",
        "snippet": "    def _hidden_inputs(html):\n        html = re.sub(r'<!--(?:(?!<!--).)*-->', '', html)\n        hidden_inputs = {}\n        for input in re.findall(r'(?i)(<input[^>]+>)', html):\n            attrs = extract_attributes(input)\n            if not input:\n                continue\n            if attrs.get('type') not in ('hidden', 'submit'):\n                continue\n            name = attrs.get('name') or attrs.get('id')\n            value = attrs.get('value')\n            if name and value is not None:\n                hidden_inputs[name] = value\n        return hidden_inputs",
        "begin_line": 1034,
        "end_line": 1047,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._form_hidden_inputs#1049",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._form_hidden_inputs(self, form_id, html)",
        "snippet": "    def _form_hidden_inputs(self, form_id, html):\n        form = self._search_regex(\n            r'(?is)<form[^>]+?id=([\"\\'])%s\\1[^>]*>(?P<form>.+?)</form>' % form_id,\n            html, '%s form' % form_id, group='form')\n        return self._hidden_inputs(form)",
        "begin_line": 1049,
        "end_line": 1053,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sort_formats#1055",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sort_formats(self, formats, field_preference=None)",
        "snippet": "    def _sort_formats(self, formats, field_preference=None):\n        if not formats:\n            raise ExtractorError('No video formats found')\n\n        for f in formats:\n            # Automatically determine tbr when missing based on abr and vbr (improves\n            # formats sorting in some cases)\n            if 'tbr' not in f and f.get('abr') is not None and f.get('vbr') is not None:\n                f['tbr'] = f['abr'] + f['vbr']\n\n        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            if isinstance(field_preference, (list, tuple)):\n                return tuple(\n                    f.get(field)\n                    if f.get(field) is not None\n                    else ('' if field == 'format_id' else -1)\n                    for field in field_preference)\n\n            preference = f.get('preference')\n            if preference is None:\n                preference = 0\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            protocol = f.get('protocol') or determine_protocol(f)\n            proto_preference = 0 if protocol in ['http', 'https'] else (-0.5 if protocol == 'rtsp' else -0.1)\n\n            if f.get('vcodec') == 'none':  # audio only\n                preference -= 50\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if f.get('acodec') == 'none':  # video only\n                    preference -= 40\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('language_preference') if f.get('language_preference') is not None else -1,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                proto_preference,\n                ext_preference,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('fps') if f.get('fps') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('source_preference') if f.get('source_preference') is not None else -1,\n                f.get('format_id') if f.get('format_id') is not None else '',\n            )\n        formats.sort(key=_formats_key)",
        "begin_line": 1055,
        "end_line": 1129,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._check_formats#1131",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._check_formats(self, formats, video_id)",
        "snippet": "    def _check_formats(self, formats, video_id):\n        if formats:\n            formats[:] = filter(\n                lambda f: self._is_valid_url(\n                    f['url'], video_id,\n                    item='%s video format' % f.get('format_id') if f.get('format_id') else 'video'),\n                formats)",
        "begin_line": 1131,
        "end_line": 1137,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._remove_duplicate_formats#1140",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._remove_duplicate_formats(formats)",
        "snippet": "    def _remove_duplicate_formats(formats):\n        format_urls = set()\n        unique_formats = []\n        for f in formats:\n            if f['url'] not in format_urls:\n                format_urls.add(f['url'])\n                unique_formats.append(f)\n        formats[:] = unique_formats",
        "begin_line": 1140,
        "end_line": 1147,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._is_valid_url#1149",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._is_valid_url(self, url, video_id, item='video', headers={})",
        "snippet": "    def _is_valid_url(self, url, video_id, item='video', headers={}):\n        url = self._proto_relative_url(url, scheme='http:')\n        # For now assume non HTTP(S) URLs always valid\n        if not (url.startswith('http://') or url.startswith('https://')):\n            return True\n        try:\n            self._request_webpage(url, video_id, 'Checking %s URL' % item, headers=headers)\n            return True\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_urllib_error.URLError):\n                self.to_screen(\n                    '%s: %s URL is invalid, skipping' % (video_id, item))\n                return False\n            raise",
        "begin_line": 1149,
        "end_line": 1162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.http_scheme#1164",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.http_scheme(self)",
        "snippet": "    def http_scheme(self):\n        \"\"\" Either \"http:\" or \"https:\", depending on the user's preferences \"\"\"\n        return (\n            'http:'\n            if self._downloader.params.get('prefer_insecure', False)\n            else 'https:')",
        "begin_line": 1164,
        "end_line": 1169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url#1171",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url(self, url, scheme=None)",
        "snippet": "    def _proto_relative_url(self, url, scheme=None):\n        if url is None:\n            return url\n        if url.startswith('//'):\n            if scheme is None:\n                scheme = self.http_scheme()\n            return scheme + url\n        else:\n            return url",
        "begin_line": 1171,
        "end_line": 1179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sleep#1181",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sleep(self, timeout, video_id, msg_template=None)",
        "snippet": "    def _sleep(self, timeout, video_id, msg_template=None):\n        if msg_template is None:\n            msg_template = '%(video_id)s: Waiting for %(timeout)s seconds'\n        msg = msg_template % {'video_id': video_id, 'timeout': timeout}\n        self.to_screen(msg)\n        time.sleep(timeout)",
        "begin_line": 1181,
        "end_line": 1186,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats#1188",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None, transform_source=lambda s: fix_xml_ampersands(s).strip(), fatal=True, m3u8_id=None)",
        "snippet": "    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None,\n                             transform_source=lambda s: fix_xml_ampersands(s).strip(),\n                             fatal=True, m3u8_id=None):\n        manifest = self._download_xml(\n            manifest_url, video_id, 'Downloading f4m manifest',\n            'Unable to download f4m manifest',\n            # Some manifests may be malformed, e.g. prosiebensat1 generated manifests\n            # (see https://github.com/rg3/youtube-dl/issues/6215#issuecomment-121704244)\n            transform_source=transform_source,\n            fatal=fatal)\n\n        if manifest is False:\n            return []\n\n        return self._parse_f4m_formats(\n            manifest, manifest_url, video_id, preference=preference, f4m_id=f4m_id,\n            transform_source=transform_source, fatal=fatal, m3u8_id=m3u8_id)",
        "begin_line": 1188,
        "end_line": 1204,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_f4m_formats#1206",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_f4m_formats(self, manifest, manifest_url, video_id, preference=None, f4m_id=None, transform_source=lambda s: fix_xml_ampersands(s).strip(), fatal=True, m3u8_id=None)",
        "snippet": "    def _parse_f4m_formats(self, manifest, manifest_url, video_id, preference=None, f4m_id=None,\n                           transform_source=lambda s: fix_xml_ampersands(s).strip(),\n                           fatal=True, m3u8_id=None):\n        # currently youtube-dl cannot decode the playerVerificationChallenge as Akamai uses Adobe Alchemy\n        akamai_pv = manifest.find('{http://ns.adobe.com/f4m/1.0}pv-2.0')\n        if akamai_pv is not None and ';' in akamai_pv.text:\n            playerVerificationChallenge = akamai_pv.text.split(';')[0]\n            if playerVerificationChallenge.strip() != '':\n                return []\n\n        formats = []\n        manifest_version = '1.0'\n        media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')\n        if not media_nodes:\n            manifest_version = '2.0'\n            media_nodes = manifest.findall('{http://ns.adobe.com/f4m/2.0}media')\n        # Remove unsupported DRM protected media from final formats\n        # rendition (see https://github.com/rg3/youtube-dl/issues/8573).\n        media_nodes = remove_encrypted_media(media_nodes)\n        if not media_nodes:\n            return formats\n        base_url = xpath_text(\n            manifest, ['{http://ns.adobe.com/f4m/1.0}baseURL', '{http://ns.adobe.com/f4m/2.0}baseURL'],\n            'base URL', default=None)\n        if base_url:\n            base_url = base_url.strip()\n\n        bootstrap_info = xpath_element(\n            manifest, ['{http://ns.adobe.com/f4m/1.0}bootstrapInfo', '{http://ns.adobe.com/f4m/2.0}bootstrapInfo'],\n            'bootstrap info', default=None)\n\n        vcodec = None\n        mime_type = xpath_text(\n            manifest, ['{http://ns.adobe.com/f4m/1.0}mimeType', '{http://ns.adobe.com/f4m/2.0}mimeType'],\n            'base URL', default=None)\n        if mime_type and mime_type.startswith('audio/'):\n            vcodec = 'none'\n\n        for i, media_el in enumerate(media_nodes):\n            tbr = int_or_none(media_el.attrib.get('bitrate'))\n            width = int_or_none(media_el.attrib.get('width'))\n            height = int_or_none(media_el.attrib.get('height'))\n            format_id = '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)]))\n            # If <bootstrapInfo> is present, the specified f4m is a\n            # stream-level manifest, and only set-level manifests may refer to\n            # external resources.  See section 11.4 and section 4 of F4M spec\n            if bootstrap_info is None:\n                media_url = None\n                # @href is introduced in 2.0, see section 11.6 of F4M spec\n                if manifest_version == '2.0':\n                    media_url = media_el.attrib.get('href')\n                if media_url is None:\n                    media_url = media_el.attrib.get('url')\n                if not media_url:\n                    continue\n                manifest_url = (\n                    media_url if media_url.startswith('http://') or media_url.startswith('https://')\n                    else ((base_url or '/'.join(manifest_url.split('/')[:-1])) + '/' + media_url))\n                # If media_url is itself a f4m manifest do the recursive extraction\n                # since bitrates in parent manifest (this one) and media_url manifest\n                # may differ leading to inability to resolve the format by requested\n                # bitrate in f4m downloader\n                ext = determine_ext(manifest_url)\n                if ext == 'f4m':\n                    f4m_formats = self._extract_f4m_formats(\n                        manifest_url, video_id, preference=preference, f4m_id=f4m_id,\n                        transform_source=transform_source, fatal=fatal)\n                    # Sometimes stream-level manifest contains single media entry that\n                    # does not contain any quality metadata (e.g. http://matchtv.ru/#live-player).\n                    # At the same time parent's media entry in set-level manifest may\n                    # contain it. We will copy it from parent in such cases.\n                    if len(f4m_formats) == 1:\n                        f = f4m_formats[0]\n                        f.update({\n                            'tbr': f.get('tbr') or tbr,\n                            'width': f.get('width') or width,\n                            'height': f.get('height') or height,\n                            'format_id': f.get('format_id') if not tbr else format_id,\n                            'vcodec': vcodec,\n                        })\n                    formats.extend(f4m_formats)\n                    continue\n                elif ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        manifest_url, video_id, 'mp4', preference=preference,\n                        m3u8_id=m3u8_id, fatal=fatal))\n                    continue\n            formats.append({\n                'format_id': format_id,\n                'url': manifest_url,\n                'manifest_url': manifest_url,\n                'ext': 'flv' if bootstrap_info is not None else None,\n                'tbr': tbr,\n                'width': width,\n                'height': height,\n                'vcodec': vcodec,\n                'preference': preference,\n            })\n        return formats",
        "begin_line": 1206,
        "end_line": 1304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._m3u8_meta_format#1306",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._m3u8_meta_format(self, m3u8_url, ext=None, preference=None, m3u8_id=None)",
        "snippet": "    def _m3u8_meta_format(self, m3u8_url, ext=None, preference=None, m3u8_id=None):\n        return {\n            'format_id': '-'.join(filter(None, [m3u8_id, 'meta'])),\n            'url': m3u8_url,\n            'ext': ext,\n            'protocol': 'm3u8',\n            'preference': preference - 100 if preference else -100,\n            'resolution': 'multiple',\n            'format_note': 'Quality selection URL',\n        }",
        "begin_line": 1306,
        "end_line": 1315,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats#1317",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats(self, m3u8_url, video_id, ext=None, entry_protocol='m3u8', preference=None, m3u8_id=None, note=None, errnote=None, fatal=True, live=False)",
        "snippet": "    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None,\n                              entry_protocol='m3u8', preference=None,\n                              m3u8_id=None, note=None, errnote=None,\n                              fatal=True, live=False):\n        res = self._download_webpage_handle(\n            m3u8_url, video_id,\n            note=note or 'Downloading m3u8 information',\n            errnote=errnote or 'Failed to download m3u8 information',\n            fatal=fatal)\n\n        if res is False:\n            return []\n\n        m3u8_doc, urlh = res\n        m3u8_url = urlh.geturl()\n\n        return self._parse_m3u8_formats(\n            m3u8_doc, m3u8_url, ext=ext, entry_protocol=entry_protocol,\n            preference=preference, m3u8_id=m3u8_id, live=live)",
        "begin_line": 1317,
        "end_line": 1335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_m3u8_formats#1337",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_m3u8_formats(self, m3u8_doc, m3u8_url, ext=None, entry_protocol='m3u8', preference=None, m3u8_id=None, live=False)",
        "snippet": "    def _parse_m3u8_formats(self, m3u8_doc, m3u8_url, ext=None,\n                            entry_protocol='m3u8', preference=None,\n                            m3u8_id=None, live=False):\n        if '#EXT-X-FAXS-CM:' in m3u8_doc:  # Adobe Flash Access\n            return []\n\n        formats = []\n\n        format_url = lambda u: (\n            u\n            if re.match(r'^https?://', u)\n            else compat_urlparse.urljoin(m3u8_url, u))\n\n        # References:\n        # 1. https://tools.ietf.org/html/draft-pantos-http-live-streaming-21\n        # 2. https://github.com/rg3/youtube-dl/issues/12211\n\n        # We should try extracting formats only from master playlists [1, 4.3.4],\n        # i.e. playlists that describe available qualities. On the other hand\n        # media playlists [1, 4.3.3] should be returned as is since they contain\n        # just the media without qualities renditions.\n        # Fortunately, master playlist can be easily distinguished from media\n        # playlist based on particular tags availability. As of [1, 4.3.3, 4.3.4]\n        # master playlist tags MUST NOT appear in a media playist and vice versa.\n        # As of [1, 4.3.3.1] #EXT-X-TARGETDURATION tag is REQUIRED for every\n        # media playlist and MUST NOT appear in master playlist thus we can\n        # clearly detect media playlist with this criterion.\n\n        if '#EXT-X-TARGETDURATION' in m3u8_doc:  # media playlist, return as is\n            return [{\n                'url': m3u8_url,\n                'format_id': m3u8_id,\n                'ext': ext,\n                'protocol': entry_protocol,\n                'preference': preference,\n            }]\n\n        groups = {}\n        last_stream_inf = {}\n\n        def extract_media(x_media_line):\n            media = parse_m3u8_attributes(x_media_line)\n            # As per [1, 4.3.4.1] TYPE, GROUP-ID and NAME are REQUIRED\n            media_type, group_id, name = media.get('TYPE'), media.get('GROUP-ID'), media.get('NAME')\n            if not (media_type and group_id and name):\n                return\n            groups.setdefault(group_id, []).append(media)\n            if media_type not in ('VIDEO', 'AUDIO'):\n                return\n            media_url = media.get('URI')\n            if media_url:\n                format_id = []\n                for v in (group_id, name):\n                    if v:\n                        format_id.append(v)\n                f = {\n                    'format_id': '-'.join(format_id),\n                    'url': format_url(media_url),\n                    'manifest_url': m3u8_url,\n                    'language': media.get('LANGUAGE'),\n                    'ext': ext,\n                    'protocol': entry_protocol,\n                    'preference': preference,\n                }\n                if media_type == 'AUDIO':\n                    f['vcodec'] = 'none'\n                formats.append(f)\n\n        def build_stream_name():\n            # Despite specification does not mention NAME attribute for\n            # EXT-X-STREAM-INF tag it still sometimes may be present (see [1]\n            # or vidio test in TestInfoExtractor.test_parse_m3u8_formats)\n            # 1. http://www.vidio.com/watch/165683-dj_ambred-booyah-live-2015\n            stream_name = last_stream_inf.get('NAME')\n            if stream_name:\n                return stream_name\n            # If there is no NAME in EXT-X-STREAM-INF it will be obtained\n            # from corresponding rendition group\n            stream_group_id = last_stream_inf.get('VIDEO')\n            if not stream_group_id:\n                return\n            stream_group = groups.get(stream_group_id)\n            if not stream_group:\n                return stream_group_id\n            rendition = stream_group[0]\n            return rendition.get('NAME') or stream_group_id\n\n        for line in m3u8_doc.splitlines():\n            if line.startswith('#EXT-X-STREAM-INF:'):\n                last_stream_inf = parse_m3u8_attributes(line)\n            elif line.startswith('#EXT-X-MEDIA:'):\n                extract_media(line)\n            elif line.startswith('#') or not line.strip():\n                continue\n            else:\n                tbr = float_or_none(\n                    last_stream_inf.get('AVERAGE-BANDWIDTH') or\n                    last_stream_inf.get('BANDWIDTH'), scale=1000)\n                format_id = []\n                if m3u8_id:\n                    format_id.append(m3u8_id)\n                stream_name = build_stream_name()\n                # Bandwidth of live streams may differ over time thus making\n                # format_id unpredictable. So it's better to keep provided\n                # format_id intact.\n                if not live:\n                    format_id.append(stream_name if stream_name else '%d' % (tbr if tbr else len(formats)))\n                manifest_url = format_url(line.strip())\n                f = {\n                    'format_id': '-'.join(format_id),\n                    'url': manifest_url,\n                    'manifest_url': m3u8_url,\n                    'tbr': tbr,\n                    'ext': ext,\n                    'fps': float_or_none(last_stream_inf.get('FRAME-RATE')),\n                    'protocol': entry_protocol,\n                    'preference': preference,\n                }\n                resolution = last_stream_inf.get('RESOLUTION')\n                if resolution:\n                    mobj = re.search(r'(?P<width>\\d+)[xX](?P<height>\\d+)', resolution)\n                    if mobj:\n                        f['width'] = int(mobj.group('width'))\n                        f['height'] = int(mobj.group('height'))\n                # Unified Streaming Platform\n                mobj = re.search(\n                    r'audio.*?(?:%3D|=)(\\d+)(?:-video.*?(?:%3D|=)(\\d+))?', f['url'])\n                if mobj:\n                    abr, vbr = mobj.groups()\n                    abr, vbr = float_or_none(abr, 1000), float_or_none(vbr, 1000)\n                    f.update({\n                        'vbr': vbr,\n                        'abr': abr,\n                    })\n                codecs = parse_codecs(last_stream_inf.get('CODECS'))\n                f.update(codecs)\n                audio_group_id = last_stream_inf.get('AUDIO')\n                # As per [1, 4.3.4.1.1] any EXT-X-STREAM-INF tag which\n                # references a rendition group MUST have a CODECS attribute.\n                # However, this is not always respected, for example, [2]\n                # contains EXT-X-STREAM-INF tag which references AUDIO\n                # rendition group but does not have CODECS and despite\n                # referencing audio group an audio group, it represents\n                # a complete (with audio and video) format. So, for such cases\n                # we will ignore references to rendition groups and treat them\n                # as complete formats.\n                if audio_group_id and codecs and f.get('vcodec') != 'none':\n                    audio_group = groups.get(audio_group_id)\n                    if audio_group and audio_group[0].get('URI'):\n                        # TODO: update acodec for audio only formats with\n                        # the same GROUP-ID\n                        f['acodec'] = 'none'\n                formats.append(f)\n                last_stream_inf = {}\n        return formats",
        "begin_line": 1337,
        "end_line": 1491,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._xpath_ns#1494",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._xpath_ns(path, namespace=None)",
        "snippet": "    def _xpath_ns(path, namespace=None):\n        if not namespace:\n            return path\n        out = []\n        for c in path.split('/'):\n            if not c or c == '.':\n                out.append(c)\n            else:\n                out.append('{%s}%s' % (namespace, c))\n        return '/'.join(out)",
        "begin_line": 1494,
        "end_line": 1503,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats#1505",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None, transform_source=None)",
        "snippet": "    def _extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None, transform_source=None):\n        smil = self._download_smil(smil_url, video_id, fatal=fatal, transform_source=transform_source)\n\n        if smil is False:\n            assert not fatal\n            return []\n\n        namespace = self._parse_smil_namespace(smil)\n\n        return self._parse_smil_formats(\n            smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)",
        "begin_line": 1505,
        "end_line": 1515,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_smil_info#1517",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_smil_info(self, smil_url, video_id, fatal=True, f4m_params=None)",
        "snippet": "    def _extract_smil_info(self, smil_url, video_id, fatal=True, f4m_params=None):\n        smil = self._download_smil(smil_url, video_id, fatal=fatal)\n        if smil is False:\n            return {}\n        return self._parse_smil(smil, smil_url, video_id, f4m_params=f4m_params)",
        "begin_line": 1517,
        "end_line": 1521,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_smil#1523",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_smil(self, smil_url, video_id, fatal=True, transform_source=None)",
        "snippet": "    def _download_smil(self, smil_url, video_id, fatal=True, transform_source=None):\n        return self._download_xml(\n            smil_url, video_id, 'Downloading SMIL file',\n            'Unable to download SMIL file', fatal=fatal, transform_source=transform_source)",
        "begin_line": 1523,
        "end_line": 1526,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil#1528",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil(self, smil, smil_url, video_id, f4m_params=None)",
        "snippet": "    def _parse_smil(self, smil, smil_url, video_id, f4m_params=None):\n        namespace = self._parse_smil_namespace(smil)\n\n        formats = self._parse_smil_formats(\n            smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)\n        subtitles = self._parse_smil_subtitles(smil, namespace=namespace)\n\n        video_id = os.path.splitext(url_basename(smil_url))[0]\n        title = None\n        description = None\n        upload_date = None\n        for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):\n            name = meta.attrib.get('name')\n            content = meta.attrib.get('content')\n            if not name or not content:\n                continue\n            if not title and name == 'title':\n                title = content\n            elif not description and name in ('description', 'abstract'):\n                description = content\n            elif not upload_date and name == 'date':\n                upload_date = unified_strdate(content)\n\n        thumbnails = [{\n            'id': image.get('type'),\n            'url': image.get('src'),\n            'width': int_or_none(image.get('width')),\n            'height': int_or_none(image.get('height')),\n        } for image in smil.findall(self._xpath_ns('.//image', namespace)) if image.get('src')]\n\n        return {\n            'id': video_id,\n            'title': title or video_id,\n            'description': description,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 1528,
        "end_line": 1566,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_namespace#1568",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_namespace(self, smil)",
        "snippet": "    def _parse_smil_namespace(self, smil):\n        return self._search_regex(\n            r'(?i)^{([^}]+)?}smil$', smil.tag, 'namespace', default=None)",
        "begin_line": 1568,
        "end_line": 1570,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_formats#1572",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None)",
        "snippet": "    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):\n        base = smil_url\n        for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):\n            b = meta.get('base') or meta.get('httpBase')\n            if b:\n                base = b\n                break\n\n        formats = []\n        rtmp_count = 0\n        http_count = 0\n        m3u8_count = 0\n\n        srcs = []\n        media = smil.findall(self._xpath_ns('.//video', namespace)) + smil.findall(self._xpath_ns('.//audio', namespace))\n        for medium in media:\n            src = medium.get('src')\n            if not src or src in srcs:\n                continue\n            srcs.append(src)\n\n            bitrate = float_or_none(medium.get('system-bitrate') or medium.get('systemBitrate'), 1000)\n            filesize = int_or_none(medium.get('size') or medium.get('fileSize'))\n            width = int_or_none(medium.get('width'))\n            height = int_or_none(medium.get('height'))\n            proto = medium.get('proto')\n            ext = medium.get('ext')\n            src_ext = determine_ext(src)\n            streamer = medium.get('streamer') or base\n\n            if proto == 'rtmp' or streamer.startswith('rtmp'):\n                rtmp_count += 1\n                formats.append({\n                    'url': streamer,\n                    'play_path': src,\n                    'ext': 'flv',\n                    'format_id': 'rtmp-%d' % (rtmp_count if bitrate is None else bitrate),\n                    'tbr': bitrate,\n                    'filesize': filesize,\n                    'width': width,\n                    'height': height,\n                })\n                if transform_rtmp_url:\n                    streamer, src = transform_rtmp_url(streamer, src)\n                    formats[-1].update({\n                        'url': streamer,\n                        'play_path': src,\n                    })\n                continue\n\n            src_url = src if src.startswith('http') else compat_urlparse.urljoin(base, src)\n            src_url = src_url.strip()\n\n            if proto == 'm3u8' or src_ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    src_url, video_id, ext or 'mp4', m3u8_id='hls', fatal=False)\n                if len(m3u8_formats) == 1:\n                    m3u8_count += 1\n                    m3u8_formats[0].update({\n                        'format_id': 'hls-%d' % (m3u8_count if bitrate is None else bitrate),\n                        'tbr': bitrate,\n                        'width': width,\n                        'height': height,\n                    })\n                formats.extend(m3u8_formats)\n                continue\n\n            if src_ext == 'f4m':\n                f4m_url = src_url\n                if not f4m_params:\n                    f4m_params = {\n                        'hdcore': '3.2.0',\n                        'plugin': 'flowplayer-3.2.0.1',\n                    }\n                f4m_url += '&' if '?' in f4m_url else '?'\n                f4m_url += compat_urllib_parse_urlencode(f4m_params)\n                formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))\n                continue\n\n            if src_url.startswith('http') and self._is_valid_url(src, video_id):\n                http_count += 1\n                formats.append({\n                    'url': src_url,\n                    'ext': ext or src_ext or 'flv',\n                    'format_id': 'http-%d' % (bitrate or http_count),\n                    'tbr': bitrate,\n                    'filesize': filesize,\n                    'width': width,\n                    'height': height,\n                })\n                continue\n\n        return formats",
        "begin_line": 1572,
        "end_line": 1664,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_smil_subtitles#1666",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en')",
        "snippet": "    def _parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en'):\n        urls = []\n        subtitles = {}\n        for num, textstream in enumerate(smil.findall(self._xpath_ns('.//textstream', namespace))):\n            src = textstream.get('src')\n            if not src or src in urls:\n                continue\n            urls.append(src)\n            ext = textstream.get('ext') or mimetype2ext(textstream.get('type')) or determine_ext(src)\n            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or textstream.get('lang') or subtitles_lang\n            subtitles.setdefault(lang, []).append({\n                'url': src,\n                'ext': ext,\n            })\n        return subtitles",
        "begin_line": 1666,
        "end_line": 1680,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_xspf_playlist#1682",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True)",
        "snippet": "    def _extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True):\n        xspf = self._download_xml(\n            playlist_url, playlist_id, 'Downloading xpsf playlist',\n            'Unable to download xspf manifest', fatal=fatal)\n        if xspf is False:\n            return []\n        return self._parse_xspf(xspf, playlist_id)",
        "begin_line": 1682,
        "end_line": 1688,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_xspf#1690",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_xspf(self, playlist, playlist_id)",
        "snippet": "    def _parse_xspf(self, playlist, playlist_id):\n        NS_MAP = {\n            'xspf': 'http://xspf.org/ns/0/',\n            's1': 'http://static.streamone.nl/player/ns/0',\n        }\n\n        entries = []\n        for track in playlist.findall(xpath_with_ns('./xspf:trackList/xspf:track', NS_MAP)):\n            title = xpath_text(\n                track, xpath_with_ns('./xspf:title', NS_MAP), 'title', default=playlist_id)\n            description = xpath_text(\n                track, xpath_with_ns('./xspf:annotation', NS_MAP), 'description')\n            thumbnail = xpath_text(\n                track, xpath_with_ns('./xspf:image', NS_MAP), 'thumbnail')\n            duration = float_or_none(\n                xpath_text(track, xpath_with_ns('./xspf:duration', NS_MAP), 'duration'), 1000)\n\n            formats = [{\n                'url': location.text,\n                'format_id': location.get(xpath_with_ns('s1:label', NS_MAP)),\n                'width': int_or_none(location.get(xpath_with_ns('s1:width', NS_MAP))),\n                'height': int_or_none(location.get(xpath_with_ns('s1:height', NS_MAP))),\n            } for location in track.findall(xpath_with_ns('./xspf:location', NS_MAP))]\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': playlist_id,\n                'title': title,\n                'description': description,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'formats': formats,\n            })\n        return entries",
        "begin_line": 1690,
        "end_line": 1723,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_mpd_formats#1725",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_mpd_formats(self, mpd_url, video_id, mpd_id=None, note=None, errnote=None, fatal=True, formats_dict={})",
        "snippet": "    def _extract_mpd_formats(self, mpd_url, video_id, mpd_id=None, note=None, errnote=None, fatal=True, formats_dict={}):\n        res = self._download_webpage_handle(\n            mpd_url, video_id,\n            note=note or 'Downloading MPD manifest',\n            errnote=errnote or 'Failed to download MPD manifest',\n            fatal=fatal)\n        if res is False:\n            return []\n        mpd, urlh = res\n        mpd_base_url = base_url(urlh.geturl())\n\n        return self._parse_mpd_formats(\n            compat_etree_fromstring(mpd.encode('utf-8')), mpd_id, mpd_base_url,\n            formats_dict=formats_dict, mpd_url=mpd_url)",
        "begin_line": 1725,
        "end_line": 1738,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_mpd_formats#1740",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}, mpd_url=None)",
        "snippet": "    def _parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}, mpd_url=None):\n        \"\"\"\n        Parse formats from MPD manifest.\n        References:\n         1. MPEG-DASH Standard, ISO/IEC 23009-1:2014(E),\n            http://standards.iso.org/ittf/PubliclyAvailableStandards/c065274_ISO_IEC_23009-1_2014.zip\n         2. https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP\n        \"\"\"\n        if mpd_doc.get('type') == 'dynamic':\n            return []\n\n        namespace = self._search_regex(r'(?i)^{([^}]+)?}MPD$', mpd_doc.tag, 'namespace', default=None)\n\n        def _add_ns(path):\n            return self._xpath_ns(path, namespace)\n\n        def is_drm_protected(element):\n            return element.find(_add_ns('ContentProtection')) is not None\n\n        def extract_multisegment_info(element, ms_parent_info):\n            ms_info = ms_parent_info.copy()\n\n            # As per [1, 5.3.9.2.2] SegmentList and SegmentTemplate share some\n            # common attributes and elements.  We will only extract relevant\n            # for us.\n            def extract_common(source):\n                segment_timeline = source.find(_add_ns('SegmentTimeline'))\n                if segment_timeline is not None:\n                    s_e = segment_timeline.findall(_add_ns('S'))\n                    if s_e:\n                        ms_info['total_number'] = 0\n                        ms_info['s'] = []\n                        for s in s_e:\n                            r = int(s.get('r', 0))\n                            ms_info['total_number'] += 1 + r\n                            ms_info['s'].append({\n                                't': int(s.get('t', 0)),\n                                # @d is mandatory (see [1, 5.3.9.6.2, Table 17, page 60])\n                                'd': int(s.attrib['d']),\n                                'r': r,\n                            })\n                start_number = source.get('startNumber')\n                if start_number:\n                    ms_info['start_number'] = int(start_number)\n                timescale = source.get('timescale')\n                if timescale:\n                    ms_info['timescale'] = int(timescale)\n                segment_duration = source.get('duration')\n                if segment_duration:\n                    ms_info['segment_duration'] = float(segment_duration)\n\n            def extract_Initialization(source):\n                initialization = source.find(_add_ns('Initialization'))\n                if initialization is not None:\n                    ms_info['initialization_url'] = initialization.attrib['sourceURL']\n\n            segment_list = element.find(_add_ns('SegmentList'))\n            if segment_list is not None:\n                extract_common(segment_list)\n                extract_Initialization(segment_list)\n                segment_urls_e = segment_list.findall(_add_ns('SegmentURL'))\n                if segment_urls_e:\n                    ms_info['segment_urls'] = [segment.attrib['media'] for segment in segment_urls_e]\n            else:\n                segment_template = element.find(_add_ns('SegmentTemplate'))\n                if segment_template is not None:\n                    extract_common(segment_template)\n                    media = segment_template.get('media')\n                    if media:\n                        ms_info['media'] = media\n                    initialization = segment_template.get('initialization')\n                    if initialization:\n                        ms_info['initialization'] = initialization\n                    else:\n                        extract_Initialization(segment_template)\n            return ms_info\n\n        mpd_duration = parse_duration(mpd_doc.get('mediaPresentationDuration'))\n        formats = []\n        for period in mpd_doc.findall(_add_ns('Period')):\n            period_duration = parse_duration(period.get('duration')) or mpd_duration\n            period_ms_info = extract_multisegment_info(period, {\n                'start_number': 1,\n                'timescale': 1,\n            })\n            for adaptation_set in period.findall(_add_ns('AdaptationSet')):\n                if is_drm_protected(adaptation_set):\n                    continue\n                adaption_set_ms_info = extract_multisegment_info(adaptation_set, period_ms_info)\n                for representation in adaptation_set.findall(_add_ns('Representation')):\n                    if is_drm_protected(representation):\n                        continue\n                    representation_attrib = adaptation_set.attrib.copy()\n                    representation_attrib.update(representation.attrib)\n                    # According to [1, 5.3.7.2, Table 9, page 41], @mimeType is mandatory\n                    mime_type = representation_attrib['mimeType']\n                    content_type = mime_type.split('/')[0]\n                    if content_type == 'text':\n                        # TODO implement WebVTT downloading\n                        pass\n                    elif content_type in ('video', 'audio'):\n                        base_url = ''\n                        for element in (representation, adaptation_set, period, mpd_doc):\n                            base_url_e = element.find(_add_ns('BaseURL'))\n                            if base_url_e is not None:\n                                base_url = base_url_e.text + base_url\n                                if re.match(r'^https?://', base_url):\n                                    break\n                        if mpd_base_url and not re.match(r'^https?://', base_url):\n                            if not mpd_base_url.endswith('/') and not base_url.startswith('/'):\n                                mpd_base_url += '/'\n                            base_url = mpd_base_url + base_url\n                        representation_id = representation_attrib.get('id')\n                        lang = representation_attrib.get('lang')\n                        url_el = representation.find(_add_ns('BaseURL'))\n                        filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength') if url_el is not None else None)\n                        bandwidth = int_or_none(representation_attrib.get('bandwidth'))\n                        f = {\n                            'format_id': '%s-%s' % (mpd_id, representation_id) if mpd_id else representation_id,\n                            'url': base_url,\n                            'manifest_url': mpd_url,\n                            'ext': mimetype2ext(mime_type),\n                            'width': int_or_none(representation_attrib.get('width')),\n                            'height': int_or_none(representation_attrib.get('height')),\n                            'tbr': float_or_none(bandwidth, 1000),\n                            'asr': int_or_none(representation_attrib.get('audioSamplingRate')),\n                            'fps': int_or_none(representation_attrib.get('frameRate')),\n                            'language': lang if lang not in ('mul', 'und', 'zxx', 'mis') else None,\n                            'format_note': 'DASH %s' % content_type,\n                            'filesize': filesize,\n                        }\n                        f.update(parse_codecs(representation_attrib.get('codecs')))\n                        representation_ms_info = extract_multisegment_info(representation, adaption_set_ms_info)\n\n                        def prepare_template(template_name, identifiers):\n                            t = representation_ms_info[template_name]\n                            t = t.replace('$RepresentationID$', representation_id)\n                            t = re.sub(r'\\$(%s)\\$' % '|'.join(identifiers), r'%(\\1)d', t)\n                            t = re.sub(r'\\$(%s)%%([^$]+)\\$' % '|'.join(identifiers), r'%(\\1)\\2', t)\n                            t.replace('$$', '$')\n                            return t\n\n                        # @initialization is a regular template like @media one\n                        # so it should be handled just the same way (see\n                        # https://github.com/rg3/youtube-dl/issues/11605)\n                        if 'initialization' in representation_ms_info:\n                            initialization_template = prepare_template(\n                                'initialization',\n                                # As per [1, 5.3.9.4.2, Table 15, page 54] $Number$ and\n                                # $Time$ shall not be included for @initialization thus\n                                # only $Bandwidth$ remains\n                                ('Bandwidth', ))\n                            representation_ms_info['initialization_url'] = initialization_template % {\n                                'Bandwidth': bandwidth,\n                            }\n\n                        def location_key(location):\n                            return 'url' if re.match(r'^https?://', location) else 'path'\n\n                        if 'segment_urls' not in representation_ms_info and 'media' in representation_ms_info:\n\n                            media_template = prepare_template('media', ('Number', 'Bandwidth', 'Time'))\n                            media_location_key = location_key(media_template)\n\n                            # As per [1, 5.3.9.4.4, Table 16, page 55] $Number$ and $Time$\n                            # can't be used at the same time\n                            if '%(Number' in media_template and 's' not in representation_ms_info:\n                                segment_duration = None\n                                if 'total_number' not in representation_ms_info and 'segment_duration':\n                                    segment_duration = float_or_none(representation_ms_info['segment_duration'], representation_ms_info['timescale'])\n                                    representation_ms_info['total_number'] = int(math.ceil(float(period_duration) / segment_duration))\n                                representation_ms_info['fragments'] = [{\n                                    media_location_key: media_template % {\n                                        'Number': segment_number,\n                                        'Bandwidth': bandwidth,\n                                    },\n                                    'duration': segment_duration,\n                                } for segment_number in range(\n                                    representation_ms_info['start_number'],\n                                    representation_ms_info['total_number'] + representation_ms_info['start_number'])]\n                            else:\n                                # $Number*$ or $Time$ in media template with S list available\n                                # Example $Number*$: http://www.svtplay.se/klipp/9023742/stopptid-om-bjorn-borg\n                                # Example $Time$: https://play.arkena.com/embed/avp/v2/player/media/b41dda37-d8e7-4d3f-b1b5-9a9db578bdfe/1/129411\n                                representation_ms_info['fragments'] = []\n                                segment_time = 0\n                                segment_d = None\n                                segment_number = representation_ms_info['start_number']\n\n                                def add_segment_url():\n                                    segment_url = media_template % {\n                                        'Time': segment_time,\n                                        'Bandwidth': bandwidth,\n                                        'Number': segment_number,\n                                    }\n                                    representation_ms_info['fragments'].append({\n                                        media_location_key: segment_url,\n                                        'duration': float_or_none(segment_d, representation_ms_info['timescale']),\n                                    })\n\n                                for num, s in enumerate(representation_ms_info['s']):\n                                    segment_time = s.get('t') or segment_time\n                                    segment_d = s['d']\n                                    add_segment_url()\n                                    segment_number += 1\n                                    for r in range(s.get('r', 0)):\n                                        segment_time += segment_d\n                                        add_segment_url()\n                                        segment_number += 1\n                                    segment_time += segment_d\n                        elif 'segment_urls' in representation_ms_info and 's' in representation_ms_info:\n                            # No media template\n                            # Example: https://www.youtube.com/watch?v=iXZV5uAYMJI\n                            # or any YouTube dashsegments video\n                            fragments = []\n                            segment_index = 0\n                            timescale = representation_ms_info['timescale']\n                            for s in representation_ms_info['s']:\n                                duration = float_or_none(s['d'], timescale)\n                                for r in range(s.get('r', 0) + 1):\n                                    segment_uri = representation_ms_info['segment_urls'][segment_index]\n                                    fragments.append({\n                                        location_key(segment_uri): segment_uri,\n                                        'duration': duration,\n                                    })\n                                    segment_index += 1\n                            representation_ms_info['fragments'] = fragments\n                        # NB: MPD manifest may contain direct URLs to unfragmented media.\n                        # No fragments key is present in this case.\n                        if 'fragments' in representation_ms_info:\n                            f.update({\n                                'fragment_base_url': base_url,\n                                'fragments': [],\n                                'protocol': 'http_dash_segments',\n                            })\n                            if 'initialization_url' in representation_ms_info:\n                                initialization_url = representation_ms_info['initialization_url']\n                                if not f.get('url'):\n                                    f['url'] = initialization_url\n                                f['fragments'].append({location_key(initialization_url): initialization_url})\n                            f['fragments'].extend(representation_ms_info['fragments'])\n                        try:\n                            existing_format = next(\n                                fo for fo in formats\n                                if fo['format_id'] == representation_id)\n                        except StopIteration:\n                            full_info = formats_dict.get(representation_id, {}).copy()\n                            full_info.update(f)\n                            formats.append(full_info)\n                        else:\n                            existing_format.update(f)\n                    else:\n                        self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)\n        return formats",
        "begin_line": 1740,
        "end_line": 1993,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_ism_formats#1995",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_ism_formats(self, ism_url, video_id, ism_id=None, note=None, errnote=None, fatal=True)",
        "snippet": "    def _extract_ism_formats(self, ism_url, video_id, ism_id=None, note=None, errnote=None, fatal=True):\n        res = self._download_webpage_handle(\n            ism_url, video_id,\n            note=note or 'Downloading ISM manifest',\n            errnote=errnote or 'Failed to download ISM manifest',\n            fatal=fatal)\n        if res is False:\n            return []\n        ism, urlh = res\n\n        return self._parse_ism_formats(\n            compat_etree_fromstring(ism.encode('utf-8')), urlh.geturl(), ism_id)",
        "begin_line": 1995,
        "end_line": 2006,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_ism_formats#2008",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_ism_formats(self, ism_doc, ism_url, ism_id=None)",
        "snippet": "    def _parse_ism_formats(self, ism_doc, ism_url, ism_id=None):\n        \"\"\"\n        Parse formats from ISM manifest.\n        References:\n         1. [MS-SSTR]: Smooth Streaming Protocol,\n            https://msdn.microsoft.com/en-us/library/ff469518.aspx\n        \"\"\"\n        if ism_doc.get('IsLive') == 'TRUE' or ism_doc.find('Protection') is not None:\n            return []\n\n        duration = int(ism_doc.attrib['Duration'])\n        timescale = int_or_none(ism_doc.get('TimeScale')) or 10000000\n\n        formats = []\n        for stream in ism_doc.findall('StreamIndex'):\n            stream_type = stream.get('Type')\n            if stream_type not in ('video', 'audio'):\n                continue\n            url_pattern = stream.attrib['Url']\n            stream_timescale = int_or_none(stream.get('TimeScale')) or timescale\n            stream_name = stream.get('Name')\n            for track in stream.findall('QualityLevel'):\n                fourcc = track.get('FourCC')\n                # TODO: add support for WVC1 and WMAP\n                if fourcc not in ('H264', 'AVC1', 'AACL'):\n                    self.report_warning('%s is not a supported codec' % fourcc)\n                    continue\n                tbr = int(track.attrib['Bitrate']) // 1000\n                # [1] does not mention Width and Height attributes. However,\n                # they're often present while MaxWidth and MaxHeight are\n                # missing, so should be used as fallbacks\n                width = int_or_none(track.get('MaxWidth') or track.get('Width'))\n                height = int_or_none(track.get('MaxHeight') or track.get('Height'))\n                sampling_rate = int_or_none(track.get('SamplingRate'))\n\n                track_url_pattern = re.sub(r'{[Bb]itrate}', track.attrib['Bitrate'], url_pattern)\n                track_url_pattern = compat_urlparse.urljoin(ism_url, track_url_pattern)\n\n                fragments = []\n                fragment_ctx = {\n                    'time': 0,\n                }\n                stream_fragments = stream.findall('c')\n                for stream_fragment_index, stream_fragment in enumerate(stream_fragments):\n                    fragment_ctx['time'] = int_or_none(stream_fragment.get('t')) or fragment_ctx['time']\n                    fragment_repeat = int_or_none(stream_fragment.get('r')) or 1\n                    fragment_ctx['duration'] = int_or_none(stream_fragment.get('d'))\n                    if not fragment_ctx['duration']:\n                        try:\n                            next_fragment_time = int(stream_fragment[stream_fragment_index + 1].attrib['t'])\n                        except IndexError:\n                            next_fragment_time = duration\n                        fragment_ctx['duration'] = (next_fragment_time - fragment_ctx['time']) / fragment_repeat\n                    for _ in range(fragment_repeat):\n                        fragments.append({\n                            'url': re.sub(r'{start[ _]time}', compat_str(fragment_ctx['time']), track_url_pattern),\n                            'duration': fragment_ctx['duration'] / stream_timescale,\n                        })\n                        fragment_ctx['time'] += fragment_ctx['duration']\n\n                format_id = []\n                if ism_id:\n                    format_id.append(ism_id)\n                if stream_name:\n                    format_id.append(stream_name)\n                format_id.append(compat_str(tbr))\n\n                formats.append({\n                    'format_id': '-'.join(format_id),\n                    'url': ism_url,\n                    'manifest_url': ism_url,\n                    'ext': 'ismv' if stream_type == 'video' else 'isma',\n                    'width': width,\n                    'height': height,\n                    'tbr': tbr,\n                    'asr': sampling_rate,\n                    'vcodec': 'none' if stream_type == 'audio' else fourcc,\n                    'acodec': 'none' if stream_type == 'video' else fourcc,\n                    'protocol': 'ism',\n                    'fragments': fragments,\n                    '_download_params': {\n                        'duration': duration,\n                        'timescale': stream_timescale,\n                        'width': width or 0,\n                        'height': height or 0,\n                        'fourcc': fourcc,\n                        'codec_private_data': track.get('CodecPrivateData'),\n                        'sampling_rate': sampling_rate,\n                        'channels': int_or_none(track.get('Channels', 2)),\n                        'bits_per_sample': int_or_none(track.get('BitsPerSample', 16)),\n                        'nal_unit_length_field': int_or_none(track.get('NALUnitLengthField', 4)),\n                    },\n                })\n        return formats",
        "begin_line": 2008,
        "end_line": 2101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_html5_media_entries#2103",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None, preference=None)",
        "snippet": "    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None, preference=None):\n        def absolute_url(video_url):\n            return compat_urlparse.urljoin(base_url, video_url)\n\n        def parse_content_type(content_type):\n            if not content_type:\n                return {}\n            ctr = re.search(r'(?P<mimetype>[^/]+/[^;]+)(?:;\\s*codecs=\"?(?P<codecs>[^\"]+))?', content_type)\n            if ctr:\n                mimetype, codecs = ctr.groups()\n                f = parse_codecs(codecs)\n                f['ext'] = mimetype2ext(mimetype)\n                return f\n            return {}\n\n        def _media_formats(src, cur_media_type, type_info={}):\n            full_url = absolute_url(src)\n            ext = type_info.get('ext') or determine_ext(full_url)\n            if ext == 'm3u8':\n                is_plain_url = False\n                formats = self._extract_m3u8_formats(\n                    full_url, video_id, ext='mp4',\n                    entry_protocol=m3u8_entry_protocol, m3u8_id=m3u8_id,\n                    preference=preference)\n            elif ext == 'mpd':\n                is_plain_url = False\n                formats = self._extract_mpd_formats(\n                    full_url, video_id, mpd_id=mpd_id)\n            else:\n                is_plain_url = True\n                formats = [{\n                    'url': full_url,\n                    'vcodec': 'none' if cur_media_type == 'audio' else None,\n                }]\n            return is_plain_url, formats\n\n        entries = []\n        # amp-video and amp-audio are very similar to their HTML5 counterparts\n        # so we wll include them right here (see\n        # https://www.ampproject.org/docs/reference/components/amp-video)\n        media_tags = [(media_tag, media_type, '')\n                      for media_tag, media_type\n                      in re.findall(r'(?s)(<(?:amp-)?(video|audio)[^>]*/>)', webpage)]\n        media_tags.extend(re.findall(\n            # We only allow video|audio followed by a whitespace or '>'.\n            # Allowing more characters may end up in significant slow down (see\n            # https://github.com/rg3/youtube-dl/issues/11979, example URL:\n            # http://www.porntrex.com/maps/videositemap.xml).\n            r'(?s)(<(?P<tag>(?:amp-)?(?:video|audio))(?:\\s+[^>]*)?>)(.*?)</(?P=tag)>', webpage))\n        for media_tag, media_type, media_content in media_tags:\n            media_info = {\n                'formats': [],\n                'subtitles': {},\n            }\n            media_attributes = extract_attributes(media_tag)\n            src = media_attributes.get('src')\n            if src:\n                _, formats = _media_formats(src, media_type)\n                media_info['formats'].extend(formats)\n            media_info['thumbnail'] = media_attributes.get('poster')\n            if media_content:\n                for source_tag in re.findall(r'<source[^>]+>', media_content):\n                    source_attributes = extract_attributes(source_tag)\n                    src = source_attributes.get('src')\n                    if not src:\n                        continue\n                    f = parse_content_type(source_attributes.get('type'))\n                    is_plain_url, formats = _media_formats(src, media_type, f)\n                    if is_plain_url:\n                        f.update(formats[0])\n                        media_info['formats'].append(f)\n                    else:\n                        media_info['formats'].extend(formats)\n                for track_tag in re.findall(r'<track[^>]+>', media_content):\n                    track_attributes = extract_attributes(track_tag)\n                    kind = track_attributes.get('kind')\n                    if not kind or kind in ('subtitles', 'captions'):\n                        src = track_attributes.get('src')\n                        if not src:\n                            continue\n                        lang = track_attributes.get('srclang') or track_attributes.get('lang') or track_attributes.get('label')\n                        media_info['subtitles'].setdefault(lang, []).append({\n                            'url': absolute_url(src),\n                        })\n            if media_info['formats'] or media_info['subtitles']:\n                entries.append(media_info)\n        return entries",
        "begin_line": 2103,
        "end_line": 2189,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_akamai_formats#2191",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_akamai_formats(self, manifest_url, video_id, hosts={})",
        "snippet": "    def _extract_akamai_formats(self, manifest_url, video_id, hosts={}):\n        formats = []\n        hdcore_sign = 'hdcore=3.7.0'\n        f4m_url = re.sub(r'(https?://[^/]+)/i/', r'\\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')\n        hds_host = hosts.get('hds')\n        if hds_host:\n            f4m_url = re.sub(r'(https?://)[^/]+', r'\\1' + hds_host, f4m_url)\n        if 'hdcore=' not in f4m_url:\n            f4m_url += ('&' if '?' in f4m_url else '?') + hdcore_sign\n        f4m_formats = self._extract_f4m_formats(\n            f4m_url, video_id, f4m_id='hds', fatal=False)\n        for entry in f4m_formats:\n            entry.update({'extra_param_to_segment_url': hdcore_sign})\n        formats.extend(f4m_formats)\n        m3u8_url = re.sub(r'(https?://[^/]+)/z/', r'\\1/i/', manifest_url).replace('/manifest.f4m', '/master.m3u8')\n        hls_host = hosts.get('hls')\n        if hls_host:\n            m3u8_url = re.sub(r'(https?://)[^/]+', r'\\1' + hls_host, m3u8_url)\n        formats.extend(self._extract_m3u8_formats(\n            m3u8_url, video_id, 'mp4', 'm3u8_native',\n            m3u8_id='hls', fatal=False))\n        return formats",
        "begin_line": 2191,
        "end_line": 2212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_wowza_formats#2214",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_wowza_formats(self, url, video_id, m3u8_entry_protocol='m3u8_native', skip_protocols=[])",
        "snippet": "    def _extract_wowza_formats(self, url, video_id, m3u8_entry_protocol='m3u8_native', skip_protocols=[]):\n        url = re.sub(r'/(?:manifest|playlist|jwplayer)\\.(?:m3u8|f4m|mpd|smil)', '', url)\n        url_base = self._search_regex(\n            r'(?:(?:https?|rtmp|rtsp):)?(//[^?]+)', url, 'format url')\n        http_base_url = '%s:%s' % ('http', url_base)\n        formats = []\n        if 'm3u8' not in skip_protocols:\n            formats.extend(self._extract_m3u8_formats(\n                http_base_url + '/playlist.m3u8', video_id, 'mp4',\n                m3u8_entry_protocol, m3u8_id='hls', fatal=False))\n        if 'f4m' not in skip_protocols:\n            formats.extend(self._extract_f4m_formats(\n                http_base_url + '/manifest.f4m',\n                video_id, f4m_id='hds', fatal=False))\n        if 'dash' not in skip_protocols:\n            formats.extend(self._extract_mpd_formats(\n                http_base_url + '/manifest.mpd',\n                video_id, mpd_id='dash', fatal=False))\n        if re.search(r'(?:/smil:|\\.smil)', url_base):\n            if 'smil' not in skip_protocols:\n                rtmp_formats = self._extract_smil_formats(\n                    http_base_url + '/jwplayer.smil',\n                    video_id, fatal=False)\n                for rtmp_format in rtmp_formats:\n                    rtsp_format = rtmp_format.copy()\n                    rtsp_format['url'] = '%s/%s' % (rtmp_format['url'], rtmp_format['play_path'])\n                    del rtsp_format['play_path']\n                    del rtsp_format['ext']\n                    rtsp_format.update({\n                        'url': rtsp_format['url'].replace('rtmp://', 'rtsp://'),\n                        'format_id': rtmp_format['format_id'].replace('rtmp', 'rtsp'),\n                        'protocol': 'rtsp',\n                    })\n                    formats.extend([rtmp_format, rtsp_format])\n        else:\n            for protocol in ('rtmp', 'rtsp'):\n                if protocol not in skip_protocols:\n                    formats.append({\n                        'url': '%s:%s' % (protocol, url_base),\n                        'format_id': protocol,\n                        'protocol': protocol,\n                    })\n        return formats",
        "begin_line": 2214,
        "end_line": 2256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._find_jwplayer_data#2258",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._find_jwplayer_data(self, webpage, video_id=None, transform_source=js_to_json)",
        "snippet": "    def _find_jwplayer_data(self, webpage, video_id=None, transform_source=js_to_json):\n        mobj = re.search(\n            r'(?s)jwplayer\\((?P<quote>[\\'\"])[^\\'\" ]+(?P=quote)\\)(?!</script>).*?\\.setup\\s*\\((?P<options>[^)]+)\\)',\n            webpage)\n        if mobj:\n            try:\n                jwplayer_data = self._parse_json(mobj.group('options'),\n                                                 video_id=video_id,\n                                                 transform_source=transform_source)\n            except ExtractorError:\n                pass\n            else:\n                if isinstance(jwplayer_data, dict):\n                    return jwplayer_data",
        "begin_line": 2258,
        "end_line": 2271,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_jwplayer_data#2273",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_jwplayer_data(self, webpage, video_id, *args, **kwargs)",
        "snippet": "    def _extract_jwplayer_data(self, webpage, video_id, *args, **kwargs):\n        jwplayer_data = self._find_jwplayer_data(\n            webpage, video_id, transform_source=js_to_json)\n        return self._parse_jwplayer_data(\n            jwplayer_data, video_id, *args, **kwargs)",
        "begin_line": 2273,
        "end_line": 2277,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_jwplayer_data#2279",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True, m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None)",
        "snippet": "    def _parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True,\n                             m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None):\n        # JWPlayer backward compatibility: flattened playlists\n        # https://github.com/jwplayer/jwplayer/blob/v7.4.3/src/js/api/config.js#L81-L96\n        if 'playlist' not in jwplayer_data:\n            jwplayer_data = {'playlist': [jwplayer_data]}\n\n        entries = []\n\n        # JWPlayer backward compatibility: single playlist item\n        # https://github.com/jwplayer/jwplayer/blob/v7.7.0/src/js/playlist/playlist.js#L10\n        if not isinstance(jwplayer_data['playlist'], list):\n            jwplayer_data['playlist'] = [jwplayer_data['playlist']]\n\n        for video_data in jwplayer_data['playlist']:\n            # JWPlayer backward compatibility: flattened sources\n            # https://github.com/jwplayer/jwplayer/blob/v7.4.3/src/js/playlist/item.js#L29-L35\n            if 'sources' not in video_data:\n                video_data['sources'] = [video_data]\n\n            this_video_id = video_id or video_data['mediaid']\n\n            formats = self._parse_jwplayer_formats(\n                video_data['sources'], video_id=this_video_id, m3u8_id=m3u8_id,\n                mpd_id=mpd_id, rtmp_params=rtmp_params, base_url=base_url)\n            self._sort_formats(formats)\n\n            subtitles = {}\n            tracks = video_data.get('tracks')\n            if tracks and isinstance(tracks, list):\n                for track in tracks:\n                    if not isinstance(track, dict):\n                        continue\n                    if track.get('kind') != 'captions':\n                        continue\n                    track_url = urljoin(base_url, track.get('file'))\n                    if not track_url:\n                        continue\n                    subtitles.setdefault(track.get('label') or 'en', []).append({\n                        'url': self._proto_relative_url(track_url)\n                    })\n\n            entries.append({\n                'id': this_video_id,\n                'title': video_data['title'] if require_title else video_data.get('title'),\n                'description': video_data.get('description'),\n                'thumbnail': self._proto_relative_url(video_data.get('image')),\n                'timestamp': int_or_none(video_data.get('pubdate')),\n                'duration': float_or_none(jwplayer_data.get('duration') or video_data.get('duration')),\n                'subtitles': subtitles,\n                'formats': formats,\n            })\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            return self.playlist_result(entries)",
        "begin_line": 2279,
        "end_line": 2334,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._parse_jwplayer_formats#2336",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._parse_jwplayer_formats(self, jwplayer_sources_data, video_id=None, m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None)",
        "snippet": "    def _parse_jwplayer_formats(self, jwplayer_sources_data, video_id=None,\n                                m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None):\n        urls = []\n        formats = []\n        for source in jwplayer_sources_data:\n            if not isinstance(source, dict):\n                continue\n            source_url = self._proto_relative_url(source.get('file'))\n            if not source_url:\n                continue\n            if base_url:\n                source_url = compat_urlparse.urljoin(base_url, source_url)\n            if source_url in urls:\n                continue\n            urls.append(source_url)\n            source_type = source.get('type') or ''\n            ext = mimetype2ext(source_type) or determine_ext(source_url)\n            if source_type == 'hls' or ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    source_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id=m3u8_id, fatal=False))\n            elif ext == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    source_url, video_id, mpd_id=mpd_id, fatal=False))\n            elif ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    source_url, video_id, fatal=False))\n            # https://github.com/jwplayer/jwplayer/blob/master/src/js/providers/default.js#L67\n            elif source_type.startswith('audio') or ext in (\n                    'oga', 'aac', 'mp3', 'mpeg', 'vorbis'):\n                formats.append({\n                    'url': source_url,\n                    'vcodec': 'none',\n                    'ext': ext,\n                })\n            else:\n                height = int_or_none(source.get('height'))\n                if height is None:\n                    # Often no height is provided but there is a label in\n                    # format like \"1080p\", \"720p SD\", or 1080.\n                    height = int_or_none(self._search_regex(\n                        r'^(\\d{3,4})[pP]?(?:\\b|$)', compat_str(source.get('label') or ''),\n                        'height', default=None))\n                a_format = {\n                    'url': source_url,\n                    'width': int_or_none(source.get('width')),\n                    'height': height,\n                    'tbr': int_or_none(source.get('bitrate')),\n                    'ext': ext,\n                }\n                if source_url.startswith('rtmp'):\n                    a_format['ext'] = 'flv'\n                    # See com/longtailvideo/jwplayer/media/RTMPMediaProvider.as\n                    # of jwplayer.flash.swf\n                    rtmp_url_parts = re.split(\n                        r'((?:mp4|mp3|flv):)', source_url, 1)\n                    if len(rtmp_url_parts) == 3:\n                        rtmp_url, prefix, play_path = rtmp_url_parts\n                        a_format.update({\n                            'url': rtmp_url,\n                            'play_path': prefix + play_path,\n                        })\n                    if rtmp_params:\n                        a_format.update(rtmp_params)\n                formats.append(a_format)\n        return formats",
        "begin_line": 2336,
        "end_line": 2401,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._live_title#2403",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._live_title(self, name)",
        "snippet": "    def _live_title(self, name):\n        \"\"\" Generate the title for a live video \"\"\"\n        now = datetime.datetime.now()\n        now_str = now.strftime('%Y-%m-%d %H:%M')\n        return name + ' ' + now_str",
        "begin_line": 2403,
        "end_line": 2407,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._int#2409",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._int(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _int(self, v, name, fatal=False, **kwargs):\n        res = int_or_none(v, **kwargs)\n        if 'get_attr' in kwargs:\n            print(getattr(v, kwargs['get_attr']))\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 2409,
        "end_line": 2419,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._float#2421",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._float(self, v, name, fatal=False, **kwargs)",
        "snippet": "    def _float(self, v, name, fatal=False, **kwargs):\n        res = float_or_none(v, **kwargs)\n        if res is None:\n            msg = 'Failed to extract %s: Could not parse value %r' % (name, v)\n            if fatal:\n                raise ExtractorError(msg)\n            else:\n                self._downloader.report_warning(msg)\n        return res",
        "begin_line": 2421,
        "end_line": 2429,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._set_cookie#2431",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._set_cookie(self, domain, name, value, expire_time=None)",
        "snippet": "    def _set_cookie(self, domain, name, value, expire_time=None):\n        cookie = compat_cookiejar.Cookie(\n            0, name, value, None, None, domain, None,\n            None, '/', True, False, expire_time, '', None, None, None)\n        self._downloader.cookiejar.set_cookie(cookie)",
        "begin_line": 2431,
        "end_line": 2435,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_cookies#2437",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_cookies(self, url)",
        "snippet": "    def _get_cookies(self, url):\n        \"\"\" Return a compat_cookies.SimpleCookie with the cookies for the url \"\"\"\n        req = sanitized_Request(url)\n        self._downloader.cookiejar.add_cookie_header(req)\n        return compat_cookies.SimpleCookie(req.get_header('Cookie'))",
        "begin_line": 2437,
        "end_line": 2441,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.get_testcases#2443",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.get_testcases(self, include_onlymatching=False)",
        "snippet": "    def get_testcases(self, include_onlymatching=False):\n        t = getattr(self, '_TEST', None)\n        if t:\n            assert not hasattr(self, '_TESTS'), \\\n                '%s has _TEST and _TESTS' % type(self).__name__\n            tests = [t]\n        else:\n            tests = getattr(self, '_TESTS', [])\n        for t in tests:\n            if not include_onlymatching and t.get('only_matching', False):\n                continue\n            t['name'] = type(self).__name__[:-len('IE')]\n            yield t",
        "begin_line": 2443,
        "end_line": 2455,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.is_suitable#2457",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.is_suitable(self, age_limit)",
        "snippet": "    def is_suitable(self, age_limit):\n        \"\"\" Test whether the extractor is generally suitable for the given\n        age limit (i.e. pornographic sites are not, all others usually are) \"\"\"\n\n        any_restricted = False\n        for tc in self.get_testcases(include_onlymatching=False):\n            if tc.get('playlist', []):\n                tc = tc['playlist'][0]\n            is_restricted = age_restricted(\n                tc.get('info_dict', {}).get('age_limit'), age_limit)\n            if not is_restricted:\n                return True\n            any_restricted = any_restricted or is_restricted\n        return not any_restricted",
        "begin_line": 2457,
        "end_line": 2470,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles#2472",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_subtitles(self, *args, **kwargs)",
        "snippet": "    def extract_subtitles(self, *args, **kwargs):\n        if (self._downloader.params.get('writesubtitles', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_subtitles(*args, **kwargs)\n        return {}",
        "begin_line": 2472,
        "end_line": 2476,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_subtitles#2478",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_subtitles(self, *args, **kwargs)",
        "snippet": "    def _get_subtitles(self, *args, **kwargs):\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 2478,
        "end_line": 2479,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._merge_subtitle_items#2482",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._merge_subtitle_items(subtitle_list1, subtitle_list2)",
        "snippet": "    def _merge_subtitle_items(subtitle_list1, subtitle_list2):\n        \"\"\" Merge subtitle items for one language. Items with duplicated URLs\n        will be dropped. \"\"\"\n        list1_urls = set([item['url'] for item in subtitle_list1])\n        ret = list(subtitle_list1)\n        ret.extend([item for item in subtitle_list2 if item['url'] not in list1_urls])\n        return ret",
        "begin_line": 2482,
        "end_line": 2488,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._merge_subtitles#2491",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._merge_subtitles(cls, subtitle_dict1, subtitle_dict2)",
        "snippet": "    def _merge_subtitles(cls, subtitle_dict1, subtitle_dict2):\n        \"\"\" Merge two subtitle dictionaries, language by language. \"\"\"\n        ret = dict(subtitle_dict1)\n        for lang in subtitle_dict2:\n            ret[lang] = cls._merge_subtitle_items(subtitle_dict1.get(lang, []), subtitle_dict2[lang])\n        return ret",
        "begin_line": 2491,
        "end_line": 2496,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions#2498",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def extract_automatic_captions(self, *args, **kwargs):\n        if (self._downloader.params.get('writeautomaticsub', False) or\n                self._downloader.params.get('listsubtitles')):\n            return self._get_automatic_captions(*args, **kwargs)\n        return {}",
        "begin_line": 2498,
        "end_line": 2502,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions#2504",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_automatic_captions(self, *args, **kwargs)",
        "snippet": "    def _get_automatic_captions(self, *args, **kwargs):\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 2504,
        "end_line": 2505,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.mark_watched#2507",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.mark_watched(self, *args, **kwargs)",
        "snippet": "    def mark_watched(self, *args, **kwargs):\n        if (self._downloader.params.get('mark_watched', False) and\n                (self._get_login_info()[0] is not None or\n                    self._downloader.params.get('cookiefile') is not None)):\n            self._mark_watched(*args, **kwargs)",
        "begin_line": 2507,
        "end_line": 2511,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._mark_watched#2513",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._mark_watched(self, *args, **kwargs)",
        "snippet": "    def _mark_watched(self, *args, **kwargs):\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 2513,
        "end_line": 2514,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.geo_verification_headers#2516",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.geo_verification_headers(self)",
        "snippet": "    def geo_verification_headers(self):\n        headers = {}\n        geo_verification_proxy = self._downloader.params.get('geo_verification_proxy')\n        if geo_verification_proxy:\n            headers['Ytdl-request-proxy'] = geo_verification_proxy\n        return headers",
        "begin_line": 2516,
        "end_line": 2521,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._generic_id#2523",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._generic_id(self, url)",
        "snippet": "    def _generic_id(self, url):\n        return compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])",
        "begin_line": 2523,
        "end_line": 2524,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._generic_title#2526",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._generic_title(self, url)",
        "snippet": "    def _generic_title(self, url):\n        return compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0])",
        "begin_line": 2526,
        "end_line": 2527,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url#2538",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url(cls)",
        "snippet": "    def _make_valid_url(cls):\n        return r'%s(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' % cls._SEARCH_KEY",
        "begin_line": 2538,
        "end_line": 2539,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.suitable#2542",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._make_valid_url(), url) is not None",
        "begin_line": 2542,
        "end_line": 2543,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract#2545",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract(self, query)",
        "snippet": "    def _real_extract(self, query):\n        mobj = re.match(self._make_valid_url(), query)\n        if mobj is None:\n            raise ExtractorError('Invalid search query \"%s\"' % query)\n\n        prefix = mobj.group('prefix')\n        query = mobj.group('query')\n        if prefix == '':\n            return self._get_n_results(query, 1)\n        elif prefix == 'all':\n            return self._get_n_results(query, self._MAX_RESULTS)\n        else:\n            n = int(prefix)\n            if n <= 0:\n                raise ExtractorError('invalid download number %s for query \"%s\"' % (n, query))\n            elif n > self._MAX_RESULTS:\n                self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))\n                n = self._MAX_RESULTS\n            return self._get_n_results(query, n)",
        "begin_line": 2545,
        "end_line": 2563,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results#2565",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        raise NotImplementedError('This method must be implemented by subclasses')",
        "begin_line": 2565,
        "end_line": 2567,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.SEARCH_KEY#2570",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.SEARCH_KEY(self)",
        "snippet": "    def SEARCH_KEY(self):\n        return self._SEARCH_KEY",
        "begin_line": 2570,
        "end_line": 2571,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.commonmistakes.CommonMistakesIE._real_extract#23",
        "src_path": "youtube_dl/extractor/commonmistakes.py",
        "class_name": "youtube_dl.extractor.commonmistakes.CommonMistakesIE",
        "signature": "youtube_dl.extractor.commonmistakes.CommonMistakesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        msg = (\n            'You\\'ve asked youtube-dl to download the URL \"%s\". '\n            'That doesn\\'t make any sense. '\n            'Simply remove the parameter in your command or configuration.'\n        ) % url\n        if not self._downloader.params.get('verbose'):\n            msg += ' Add -v to the command line to see what arguments and configuration youtube-dl got.'\n        raise ExtractorError(msg, expected=True)",
        "begin_line": 23,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE._real_extract#45",
        "src_path": "youtube_dl/extractor/commonmistakes.py",
        "class_name": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE",
        "signature": "youtube_dl.extractor.commonmistakes.UnicodeBOMIE._real_extract(self, url)",
        "snippet": "        def _real_extract(self, url):\n            real_url = self._match_id(url)\n            self.report_warning(\n                'Your URL starts with a Byte Order Mark (BOM). '\n                'Removing the BOM and looking for \"%s\" ...' % real_url)\n            return self.url_result(real_url)",
        "begin_line": 45,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.commonprotocols.RtmpIE._real_extract#21",
        "src_path": "youtube_dl/extractor/commonprotocols.py",
        "class_name": "youtube_dl.extractor.commonprotocols.RtmpIE",
        "signature": "youtube_dl.extractor.commonprotocols.RtmpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._generic_id(url)\n        title = self._generic_title(url)\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': [{\n                'url': url,\n                'ext': 'flv',\n                'format_id': compat_urlparse.urlparse(url).scheme,\n            }],\n        }",
        "begin_line": 21,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.commonprotocols.MmsIE._real_extract#52",
        "src_path": "youtube_dl/extractor/commonprotocols.py",
        "class_name": "youtube_dl.extractor.commonprotocols.MmsIE",
        "signature": "youtube_dl.extractor.commonprotocols.MmsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._generic_id(url)\n        title = self._generic_title(url)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': url,\n        }",
        "begin_line": 52,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_series#106",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_series(self, url, webpage)",
        "snippet": "    def _extract_series(self, url, webpage):\n        title = self._html_search_regex(\n            r'(?s)<div class=\"cne-series-info\">.*?<h1>(.+?)</h1>',\n            webpage, 'series title')\n        url_object = compat_urllib_parse_urlparse(url)\n        base_url = '%s://%s' % (url_object.scheme, url_object.netloc)\n        m_paths = re.finditer(\n            r'(?s)<p class=\"cne-thumb-title\">.*?<a href=\"(/watch/.+?)[\"\\?]', webpage)\n        paths = orderedSet(m.group(1) for m in m_paths)\n        build_url = lambda path: compat_urlparse.urljoin(base_url, path)\n        entries = [self.url_result(build_url(path), 'CondeNast') for path in paths]\n        return self.playlist_result(entries, playlist_title=title)",
        "begin_line": 106,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_video_params#119",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_video_params(self, webpage)",
        "snippet": "    def _extract_video_params(self, webpage):\n        query = {}\n        params = self._search_regex(\n            r'(?s)var params = {(.+?)}[;,]', webpage, 'player params', default=None)\n        if params:\n            query.update({\n                'videoId': self._search_regex(r'videoId: [\\'\"](.+?)[\\'\"]', params, 'video id'),\n                'playerId': self._search_regex(r'playerId: [\\'\"](.+?)[\\'\"]', params, 'player id'),\n                'target': self._search_regex(r'target: [\\'\"](.+?)[\\'\"]', params, 'target'),\n            })\n        else:\n            params = extract_attributes(self._search_regex(\n                r'(<[^>]+data-js=\"video-player\"[^>]+>)',\n                webpage, 'player params element'))\n            query.update({\n                'videoId': params['data-video'],\n                'playerId': params['data-player'],\n                'target': params['id'],\n            })\n        return query",
        "begin_line": 119,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_video#140",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_video(self, params)",
        "snippet": "    def _extract_video(self, params):\n        video_id = params['videoId']\n\n        video_info = None\n        if params.get('playerId'):\n            info_page = self._download_json(\n                'http://player.cnevids.com/player/video.js',\n                video_id, 'Downloading video info', fatal=False, query=params)\n            if info_page:\n                video_info = info_page.get('video')\n            if not video_info:\n                info_page = self._download_webpage(\n                    'http://player.cnevids.com/player/loader.js',\n                    video_id, 'Downloading loader info', query=params)\n        else:\n            info_page = self._download_webpage(\n                'https://player.cnevids.com/inline/video/%s.js' % video_id,\n                video_id, 'Downloading inline info', query={\n                    'target': params.get('target', 'embedplayer')\n                })\n\n        if not video_info:\n            video_info = self._parse_json(\n                self._search_regex(\n                    r'(?s)var\\s+config\\s*=\\s*({.+?});', info_page, 'config'),\n                video_id, transform_source=js_to_json)['video']\n\n        title = video_info['title']\n\n        formats = []\n        for fdata in video_info['sources']:\n            src = fdata.get('src')\n            if not src:\n                continue\n            ext = mimetype2ext(fdata.get('type')) or determine_ext(src)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n                continue\n            quality = fdata.get('quality')\n            formats.append({\n                'format_id': ext + ('-%s' % quality if quality else ''),\n                'url': src,\n                'ext': ext,\n                'quality': 1 if quality == 'high' else 0,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'thumbnail': video_info.get('poster_frame'),\n            'uploader': video_info.get('brand'),\n            'duration': int_or_none(video_info.get('duration')),\n            'tags': video_info.get('tags'),\n            'series': video_info.get('series_title'),\n            'season': video_info.get('season_title'),\n            'timestamp': parse_iso8601(video_info.get('premiere_date')),\n            'categories': video_info.get('categories'),\n        }",
        "begin_line": 140,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._real_extract#203",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, player_id, target, url_type, display_id = re.match(self._VALID_URL, url).groups()\n\n        if video_id:\n            return self._extract_video({\n                'videoId': video_id,\n                'playerId': player_id,\n                'target': target,\n            })\n\n        webpage = self._download_webpage(url, display_id)\n\n        if url_type == 'series':\n            return self._extract_series(url, webpage)\n        else:\n            params = self._extract_video_params(webpage)\n            info = self._search_json_ld(\n                webpage, display_id, fatal=False)\n            info.update(self._extract_video(params))\n            return info",
        "begin_line": 203,
        "end_line": 222,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.corus.CorusIE._real_extract#78",
        "src_path": "youtube_dl/extractor/corus.py",
        "class_name": "youtube_dl.extractor.corus.CorusIE",
        "signature": "youtube_dl.extractor.corus.CorusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, video_id = re.match(self._VALID_URL, url).groups()\n        feed_info = self._TP_FEEDS[domain.split('.')[0]]\n        return self._extract_feed_info('dtjsEC', feed_info['feed_id'], 'byId=' + video_id, video_id, lambda e: {\n            'episode_number': int_or_none(e.get('pl1$episode')),\n            'season_number': int_or_none(e.get('pl1$season')),\n            'series': e.get('pl1$show'),\n        }, {\n            'HLS': {\n                'manifest': 'm3u',\n            },\n            'DesktopHLS Default': {\n                'manifest': 'm3u',\n            },\n            'MP4 MBR': {\n                'manifest': 'm3u',\n            },\n        }, feed_info['account_id'])",
        "begin_line": 78,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.coub.CoubIE._real_extract#46",
        "src_path": "youtube_dl/extractor/coub.py",
        "class_name": "youtube_dl.extractor.coub.CoubIE",
        "signature": "youtube_dl.extractor.coub.CoubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        coub = self._download_json(\n            'http://coub.com/api/v2/coubs/%s.json' % video_id, video_id)\n\n        if coub.get('error'):\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, coub['error']), expected=True)\n\n        title = coub['title']\n\n        file_versions = coub['file_versions']\n\n        QUALITIES = ('low', 'med', 'high')\n\n        MOBILE = 'mobile'\n        IPHONE = 'iphone'\n        HTML5 = 'html5'\n\n        SOURCE_PREFERENCE = (MOBILE, IPHONE, HTML5)\n\n        quality_key = qualities(QUALITIES)\n        preference_key = qualities(SOURCE_PREFERENCE)\n\n        formats = []\n\n        for kind, items in file_versions.get(HTML5, {}).items():\n            if kind not in ('video', 'audio'):\n                continue\n            if not isinstance(items, dict):\n                continue\n            for quality, item in items.items():\n                if not isinstance(item, dict):\n                    continue\n                item_url = item.get('url')\n                if not item_url:\n                    continue\n                formats.append({\n                    'url': item_url,\n                    'format_id': '%s-%s-%s' % (HTML5, kind, quality),\n                    'filesize': int_or_none(item.get('size')),\n                    'vcodec': 'none' if kind == 'audio' else None,\n                    'quality': quality_key(quality),\n                    'preference': preference_key(HTML5),\n                })\n\n        iphone_url = file_versions.get(IPHONE, {}).get('url')\n        if iphone_url:\n            formats.append({\n                'url': iphone_url,\n                'format_id': IPHONE,\n                'preference': preference_key(IPHONE),\n            })\n\n        mobile_url = file_versions.get(MOBILE, {}).get('audio_url')\n        if mobile_url:\n            formats.append({\n                'url': mobile_url,\n                'format_id': '%s-audio' % MOBILE,\n                'preference': preference_key(MOBILE),\n            })\n\n        self._sort_formats(formats)\n\n        thumbnail = coub.get('picture')\n        duration = float_or_none(coub.get('duration'))\n        timestamp = parse_iso8601(coub.get('published_at') or coub.get('created_at'))\n        uploader = coub.get('channel', {}).get('title')\n        uploader_id = coub.get('channel', {}).get('permalink')\n\n        view_count = int_or_none(coub.get('views_count') or coub.get('views_increase_count'))\n        like_count = int_or_none(coub.get('likes_count'))\n        repost_count = int_or_none(coub.get('recoubs_count'))\n\n        age_restricted = coub.get('age_restricted', coub.get('age_restricted_by_admin'))\n        if age_restricted is not None:\n            age_limit = 18 if age_restricted is True else 0\n        else:\n            age_limit = None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'repost_count': repost_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cracked.CrackedIE._real_extract#39",
        "src_path": "youtube_dl/extractor/cracked.py",
        "class_name": "youtube_dl.extractor.cracked.CrackedIE",
        "signature": "youtube_dl.extractor.cracked.CrackedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        youtube_url = self._search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//www\\.youtube\\.com/embed/[^\"]+)\"',\n            webpage, 'youtube url', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube')\n\n        video_url = self._html_search_regex(\n            [r'var\\s+CK_vidSrc\\s*=\\s*\"([^\"]+)\"', r'<video\\s+src=\"([^\"]+)\"'],\n            webpage, 'video URL')\n\n        title = self._search_regex(\n            [r'property=\"?og:title\"?\\s+content=\"([^\"]+)\"', r'class=\"?title\"?>([^<]+)'],\n            webpage, 'title')\n\n        description = self._search_regex(\n            r'name=\"?(?:og:)?description\"?\\s+content=\"([^\"]+)\"',\n            webpage, 'description', default=None)\n\n        timestamp = self._html_search_regex(\n            r'\"date\"\\s*:\\s*\"([^\"]+)\"', webpage, 'upload date', fatal=False)\n        if timestamp:\n            timestamp = parse_iso8601(timestamp[:-6])\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<span\\s+class=\"?views\"? id=\"?viewCounts\"?>([\\d,\\.]+) Views</span>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span\\s+id=\"?commentCounts\"?>([\\d,\\.]+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        m = re.search(r'_(?P<width>\\d+)X(?P<height>\\d+)\\.mp4$', video_url)\n        if m:\n            width = int(m.group('width'))\n            height = int(m.group('height'))\n        else:\n            width = height = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'height': height,\n            'width': width,\n        }",
        "begin_line": 39,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crackle.CrackleIE._real_extract#81",
        "src_path": "youtube_dl/extractor/crackle.py",
        "class_name": "youtube_dl.extractor.crackle.CrackleIE",
        "signature": "youtube_dl.extractor.crackle.CrackleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config_doc = self._download_xml(\n            'http://legacyweb-us.crackle.com/flash/QueryReferrer.ashx?site=16',\n            video_id, 'Downloading config')\n\n        item = self._download_xml(\n            'http://legacyweb-us.crackle.com/app/revamp/vidwallcache.aspx?flags=-1&fm=%s' % video_id,\n            video_id, headers=self.geo_verification_headers()).find('i')\n        title = item.attrib['t']\n\n        subtitles = {}\n        formats = self._extract_m3u8_formats(\n            'http://content.uplynk.com/ext/%s/%s.m3u8' % (config_doc.attrib['strUplynkOwnerId'], video_id),\n            video_id, 'mp4', m3u8_id='hls', fatal=None)\n        thumbnails = []\n        path = item.attrib.get('p')\n        if path:\n            for width, height in self._THUMBNAIL_RES:\n                res = '%dx%d' % (width, height)\n                thumbnails.append({\n                    'id': res,\n                    'url': 'http://images-us-am.crackle.com/%stnl_%s.jpg' % (path, res),\n                    'width': width,\n                    'height': height,\n                    'resolution': res,\n                })\n            http_base_url = 'http://ahttp.crackle.com/' + path\n            for mfs_path, mfs_info in self._MEDIA_FILE_SLOTS.items():\n                formats.append({\n                    'url': http_base_url + mfs_path,\n                    'format_id': 'http-' + mfs_path.split('.')[0],\n                    'width': mfs_info['width'],\n                    'height': mfs_info['height'],\n                })\n            for cc in item.findall('cc'):\n                locale = cc.attrib.get('l')\n                v = cc.attrib.get('v')\n                if locale and v:\n                    if locale not in subtitles:\n                        subtitles[locale] = []\n                    for url_ext, ext in (('vtt', 'vtt'), ('xml', 'tt')):\n                        subtitles.setdefault(locale, []).append({\n                            'url': '%s/%s%s_%s.%s' % (config_doc.attrib['strSubtitleServer'], path, locale, v, url_ext),\n                            'ext': ext,\n                        })\n        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': item.attrib.get('d'),\n            'duration': int(item.attrib.get('r'), 16) / 1000 if item.attrib.get('r') else None,\n            'series': item.attrib.get('sn'),\n            'season_number': int_or_none(item.attrib.get('se')),\n            'episode_number': int_or_none(item.attrib.get('ep')),\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 81,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.criterion.CriterionIE._real_extract#21",
        "src_path": "youtube_dl/extractor/criterion.py",
        "class_name": "youtube_dl.extractor.criterion.CriterionIE",
        "signature": "youtube_dl.extractor.criterion.CriterionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        final_url = self._search_regex(\n            r'so\\.addVariable\\(\"videoURL\", \"(.+?)\"\\)\\;', webpage, 'video url')\n        title = self._og_search_title(webpage)\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._search_regex(\n            r'so\\.addVariable\\(\"thumbnailURL\", \"(.+?)\"\\)\\;',\n            webpage, 'thumbnail url')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE._real_extract#30",
        "src_path": "youtube_dl/extractor/crooksandliars.py",
        "class_name": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE",
        "signature": "youtube_dl.extractor.crooksandliars.CrooksAndLiarsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://embed.crooksandliars.com/embed/%s' % video_id, video_id)\n\n        manifest = self._parse_json(\n            self._search_regex(\n                r'var\\s+manifest\\s*=\\s*({.+?})\\n', webpage, 'manifest JSON'),\n            video_id)\n\n        quality = qualities(('webm_low', 'mp4_low', 'webm_high', 'mp4_high'))\n\n        formats = [{\n            'url': item['url'],\n            'format_id': item['type'],\n            'quality': quality(item['type']),\n        } for item in manifest['flavors'] if item['mime'].startswith('video/')]\n        self._sort_formats(formats)\n\n        return {\n            'url': url,\n            'id': video_id,\n            'title': manifest['title'],\n            'description': manifest.get('description'),\n            'thumbnail': self._proto_relative_url(manifest.get('poster')),\n            'timestamp': int_or_none(manifest.get('created')),\n            'uploader': manifest.get('author'),\n            'duration': int_or_none(manifest.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._login#41",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        def is_logged(webpage):\n            return '<title>Redirecting' in webpage\n\n        # Already logged in\n        if is_logged(login_page):\n            return\n\n        login_form_str = self._search_regex(\n            r'(?P<form><form[^>]+?id=([\"\\'])%s\\2[^>]*>)' % self._LOGIN_FORM,\n            login_page, 'login form', group='form')\n\n        post_url = extract_attributes(login_form_str).get('action')\n        if not post_url:\n            post_url = self._LOGIN_URL\n        elif not post_url.startswith('http'):\n            post_url = compat_urlparse.urljoin(self._LOGIN_URL, post_url)\n\n        login_form = self._form_hidden_inputs(self._LOGIN_FORM, login_page)\n\n        login_form.update({\n            'login_form[name]': username,\n            'login_form[password]': password,\n        })\n\n        response = self._download_webpage(\n            post_url, None, 'Logging in', 'Wrong login info',\n            data=urlencode_postdata(login_form),\n            headers={'Content-Type': 'application/x-www-form-urlencoded'})\n\n        # Successful login\n        if is_logged(response):\n            return\n\n        error = self._html_search_regex(\n            '(?s)<ul[^>]+class=[\"\\']messages[\"\\'][^>]*>(.+?)</ul>',\n            response, 'error message', default=None)\n        if error:\n            raise ExtractorError('Unable to login: %s' % error, expected=True)\n\n        raise ExtractorError('Unable to log in')",
        "begin_line": 41,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._real_initialize#90",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 90,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._download_webpage#93",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._download_webpage(self, url_or_request, *args, **kwargs)",
        "snippet": "    def _download_webpage(self, url_or_request, *args, **kwargs):\n        request = (url_or_request if isinstance(url_or_request, compat_urllib_request.Request)\n                   else sanitized_Request(url_or_request))\n        # Accept-Language must be set explicitly to accept any language to avoid issues\n        # similar to https://github.com/rg3/youtube-dl/issues/6797.\n        # Along with IP address Crunchyroll uses Accept-Language to guess whether georestriction\n        # should be imposed or not (from what I can see it just takes the first language\n        # ignoring the priority and requires it to correspond the IP). By the way this causes\n        # Crunchyroll to not work in georestriction cases in some browsers that don't place\n        # the locale lang first in header. However allowing any language seems to workaround the issue.\n        request.add_header('Accept-Language', '*')\n        return super(CrunchyrollBaseIE, self)._download_webpage(request, *args, **kwargs)",
        "begin_line": 93,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._add_skip_wall#107",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollBaseIE._add_skip_wall(url)",
        "snippet": "    def _add_skip_wall(url):\n        parsed_url = compat_urlparse.urlparse(url)\n        qs = compat_urlparse.parse_qs(parsed_url.query)\n        # Always force skip_wall to bypass maturity wall, namely 18+ confirmation message:\n        # > This content may be inappropriate for some people.\n        # > Are you sure you want to continue?\n        # since it's not disabled by default in crunchyroll account's settings.\n        # See https://github.com/rg3/youtube-dl/issues/7202.\n        qs['skip_wall'] = ['1']\n        return compat_urlparse.urlunparse(\n            parsed_url._replace(query=compat_urllib_parse_urlencode(qs, True)))",
        "begin_line": 107,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles#252",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles(self, data, iv, id)",
        "snippet": "    def _decrypt_subtitles(self, data, iv, id):\n        data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))\n        iv = bytes_to_intlist(base64.b64decode(iv.encode('utf-8')))\n        id = int(id)\n\n        def obfuscate_key_aux(count, modulo, start):\n            output = list(start)\n            for _ in range(count):\n                output.append(output[-1] + output[-2])\n            # cut off start values\n            output = output[2:]\n            output = list(map(lambda x: x % modulo + 33, output))\n            return output\n\n        def obfuscate_key(key):\n            num1 = int(floor(pow(2, 25) * sqrt(6.9)))\n            num2 = (num1 ^ key) << 5\n            num3 = key ^ num1\n            num4 = num3 ^ (num3 >> 3) ^ num2\n            prefix = intlist_to_bytes(obfuscate_key_aux(20, 97, (1, 2)))\n            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode('ascii')).digest())\n            # Extend 160 Bit hash to 256 Bit\n            return shaHash + [0] * 12\n\n        key = obfuscate_key(id)\n\n        decrypted_data = intlist_to_bytes(aes_cbc_decrypt(data, key, iv))\n        return zlib.decompress(decrypted_data)",
        "begin_line": 252,
        "end_line": 279,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt#281",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt(self, sub_root)",
        "snippet": "    def _convert_subtitles_to_srt(self, sub_root):\n        output = ''\n\n        for i, event in enumerate(sub_root.findall('./events/event'), 1):\n            start = event.attrib['start'].replace('.', ',')\n            end = event.attrib['end'].replace('.', ',')\n            text = event.attrib['text'].replace('\\\\N', '\\n')\n            output += '%d\\n%s --> %s\\n%s\\n\\n' % (i, start, end, text)\n        return output",
        "begin_line": 281,
        "end_line": 289,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass#291",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass(self, sub_root)",
        "snippet": "    def _convert_subtitles_to_ass(self, sub_root):\n        output = ''\n\n        def ass_bool(strvalue):\n            assvalue = '0'\n            if strvalue == '1':\n                assvalue = '-1'\n            return assvalue\n\n        output = '[Script Info]\\n'\n        output += 'Title: %s\\n' % sub_root.attrib['title']\n        output += 'ScriptType: v4.00+\\n'\n        output += 'WrapStyle: %s\\n' % sub_root.attrib['wrap_style']\n        output += 'PlayResX: %s\\n' % sub_root.attrib['play_res_x']\n        output += 'PlayResY: %s\\n' % sub_root.attrib['play_res_y']\n        output += \"\"\"\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n\"\"\"\n        for style in sub_root.findall('./styles/style'):\n            output += 'Style: ' + style.attrib['name']\n            output += ',' + style.attrib['font_name']\n            output += ',' + style.attrib['font_size']\n            output += ',' + style.attrib['primary_colour']\n            output += ',' + style.attrib['secondary_colour']\n            output += ',' + style.attrib['outline_colour']\n            output += ',' + style.attrib['back_colour']\n            output += ',' + ass_bool(style.attrib['bold'])\n            output += ',' + ass_bool(style.attrib['italic'])\n            output += ',' + ass_bool(style.attrib['underline'])\n            output += ',' + ass_bool(style.attrib['strikeout'])\n            output += ',' + style.attrib['scale_x']\n            output += ',' + style.attrib['scale_y']\n            output += ',' + style.attrib['spacing']\n            output += ',' + style.attrib['angle']\n            output += ',' + style.attrib['border_style']\n            output += ',' + style.attrib['outline']\n            output += ',' + style.attrib['shadow']\n            output += ',' + style.attrib['alignment']\n            output += ',' + style.attrib['margin_l']\n            output += ',' + style.attrib['margin_r']\n            output += ',' + style.attrib['margin_v']\n            output += ',' + style.attrib['encoding']\n            output += '\\n'\n\n        output += \"\"\"\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\"\n        for event in sub_root.findall('./events/event'):\n            output += 'Dialogue: 0'\n            output += ',' + event.attrib['start']\n            output += ',' + event.attrib['end']\n            output += ',' + event.attrib['style']\n            output += ',' + event.attrib['name']\n            output += ',' + event.attrib['margin_l']\n            output += ',' + event.attrib['margin_r']\n            output += ',' + event.attrib['margin_v']\n            output += ',' + event.attrib['effect']\n            output += ',' + event.attrib['text']\n            output += '\\n'\n\n        return output",
        "begin_line": 291,
        "end_line": 353,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._extract_subtitles#355",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._extract_subtitles(self, subtitle)",
        "snippet": "    def _extract_subtitles(self, subtitle):\n        sub_root = compat_etree_fromstring(subtitle)\n        return [{\n            'ext': 'srt',\n            'data': self._convert_subtitles_to_srt(sub_root),\n        }, {\n            'ext': 'ass',\n            'data': self._convert_subtitles_to_ass(sub_root),\n        }]",
        "begin_line": 355,
        "end_line": 363,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._get_subtitles#365",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        subtitles = {}\n        for sub_id, sub_name in re.findall(r'\\bssid=([0-9]+)\"[^>]+?\\btitle=\"([^\"]+)', webpage):\n            sub_page = self._download_webpage(\n                'http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id=' + sub_id,\n                video_id, note='Downloading subtitles for ' + sub_name)\n            id = self._search_regex(r'id=\\'([0-9]+)', sub_page, 'subtitle_id', fatal=False)\n            iv = self._search_regex(r'<iv>([^<]+)', sub_page, 'subtitle_iv', fatal=False)\n            data = self._search_regex(r'<data>([^<]+)', sub_page, 'subtitle_data', fatal=False)\n            if not id or not iv or not data:\n                continue\n            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')\n            lang_code = self._search_regex(r'lang_code=[\"\\']([^\"\\']+)', subtitle, 'subtitle_lang_code', fatal=False)\n            if not lang_code:\n                continue\n            subtitles[lang_code] = self._extract_subtitles(subtitle)\n        return subtitles",
        "begin_line": 365,
        "end_line": 381,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract#383",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        if mobj.group('prefix') == 'm':\n            mobile_webpage = self._download_webpage(url, video_id, 'Downloading mobile webpage')\n            webpage_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)\" />', mobile_webpage, 'webpage_url')\n        else:\n            webpage_url = 'http://www.' + mobj.group('url')\n\n        webpage = self._download_webpage(\n            self._add_skip_wall(webpage_url), video_id,\n            headers=self.geo_verification_headers())\n        note_m = self._html_search_regex(\n            r'<div class=\"showmedia-trailer-notice\">(.+?)</div>',\n            webpage, 'trailer-notice', default='')\n        if note_m:\n            raise ExtractorError(note_m)\n\n        mobj = re.search(r'Page\\.messaging_box_controller\\.addItems\\(\\[(?P<msg>{.+?})\\]\\)', webpage)\n        if mobj:\n            msg = json.loads(mobj.group('msg'))\n            if msg.get('type') == 'error':\n                raise ExtractorError('crunchyroll returned error: %s' % msg['message_body'], expected=True)\n\n        if 'To view this, please log in to verify you are 18 or older.' in webpage:\n            self.raise_login_required()\n\n        video_title = self._html_search_regex(\n            r'(?s)<h1[^>]*>((?:(?!<h1).)*?<span[^>]+itemprop=[\"\\']title[\"\\'][^>]*>(?:(?!<h1).)+?)</h1>',\n            webpage, 'video_title')\n        video_title = re.sub(r' {2,}', ' ', video_title)\n        video_description = self._parse_json(self._html_search_regex(\n            r'<script[^>]*>\\s*.+?\\[media_id=%s\\].+?({.+?\"description\"\\s*:.+?})\\);' % video_id,\n            webpage, 'description', default='{}'), video_id).get('description')\n        if video_description:\n            video_description = lowercase_escape(video_description.replace(r'\\r\\n', '\\n'))\n        video_upload_date = self._html_search_regex(\n            [r'<div>Availability for free users:(.+?)</div>', r'<div>[^<>]+<span>\\s*(.+?\\d{4})\\s*</span></div>'],\n            webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)\n        if video_upload_date:\n            video_upload_date = unified_strdate(video_upload_date)\n        video_uploader = self._html_search_regex(\n            # try looking for both an uploader that's a link and one that's not\n            [r'<a[^>]+href=\"/publisher/[^\"]+\"[^>]*>([^<]+)</a>', r'<div>\\s*Publisher:\\s*<span>\\s*(.+?)\\s*</span>\\s*</div>'],\n            webpage, 'video_uploader', fatal=False)\n\n        available_fmts = []\n        for a, fmt in re.findall(r'(<a[^>]+token=[\"\\']showmedia\\.([0-9]{3,4})p[\"\\'][^>]+>)', webpage):\n            attrs = extract_attributes(a)\n            href = attrs.get('href')\n            if href and '/freetrial' in href:\n                continue\n            available_fmts.append(fmt)\n        if not available_fmts:\n            for p in (r'token=[\"\\']showmedia\\.([0-9]{3,4})p\"', r'showmedia\\.([0-9]{3,4})p'):\n                available_fmts = re.findall(p, webpage)\n                if available_fmts:\n                    break\n        video_encode_ids = []\n        formats = []\n        for fmt in available_fmts:\n            stream_quality, stream_format = self._FORMAT_IDS[fmt]\n            video_format = fmt + 'p'\n            streamdata_req = sanitized_Request(\n                'http://www.crunchyroll.com/xml/?req=RpcApiVideoPlayer_GetStandardConfig&media_id=%s&video_format=%s&video_quality=%s'\n                % (video_id, stream_format, stream_quality),\n                compat_urllib_parse_urlencode({'current_page': url}).encode('utf-8'))\n            streamdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            streamdata = self._download_xml(\n                streamdata_req, video_id,\n                note='Downloading media info for %s' % video_format)\n            stream_info = streamdata.find('./{default}preload/stream_info')\n            video_encode_id = xpath_text(stream_info, './video_encode_id')\n            if video_encode_id in video_encode_ids:\n                continue\n            video_encode_ids.append(video_encode_id)\n\n            video_file = xpath_text(stream_info, './file')\n            if not video_file:\n                continue\n            if video_file.startswith('http'):\n                formats.extend(self._extract_m3u8_formats(\n                    video_file, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n                continue\n\n            video_url = xpath_text(stream_info, './host')\n            if not video_url:\n                continue\n            metadata = stream_info.find('./metadata')\n            format_info = {\n                'format': video_format,\n                'format_id': video_format,\n                'height': int_or_none(xpath_text(metadata, './height')),\n                'width': int_or_none(xpath_text(metadata, './width')),\n            }\n\n            if '.fplive.net/' in video_url:\n                video_url = re.sub(r'^rtmpe?://', 'http://', video_url.strip())\n                parsed_video_url = compat_urlparse.urlparse(video_url)\n                direct_video_url = compat_urlparse.urlunparse(parsed_video_url._replace(\n                    netloc='v.lvlt.crcdn.net',\n                    path='%s/%s' % (remove_end(parsed_video_url.path, '/'), video_file.split(':')[-1])))\n                if self._is_valid_url(direct_video_url, video_id, video_format):\n                    format_info.update({\n                        'url': direct_video_url,\n                    })\n                    formats.append(format_info)\n                    continue\n\n            format_info.update({\n                'url': video_url,\n                'play_path': video_file,\n                'ext': 'flv',\n            })\n            formats.append(format_info)\n        self._sort_formats(formats)\n\n        metadata = self._download_xml(\n            'http://www.crunchyroll.com/xml', video_id,\n            note='Downloading media info', query={\n                'req': 'RpcApiVideoPlayer_GetMediaMetadata',\n                'media_id': video_id,\n            })\n\n        subtitles = self.extract_subtitles(video_id, webpage)\n\n        # webpage provide more accurate data than series_title from XML\n        series = self._html_search_regex(\n            r'(?s)<h\\d[^>]+\\bid=[\"\\']showmedia_about_episode_num[^>]+>(.+?)</h\\d',\n            webpage, 'series', fatal=False)\n        season = xpath_text(metadata, 'series_title')\n\n        episode = xpath_text(metadata, 'episode_title')\n        episode_number = int_or_none(xpath_text(metadata, 'episode_number'))\n\n        season_number = int_or_none(self._search_regex(\n            r'(?s)<h\\d[^>]+id=[\"\\']showmedia_about_episode_num[^>]+>.+?</h\\d>\\s*<h4>\\s*Season (\\d+)',\n            webpage, 'season number', default=None))\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'thumbnail': xpath_text(metadata, 'episode_image_url'),\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n            'series': series,\n            'season': season,\n            'season_number': season_number,\n            'episode': episode,\n            'episode_number': episode_number,\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 383,
        "end_line": 538,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE._real_extract#567",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollShowPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            self._add_skip_wall(url), show_id,\n            headers=self.geo_verification_headers())\n        title = self._html_search_regex(\n            r'(?s)<h1[^>]*>\\s*<span itemprop=\"name\">(.*?)</span>',\n            webpage, 'title')\n        episode_paths = re.findall(\n            r'(?s)<li id=\"showview_videos_media_(\\d+)\"[^>]+>.*?<a href=\"([^\"]+)\"',\n            webpage)\n        entries = [\n            self.url_result('http://www.crunchyroll.com' + ep, 'Crunchyroll', ep_id)\n            for ep_id, ep in episode_paths\n        ]\n        entries.reverse()\n\n        return {\n            '_type': 'playlist',\n            'id': show_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 567,
        "end_line": 590,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cspan.CSpanIE._real_extract#74",
        "src_path": "youtube_dl/extractor/cspan.py",
        "class_name": "youtube_dl.extractor.cspan.CSpanIE",
        "signature": "youtube_dl.extractor.cspan.CSpanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_type = None\n        webpage = self._download_webpage(url, video_id)\n\n        ustream_url = UstreamIE._extract_url(webpage)\n        if ustream_url:\n            return self.url_result(ustream_url, UstreamIE.ie_key())\n\n        if '&vod' not in url:\n            bc = self._search_regex(\n                r\"(<[^>]+id='brightcove-player-embed'[^>]+>)\",\n                webpage, 'brightcove embed', default=None)\n            if bc:\n                bc_attr = extract_attributes(bc)\n                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (\n                    bc_attr.get('data-bcaccountid', '3162030207001'),\n                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),\n                    bc_attr.get('data-newbcplayerid', 'default'),\n                    bc_attr['data-bcid'])\n                return self.url_result(smuggle_url(bc_url, {'source_url': url}))\n\n        # We first look for clipid, because clipprog always appears before\n        patterns = [r'id=\\'clip(%s)\\'\\s*value=\\'([0-9]+)\\'' % t for t in ('id', 'prog')]\n        results = list(filter(None, (re.search(p, webpage) for p in patterns)))\n        if results:\n            matches = results[0]\n            video_type, video_id = matches.groups()\n            video_type = 'clip' if video_type == 'id' else 'program'\n        else:\n            m = re.search(r'data-(?P<type>clip|prog)id=[\"\\'](?P<id>\\d+)', webpage)\n            if m:\n                video_id = m.group('id')\n                video_type = 'program' if m.group('type') == 'prog' else 'clip'\n            else:\n                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n                if senate_isvp_url:\n                    title = self._og_search_title(webpage)\n                    surl = smuggle_url(senate_isvp_url, {'force_title': title})\n                    return self.url_result(surl, 'SenateISVP', video_id, title)\n        if video_type is None or video_id is None:\n            raise ExtractorError('unable to find video id and type')\n\n        def get_text_attr(d, attr):\n            return d.get(attr, {}).get('#text')\n\n        data = self._download_json(\n            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),\n            video_id)['video']\n        if data['@status'] != 'Success':\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)\n\n        doc = self._download_xml(\n            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),\n            video_id)\n\n        description = self._html_search_meta('description', webpage)\n\n        title = find_xpath_attr(doc, './/string', 'name', 'title').text\n        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text\n\n        files = data['files']\n        capfile = get_text_attr(data, 'capfile')\n\n        entries = []\n        for partnum, f in enumerate(files):\n            formats = []\n            for quality in f['qualities']:\n                formats.append({\n                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),\n                    'url': unescapeHTML(get_text_attr(quality, 'file')),\n                    'height': int_or_none(get_text_attr(quality, 'height')),\n                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),\n                })\n            if not formats:\n                path = unescapeHTML(get_text_attr(f, 'path'))\n                if not path:\n                    continue\n                formats = self._extract_m3u8_formats(\n                    path, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]\n            self._sort_formats(formats)\n            entries.append({\n                'id': '%s_%d' % (video_id, partnum + 1),\n                'title': (\n                    title if len(files) == 1 else\n                    '%s part %d' % (title, partnum + 1)),\n                'formats': formats,\n                'description': description,\n                'thumbnail': thumbnail,\n                'duration': int_or_none(get_text_attr(f, 'length')),\n                'subtitles': {\n                    'en': [{\n                        'url': capfile,\n                        'ext': determine_ext(capfile, 'dfxp')\n                    }],\n                } if capfile else None,\n            })\n\n        if len(entries) == 1:\n            entry = dict(entries[0])\n            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id\n            return entry\n        else:\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n                'title': title,\n                'id': 'c' + video_id if video_type == 'clip' else video_id,\n            }",
        "begin_line": 74,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ctsnews.CtsNewsIE._real_extract#52",
        "src_path": "youtube_dl/extractor/ctsnews.py",
        "class_name": "youtube_dl.extractor.ctsnews.CtsNewsIE",
        "signature": "youtube_dl.extractor.ctsnews.CtsNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        page = self._download_webpage(url, news_id)\n\n        news_id = self._hidden_inputs(page).get('get_id')\n\n        if news_id:\n            mp4_feed = self._download_json(\n                'http://news.cts.com.tw/action/test_mp4feed.php',\n                news_id, note='Fetching feed', query={'news_id': news_id})\n            video_url = mp4_feed['source_url']\n        else:\n            self.to_screen('Not CTSPlayer video, trying Youtube...')\n            youtube_url = self._search_regex(\n                r'src=\"(//www\\.youtube\\.com/embed/[^\"]+)\"', page, 'youtube url')\n\n            return self.url_result(youtube_url, ie='Youtube')\n\n        description = self._html_search_meta('description', page)\n        title = self._html_search_meta('title', page, fatal=True)\n        thumbnail = self._html_search_meta('image', page)\n\n        datetime_str = self._html_search_regex(\n            r'(\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2})', page, 'date and time', fatal=False)\n        timestamp = None\n        if datetime_str:\n            timestamp = unified_timestamp(datetime_str) - 8 * 3600\n\n        return {\n            'id': news_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n        }",
        "begin_line": 52,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ctvnews.CTVNewsIE._real_extract#48",
        "src_path": "youtube_dl/extractor/ctvnews.py",
        "class_name": "youtube_dl.extractor.ctvnews.CTVNewsIE",
        "signature": "youtube_dl.extractor.ctvnews.CTVNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        def ninecninemedia_url_result(clip_id):\n            return {\n                '_type': 'url_transparent',\n                'id': clip_id,\n                'url': '9c9media:ctvnews_web:%s' % clip_id,\n                'ie_key': 'NineCNineMedia',\n            }\n\n        if page_id.isdigit():\n            return ninecninemedia_url_result(page_id)\n        else:\n            webpage = self._download_webpage('http://www.ctvnews.ca/%s' % page_id, page_id, query={\n                'ot': 'example.AjaxPageLayout.ot',\n                'maxItemsPerPage': 1000000,\n            })\n            entries = [ninecninemedia_url_result(clip_id) for clip_id in orderedSet(\n                re.findall(r'clip\\.id\\s*=\\s*(\\d+);', webpage))]\n            return self.playlist_result(entries, page_id)",
        "begin_line": 48,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cultureunplugged.CultureUnpluggedIE._real_extract#34",
        "src_path": "youtube_dl/extractor/cultureunplugged.py",
        "class_name": "youtube_dl.extractor.cultureunplugged.CultureUnpluggedIE",
        "signature": "youtube_dl.extractor.cultureunplugged.CultureUnpluggedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        # request setClientTimezone.php to get PHPSESSID cookie which is need to get valid json data in the next request\n        self._request_webpage(HEADRequest(\n            'http://www.cultureunplugged.com/setClientTimezone.php?timeOffset=%d' % -(time.timezone / 3600)), display_id)\n        movie_data = self._download_json(\n            'http://www.cultureunplugged.com/movie-data/cu-%s.json' % video_id, display_id)\n\n        video_url = movie_data['url']\n        title = movie_data['title']\n\n        description = movie_data.get('synopsis')\n        creator = movie_data.get('producer')\n        duration = int_or_none(movie_data.get('duration'))\n        view_count = int_or_none(movie_data.get('views'))\n\n        thumbnails = [{\n            'url': movie_data['%s_thumb' % size],\n            'id': size,\n            'preference': preference,\n        } for preference, size in enumerate((\n            'small', 'large')) if movie_data.get('%s_thumb' % size)]\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'creator': creator,\n            'duration': duration,\n            'view_count': view_count,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 34,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._handle_errors#20",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._handle_errors(self, result)",
        "snippet": "    def _handle_errors(self, result):\n        error = result.get('error', {}).get('message')\n        if error:\n            if isinstance(error, dict):\n                error = ', '.join(error.values())\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, error), expected=True)",
        "begin_line": 20,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._call_api#28",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._call_api(self, path, video_id)",
        "snippet": "    def _call_api(self, path, video_id):\n        headers = {}\n        if self._auth_token:\n            headers['X-Auth-Token'] = self._auth_token\n        result = self._download_json(\n            self._API_BASE_URL + path, video_id, headers=headers)\n        self._handle_errors(result)\n        return result['data']",
        "begin_line": 28,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._real_initialize#37",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        (email, password) = self._get_login_info()\n        if email is None:\n            return\n        result = self._download_json(\n            self._API_BASE_URL + 'login', None, data=urlencode_postdata({\n                'email': email,\n                'password': password,\n            }))\n        self._handle_errors(result)\n        self._auth_token = result['message']['auth_token']",
        "begin_line": 37,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._extract_media_info#49",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamBaseIE._extract_media_info(self, media)",
        "snippet": "    def _extract_media_info(self, media):\n        video_id = compat_str(media['id'])\n        title = media['title']\n\n        formats = []\n        for encoding in media.get('encodings', []):\n            m3u8_url = encoding.get('master_playlist_url')\n            if m3u8_url:\n                formats.extend(self._extract_m3u8_formats(\n                    m3u8_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            encoding_url = encoding.get('url')\n            file_url = encoding.get('file_url')\n            if not encoding_url and not file_url:\n                continue\n            f = {\n                'width': int_or_none(encoding.get('width')),\n                'height': int_or_none(encoding.get('height')),\n                'vbr': int_or_none(encoding.get('video_bitrate')),\n                'abr': int_or_none(encoding.get('audio_bitrate')),\n                'filesize': int_or_none(encoding.get('size_in_bytes')),\n                'vcodec': encoding.get('video_codec'),\n                'acodec': encoding.get('audio_codec'),\n                'container': encoding.get('container_type'),\n            }\n            for f_url in (encoding_url, file_url):\n                if not f_url:\n                    continue\n                fmt = f.copy()\n                rtmp = re.search(r'^(?P<url>rtmpe?://(?P<host>[^/]+)/(?P<app>.+))/(?P<playpath>mp[34]:.+)$', f_url)\n                if rtmp:\n                    fmt.update({\n                        'url': rtmp.group('url'),\n                        'play_path': rtmp.group('playpath'),\n                        'app': rtmp.group('app'),\n                        'ext': 'flv',\n                        'format_id': 'rtmp',\n                    })\n                else:\n                    fmt.update({\n                        'url': f_url,\n                        'format_id': 'http',\n                    })\n                formats.append(fmt)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for closed_caption in media.get('closed_captions', []):\n            sub_url = closed_caption.get('file')\n            if not sub_url:\n                continue\n            lang = closed_caption.get('code') or closed_caption.get('language') or 'en'\n            subtitles.setdefault(lang, []).append({\n                'url': sub_url,\n            })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': media.get('description'),\n            'thumbnail': media.get('image_large') or media.get('image_medium') or media.get('image_small'),\n            'duration': int_or_none(media.get('duration')),\n            'tags': media.get('tags'),\n            'subtitles': subtitles,\n        }",
        "begin_line": 49,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamIE._real_extract#131",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        media = self._call_api('media/' + video_id, video_id)\n        return self._extract_media_info(media)",
        "begin_line": 131,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.curiositystream.CuriosityStreamCollectionIE._real_extract#150",
        "src_path": "youtube_dl/extractor/curiositystream.py",
        "class_name": "youtube_dl.extractor.curiositystream.CuriosityStreamCollectionIE",
        "signature": "youtube_dl.extractor.curiositystream.CuriosityStreamCollectionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        collection_id = self._match_id(url)\n        collection = self._call_api(\n            'collections/' + collection_id, collection_id)\n        entries = []\n        for media in collection.get('media', []):\n            entries.append(self._extract_media_info(media))\n        return self.playlist_result(\n            entries, collection_id,\n            collection.get('title'), collection.get('description'))",
        "begin_line": 150,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.cwtv.CWTVIE._real_extract#59",
        "src_path": "youtube_dl/extractor/cwtv.py",
        "class_name": "youtube_dl.extractor.cwtv.CWTVIE",
        "signature": "youtube_dl.extractor.cwtv.CWTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = None\n        formats = []\n        for partner in (154, 213):\n            vdata = self._download_json(\n                'http://metaframe.digitalsmiths.tv/v2/CWtv/assets/%s/partner/%d?format=json' % (video_id, partner), video_id, fatal=False)\n            if not vdata:\n                continue\n            video_data = vdata\n            for quality, quality_data in vdata.get('videos', {}).items():\n                quality_url = quality_data.get('uri')\n                if not quality_url:\n                    continue\n                if quality == 'variantplaylist':\n                    formats.extend(self._extract_m3u8_formats(\n                        quality_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n                else:\n                    tbr = int_or_none(quality_data.get('bitrate'))\n                    format_id = 'http' + ('-%d' % tbr if tbr else '')\n                    if self._is_valid_url(quality_url, video_id, format_id):\n                        formats.append({\n                            'format_id': format_id,\n                            'url': quality_url,\n                            'tbr': tbr,\n                        })\n        video_metadata = video_data['assetFields']\n        ism_url = video_metadata.get('smoothStreamingUrl')\n        if ism_url:\n            formats.extend(self._extract_ism_formats(\n                ism_url, video_id, ism_id='mss', fatal=False))\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': image['uri'],\n            'width': image.get('width'),\n            'height': image.get('height'),\n        } for image_id, image in video_data['images'].items() if image.get('uri')] if video_data.get('images') else None\n\n        subtitles = {\n            'en': [{\n                'url': video_metadata['UnicornCcUrl'],\n            }],\n        } if video_metadata.get('UnicornCcUrl') else None\n\n        return {\n            'id': video_id,\n            'title': video_metadata['title'],\n            'description': video_metadata.get('description'),\n            'duration': int_or_none(video_metadata.get('duration')),\n            'series': video_metadata.get('seriesName'),\n            'season_number': int_or_none(video_metadata.get('seasonNumber')),\n            'season': video_metadata.get('seasonName'),\n            'episode_number': int_or_none(video_metadata.get('episodeNumber')),\n            'timestamp': parse_iso8601(video_data.get('startTime')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 59,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymail.DailyMailIE._extract_urls#33",
        "src_path": "youtube_dl/extractor/dailymail.py",
        "class_name": "youtube_dl.extractor.dailymail.DailyMailIE",
        "signature": "youtube_dl.extractor.dailymail.DailyMailIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe\\b[^>]+\\bsrc=[\"\\'](?P<url>(?:https?:)?//(?:www\\.)?dailymail\\.co\\.uk/embed/video/\\d+\\.html)',\n            webpage)",
        "begin_line": 33,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymail.DailyMailIE._real_extract#38",
        "src_path": "youtube_dl/extractor/dailymail.py",
        "class_name": "youtube_dl.extractor.dailymail.DailyMailIE",
        "signature": "youtube_dl.extractor.dailymail.DailyMailIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_data = self._parse_json(self._search_regex(\n            r\"data-opts='({.+?})'\", webpage, 'video data'), video_id)\n        title = unescapeHTML(video_data['title'])\n\n        sources_url = (try_get(\n            video_data,\n            (lambda x: x['plugins']['sources']['url'],\n             lambda x: x['sources']['url']), compat_str) or\n            'http://www.dailymail.co.uk/api/player/%s/video-sources.json' % video_id)\n\n        video_sources = self._download_json(sources_url, video_id)\n\n        formats = []\n        for rendition in video_sources['renditions']:\n            rendition_url = rendition.get('url')\n            if not rendition_url:\n                continue\n            tbr = int_or_none(rendition.get('encodingRate'), 1000)\n            container = rendition.get('videoContainer')\n            is_hls = container == 'M2TS'\n            protocol = 'm3u8_native' if is_hls else determine_protocol({'url': rendition_url})\n            formats.append({\n                'format_id': ('hls' if is_hls else protocol) + ('-%d' % tbr if tbr else ''),\n                'url': rendition_url,\n                'width': int_or_none(rendition.get('frameWidth')),\n                'height': int_or_none(rendition.get('frameHeight')),\n                'tbr': tbr,\n                'vcodec': rendition.get('videoCodec'),\n                'container': container,\n                'protocol': protocol,\n                'ext': 'mp4' if is_hls else None,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': unescapeHTML(video_data.get('descr')),\n            'thumbnail': video_data.get('poster') or video_data.get('thumbnail'),\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request#25",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request(url)",
        "snippet": "    def _build_request(url):\n        \"\"\"Build a request with the family filter disabled\"\"\"\n        request = sanitized_Request(url)\n        request.add_header('Cookie', 'family_filter=off; ff=off')\n        return request",
        "begin_line": 25,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_handle_no_ff#31",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_handle_no_ff(self, url, *args, **kwargs)",
        "snippet": "    def _download_webpage_handle_no_ff(self, url, *args, **kwargs):\n        request = self._build_request(url)\n        return self._download_webpage_handle(request, *args, **kwargs)",
        "begin_line": 31,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_no_ff#35",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._download_webpage_no_ff(self, url, *args, **kwargs)",
        "snippet": "    def _download_webpage_no_ff(self, url, *args, **kwargs):\n        request = self._build_request(url)\n        return self._download_webpage(request, *args, **kwargs)",
        "begin_line": 35,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._extract_urls#130",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        # Look for embedded Dailymotion player\n        matches = re.findall(\n            r'<(?:(?:embed|iframe)[^>]+?src=|input[^>]+id=[\\'\"]dmcloudUrlEmissionSelect[\\'\"][^>]+value=)([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.com/(?:embed|swf)/video/.+?)\\1', webpage)\n        return list(map(lambda m: unescapeHTML(m[1]), matches))",
        "begin_line": 130,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract#136",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage_no_ff(\n            'https://www.dailymotion.com/video/%s' % video_id, video_id)\n\n        age_limit = self._rta_search(webpage)\n\n        description = self._og_search_description(webpage) or self._html_search_meta(\n            'description', webpage, 'description')\n\n        view_count_str = self._search_regex(\n            (r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserPlays:([\\s\\d,.]+)\"',\n             r'video_views_count[^>]+>\\s+([\\s\\d\\,.]+)'),\n            webpage, 'view count', default=None)\n        if view_count_str:\n            view_count_str = re.sub(r'\\s', '', view_count_str)\n        view_count = str_to_int(view_count_str)\n        comment_count = int_or_none(self._search_regex(\n            r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserComments:(\\d+)\"',\n            webpage, 'comment count', default=None))\n\n        player_v5 = self._search_regex(\n            [r'buildPlayer\\(({.+?})\\);\\n',  # See https://github.com/rg3/youtube-dl/issues/7826\n             r'playerV5\\s*=\\s*dmp\\.create\\([^,]+?,\\s*({.+?})\\);',\n             r'buildPlayer\\(({.+?})\\);',\n             r'var\\s+config\\s*=\\s*({.+?});',\n             # New layout regex (see https://github.com/rg3/youtube-dl/issues/13580)\n             r'__PLAYER_CONFIG__\\s*=\\s*({.+?});'],\n            webpage, 'player v5', default=None)\n        if player_v5:\n            player = self._parse_json(player_v5, video_id)\n            metadata = player['metadata']\n\n            self._check_error(metadata)\n\n            formats = []\n            for quality, media_list in metadata['qualities'].items():\n                for media in media_list:\n                    media_url = media.get('url')\n                    if not media_url:\n                        continue\n                    type_ = media.get('type')\n                    if type_ == 'application/vnd.lumberjack.manifest':\n                        continue\n                    ext = mimetype2ext(type_) or determine_ext(media_url)\n                    if ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            media_url, video_id, 'mp4', preference=-1,\n                            m3u8_id='hls', fatal=False))\n                    elif ext == 'f4m':\n                        formats.extend(self._extract_f4m_formats(\n                            media_url, video_id, preference=-1, f4m_id='hds', fatal=False))\n                    else:\n                        f = {\n                            'url': media_url,\n                            'format_id': 'http-%s' % quality,\n                            'ext': ext,\n                        }\n                        m = re.search(r'H264-(?P<width>\\d+)x(?P<height>\\d+)', media_url)\n                        if m:\n                            f.update({\n                                'width': int(m.group('width')),\n                                'height': int(m.group('height')),\n                            })\n                        formats.append(f)\n            self._sort_formats(formats)\n\n            title = metadata['title']\n            duration = int_or_none(metadata.get('duration'))\n            timestamp = int_or_none(metadata.get('created_time'))\n            thumbnail = metadata.get('poster_url')\n            uploader = metadata.get('owner', {}).get('screenname')\n            uploader_id = metadata.get('owner', {}).get('id')\n\n            subtitles = {}\n            subtitles_data = metadata.get('subtitles', {}).get('data', {})\n            if subtitles_data and isinstance(subtitles_data, dict):\n                for subtitle_lang, subtitle in subtitles_data.items():\n                    subtitles[subtitle_lang] = [{\n                        'ext': determine_ext(subtitle_url),\n                        'url': subtitle_url,\n                    } for subtitle_url in subtitle.get('urls', [])]\n\n            return {\n                'id': video_id,\n                'title': title,\n                'description': description,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'timestamp': timestamp,\n                'uploader': uploader,\n                'uploader_id': uploader_id,\n                'age_limit': age_limit,\n                'view_count': view_count,\n                'comment_count': comment_count,\n                'formats': formats,\n                'subtitles': subtitles,\n            }\n\n        # vevo embed\n        vevo_id = self._search_regex(\n            r'<link rel=\"video_src\" href=\"[^\"]*?vevo.com[^\"]*?video=(?P<id>[\\w]*)',\n            webpage, 'vevo embed', default=None)\n        if vevo_id:\n            return self.url_result('vevo:%s' % vevo_id, 'Vevo')\n\n        # fallback old player\n        embed_page = self._download_webpage_no_ff(\n            'https://www.dailymotion.com/embed/video/%s' % video_id,\n            video_id, 'Downloading embed page')\n\n        timestamp = parse_iso8601(self._html_search_meta(\n            'video:release_date', webpage, 'upload date'))\n\n        info = self._parse_json(\n            self._search_regex(\n                r'var info = ({.*?}),$', embed_page,\n                'video info', flags=re.MULTILINE),\n            video_id)\n\n        self._check_error(info)\n\n        formats = []\n        for (key, format_id) in self._FORMATS:\n            video_url = info.get(key)\n            if video_url is not None:\n                m_size = re.search(r'H264-(\\d+)x(\\d+)', video_url)\n                if m_size is not None:\n                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))\n                else:\n                    width, height = None, None\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'format_id': format_id,\n                    'width': width,\n                    'height': height,\n                })\n        self._sort_formats(formats)\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, webpage)\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                r'(?s)<span\\s+id=\"video_title\"[^>]*>(.*?)</span>', webpage,\n                'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': info['owner.screenname'],\n            'timestamp': timestamp,\n            'title': title,\n            'description': description,\n            'subtitles': video_subtitles,\n            'thumbnail': info['thumbnail_url'],\n            'age_limit': age_limit,\n            'view_count': view_count,\n            'duration': info['duration']\n        }",
        "begin_line": 136,
        "end_line": 298,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._check_error#300",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._check_error(self, info)",
        "snippet": "    def _check_error(self, info):\n        error = info.get('error')\n        if info.get('error') is not None:\n            title = error['title']\n            # See https://developer.dailymotion.com/api#access-error\n            if error.get('code') == 'DM007':\n                self.raise_geo_restricted(msg=title)\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, title), expected=True)",
        "begin_line": 300,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._get_subtitles#310",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://api.dailymotion.com/video/%s/subtitles?fields=id,language,url' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))\n            return {}\n        info = json.loads(sub_list)\n        if (info['total'] > 0):\n            sub_lang_list = dict((l['language'], [{'url': l['url'], 'ext': 'srt'}]) for l in info['list'])\n            return sub_lang_list\n        self._downloader.report_warning('video doesn\\'t have subtitles')\n        return {}",
        "begin_line": 310,
        "end_line": 323,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries#340",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries(self, id)",
        "snippet": "    def _extract_entries(self, id):\n        video_ids = set()\n        processed_urls = set()\n        for pagenum in itertools.count(1):\n            page_url = self._PAGE_TEMPLATE % (id, pagenum)\n            webpage, urlh = self._download_webpage_handle_no_ff(\n                page_url, id, 'Downloading page %s' % pagenum)\n            if urlh.geturl() in processed_urls:\n                self.report_warning('Stopped at duplicated page %s, which is the same as %s' % (\n                    page_url, urlh.geturl()), id)\n                break\n\n            processed_urls.add(urlh.geturl())\n\n            for video_id in re.findall(r'data-xid=\"(.+?)\"', webpage):\n                if video_id not in video_ids:\n                    yield self.url_result(\n                        'http://www.dailymotion.com/video/%s' % video_id,\n                        DailymotionIE.ie_key(), video_id)\n                    video_ids.add(video_id)\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage) is None:\n                break",
        "begin_line": 340,
        "end_line": 362,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract#364",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist_id),\n        }",
        "begin_line": 364,
        "end_line": 374,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract#401",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionUserIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        webpage = self._download_webpage(\n            'https://www.dailymotion.com/user/%s' % user, user)\n        full_user = unescapeHTML(self._html_search_regex(\n            r'<a class=\"nav-image\" title=\"([^\"]+)\" href=\"/%s\">' % re.escape(user),\n            webpage, 'user'))\n\n        return {\n            '_type': 'playlist',\n            'id': user,\n            'title': full_user,\n            'entries': self._extract_entries(user),\n        }",
        "begin_line": 401,
        "end_line": 415,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url#435",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._extract_dmcloud_url(cls, webpage)",
        "snippet": "    def _extract_dmcloud_url(cls, webpage):\n        mobj = re.search(r'<iframe[^>]+src=[\\'\"](%s)[\\'\"]' % cls._VALID_EMBED_URL, webpage)\n        if mobj:\n            return mobj.group(1)\n\n        mobj = re.search(\n            r'<input[^>]+id=[\\'\"]dmcloudUrlEmissionSelect[\\'\"][^>]+value=[\\'\"](%s)[\\'\"]' % cls._VALID_EMBED_URL,\n            webpage)\n        if mobj:\n            return mobj.group(1)",
        "begin_line": 435,
        "end_line": 444,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._real_extract#446",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionCloudIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionCloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage_no_ff(url, video_id)\n\n        title = self._html_search_regex(r'<title>([^>]+)</title>', webpage, 'title')\n\n        video_info = self._parse_json(self._search_regex(\n            r'var\\s+info\\s*=\\s*([^;]+);', webpage, 'video info'), video_id)\n\n        # TODO: parse ios_url, which is in fact a manifest\n        video_url = video_info['mp4_url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': video_info.get('thumbnail_url'),\n        }",
        "begin_line": 446,
        "end_line": 464,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daisuki.DaisukiIE._real_extract#52",
        "src_path": "youtube_dl/extractor/daisuki.py",
        "class_name": "youtube_dl.extractor.daisuki.DaisukiIE",
        "signature": "youtube_dl.extractor.daisuki.DaisukiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        flashvars = self._parse_json(self._search_regex(\n            r'(?s)var\\s+flashvars\\s*=\\s*({.+?});', webpage, 'flashvars'),\n            video_id, transform_source=js_to_json)\n\n        iv = [0] * 16\n\n        data = {}\n        for key in ('device_cd', 'mv_id', 'ss1_prm', 'ss2_prm', 'ss3_prm', 'ss_id'):\n            data[key] = flashvars.get(key, '')\n\n        encrypted_rtn = None\n\n        # Some AES keys are rejected. Try it with different AES keys\n        for idx in range(5):\n            aes_key = [random.randint(0, 254) for _ in range(32)]\n            padded_aeskey = intlist_to_bytes(pkcs1pad(aes_key, 128))\n\n            n, e = self._RSA_KEY\n            encrypted_aeskey = long_to_bytes(pow(bytes_to_long(padded_aeskey), e, n))\n            init_data = self._download_json('http://www.daisuki.net/bin/bgn/init', video_id, query={\n                's': flashvars.get('s', ''),\n                'c': flashvars.get('ss3_prm', ''),\n                'e': url,\n                'd': base64.b64encode(intlist_to_bytes(aes_cbc_encrypt(\n                    bytes_to_intlist(json.dumps(data)),\n                    aes_key, iv))).decode('ascii'),\n                'a': base64.b64encode(encrypted_aeskey).decode('ascii'),\n            }, note='Downloading JSON metadata' + (' (try #%d)' % (idx + 1) if idx > 0 else ''))\n\n            if 'rtn' in init_data:\n                encrypted_rtn = init_data['rtn']\n                break\n\n            self._sleep(5, video_id)\n\n        if encrypted_rtn is None:\n            raise ExtractorError('Failed to fetch init data')\n\n        rtn = self._parse_json(\n            intlist_to_bytes(aes_cbc_decrypt(bytes_to_intlist(\n                base64.b64decode(encrypted_rtn)),\n                aes_key, iv)).decode('utf-8').rstrip('\\0'),\n            video_id)\n\n        formats = self._extract_m3u8_formats(\n            rtn['play_url'], video_id, ext='mp4', entry_protocol='m3u8_native')\n\n        title = remove_end(self._og_search_title(webpage), ' - DAISUKI')\n\n        creator = self._html_search_regex(\n            r'Creator\\s*:\\s*([^<]+)', webpage, 'creator', fatal=False)\n\n        subtitles = {}\n        caption_url = rtn.get('caption_url')\n        if caption_url:\n            # mul: multiple languages\n            subtitles['mul'] = [{\n                'url': caption_url,\n                'ext': 'ttml',\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'creator': creator,\n        }",
        "begin_line": 52,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daisuki.DaisukiPlaylistIE._real_extract#140",
        "src_path": "youtube_dl/extractor/daisuki.py",
        "class_name": "youtube_dl.extractor.daisuki.DaisukiPlaylistIE",
        "signature": "youtube_dl.extractor.daisuki.DaisukiPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        episode_pattern = r'''(?sx)\n            <img[^>]+delay=\"[^\"]+/(\\d+)/movie\\.jpg\".+?\n            <p[^>]+class=\".*?\\bepisodeNumber\\b.*?\">(?:<a[^>]+>)?([^<]+)'''\n        entries = [{\n            '_type': 'url_transparent',\n            'url': url.replace('detail', 'watch').replace('.html', '.' + movie_id + '.html'),\n            'episode_id': episode_id,\n            'episode_number': int_or_none(episode_id),\n        } for movie_id, episode_id in re.findall(episode_pattern, webpage)]\n\n        playlist_title = remove_end(\n            self._og_search_title(webpage, fatal=False), ' - Anime - DAISUKI')\n        playlist_description = clean_html(get_element_by_id('synopsisTxt', webpage))\n\n        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 140,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumIE._real_extract#82",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumIE",
        "signature": "youtube_dl.extractor.daum.DaumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = compat_urllib_parse_unquote(self._match_id(url))\n        movie_data = self._download_json(\n            'http://videofarm.daum.net/controller/api/closed/v1_2/IntegratedMovieData.json',\n            video_id, 'Downloading video formats info', query={'vid': video_id, 'dte_type': 'WEB'})\n\n        # For urls like http://m.tvpot.daum.net/v/65139429, where the video_id is really a clipid\n        if not movie_data.get('output_list', {}).get('output_list') and re.match(r'^\\d+$', video_id):\n            return self.url_result('http://tvpot.daum.net/clip/ClipView.do?clipid=%s' % video_id)\n\n        info = self._download_xml(\n            'http://tvpot.daum.net/clip/ClipInfoXml.do', video_id,\n            'Downloading video info', query={'vid': video_id})\n\n        formats = []\n        for format_el in movie_data['output_list']['output_list']:\n            profile = format_el['profile']\n            format_query = compat_urllib_parse_urlencode({\n                'vid': video_id,\n                'profile': profile,\n            })\n            url_doc = self._download_xml(\n                'http://videofarm.daum.net/controller/api/open/v1_2/MovieLocation.apixml?' + format_query,\n                video_id, note='Downloading video data for %s format' % profile)\n            format_url = url_doc.find('result/url').text\n            formats.append({\n                'url': format_url,\n                'format_id': profile,\n                'width': int_or_none(format_el.get('width')),\n                'height': int_or_none(format_el.get('height')),\n                'filesize': int_or_none(format_el.get('filesize')),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info.find('TITLE').text,\n            'formats': formats,\n            'thumbnail': xpath_text(info, 'THUMB_URL'),\n            'description': xpath_text(info, 'CONTENTS'),\n            'duration': int_or_none(xpath_text(info, 'DURATION')),\n            'upload_date': info.find('REGDTTM').text[:8],\n            'view_count': str_to_int(xpath_text(info, 'PLAY_CNT')),\n            'comment_count': str_to_int(xpath_text(info, 'COMMENT_CNT')),\n        }",
        "begin_line": 82,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumClipIE.suitable#152",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumClipIE",
        "signature": "youtube_dl.extractor.daum.DaumClipIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if DaumPlaylistIE.suitable(url) or DaumUserIE.suitable(url) else super(DaumClipIE, cls).suitable(url)",
        "begin_line": 152,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumClipIE._real_extract#155",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumClipIE",
        "signature": "youtube_dl.extractor.daum.DaumClipIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        clip_info = self._download_json(\n            'http://tvpot.daum.net/mypot/json/GetClipInfo.do?clipid=%s' % video_id,\n            video_id, 'Downloading clip info')['clip_bean']\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': 'http://tvpot.daum.net/v/%s' % clip_info['vid'],\n            'title': unescapeHTML(clip_info['title']),\n            'thumbnail': clip_info.get('thumb_url'),\n            'description': clip_info.get('contents'),\n            'duration': int_or_none(clip_info.get('duration')),\n            'upload_date': clip_info.get('up_date')[:8],\n            'view_count': int_or_none(clip_info.get('play_count')),\n            'ie_key': 'Daum',\n        }",
        "begin_line": 155,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumListIE._get_entries#176",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumListIE",
        "signature": "youtube_dl.extractor.daum.DaumListIE._get_entries(self, list_id, list_id_type)",
        "snippet": "    def _get_entries(self, list_id, list_id_type):\n        name = None\n        entries = []\n        for pagenum in itertools.count(1):\n            list_info = self._download_json(\n                'http://tvpot.daum.net/mypot/json/GetClipInfo.do?size=48&init=true&order=date&page=%d&%s=%s' % (\n                    pagenum, list_id_type, list_id), list_id, 'Downloading list info - %s' % pagenum)\n\n            entries.extend([\n                self.url_result(\n                    'http://tvpot.daum.net/v/%s' % clip['vid'])\n                for clip in list_info['clip_list']\n            ])\n\n            if not name:\n                name = list_info.get('playlist_bean', {}).get('name') or \\\n                    list_info.get('potInfo', {}).get('name')\n\n            if not list_info.get('has_more'):\n                break\n\n        return name, entries",
        "begin_line": 176,
        "end_line": 197,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumListIE._check_clip#199",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumListIE",
        "signature": "youtube_dl.extractor.daum.DaumListIE._check_clip(self, url, list_id)",
        "snippet": "    def _check_clip(self, url, list_id):\n        query_dict = compat_parse_qs(compat_urlparse.urlparse(url).query)\n        if 'clipid' in query_dict:\n            clip_id = query_dict['clipid'][0]\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % clip_id)\n                return self.url_result(DaumClipIE._URL_TEMPLATE % clip_id, 'DaumClip')\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video' % list_id)",
        "begin_line": 199,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumPlaylistIE.suitable#239",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumPlaylistIE",
        "signature": "youtube_dl.extractor.daum.DaumPlaylistIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if DaumUserIE.suitable(url) else super(DaumPlaylistIE, cls).suitable(url)",
        "begin_line": 239,
        "end_line": 240,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumPlaylistIE._real_extract#242",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumPlaylistIE",
        "signature": "youtube_dl.extractor.daum.DaumPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        clip_result = self._check_clip(url, list_id)\n        if clip_result:\n            return clip_result\n\n        name, entries = self._get_entries(list_id, 'playlistid')\n\n        return self.playlist_result(entries, list_id, name)",
        "begin_line": 242,
        "end_line": 251,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.daum.DaumUserIE._real_extract#294",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumUserIE",
        "signature": "youtube_dl.extractor.daum.DaumUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        clip_result = self._check_clip(url, list_id)\n        if clip_result:\n            return clip_result\n\n        query_dict = compat_parse_qs(compat_urlparse.urlparse(url).query)\n        if 'playlistid' in query_dict:\n            playlist_id = query_dict['playlistid'][0]\n            return self.url_result(DaumPlaylistIE._URL_TEMPLATE % playlist_id, 'DaumPlaylist')\n\n        name, entries = self._get_entries(list_id, 'ownerid')\n\n        return self.playlist_result(entries, list_id, name)",
        "begin_line": 294,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dbtv.DBTVIE._extract_urls#42",
        "src_path": "youtube_dl/extractor/dbtv.py",
        "class_name": "youtube_dl.extractor.dbtv.DBTVIE",
        "signature": "youtube_dl.extractor.dbtv.DBTVIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+src=([\"\\'])((?:https?:)?//(?:www\\.)?dbtv\\.no/(?:lazy)?player/\\d+.*?)\\1',\n            webpage)]",
        "begin_line": 42,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dbtv.DBTVIE._real_extract#47",
        "src_path": "youtube_dl/extractor/dbtv.py",
        "class_name": "youtube_dl.extractor.dbtv.DBTVIE",
        "signature": "youtube_dl.extractor.dbtv.DBTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id = re.match(self._VALID_URL, url).groups()\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'http://players.brightcove.net/1027729757001/default_default/index.html?videoId=%s' % video_id,\n            'id': video_id,\n            'display_id': display_id,\n            'ie_key': 'BrightcoveNew',\n        }",
        "begin_line": 47,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dctp.DctpTvIE._real_extract#24",
        "src_path": "youtube_dl/extractor/dctp.py",
        "class_name": "youtube_dl.extractor.dctp.DctpTvIE",
        "signature": "youtube_dl.extractor.dctp.DctpTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        object_id = self._html_search_meta('DC.identifier', webpage)\n\n        servers_json = self._download_json(\n            'http://www.dctp.tv/elastic_streaming_client/get_streaming_server/',\n            video_id, note='Downloading server list')\n        server = servers_json[0]['server']\n        m3u8_path = self._search_regex(\n            r'\\'([^\\'\"]+/playlist\\.m3u8)\"', webpage, 'm3u8 path')\n        formats = self._extract_m3u8_formats(\n            'http://%s%s' % (server, m3u8_path), video_id, ext='mp4',\n            entry_protocol='m3u8_native')\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_meta('DC.description', webpage)\n        upload_date = unified_strdate(\n            self._html_search_meta('DC.date.created', webpage))\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': object_id,\n            'title': title,\n            'formats': formats,\n            'display_id': video_id,\n            'description': description,\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract#28",
        "src_path": "youtube_dl/extractor/deezer.py",
        "class_name": "youtube_dl.extractor.deezer.DeezerPlaylistIE",
        "signature": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if 'test' not in self._downloader.params:\n            self._downloader.report_warning('For now, this extractor only supports the 30 second previews. Patches welcome!')\n\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        geoblocking_msg = self._html_search_regex(\n            r'<p class=\"soon-txt\">(.*?)</p>', webpage, 'geoblocking message',\n            default=None)\n        if geoblocking_msg is not None:\n            raise ExtractorError(\n                'Deezer said: %s' % geoblocking_msg, expected=True)\n\n        data_json = self._search_regex(\n            (r'__DZR_APP_STATE__\\s*=\\s*({.+?})\\s*</script>',\n             r'naboo\\.display\\(\\'[^\\']+\\',\\s*(.*?)\\);\\n'),\n            webpage, 'data JSON')\n        data = json.loads(data_json)\n\n        playlist_title = data.get('DATA', {}).get('TITLE')\n        playlist_uploader = data.get('DATA', {}).get('PARENT_USERNAME')\n        playlist_thumbnail = self._search_regex(\n            r'<img id=\"naboo_playlist_image\".*?src=\"([^\"]+)\"', webpage,\n            'playlist thumbnail')\n\n        preview_pattern = self._search_regex(\n            r\"var SOUND_PREVIEW_GATEWAY\\s*=\\s*'([^']+)';\", webpage,\n            'preview URL pattern', fatal=False)\n        entries = []\n        for s in data['SONGS']['data']:\n            puid = s['MD5_ORIGIN']\n            preview_video_url = preview_pattern.\\\n                replace('{0}', puid[0]).\\\n                replace('{1}', puid).\\\n                replace('{2}', s['MEDIA_VERSION'])\n            formats = [{\n                'format_id': 'preview',\n                'url': preview_video_url,\n                'preference': -100,  # Only the first 30 seconds\n                'ext': 'mp3',\n            }]\n            self._sort_formats(formats)\n            artists = ', '.join(\n                orderedSet(a['ART_NAME'] for a in s['ARTISTS']))\n            entries.append({\n                'id': s['SNG_ID'],\n                'duration': int_or_none(s.get('DURATION')),\n                'title': '%s - %s' % (artists, s['SNG_TITLE']),\n                'uploader': s['ART_NAME'],\n                'uploader_id': s['ART_ID'],\n                'age_limit': 16 if s.get('EXPLICIT_LYRICS') == '1' else 0,\n                'formats': formats,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'uploader': playlist_uploader,\n            'thumbnail': playlist_thumbnail,\n            'entries': entries,\n        }",
        "begin_line": 28,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract#20",
        "src_path": "youtube_dl/extractor/defense.py",
        "class_name": "youtube_dl.extractor.defense.DefenseGouvFrIE",
        "signature": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = self._match_id(url)\n        webpage = self._download_webpage(url, title)\n\n        video_id = self._search_regex(\n            r\"flashvars.pvg_id=\\\"(\\d+)\\\";\",\n            webpage, 'ID')\n\n        json_url = (\n            'http://static.videos.gouv.fr/brightcovehub/export/json/%s' %\n            video_id)\n        info = self._download_json(json_url, title, 'Downloading JSON config')\n        video_url = info['renditions'][0]['url']\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 20,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.democracynow.DemocracynowIE._real_extract#40",
        "src_path": "youtube_dl/extractor/democracynow.py",
        "class_name": "youtube_dl.extractor.democracynow.DemocracynowIE",
        "signature": "youtube_dl.extractor.democracynow.DemocracynowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        json_data = self._parse_json(self._search_regex(\n            r'<script[^>]+type=\"text/json\"[^>]*>\\s*({[^>]+})', webpage, 'json'),\n            display_id)\n\n        title = json_data['title']\n        formats = []\n\n        video_id = None\n\n        for key in ('file', 'audio', 'video', 'high_res_video'):\n            media_url = json_data.get(key, '')\n            if not media_url:\n                continue\n            media_url = re.sub(r'\\?.*', '', compat_urlparse.urljoin(url, media_url))\n            video_id = video_id or remove_start(os.path.splitext(url_basename(media_url))[0], 'dn')\n            formats.append({\n                'url': media_url,\n                'vcodec': 'none' if key == 'audio' else None,\n            })\n\n        self._sort_formats(formats)\n\n        default_lang = 'en'\n        subtitles = {}\n\n        def add_subtitle_item(lang, info_dict):\n            if lang not in subtitles:\n                subtitles[lang] = []\n            subtitles[lang].append(info_dict)\n\n        # chapter_file are not subtitles\n        if 'caption_file' in json_data:\n            add_subtitle_item(default_lang, {\n                'url': compat_urlparse.urljoin(url, json_data['caption_file']),\n            })\n\n        for subtitle_item in json_data.get('captions', []):\n            lang = subtitle_item.get('language', '').lower() or default_lang\n            add_subtitle_item(lang, {\n                'url': compat_urlparse.urljoin(url, subtitle_item['url']),\n            })\n\n        description = self._og_search_description(webpage, default=None)\n\n        return {\n            'id': video_id or display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': json_data.get('image'),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dfb.DFBIE._real_extract#25",
        "src_path": "youtube_dl/extractor/dfb.py",
        "class_name": "youtube_dl.extractor.dfb.DFBIE",
        "signature": "youtube_dl.extractor.dfb.DFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id, video_id = re.match(self._VALID_URL, url).groups()\n\n        player_info = self._download_xml(\n            'http://tv.dfb.de/server/hd_video.php?play=%s' % video_id,\n            display_id)\n        video_info = player_info.find('video')\n        stream_access_url = self._proto_relative_url(video_info.find('url').text.strip())\n\n        formats = []\n        # see http://tv.dfb.de/player/js/ajax.js for the method to extract m3u8 formats\n        for sa_url in (stream_access_url, stream_access_url + '&area=&format=iphone'):\n            stream_access_info = self._download_xml(sa_url, display_id)\n            token_el = stream_access_info.find('token')\n            manifest_url = token_el.attrib['url'] + '?' + 'hdnea=' + token_el.attrib['auth']\n            if '.f4m' in manifest_url:\n                formats.extend(self._extract_f4m_formats(\n                    manifest_url + '&hdcore=3.2.0',\n                    display_id, f4m_id='hds', fatal=False))\n            else:\n                formats.extend(self._extract_m3u8_formats(\n                    manifest_url, display_id, 'mp4',\n                    'm3u8_native', m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': video_info.find('title').text,\n            'thumbnail': 'http://tv.dfb.de/images/%s_640x360.jpg' % video_id,\n            'upload_date': unified_strdate(video_info.find('time_date').text),\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dhm.DHMIE._real_extract#33",
        "src_path": "youtube_dl/extractor/dhm.py",
        "class_name": "youtube_dl.extractor.dhm.DHMIE",
        "signature": "youtube_dl.extractor.dhm.DHMIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist_url = self._search_regex(\n            r\"file\\s*:\\s*'([^']+)'\", webpage, 'playlist url')\n\n        entries = self._extract_xspf_playlist(playlist_url, playlist_id)\n\n        title = self._search_regex(\n            [r'dc:title=\"([^\"]+)\"', r'<title> &raquo;([^<]+)</title>'],\n            webpage, 'title').strip()\n        description = self._html_search_regex(\n            r'<p><strong>Description:</strong>(.+?)</p>',\n            webpage, 'description', default=None)\n        duration = parse_duration(self._search_regex(\n            r'<em>Length\\s*</em>\\s*:\\s*</strong>([^<]+)',\n            webpage, 'duration', default=None))\n\n        entries[0].update({\n            'title': title,\n            'description': description,\n            'duration': duration,\n        })\n\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 33,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.digiteka.DigitekaIE._extract_url#65",
        "src_path": "youtube_dl/extractor/digiteka.py",
        "class_name": "youtube_dl.extractor.digiteka.DigitekaIE",
        "signature": "youtube_dl.extractor.digiteka.DigitekaIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<(?:iframe|script)[^>]+src=[\"\\'](?P<url>(?:https?:)?//(?:www\\.)?ultimedia\\.com/deliver/(?:generic|musique)(?:/[^/]+)*/(?:src|article)/[\\d+a-z]+)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 65,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.digiteka.DigitekaIE._real_extract#72",
        "src_path": "youtube_dl/extractor/digiteka.py",
        "class_name": "youtube_dl.extractor.digiteka.DigitekaIE",
        "signature": "youtube_dl.extractor.digiteka.DigitekaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_type = mobj.group('embed_type') or mobj.group('site_type')\n        if video_type == 'music':\n            video_type = 'musique'\n\n        deliver_info = self._download_json(\n            'http://www.ultimedia.com/deliver/video?video=%s&topic=%s' % (video_id, video_type),\n            video_id)\n\n        yt_id = deliver_info.get('yt_id')\n        if yt_id:\n            return self.url_result(yt_id, 'Youtube')\n\n        jwconf = deliver_info['jwconf']\n\n        formats = []\n        for source in jwconf['playlist'][0]['sources']:\n            formats.append({\n                'url': source['file'],\n                'format_id': source.get('label'),\n            })\n\n        self._sort_formats(formats)\n\n        title = deliver_info['title']\n        thumbnail = jwconf.get('image')\n        duration = int_or_none(deliver_info.get('duration'))\n        timestamp = int_or_none(deliver_info.get('release_time'))\n        uploader_id = deliver_info.get('owner_id')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 72,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract#65",
        "src_path": "youtube_dl/extractor/discovery.py",
        "class_name": "youtube_dl.extractor.discovery.DiscoveryIE",
        "signature": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        info = self._download_json(url + '?flat=1', display_id)\n\n        video_title = info.get('playlist_title') or info.get('video_title')\n\n        entries = []\n\n        for idx, video_info in enumerate(info['playlist']):\n            subtitles = {}\n            caption_url = video_info.get('captionsUrl')\n            if caption_url:\n                subtitles = {\n                    'en': [{\n                        'url': caption_url,\n                    }]\n                }\n\n            entries.append({\n                '_type': 'url_transparent',\n                'url': 'http://players.brightcove.net/103207/default_default/index.html?videoId=ref:%s' % video_info['referenceId'],\n                'id': compat_str(video_info['id']),\n                'title': video_info['title'],\n                'description': video_info.get('description'),\n                'duration': parse_duration(video_info.get('video_length')),\n                'webpage_url': video_info.get('href') or video_info.get('url'),\n                'thumbnail': video_info.get('thumbnailURL'),\n                'alt_title': video_info.get('secondary_title'),\n                'timestamp': parse_iso8601(video_info.get('publishedDate')),\n                'subtitles': subtitles,\n            })\n\n        return self.playlist_result(entries, display_id, video_title)",
        "begin_line": 65,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discoverygo.DiscoveryGoIE._real_extract#49",
        "src_path": "youtube_dl/extractor/discoverygo.py",
        "class_name": "youtube_dl.extractor.discoverygo.DiscoveryGoIE",
        "signature": "youtube_dl.extractor.discoverygo.DiscoveryGoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        container = extract_attributes(\n            self._search_regex(\n                r'(<div[^>]+class=[\"\\']video-player-container[^>]+>)',\n                webpage, 'video container'))\n\n        video = self._parse_json(\n            container.get('data-video') or container.get('data-json'),\n            display_id)\n\n        title = video['name']\n\n        stream = video.get('stream')\n        if not stream:\n            if video.get('authenticated') is True:\n                raise ExtractorError(\n                    'This video is only available via cable service provider subscription that'\n                    ' is not currently supported. You may want to use --cookies.', expected=True)\n            else:\n                raise ExtractorError('Unable to find stream')\n        STREAM_URL_SUFFIX = 'streamUrl'\n        formats = []\n        for stream_kind in ('', 'hds'):\n            suffix = STREAM_URL_SUFFIX.capitalize() if stream_kind else STREAM_URL_SUFFIX\n            stream_url = stream.get('%s%s' % (stream_kind, suffix))\n            if not stream_url:\n                continue\n            if stream_kind == '':\n                formats.extend(self._extract_m3u8_formats(\n                    stream_url, display_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif stream_kind == 'hds':\n                formats.extend(self._extract_f4m_formats(\n                    stream_url, display_id, f4m_id=stream_kind, fatal=False))\n        self._sort_formats(formats)\n\n        video_id = video.get('id') or display_id\n        description = video.get('description', {}).get('detailed')\n        duration = int_or_none(video.get('duration'))\n\n        series = video.get('show', {}).get('name')\n        season_number = int_or_none(video.get('season', {}).get('number'))\n        episode_number = int_or_none(video.get('episodeNumber'))\n\n        tags = video.get('tags')\n        age_limit = parse_age_limit(video.get('parental', {}).get('rating'))\n\n        subtitles = {}\n        captions = stream.get('captions')\n        if isinstance(captions, list):\n            for caption in captions:\n                subtitle_url = caption.get('fileUrl')\n                if (not subtitle_url or not isinstance(subtitle_url, compat_str) or\n                        not subtitle_url.startswith('http')):\n                    continue\n                lang = caption.get('fileLang', 'en')\n                subtitles.setdefault(lang, []).append({'url': subtitle_url})\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'series': series,\n            'season_number': season_number,\n            'episode_number': episode_number,\n            'tags': tags,\n            'age_limit': age_limit,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 49,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE.suitable#140",
        "src_path": "youtube_dl/extractor/discoverygo.py",
        "class_name": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE",
        "signature": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if DiscoveryGoIE.suitable(url) else super(\n            DiscoveryGoPlaylistIE, cls).suitable(url)",
        "begin_line": 140,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE._real_extract#144",
        "src_path": "youtube_dl/extractor/discoverygo.py",
        "class_name": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE",
        "signature": "youtube_dl.extractor.discoverygo.DiscoveryGoPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        entries = []\n        for mobj in re.finditer(r'data-json=([\"\\'])(?P<json>{.+?})\\1', webpage):\n            data = self._parse_json(\n                mobj.group('json'), display_id,\n                transform_source=unescapeHTML, fatal=False)\n            if not isinstance(data, dict) or data.get('type') != 'episode':\n                continue\n            episode_url = data.get('socialUrl')\n            if not episode_url:\n                continue\n            entries.append(self.url_result(\n                episode_url, ie=DiscoveryGoIE.ie_key(),\n                video_id=data.get('id')))\n\n        return self.playlist_result(\n            entries, display_id,\n            remove_end(self._og_search_title(\n                webpage, fatal=False), ' | Discovery GO'),\n            self._og_search_description(webpage))",
        "begin_line": 144,
        "end_line": 167,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discoverynetworks.DiscoveryNetworksDeIE._real_extract#41",
        "src_path": "youtube_dl/extractor/discoverynetworks.py",
        "class_name": "youtube_dl.extractor.discoverynetworks.DiscoveryNetworksDeIE",
        "signature": "youtube_dl.extractor.discoverynetworks.DiscoveryNetworksDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        brightcove_id = mobj.group('id')\n        if not brightcove_id:\n            title = mobj.group('title')\n            webpage = self._download_webpage(url, title)\n            brightcove_legacy_url = BrightcoveLegacyIE._extract_brightcove_url(webpage)\n            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(\n                brightcove_legacy_url).query)['@videoPlayer'][0]\n        return self.url_result(smuggle_url(\n            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, {'geo_countries': ['DE']}),\n            'BrightcoveNew', brightcove_id)",
        "begin_line": 41,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.discoveryvr.DiscoveryVRIE._real_extract#21",
        "src_path": "youtube_dl/extractor/discoveryvr.py",
        "class_name": "youtube_dl.extractor.discoveryvr.DiscoveryVRIE",
        "signature": "youtube_dl.extractor.discoveryvr.DiscoveryVRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        bootstrap_data = self._search_regex(\n            r'root\\.DVR\\.bootstrapData\\s+=\\s+\"({.+?})\";',\n            webpage, 'bootstrap data')\n        bootstrap_data = self._parse_json(\n            bootstrap_data.encode('utf-8').decode('unicode_escape'),\n            display_id)\n        videos = self._parse_json(bootstrap_data['videos'], display_id)['allVideos']\n        video_data = next(video for video in videos if video.get('slug') == display_id)\n\n        series = video_data.get('showTitle')\n        title = episode = video_data.get('title') or series\n        if series and series != title:\n            title = '%s - %s' % (series, title)\n\n        formats = []\n        for f, format_id in (('cdnUriM3U8', 'mobi'), ('webVideoUrlSd', 'sd'), ('webVideoUrlHd', 'hd')):\n            f_url = video_data.get(f)\n            if not f_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': f_url,\n            })\n\n        return {\n            'id': display_id,\n            'display_id': display_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnail'),\n            'duration': parse_duration(video_data.get('runTime')),\n            'formats': formats,\n            'episode': episode,\n            'series': series,\n        }",
        "begin_line": 21,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.disney.DisneyIE._real_extract#79",
        "src_path": "youtube_dl/extractor/disney.py",
        "class_name": "youtube_dl.extractor.disney.DisneyIE",
        "signature": "youtube_dl.extractor.disney.DisneyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, video_id, display_id = re.match(self._VALID_URL, url).groups()\n        if not video_id:\n            webpage = self._download_webpage(url, display_id)\n            grill = re.sub(r'\"\\s*\\+\\s*\"', '', self._search_regex(\n                r'Grill\\.burger\\s*=\\s*({.+})\\s*:',\n                webpage, 'grill data'))\n            page_data = next(s for s in self._parse_json(grill, display_id)['stack'] if s.get('type') == 'video')\n            video_data = page_data['data'][0]\n        else:\n            webpage = self._download_webpage(\n                'http://%s/embed/%s' % (domain, video_id), video_id)\n            page_data = self._parse_json(self._search_regex(\n                r'Disney\\.EmbedVideo\\s*=\\s*({.+});',\n                webpage, 'embed data'), video_id)\n            video_data = page_data['video']\n\n        for external in video_data.get('externals', []):\n            if external.get('source') == 'vevo':\n                return self.url_result('vevo:' + external['data_id'], 'Vevo')\n\n        video_id = video_data['id']\n        title = video_data['title']\n\n        formats = []\n        for flavor in video_data.get('flavors', []):\n            flavor_format = flavor.get('format')\n            flavor_url = flavor.get('url')\n            if not flavor_url or not re.match(r'https?://', flavor_url) or flavor_format == 'mp4_access':\n                continue\n            tbr = int_or_none(flavor.get('bitrate'))\n            if tbr == 99999:\n                formats.extend(self._extract_m3u8_formats(\n                    flavor_url, video_id, 'mp4',\n                    m3u8_id=flavor_format, fatal=False))\n                continue\n            format_id = []\n            if flavor_format:\n                format_id.append(flavor_format)\n            if tbr:\n                format_id.append(compat_str(tbr))\n            ext = determine_ext(flavor_url)\n            if flavor_format == 'applehttp' or ext == 'm3u8':\n                ext = 'mp4'\n            width = int_or_none(flavor.get('width'))\n            height = int_or_none(flavor.get('height'))\n            formats.append({\n                'format_id': '-'.join(format_id),\n                'url': flavor_url,\n                'width': width,\n                'height': height,\n                'tbr': tbr,\n                'ext': ext,\n                'vcodec': 'none' if (width == 0 and height == 0) else None,\n            })\n        if not formats and video_data.get('expired'):\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, page_data['translations']['video_expired']),\n                expected=True)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for caption in video_data.get('captions', []):\n            caption_url = caption.get('url')\n            caption_format = caption.get('format')\n            if not caption_url or caption_format.startswith('unknown'):\n                continue\n            subtitles.setdefault(caption.get('language', 'en'), []).append({\n                'url': caption_url,\n                'ext': {\n                    'webvtt': 'vtt',\n                }.get(caption_format, caption_format),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description') or video_data.get('short_desc'),\n            'thumbnail': video_data.get('thumb') or video_data.get('thumb_secure'),\n            'duration': int_or_none(video_data.get('duration_sec')),\n            'upload_date': unified_strdate(video_data.get('publish_date')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 79,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._parse_mp4#37",
        "src_path": "youtube_dl/extractor/dispeak.py",
        "class_name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE",
        "signature": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._parse_mp4(self, metadata)",
        "snippet": "    def _parse_mp4(self, metadata):\n        video_formats = []\n        video_root = None\n\n        mp4_video = xpath_text(metadata, './mp4video', default=None)\n        if mp4_video is not None:\n            mobj = re.match(r'(?P<root>https?://.*?/).*', mp4_video)\n            video_root = mobj.group('root')\n        if video_root is None:\n            http_host = xpath_text(metadata, 'httpHost', default=None)\n            if http_host:\n                video_root = 'http://%s/' % http_host\n        if video_root is None:\n            # Hard-coded in http://evt.dispeak.com/ubm/gdc/sf16/custom/player2.js\n            # Works for GPUTechConf, too\n            video_root = 'http://s3-2u.digitallyspeaking.com/'\n\n        formats = metadata.findall('./MBRVideos/MBRVideo')\n        if not formats:\n            return None\n        for a_format in formats:\n            stream_name = xpath_text(a_format, 'streamName', fatal=True)\n            video_path = re.match(r'mp4\\:(?P<path>.*)', stream_name).group('path')\n            url = video_root + video_path\n            vbr = xpath_text(a_format, 'bitrate')\n            video_formats.append({\n                'url': url,\n                'vbr': int_or_none(vbr),\n            })\n        return video_formats",
        "begin_line": 37,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._parse_flv#68",
        "src_path": "youtube_dl/extractor/dispeak.py",
        "class_name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE",
        "signature": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._parse_flv(self, metadata)",
        "snippet": "    def _parse_flv(self, metadata):\n        formats = []\n        akamai_url = xpath_text(metadata, './akamaiHost', fatal=True)\n        audios = metadata.findall('./audios/audio')\n        for audio in audios:\n            formats.append({\n                'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n                'play_path': remove_end(audio.get('url'), '.flv'),\n                'ext': 'flv',\n                'vcodec': 'none',\n                'format_id': audio.get('code'),\n            })\n        slide_video_path = xpath_text(metadata, './slideVideo', fatal=True)\n        formats.append({\n            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n            'play_path': remove_end(slide_video_path, '.flv'),\n            'ext': 'flv',\n            'format_note': 'slide deck video',\n            'quality': -2,\n            'preference': -2,\n            'format_id': 'slides',\n        })\n        speaker_video_path = xpath_text(metadata, './speakerVideo', fatal=True)\n        formats.append({\n            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,\n            'play_path': remove_end(speaker_video_path, '.flv'),\n            'ext': 'flv',\n            'format_note': 'speaker video',\n            'quality': -1,\n            'preference': -1,\n            'format_id': 'speaker',\n        })\n        return formats",
        "begin_line": 68,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._real_extract#102",
        "src_path": "youtube_dl/extractor/dispeak.py",
        "class_name": "youtube_dl.extractor.dispeak.DigitallySpeakingIE",
        "signature": "youtube_dl.extractor.dispeak.DigitallySpeakingIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        xml_description = self._download_xml(url, video_id)\n        metadata = xpath_element(xml_description, 'metadata')\n\n        video_formats = self._parse_mp4(metadata)\n        if video_formats is None:\n            video_formats = self._parse_flv(metadata)\n\n        return {\n            'id': video_id,\n            'formats': video_formats,\n            'title': xpath_text(metadata, 'title', fatal=True),\n            'duration': parse_duration(xpath_text(metadata, 'endTime')),\n            'creator': xpath_text(metadata, 'speaker'),\n        }",
        "begin_line": 102,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dotsub.DotsubIE._real_extract#46",
        "src_path": "youtube_dl/extractor/dotsub.py",
        "class_name": "youtube_dl.extractor.dotsub.DotsubIE",
        "signature": "youtube_dl.extractor.dotsub.DotsubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'https://dotsub.com/api/media/%s/metadata' % video_id, video_id)\n        video_url = info.get('mediaURI')\n\n        if not video_url:\n            webpage = self._download_webpage(url, video_id)\n            video_url = self._search_regex(\n                [r'<source[^>]+src=\"([^\"]+)\"', r'\"file\"\\s*:\\s*\\'([^\\']+)'],\n                webpage, 'video url', default=None)\n            info_dict = {\n                'id': video_id,\n                'url': video_url,\n                'ext': 'flv',\n            }\n\n        if not video_url:\n            setup_data = self._parse_json(self._html_search_regex(\n                r'(?s)data-setup=([\\'\"])(?P<content>(?!\\1).+?)\\1',\n                webpage, 'setup data', group='content'), video_id)\n            info_dict = {\n                '_type': 'url_transparent',\n                'url': setup_data['src'],\n            }\n\n        info_dict.update({\n            'title': info['title'],\n            'description': info.get('description'),\n            'thumbnail': info.get('screenshotURI'),\n            'duration': int_or_none(info.get('duration'), 1000),\n            'uploader': info.get('user'),\n            'timestamp': float_or_none(info.get('dateCreated'), 1000),\n            'view_count': int_or_none(info.get('numberOfViews')),\n        })\n\n        return info_dict",
        "begin_line": 46,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.douyutv.DouyuTVIE._real_extract#75",
        "src_path": "youtube_dl/extractor/douyutv.py",
        "class_name": "youtube_dl.extractor.douyutv.DouyuTVIE",
        "signature": "youtube_dl.extractor.douyutv.DouyuTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        if video_id.isdigit():\n            room_id = video_id\n        else:\n            page = self._download_webpage(url, video_id)\n            room_id = self._html_search_regex(\n                r'\"room_id\\\\?\"\\s*:\\s*(\\d+),', page, 'room id')\n\n        # Grab metadata from mobile API\n        room = self._download_json(\n            'http://m.douyu.com/html5/live?roomId=%s' % room_id, video_id,\n            note='Downloading room info')['data']\n\n        # 1 = live, 2 = offline\n        if room.get('show_status') == '2':\n            raise ExtractorError('Live stream is offline', expected=True)\n\n        # Grab the URL from PC client API\n        # The m3u8 url from mobile API requires re-authentication every 5 minutes\n        tt = int(time.time())\n        signContent = 'lapi/live/thirdPart/getPlay/%s?aid=pcclient&rate=0&time=%d9TUk5fjjUjg9qIMH3sdnh' % (room_id, tt)\n        sign = hashlib.md5(signContent.encode('ascii')).hexdigest()\n        video_url = self._download_json(\n            'http://coapi.douyucdn.cn/lapi/live/thirdPart/getPlay/' + room_id,\n            video_id, note='Downloading video URL info',\n            query={'rate': 0}, headers={\n                'auth': sign,\n                'time': str(tt),\n                'aid': 'pcclient'\n            })['data']['live_url']\n\n        title = self._live_title(unescapeHTML(room['room_name']))\n        description = room.get('show_details')\n        thumbnail = room.get('room_src')\n        uploader = room.get('nickname')\n\n        return {\n            'id': room_id,\n            'display_id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'is_live': True,\n        }",
        "begin_line": 75,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.douyutv.DouyuShowIE._real_extract#147",
        "src_path": "youtube_dl/extractor/douyutv.py",
        "class_name": "youtube_dl.extractor.douyutv.DouyuShowIE",
        "signature": "youtube_dl.extractor.douyutv.DouyuShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url = url.replace('vmobile.', 'v.')\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        room_info = self._parse_json(self._search_regex(\n            r'var\\s+\\$ROOM\\s*=\\s*({.+});', webpage, 'room info'), video_id)\n\n        video_info = None\n\n        for trial in range(5):\n            # Sometimes Douyu rejects our request. Let's try it more times\n            try:\n                video_info = self._download_json(\n                    'https://vmobile.douyu.com/video/getInfo', video_id,\n                    query={'vid': video_id},\n                    headers={\n                        'Referer': url,\n                        'x-requested-with': 'XMLHttpRequest',\n                    })\n                break\n            except ExtractorError:\n                self._sleep(1, video_id)\n\n        if not video_info:\n            raise ExtractorError('Can\\'t fetch video info')\n\n        formats = self._extract_m3u8_formats(\n            video_info['data']['video_url'], video_id,\n            entry_protocol='m3u8_native', ext='mp4')\n\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<em>\u4e0a\u4f20\u65f6\u95f4\uff1a</em><span>([^<]+)</span>', webpage,\n            'upload date', fatal=False))\n\n        uploader = uploader_id = uploader_url = None\n        mobj = re.search(\n            r'(?m)<a[^>]+href=\"/author/([0-9a-zA-Z]+)\".+?<strong[^>]+title=\"([^\"]+)\"',\n            webpage)\n        if mobj:\n            uploader_id, uploader = mobj.groups()\n            uploader_url = urljoin(url, '/author/' + uploader_id)\n\n        return {\n            'id': video_id,\n            'title': room_info['name'],\n            'formats': formats,\n            'duration': room_info.get('duration'),\n            'thumbnail': room_info.get('pic'),\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'uploader_url': uploader_url,\n        }",
        "begin_line": 147,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dplay.DPlayIE._real_extract#70",
        "src_path": "youtube_dl/extractor/dplay.py",
        "class_name": "youtube_dl.extractor.dplay.DPlayIE",
        "signature": "youtube_dl.extractor.dplay.DPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        domain = mobj.group('domain')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'data-video-id=[\"\\'](\\d+)', webpage, 'video id')\n\n        info = self._download_json(\n            'http://%s/api/v2/ajax/videos?video_id=%s' % (domain, video_id),\n            video_id)['data'][0]\n\n        title = info['title']\n\n        PROTOCOLS = ('hls', 'hds')\n        formats = []\n\n        def extract_formats(protocol, manifest_url):\n            if protocol == 'hls':\n                m3u8_formats = self._extract_m3u8_formats(\n                    manifest_url, video_id, ext='mp4',\n                    entry_protocol='m3u8_native', m3u8_id=protocol, fatal=False)\n                # Sometimes final URLs inside m3u8 are unsigned, let's fix this\n                # ourselves. Also fragments' URLs are only served signed for\n                # Safari user agent.\n                query = compat_urlparse.parse_qs(compat_urlparse.urlparse(manifest_url).query)\n                for m3u8_format in m3u8_formats:\n                    m3u8_format.update({\n                        'url': update_url_query(m3u8_format['url'], query),\n                        'http_headers': {\n                            'User-Agent': USER_AGENTS['Safari'],\n                        },\n                    })\n                formats.extend(m3u8_formats)\n            elif protocol == 'hds':\n                formats.extend(self._extract_f4m_formats(\n                    manifest_url + '&hdcore=3.8.0&plugin=flowplayer-3.8.0.0',\n                    video_id, f4m_id=protocol, fatal=False))\n\n        domain_tld = domain.split('.')[-1]\n        if domain_tld in ('se', 'dk', 'no'):\n            for protocol in PROTOCOLS:\n                # Providing dsc-geo allows to bypass geo restriction in some cases\n                self._set_cookie(\n                    'secure.dplay.%s' % domain_tld, 'dsc-geo',\n                    json.dumps({\n                        'countryCode': domain_tld.upper(),\n                        'expiry': (time.time() + 20 * 60) * 1000,\n                    }))\n                stream = self._download_json(\n                    'https://secure.dplay.%s/secure/api/v2/user/authorization/stream/%s?stream_type=%s'\n                    % (domain_tld, video_id, protocol), video_id,\n                    'Downloading %s stream JSON' % protocol, fatal=False)\n                if stream and stream.get(protocol):\n                    extract_formats(protocol, stream[protocol])\n\n        # The last resort is to try direct unsigned hls/hds URLs from info dictionary.\n        # Sometimes this does work even when secure API with dsc-geo has failed (e.g.\n        # http://www.dplay.no/pga-tour/season-1-hoydepunkter-18-21-februar/).\n        if not formats:\n            for protocol in PROTOCOLS:\n                if info.get(protocol):\n                    extract_formats(protocol, info[protocol])\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for lang in ('se', 'sv', 'da', 'nl', 'no'):\n            for format_id in ('web_vtt', 'vtt', 'srt'):\n                subtitle_url = info.get('subtitles_%s_%s' % (lang, format_id))\n                if subtitle_url:\n                    subtitles.setdefault(lang, []).append({'url': subtitle_url})\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': info.get('video_metadata_longDescription'),\n            'duration': int_or_none(info.get('video_metadata_length'), scale=1000),\n            'timestamp': int_or_none(info.get('video_publish_date')),\n            'creator': info.get('video_metadata_homeChannel'),\n            'series': info.get('video_metadata_show'),\n            'season_number': int_or_none(info.get('season')),\n            'episode_number': int_or_none(info.get('episode')),\n            'age_limit': int_or_none(info.get('minimum_age')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 70,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dplay.DPlayItIE._real_extract#183",
        "src_path": "youtube_dl/extractor/dplay.py",
        "class_name": "youtube_dl.extractor.dplay.DPlayItIE",
        "signature": "youtube_dl.extractor.dplay.DPlayItIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = remove_end(self._og_search_title(webpage), ' | Dplay')\n\n        video_id = None\n\n        info = self._search_regex(\n            r'playback_json\\s*:\\s*JSON\\.parse\\s*\\(\\s*(\"(?:\\\\.|[^\"\\\\])+?\")',\n            webpage, 'playback JSON', default=None)\n        if info:\n            for _ in range(2):\n                info = self._parse_json(info, display_id, fatal=False)\n                if not info:\n                    break\n            else:\n                video_id = try_get(info, lambda x: x['data']['id'])\n\n        if not info:\n            info_url = self._search_regex(\n                r'url\\s*[:=]\\s*[\"\\']((?:https?:)?//[^/]+/playback/videoPlaybackInfo/\\d+)',\n                webpage, 'info url')\n\n            video_id = info_url.rpartition('/')[-1]\n\n            try:\n                info = self._download_json(\n                    info_url, display_id, headers={\n                        'Authorization': 'Bearer %s' % self._get_cookies(url).get(\n                            'dplayit_token').value,\n                        'Referer': url,\n                    })\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code in (400, 403):\n                    info = self._parse_json(e.cause.read().decode('utf-8'), display_id)\n                    error = info['errors'][0]\n                    if error.get('code') == 'access.denied.geoblocked':\n                        self.raise_geo_restricted(\n                            msg=error.get('detail'), countries=self._GEO_COUNTRIES)\n                    raise ExtractorError(info['errors'][0]['detail'], expected=True)\n                raise\n\n        hls_url = info['data']['attributes']['streaming']['hls']['url']\n\n        formats = self._extract_m3u8_formats(\n            hls_url, display_id, ext='mp4', entry_protocol='m3u8_native',\n            m3u8_id='hls')\n\n        series = self._html_search_regex(\n            r'(?s)<h1[^>]+class=[\"\\'].*?\\bshow_title\\b.*?[\"\\'][^>]*>(.+?)</h1>',\n            webpage, 'series', fatal=False)\n        episode = self._search_regex(\n            r'<p[^>]+class=[\"\\'].*?\\bdesc_ep\\b.*?[\"\\'][^>]*>\\s*<br/>\\s*<b>([^<]+)',\n            webpage, 'episode', fatal=False)\n\n        mobj = re.search(\n            r'(?s)<span[^>]+class=[\"\\']dates[\"\\'][^>]*>.+?\\bS\\.(?P<season_number>\\d+)\\s+E\\.(?P<episode_number>\\d+)\\s*-\\s*(?P<upload_date>\\d{2}/\\d{2}/\\d{4})',\n            webpage)\n        if mobj:\n            season_number = int(mobj.group('season_number'))\n            episode_number = int(mobj.group('episode_number'))\n            upload_date = unified_strdate(mobj.group('upload_date'))\n        else:\n            season_number = episode_number = upload_date = None\n\n        return {\n            'id': compat_str(video_id or display_id),\n            'display_id': display_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'series': series,\n            'season_number': season_number,\n            'episode': episode,\n            'episode_number': episode_number,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 183,
        "end_line": 262,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._get_consumer_secret#30",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._get_consumer_secret(self)",
        "snippet": "    def _get_consumer_secret(self):\n        mainjs = self._download_webpage(\n            'http://www.dramafever.com/static/51afe95/df2014/scripts/main.js',\n            None, 'Downloading main.js', fatal=False)\n        if not mainjs:\n            return self._CONSUMER_SECRET\n        return self._search_regex(\n            r\"var\\s+cs\\s*=\\s*'([^']+)'\", mainjs,\n            'consumer secret', default=self._CONSUMER_SECRET)",
        "begin_line": 30,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._real_initialize#40",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()\n        self._consumer_secret = self._get_consumer_secret()",
        "begin_line": 40,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._login#44",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverBaseIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form))\n        response = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if all(logout_pattern not in response\n               for logout_pattern in ['href=\"/accounts/logout/\"', '>Log out<']):\n            error = self._html_search_regex(\n                r'(?s)class=\"hidden-xs prompt\"[^>]*>(.+?)<',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 44,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverIE._real_extract#113",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url).replace('/', '.')\n\n        try:\n            info = self._extract_feed_info(\n                'http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                self.raise_geo_restricted(\n                    msg='Currently unavailable in your country',\n                    countries=self._GEO_COUNTRIES)\n            raise\n\n        # title is postfixed with video id for some reason, removing\n        if info.get('title'):\n            info['title'] = remove_end(info['title'], video_id).strip()\n\n        series_id, episode_number = video_id.split('.')\n        episode_info = self._download_json(\n            # We only need a single episode info, so restricting page size to one episode\n            # and dealing with page number as with episode number\n            r'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_number=%s&page_size=1'\n            % (self._consumer_secret, series_id, episode_number),\n            video_id, 'Downloading episode info JSON', fatal=False)\n        if episode_info:\n            value = episode_info.get('value')\n            if isinstance(value, list):\n                for v in value:\n                    if v.get('type') == 'Episode':\n                        subfile = v.get('subfile') or v.get('new_subfile')\n                        if subfile and subfile != 'http://www.dramafever.com/st/':\n                            info.setdefault('subtitles', {}).setdefault('English', []).append({\n                                'ext': 'srt',\n                                'url': subfile,\n                            })\n                        episode_number = int_or_none(v.get('number'))\n                        episode_fallback = 'Episode'\n                        if episode_number:\n                            episode_fallback += ' %d' % episode_number\n                        info['episode'] = v.get('title') or episode_fallback\n                        info['episode_number'] = episode_number\n                        break\n\n        return info",
        "begin_line": 113,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE._real_extract#182",
        "src_path": "youtube_dl/extractor/dramafever.py",
        "class_name": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE",
        "signature": "youtube_dl.extractor.dramafever.DramaFeverSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        series_id = self._match_id(url)\n\n        series = self._download_json(\n            'http://www.dramafever.com/api/4/series/query/?cs=%s&series_id=%s'\n            % (self._consumer_secret, series_id),\n            series_id, 'Downloading series JSON')['series'][series_id]\n\n        title = clean_html(series['name'])\n        description = clean_html(series.get('description') or series.get('description_short'))\n\n        entries = []\n        for page_num in itertools.count(1):\n            episodes = self._download_json(\n                'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_size=%d&page_number=%d'\n                % (self._consumer_secret, series_id, self._PAGE_SIZE, page_num),\n                series_id, 'Downloading episodes JSON page #%d' % page_num)\n            for episode in episodes.get('value', []):\n                episode_url = episode.get('episode_url')\n                if not episode_url:\n                    continue\n                entries.append(self.url_result(\n                    compat_urlparse.urljoin(url, episode_url),\n                    'DramaFever', episode.get('guid')))\n            if page_num == episodes['num_pages']:\n                break\n\n        return self.playlist_result(entries, series_id, title, description)",
        "begin_line": 182,
        "end_line": 209,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.drbonanza.DRBonanzaIE._real_extract#28",
        "src_path": "youtube_dl/extractor/drbonanza.py",
        "class_name": "youtube_dl.extractor.drbonanza.DRBonanzaIE",
        "signature": "youtube_dl.extractor.drbonanza.DRBonanzaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, display_id = mobj.group('id', 'display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        info = self._parse_html5_media_entries(\n            url, webpage, display_id, m3u8_id='hls',\n            m3u8_entry_protocol='m3u8_native')[0]\n        self._sort_formats(info['formats'])\n\n        asset = self._parse_json(\n            self._search_regex(\n                r'(?s)currentAsset\\s*=\\s*({.+?})\\s*</script', webpage, 'asset'),\n            display_id, transform_source=js_to_json)\n\n        title = unescapeHTML(asset['AssetTitle']).strip()\n\n        def extract(field):\n            return self._search_regex(\n                r'<div[^>]+>\\s*<p>%s:<p>\\s*</div>\\s*<div[^>]+>\\s*<p>([^<]+)</p>' % field,\n                webpage, field, default=None)\n\n        info.update({\n            'id': asset.get('AssetId') or video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': extract('Programinfo'),\n            'duration': parse_duration(extract('Tid')),\n            'thumbnail': asset.get('AssetImageUrl'),\n        })\n        return info",
        "begin_line": 28,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE._parse_smil_formats#43",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE._parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None)",
        "snippet": "    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):\n        param_groups = {}\n        for param_group in smil.findall(self._xpath_ns('./head/paramGroup', namespace)):\n            group_id = param_group.attrib.get(self._xpath_ns('id', 'http://www.w3.org/XML/1998/namespace'))\n            params = {}\n            for param in param_group:\n                params[param.get('name')] = param.get('value')\n            param_groups[group_id] = params\n\n        formats = []\n        for video in smil.findall(self._xpath_ns('.//video', namespace)):\n            src = video.get('src')\n            if not src:\n                continue\n            bitrate = float_or_none(video.get('system-bitrate') or video.get('systemBitrate'), 1000)\n            group_id = video.get('paramGroup')\n            param_group = param_groups[group_id]\n            for proto in param_group['protocols'].split(','):\n                formats.append({\n                    'url': '%s://%s' % (proto, param_group['host']),\n                    'app': param_group['app'],\n                    'play_path': src,\n                    'ext': 'flv',\n                    'format_id': '%s-%d' % (proto, bitrate),\n                    'tbr': bitrate,\n                })\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 43,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE.extract_from_xml_url#72",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE.extract_from_xml_url(self, video_id, xml_url)",
        "snippet": "    def extract_from_xml_url(self, video_id, xml_url):\n        doc = self._download_xml(\n            xml_url, video_id,\n            note='Downloading video info',\n            errnote='Failed to download video info')\n\n        status_code = doc.find('./status/statuscode')\n        if status_code is not None and status_code.text != 'ok':\n            code = status_code.text\n            if code == 'notVisibleAnymore':\n                message = 'Video %s is not available' % video_id\n            else:\n                message = '%s returned error: %s' % (self.IE_NAME, code)\n            raise ExtractorError(message, expected=True)\n\n        title = doc.find('.//information/title').text\n        description = xpath_text(doc, './/information/detail', 'description')\n        duration = int_or_none(xpath_text(doc, './/details/lengthSec', 'duration'))\n        uploader = xpath_text(doc, './/details/originChannelTitle', 'uploader')\n        uploader_id = xpath_text(doc, './/details/originChannelId', 'uploader id')\n        upload_date = unified_strdate(xpath_text(doc, './/details/airtime', 'upload date'))\n\n        def xml_to_thumbnails(fnode):\n            thumbnails = []\n            for node in fnode:\n                thumbnail_url = node.text\n                if not thumbnail_url:\n                    continue\n                thumbnail = {\n                    'url': thumbnail_url,\n                }\n                if 'key' in node.attrib:\n                    m = re.match('^([0-9]+)x([0-9]+)$', node.attrib['key'])\n                    if m:\n                        thumbnail['width'] = int(m.group(1))\n                        thumbnail['height'] = int(m.group(2))\n                thumbnails.append(thumbnail)\n            return thumbnails\n\n        thumbnails = xml_to_thumbnails(doc.findall('.//teaserimages/teaserimage'))\n\n        format_nodes = doc.findall('.//formitaeten/formitaet')\n        quality = qualities(['veryhigh', 'high', 'med', 'low'])\n\n        def get_quality(elem):\n            return quality(xpath_text(elem, 'quality'))\n        format_nodes.sort(key=get_quality)\n        format_ids = []\n        formats = []\n        for fnode in format_nodes:\n            video_url = fnode.find('url').text\n            is_available = 'http://www.metafilegenerator' not in video_url\n            if not is_available:\n                continue\n            format_id = fnode.attrib['basetype']\n            quality = xpath_text(fnode, './quality', 'quality')\n            format_m = re.match(r'''(?x)\n                (?P<vcodec>[^_]+)_(?P<acodec>[^_]+)_(?P<container>[^_]+)_\n                (?P<proto>[^_]+)_(?P<index>[^_]+)_(?P<indexproto>[^_]+)\n            ''', format_id)\n\n            ext = determine_ext(video_url, None) or format_m.group('container')\n            if ext not in ('smil', 'f4m', 'm3u8'):\n                format_id = format_id + '-' + quality\n            if format_id in format_ids:\n                continue\n\n            if ext == 'meta':\n                continue\n            elif ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    video_url, video_id, fatal=False))\n            elif ext == 'm3u8':\n                # the certificates are misconfigured (see\n                # https://github.com/rg3/youtube-dl/issues/8665)\n                if video_url.startswith('https://'):\n                    continue\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', m3u8_id=format_id, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    video_url, video_id, f4m_id=format_id, fatal=False))\n            else:\n                proto = format_m.group('proto').lower()\n\n                abr = int_or_none(xpath_text(fnode, './audioBitrate', 'abr'), 1000)\n                vbr = int_or_none(xpath_text(fnode, './videoBitrate', 'vbr'), 1000)\n\n                width = int_or_none(xpath_text(fnode, './width', 'width'))\n                height = int_or_none(xpath_text(fnode, './height', 'height'))\n\n                filesize = int_or_none(xpath_text(fnode, './filesize', 'filesize'))\n\n                format_note = ''\n                if not format_note:\n                    format_note = None\n\n                formats.append({\n                    'format_id': format_id,\n                    'url': video_url,\n                    'ext': ext,\n                    'acodec': format_m.group('acodec'),\n                    'vcodec': format_m.group('vcodec'),\n                    'abr': abr,\n                    'vbr': vbr,\n                    'width': width,\n                    'height': height,\n                    'filesize': filesize,\n                    'format_note': format_note,\n                    'protocol': proto,\n                    '_available': is_available,\n                })\n            format_ids.append(format_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnails': thumbnails,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 72,
        "end_line": 198,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract#200",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        details_url = 'http://www.3sat.de/mediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        return self.extract_from_xml_url(video_id, details_url)",
        "begin_line": 200,
        "end_line": 204,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dropbox.DropboxIE._real_extract#28",
        "src_path": "youtube_dl/extractor/dropbox.py",
        "class_name": "youtube_dl.extractor.dropbox.DropboxIE",
        "signature": "youtube_dl.extractor.dropbox.DropboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        fn = compat_urllib_parse_unquote(url_basename(url))\n        title = os.path.splitext(fn)[0]\n        video_url = re.sub(r'[?&]dl=0', '', url)\n        video_url += ('?' if '?' not in video_url else '&') + 'dl=1'\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 28,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.drtuber.DrTuberIE._extract_urls#34",
        "src_path": "youtube_dl/extractor/drtuber.py",
        "class_name": "youtube_dl.extractor.drtuber.DrTuberIE",
        "signature": "youtube_dl.extractor.drtuber.DrTuberIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+?src=[\"\\'](?P<url>(?:https?:)?//(?:www\\.)?drtuber\\.com/embed/\\d+)',\n            webpage)",
        "begin_line": 34,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract#39",
        "src_path": "youtube_dl/extractor/drtuber.py",
        "class_name": "youtube_dl.extractor.drtuber.DrTuberIE",
        "signature": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(\n            'http://www.drtuber.com/video/%s' % video_id, display_id)\n\n        video_data = self._download_json(\n            'http://www.drtuber.com/player_config_json/', video_id, query={\n                'vid': video_id,\n                'embed': 0,\n                'aid': 0,\n                'domain_id': 0,\n            })\n\n        formats = []\n        for format_id, video_url in video_data['files'].items():\n            if video_url:\n                formats.append({\n                    'format_id': format_id,\n                    'quality': 2 if format_id == 'hq' else 1,\n                    'url': video_url\n                })\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            (r'class=\"title_watch\"[^>]*><(?:p|h\\d+)[^>]*>([^<]+)<',\n             r'<p[^>]+class=\"title_substrate\">([^<]+)</p>',\n             r'<title>([^<]+) - \\d+'),\n            webpage, 'title')\n\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        def extract_count(id_, name, default=NO_DEFAULT):\n            return str_to_int(self._html_search_regex(\n                r'<span[^>]+(?:class|id)=\"%s\"[^>]*>([\\d,\\.]+)</span>' % id_,\n                webpage, '%s count' % name, default=default, fatal=False))\n\n        like_count = extract_count('rate_likes', 'like')\n        dislike_count = extract_count('rate_dislikes', 'dislike', default=None)\n        comment_count = extract_count('comments_count', 'comment')\n\n        cats_str = self._search_regex(\n            r'<div[^>]+class=\"categories_list\">(.+?)</div>',\n            webpage, 'categories', fatal=False)\n        categories = [] if not cats_str else re.findall(\n            r'<a title=\"([^\"]+)\"', cats_str)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': title,\n            'thumbnail': thumbnail,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 39,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.drtv.DRTVIE._real_extract#66",
        "src_path": "youtube_dl/extractor/drtv.py",
        "class_name": "youtube_dl.extractor.drtv.DRTVIE",
        "signature": "youtube_dl.extractor.drtv.DRTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>Programmet er ikke l\u00e6ngere tilg\u00e6ngeligt' in webpage:\n            raise ExtractorError(\n                'Video %s is not available' % video_id, expected=True)\n\n        video_id = self._search_regex(\n            (r'data-(?:material-identifier|episode-slug)=\"([^\"]+)\"',\n                r'data-resource=\"[^>\"]+mu/programcard/expanded/([^\"]+)\"'),\n            webpage, 'video id')\n\n        programcard = self._download_json(\n            'http://www.dr.dk/mu/programcard/expanded/%s' % video_id,\n            video_id, 'Downloading video JSON')\n        data = programcard['Data'][0]\n\n        title = remove_end(self._og_search_title(\n            webpage, default=None), ' | TV | DR') or data['Title']\n        description = self._og_search_description(\n            webpage, default=None) or data.get('Description')\n\n        timestamp = parse_iso8601(data.get('CreatedTime'))\n\n        thumbnail = None\n        duration = None\n\n        restricted_to_denmark = False\n\n        formats = []\n        subtitles = {}\n\n        for asset in data['Assets']:\n            kind = asset.get('Kind')\n            if kind == 'Image':\n                thumbnail = asset.get('Uri')\n            elif kind in ('VideoResource', 'AudioResource'):\n                duration = float_or_none(asset.get('DurationInMilliseconds'), 1000)\n                restricted_to_denmark = asset.get('RestrictedToDenmark')\n                asset_target = asset.get('Target')\n                for link in asset.get('Links', []):\n                    uri = link.get('Uri')\n                    if not uri:\n                        continue\n                    target = link.get('Target')\n                    format_id = target or ''\n                    preference = None\n                    if asset_target in ('SpokenSubtitles', 'SignLanguage'):\n                        preference = -1\n                        format_id += '-%s' % asset_target\n                    if target == 'HDS':\n                        f4m_formats = self._extract_f4m_formats(\n                            uri + '?hdcore=3.3.0&plugin=aasp-3.3.0.99.43',\n                            video_id, preference, f4m_id=format_id, fatal=False)\n                        if kind == 'AudioResource':\n                            for f in f4m_formats:\n                                f['vcodec'] = 'none'\n                        formats.extend(f4m_formats)\n                    elif target == 'HLS':\n                        formats.extend(self._extract_m3u8_formats(\n                            uri, video_id, 'mp4', entry_protocol='m3u8_native',\n                            preference=preference, m3u8_id=format_id,\n                            fatal=False))\n                    else:\n                        bitrate = link.get('Bitrate')\n                        if bitrate:\n                            format_id += '-%s' % bitrate\n                        formats.append({\n                            'url': uri,\n                            'format_id': format_id,\n                            'tbr': int_or_none(bitrate),\n                            'ext': link.get('FileFormat'),\n                            'vcodec': 'none' if kind == 'AudioResource' else None,\n                        })\n                subtitles_list = asset.get('SubtitlesList')\n                if isinstance(subtitles_list, list):\n                    LANGS = {\n                        'Danish': 'da',\n                    }\n                    for subs in subtitles_list:\n                        if not subs.get('Uri'):\n                            continue\n                        lang = subs.get('Language') or 'da'\n                        subtitles.setdefault(LANGS.get(lang, lang), []).append({\n                            'url': subs['Uri'],\n                            'ext': mimetype2ext(subs.get('MimeType')) or 'vtt'\n                        })\n\n        if not formats and restricted_to_denmark:\n            self.raise_geo_restricted(\n                'Unfortunately, DR is not allowed to show this program outside Denmark.',\n                countries=self._GEO_COUNTRIES)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 66,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.drtv.DRTVLiveIE._real_extract#192",
        "src_path": "youtube_dl/extractor/drtv.py",
        "class_name": "youtube_dl.extractor.drtv.DRTVLiveIE",
        "signature": "youtube_dl.extractor.drtv.DRTVLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n        channel_data = self._download_json(\n            'https://www.dr.dk/mu-online/api/1.0/channel/' + channel_id,\n            channel_id)\n        title = self._live_title(channel_data['Title'])\n\n        formats = []\n        for streaming_server in channel_data.get('StreamingServers', []):\n            server = streaming_server.get('Server')\n            if not server:\n                continue\n            link_type = streaming_server.get('LinkType')\n            for quality in streaming_server.get('Qualities', []):\n                for stream in quality.get('Streams', []):\n                    stream_path = stream.get('Stream')\n                    if not stream_path:\n                        continue\n                    stream_url = update_url_query(\n                        '%s/%s' % (server, stream_path), {'b': ''})\n                    if link_type == 'HLS':\n                        formats.extend(self._extract_m3u8_formats(\n                            stream_url, channel_id, 'mp4',\n                            m3u8_id=link_type, fatal=False, live=True))\n                    elif link_type == 'HDS':\n                        formats.extend(self._extract_f4m_formats(update_url_query(\n                            '%s/%s' % (server, stream_path), {'hdcore': '3.7.0'}),\n                            channel_id, f4m_id=link_type, fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': channel_id,\n            'title': title,\n            'thumbnail': channel_data.get('PrimaryImageUri'),\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 192,
        "end_line": 228,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dumpert.DumpertIE._real_extract#31",
        "src_path": "youtube_dl/extractor/dumpert.py",
        "class_name": "youtube_dl.extractor.dumpert.DumpertIE",
        "signature": "youtube_dl.extractor.dumpert.DumpertIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        protocol = mobj.group('protocol')\n\n        url = '%s://www.dumpert.nl/mediabase/%s' % (protocol, video_id)\n        req = sanitized_Request(url)\n        req.add_header('Cookie', 'nsfw=1; cpc=10')\n        webpage = self._download_webpage(req, video_id)\n\n        files_base64 = self._search_regex(\n            r'data-files=\"([^\"]+)\"', webpage, 'data files')\n\n        files = self._parse_json(\n            base64.b64decode(files_base64.encode('utf-8')).decode('utf-8'),\n            video_id)\n\n        quality = qualities(['flv', 'mobile', 'tablet', '720p'])\n\n        formats = [{\n            'url': video_url,\n            'format_id': format_id,\n            'quality': quality(format_id),\n        } for format_id, video_url in files.items() if format_id != 'still']\n        self._sort_formats(formats)\n\n        title = self._html_search_meta(\n            'title', webpage) or self._og_search_title(webpage)\n        description = self._html_search_meta(\n            'description', webpage) or self._og_search_description(webpage)\n        thumbnail = files.get('still') or self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats\n        }",
        "begin_line": 31,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dvtv.DVTVIE._parse_video_metadata#96",
        "src_path": "youtube_dl/extractor/dvtv.py",
        "class_name": "youtube_dl.extractor.dvtv.DVTVIE",
        "signature": "youtube_dl.extractor.dvtv.DVTVIE._parse_video_metadata(self, js, video_id)",
        "snippet": "    def _parse_video_metadata(self, js, video_id):\n        data = self._parse_json(js, video_id, transform_source=js_to_json)\n\n        title = unescapeHTML(data['title'])\n\n        formats = []\n        for video in data['sources']:\n            video_url = video.get('file')\n            if not video_url:\n                continue\n            video_type = video.get('type')\n            ext = determine_ext(video_url, mimetype2ext(video_type))\n            if video_type == 'application/vnd.apple.mpegurl' or ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif video_type == 'application/dash+xml' or ext == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    video_url, video_id, mpd_id='dash', fatal=False))\n            else:\n                label = video.get('label')\n                height = self._search_regex(\n                    r'^(\\d+)[pP]', label or '', 'height', default=None)\n                format_id = ['http']\n                for f in (ext, label):\n                    if f:\n                        format_id.append(f)\n                formats.append({\n                    'url': video_url,\n                    'format_id': '-'.join(format_id),\n                    'height': int_or_none(height),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': data.get('mediaid') or video_id,\n            'title': title,\n            'description': data.get('description'),\n            'thumbnail': data.get('image'),\n            'duration': int_or_none(data.get('duration')),\n            'timestamp': int_or_none(data.get('pubtime')),\n            'formats': formats\n        }",
        "begin_line": 96,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dvtv.DVTVIE._real_extract#140",
        "src_path": "youtube_dl/extractor/dvtv.py",
        "class_name": "youtube_dl.extractor.dvtv.DVTVIE",
        "signature": "youtube_dl.extractor.dvtv.DVTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        # single video\n        item = self._search_regex(\n            r'(?s)embedData[0-9a-f]{32}\\[[\"\\']asset[\"\\']\\]\\s*=\\s*(\\{.+?\\});',\n            webpage, 'video', default=None, fatal=False)\n\n        if item:\n            return self._parse_video_metadata(item, video_id)\n\n        # playlist\n        items = re.findall(\n            r\"(?s)BBX\\.context\\.assets\\['[0-9a-f]{32}'\\]\\.push\\(({.+?})\\);\",\n            webpage)\n        if not items:\n            items = re.findall(r'(?s)var\\s+asset\\s*=\\s*({.+?});\\n', webpage)\n\n        if items:\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'entries': [self._parse_video_metadata(i, video_id) for i in items]\n            }\n\n        raise ExtractorError('Could not find neither video nor playlist')",
        "begin_line": 140,
        "end_line": 168,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dw.DWIE._real_extract#51",
        "src_path": "youtube_dl/extractor/dw.py",
        "class_name": "youtube_dl.extractor.dw.DWIE",
        "signature": "youtube_dl.extractor.dw.DWIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n        webpage = self._download_webpage(url, media_id)\n        hidden_inputs = self._hidden_inputs(webpage)\n        title = hidden_inputs['media_title']\n        media_id = hidden_inputs.get('media_id') or media_id\n\n        if hidden_inputs.get('player_type') == 'video' and hidden_inputs.get('stream_file') == '1':\n            formats = self._extract_smil_formats(\n                'http://www.dw.com/smil/v-%s' % media_id, media_id,\n                transform_source=lambda s: s.replace(\n                    'rtmp://tv-od.dw.de/flash/',\n                    'http://tv-download.dw.de/dwtv_video/flv/'))\n            self._sort_formats(formats)\n        else:\n            formats = [{'url': hidden_inputs['file_name']}]\n\n        upload_date = hidden_inputs.get('display_date')\n        if not upload_date:\n            upload_date = self._html_search_regex(\n                r'<span[^>]+class=\"date\">([0-9.]+)\\s*\\|', webpage,\n                'upload date', default=None)\n            upload_date = unified_strdate(upload_date)\n\n        return {\n            'id': media_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': hidden_inputs.get('preview_image'),\n            'duration': int_or_none(hidden_inputs.get('file_duration')),\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 51,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.dw.DWArticleIE._real_extract#101",
        "src_path": "youtube_dl/extractor/dw.py",
        "class_name": "youtube_dl.extractor.dw.DWArticleIE",
        "signature": "youtube_dl.extractor.dw.DWArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        article_id = self._match_id(url)\n        webpage = self._download_webpage(url, article_id)\n        hidden_inputs = self._hidden_inputs(webpage)\n        media_id = hidden_inputs['media_id']\n        media_path = self._search_regex(r'href=\"([^\"]+av-%s)\"\\s+class=\"overlayLink\"' % media_id, webpage, 'media url')\n        media_url = compat_urlparse.urljoin(url, media_path)\n        return self.url_result(media_url, 'DW', media_id)",
        "begin_line": 101,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._extract_url#61",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        # Regular iframe embedding\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//.+?\\.media\\.eagleplatform\\.com/index/player\\?.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return mobj.group('url')\n        PLAYER_JS_RE = r'''\n                        <script[^>]+\n                            src=(?P<qjs>[\"\\'])(?:https?:)?//(?P<host>(?:(?!(?P=qjs)).)+\\.media\\.eagleplatform\\.com)/player/player\\.js(?P=qjs)\n                        .+?\n                    '''\n        # \"Basic usage\" embedding (see http://dultonmedia.github.io/eplayer/)\n        mobj = re.search(\n            r'''(?xs)\n                    %s\n                    <div[^>]+\n                        class=(?P<qclass>[\"\\'])eagleplayer(?P=qclass)[^>]+\n                        data-id=[\"\\'](?P<id>\\d+)\n            ''' % PLAYER_JS_RE, webpage)\n        if mobj is not None:\n            return 'eagleplatform:%(host)s:%(id)s' % mobj.groupdict()\n        # Generalization of \"Javascript code usage\", \"Combined usage\" and\n        # \"Usage without attaching to DOM\" embeddings (see\n        # http://dultonmedia.github.io/eplayer/)\n        mobj = re.search(\n            r'''(?xs)\n                    %s\n                    <script>\n                    .+?\n                    new\\s+EaglePlayer\\(\n                        (?:[^,]+\\s*,\\s*)?\n                        {\n                            .+?\n                            \\bid\\s*:\\s*[\"\\']?(?P<id>\\d+)\n                            .+?\n                        }\n                    \\s*\\)\n                    .+?\n                    </script>\n            ''' % PLAYER_JS_RE, webpage)\n        if mobj is not None:\n            return 'eagleplatform:%(host)s:%(id)s' % mobj.groupdict()",
        "begin_line": 61,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._handle_error#106",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._handle_error(response)",
        "snippet": "    def _handle_error(response):\n        status = int_or_none(response.get('status', 200))\n        if status != 200:\n            raise ExtractorError(' '.join(response['errors']), expected=True)",
        "begin_line": 106,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._download_json#111",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._download_json(self, url_or_request, video_id, *args, **kwargs)",
        "snippet": "    def _download_json(self, url_or_request, video_id, *args, **kwargs):\n        try:\n            response = super(EaglePlatformIE, self)._download_json(\n                url_or_request, video_id, *args, **kwargs)\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError):\n                response = self._parse_json(ee.cause.read().decode('utf-8'), video_id)\n                self._handle_error(response)\n            raise\n        return response",
        "begin_line": 111,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._get_video_url#122",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._get_video_url(self, url_or_request, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _get_video_url(self, url_or_request, video_id, note='Downloading JSON metadata'):\n        return self._download_json(url_or_request, video_id, note)['data'][0]",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._real_extract#125",
        "src_path": "youtube_dl/extractor/eagleplatform.py",
        "class_name": "youtube_dl.extractor.eagleplatform.EaglePlatformIE",
        "signature": "youtube_dl.extractor.eagleplatform.EaglePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        host, video_id = mobj.group('custom_host') or mobj.group('host'), mobj.group('id')\n\n        headers = {}\n        query = {\n            'id': video_id,\n        }\n\n        referrer = smuggled_data.get('referrer')\n        if referrer:\n            headers['Referer'] = referrer\n            query['referrer'] = referrer\n\n        player_data = self._download_json(\n            'http://%s/api/player_data' % host, video_id,\n            headers=headers, query=query)\n\n        media = player_data['data']['playlist']['viewports'][0]['medialist'][0]\n\n        title = media['title']\n        description = media.get('description')\n        thumbnail = self._proto_relative_url(media.get('snapshot'), 'http:')\n        duration = int_or_none(media.get('duration'))\n        view_count = int_or_none(media.get('views'))\n\n        age_restriction = media.get('age_restriction')\n        age_limit = None\n        if age_restriction:\n            age_limit = 0 if age_restriction == 'allow_all' else 18\n\n        secure_m3u8 = self._proto_relative_url(media['sources']['secure_m3u8']['auto'], 'http:')\n\n        formats = []\n\n        m3u8_url = self._get_video_url(secure_m3u8, video_id, 'Downloading m3u8 JSON')\n        m3u8_formats = self._extract_m3u8_formats(\n            m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native',\n            m3u8_id='hls', fatal=False)\n        formats.extend(m3u8_formats)\n\n        m3u8_formats_dict = {}\n        for f in m3u8_formats:\n            if f.get('height') is not None:\n                m3u8_formats_dict[f['height']] = f\n\n        mp4_data = self._download_json(\n            # Secure mp4 URL is constructed according to Player.prototype.mp4 from\n            # http://lentaru.media.eagleplatform.com/player/player.js\n            re.sub(r'm3u8|hlsvod|hls|f4m', 'mp4s', secure_m3u8),\n            video_id, 'Downloading mp4 JSON', fatal=False)\n        if mp4_data:\n            for format_id, format_url in mp4_data.get('data', {}).items():\n                if not isinstance(format_url, compat_str):\n                    continue\n                height = int_or_none(format_id)\n                if height is not None and m3u8_formats_dict.get(height):\n                    f = m3u8_formats_dict[height].copy()\n                    f.update({\n                        'format_id': f['format_id'].replace('hls', 'http'),\n                        'protocol': 'http',\n                    })\n                else:\n                    f = {\n                        'format_id': 'http-%s' % format_id,\n                        'height': int_or_none(format_id),\n                    }\n                f['url'] = format_url\n                formats.append(f)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 125,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract#20",
        "src_path": "youtube_dl/extractor/ebaumsworld.py",
        "class_name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE",
        "signature": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        config = self._download_xml(\n            'http://www.ebaumsworld.com/video/player/%s' % video_id, video_id)\n        video_url = config.find('file').text\n\n        return {\n            'id': video_id,\n            'title': config.find('title').text,\n            'url': video_url,\n            'description': config.find('description').text,\n            'thumbnail': config.find('image').text,\n            'uploader': config.find('username').text,\n        }",
        "begin_line": 20,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.echomsk.EchoMskIE._real_extract#21",
        "src_path": "youtube_dl/extractor/echomsk.py",
        "class_name": "youtube_dl.extractor.echomsk.EchoMskIE",
        "signature": "youtube_dl.extractor.echomsk.EchoMskIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        audio_url = self._search_regex(\n            r'<a rel=\"mp3\" href=\"([^\"]+)\">', webpage, 'audio URL')\n\n        title = self._html_search_regex(\n            r'<a href=\"/programs/[^\"]+\" target=\"_blank\">([^<]+)</a>',\n            webpage, 'title')\n\n        air_date = self._html_search_regex(\n            r'(?s)<div class=\"date\">(.+?)</div>',\n            webpage, 'date', fatal=False, default=None)\n\n        if air_date:\n            air_date = re.sub(r'(\\s)\\1+', r'\\1', air_date)\n            if air_date:\n                title = '%s - %s' % (title, air_date)\n\n        return {\n            'id': video_id,\n            'url': audio_url,\n            'title': title,\n        }",
        "begin_line": 21,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.egghead.EggheadCourseIE._real_extract#26",
        "src_path": "youtube_dl/extractor/egghead.py",
        "class_name": "youtube_dl.extractor.egghead.EggheadCourseIE",
        "signature": "youtube_dl.extractor.egghead.EggheadCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        course = self._download_json(\n            'https://egghead.io/api/v1/series/%s' % playlist_id, playlist_id)\n\n        entries = [\n            self.url_result(\n                'wistia:%s' % lesson['wistia_id'], ie='Wistia',\n                video_id=lesson['wistia_id'], video_title=lesson.get('title'))\n            for lesson in course['lessons'] if lesson.get('wistia_id')]\n\n        return self.playlist_result(\n            entries, playlist_id, course.get('title'),\n            course.get('description'))",
        "begin_line": 26,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.egghead.EggheadLessonIE._real_extract#66",
        "src_path": "youtube_dl/extractor/egghead.py",
        "class_name": "youtube_dl.extractor.egghead.EggheadLessonIE",
        "signature": "youtube_dl.extractor.egghead.EggheadLessonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lesson_id = self._match_id(url)\n\n        lesson = self._download_json(\n            'https://egghead.io/api/v1/lessons/%s' % lesson_id, lesson_id)\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Wistia',\n            'url': 'wistia:%s' % lesson['wistia_id'],\n            'id': lesson['wistia_id'],\n            'title': lesson.get('title'),\n            'description': lesson.get('summary'),\n            'thumbnail': lesson.get('thumb_nail'),\n            'timestamp': unified_timestamp(lesson.get('published_at')),\n            'duration': int_or_none(lesson.get('duration')),\n            'view_count': int_or_none(lesson.get('plays_count')),\n            'tags': try_get(lesson, lambda x: x['tag_list'], list),\n        }",
        "begin_line": 66,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ehow.EHowIE._real_extract#22",
        "src_path": "youtube_dl/extractor/ehow.py",
        "class_name": "youtube_dl.extractor.ehow.EHowIE",
        "signature": "youtube_dl.extractor.ehow.EHowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r'(?:file|source)=(http[^\\'\"&]*)', webpage, 'video URL')\n        final_url = compat_urllib_parse_unquote(video_url)\n        uploader = self._html_search_meta('uploader', webpage)\n        title = self._og_search_title(webpage).replace(' | eHow', '')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract#104",
        "src_path": "youtube_dl/extractor/eighttracks.py",
        "class_name": "youtube_dl.extractor.eighttracks.EightTracksIE",
        "signature": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r\"(?s)PAGE\\.mix\\s*=\\s*({.+?});\\n\", webpage, 'trax information'),\n            playlist_id)\n\n        session = str(random.randint(0, 1000000000))\n        mix_id = data['id']\n        track_count = data['tracks_count']\n        duration = data['duration']\n        avg_song_duration = float(duration) / track_count\n        # duration is sometimes negative, use predefined avg duration\n        if avg_song_duration <= 0:\n            avg_song_duration = 300\n        first_url = 'http://8tracks.com/sets/%s/play?player=sm&mix_id=%s&format=jsonh' % (session, mix_id)\n        next_url = first_url\n        entries = []\n\n        for i in range(track_count):\n            api_json = None\n            download_tries = 0\n\n            while api_json is None:\n                try:\n                    api_json = self._download_webpage(\n                        next_url, playlist_id,\n                        note='Downloading song information %d/%d' % (i + 1, track_count),\n                        errnote='Failed to download song information')\n                except ExtractorError:\n                    if download_tries > 3:\n                        raise\n                    else:\n                        download_tries += 1\n                        self._sleep(avg_song_duration, playlist_id)\n\n            api_data = json.loads(api_json)\n            track_data = api_data['set']['track']\n            info = {\n                'id': compat_str(track_data['id']),\n                'url': track_data['track_file_stream_url'],\n                'title': track_data['performer'] + ' - ' + track_data['name'],\n                'raw_title': track_data['name'],\n                'uploader_id': data['user']['login'],\n                'ext': 'm4a',\n            }\n            entries.append(info)\n\n            next_url = 'http://8tracks.com/sets/%s/next?player=sm&mix_id=%s&format=jsonh&track_id=%s' % (\n                session, mix_id, track_data['id'])\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': compat_str(mix_id),\n            'display_id': playlist_id,\n            'title': data.get('name'),\n            'description': data.get('description'),\n        }",
        "begin_line": 104,
        "end_line": 164,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.einthusan.EinthusanIE._decrypt#38",
        "src_path": "youtube_dl/extractor/einthusan.py",
        "class_name": "youtube_dl.extractor.einthusan.EinthusanIE",
        "signature": "youtube_dl.extractor.einthusan.EinthusanIE._decrypt(self, encrypted_data, video_id)",
        "snippet": "    def _decrypt(self, encrypted_data, video_id):\n        return self._parse_json(base64.b64decode((\n            encrypted_data[:10] + encrypted_data[-1] + encrypted_data[12:-1]\n        ).encode('ascii')).decode('utf-8'), video_id)",
        "begin_line": 38,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.einthusan.EinthusanIE._real_extract#43",
        "src_path": "youtube_dl/extractor/einthusan.py",
        "class_name": "youtube_dl.extractor.einthusan.EinthusanIE",
        "signature": "youtube_dl.extractor.einthusan.EinthusanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<h3>([^<]+)</h3>', webpage, 'title')\n\n        player_params = extract_attributes(self._search_regex(\n            r'(<section[^>]+id=\"UIVideoPlayer\"[^>]+>)', webpage, 'player parameters'))\n\n        page_id = self._html_search_regex(\n            '<html[^>]+data-pageid=\"([^\"]+)\"', webpage, 'page ID')\n        video_data = self._download_json(\n            'https://einthusan.tv/ajax/movie/watch/%s/' % video_id, video_id,\n            data=urlencode_postdata({\n                'xEvent': 'UIVideoPlayer.PingOutcome',\n                'xJson': json.dumps({\n                    'EJOutcomes': player_params['data-ejpingables'],\n                    'NativeHLS': False\n                }),\n                'arcVersion': 3,\n                'appVersion': 59,\n                'gorilla.csrf.Token': page_id,\n            }))['Data']\n\n        if isinstance(video_data, compat_str) and video_data.startswith('/ratelimited/'):\n            raise ExtractorError(\n                'Download rate reached. Please try again later.', expected=True)\n\n        ej_links = self._decrypt(video_data['EJLinks'], video_id)\n\n        formats = []\n\n        m3u8_url = ej_links.get('HLSLink')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, ext='mp4', entry_protocol='m3u8_native'))\n\n        mp4_url = ej_links.get('MP4Link')\n        if mp4_url:\n            formats.append({\n                'url': mp4_url,\n            })\n\n        self._sort_formats(formats)\n\n        description = get_elements_by_class('synopsis', webpage)[0]\n        thumbnail = self._html_search_regex(\n            r'''<img[^>]+src=([\"'])(?P<url>(?!\\1).+?/moviecovers/(?!\\1).+?)\\1''',\n            webpage, 'thumbnail url', fatal=False, group='url')\n        if thumbnail is not None:\n            thumbnail = compat_urlparse.urljoin(url, thumbnail)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 43,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eitb.EitbIE._real_extract#32",
        "src_path": "youtube_dl/extractor/eitb.py",
        "class_name": "youtube_dl.extractor.eitb.EitbIE",
        "signature": "youtube_dl.extractor.eitb.EitbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://mam.eitb.eus/mam/REST/ServiceMultiweb/Video/MULTIWEBTV/%s/' % video_id,\n            video_id, 'Downloading video JSON')\n\n        media = video['web_media'][0]\n\n        formats = []\n        for rendition in media['RENDITIONS']:\n            video_url = rendition.get('PMD_URL')\n            if not video_url:\n                continue\n            tbr = float_or_none(rendition.get('ENCODING_RATE'), 1000)\n            format_id = 'http'\n            if tbr:\n                format_id += '-%d' % int(tbr)\n            formats.append({\n                'url': rendition['PMD_URL'],\n                'format_id': format_id,\n                'width': int_or_none(rendition.get('FRAME_WIDTH')),\n                'height': int_or_none(rendition.get('FRAME_HEIGHT')),\n                'tbr': tbr,\n            })\n\n        hls_url = media.get('HLS_SURL')\n        if hls_url:\n            request = sanitized_Request(\n                'http://mam.eitb.eus/mam/REST/ServiceMultiweb/DomainRestrictedSecurity/TokenAuth/',\n                headers={'Referer': url})\n            token_data = self._download_json(\n                request, video_id, 'Downloading auth token', fatal=False)\n            if token_data:\n                token = token_data.get('token')\n                if token:\n                    formats.extend(self._extract_m3u8_formats(\n                        '%s?hdnts=%s' % (hls_url, token), video_id, m3u8_id='hls', fatal=False))\n\n        hds_url = media.get('HDS_SURL')\n        if hds_url:\n            formats.extend(self._extract_f4m_formats(\n                '%s?hdcore=3.7.0' % hds_url.replace('euskalsvod', 'euskalvod'),\n                video_id, f4m_id='hds', fatal=False))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': media.get('NAME_ES') or media.get('name') or media['NAME_EU'],\n            'description': media.get('SHORT_DESC_ES') or video.get('desc_group') or media.get('SHORT_DESC_EU'),\n            'thumbnail': media.get('STILL_URL') or media.get('THUMBNAIL_URL'),\n            'duration': float_or_none(media.get('LENGTH'), 1000),\n            'timestamp': parse_iso8601(media.get('BROADCST_DATE'), ' '),\n            'tags': media.get('TAGS'),\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract#40",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        URLS = ('http://widgets.ellentube.com/videos/%s' % video_id, url)\n\n        for num, url_ in enumerate(URLS, 1):\n            webpage = self._download_webpage(\n                url_, video_id, fatal=num == len(URLS))\n\n            default = NO_DEFAULT if num == len(URLS) else None\n\n            partner_id = self._search_regex(\n                r\"var\\s+partnerId\\s*=\\s*'([^']+)\", webpage, 'partner id',\n                default=default)\n\n            kaltura_id = self._search_regex(\n                [r'id=\"kaltura_player_([^\"]+)\"',\n                 r\"_wb_entry_id\\s*:\\s*'([^']+)\",\n                 r'data-kaltura-entry-id=\"([^\"]+)'],\n                webpage, 'kaltura id', default=default)\n\n            if partner_id and kaltura_id:\n                break\n\n        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), KalturaIE.ie_key())",
        "begin_line": 40,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract#79",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n        playlist = self._extract_playlist(webpage, playlist_id)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist)\n        }",
        "begin_line": 79,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist#92",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist(self, webpage, playlist_id)",
        "snippet": "    def _extract_playlist(self, webpage, playlist_id):\n        json_string = self._search_regex(r'playerView.addClips\\(\\[\\{(.*?)\\}\\]\\);', webpage, 'json')\n        return self._parse_json('[{' + json_string + '}]', playlist_id)",
        "begin_line": 92,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries#96",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries(self, playlist)",
        "snippet": "    def _extract_entries(self, playlist):\n        return [\n            self.url_result(\n                'kaltura:%s:%s' % (item['kaltura_partner_id'], item['kaltura_entry_id']),\n                KalturaIE.ie_key(), video_id=item['kaltura_entry_id'])\n            for item in playlist]",
        "begin_line": 96,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.elpais.ElPaisIE._real_extract#56",
        "src_path": "youtube_dl/extractor/elpais.py",
        "class_name": "youtube_dl.extractor.elpais.ElPaisIE",
        "signature": "youtube_dl.extractor.elpais.ElPaisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        prefix = self._html_search_regex(\n            r'var\\s+url_cache\\s*=\\s*\"([^\"]+)\";', webpage, 'URL prefix')\n        id_multimedia = self._search_regex(\n            r\"id_multimedia\\s*=\\s*'([^']+)'\", webpage, 'ID multimedia', default=None)\n        if id_multimedia:\n            url_info = self._download_json(\n                'http://elpais.com/vdpep/1/?pepid=' + id_multimedia, video_id, transform_source=strip_jsonp)\n            video_suffix = url_info['mp4']\n        else:\n            video_suffix = self._search_regex(\n                r\"(?:URLMediaFile|urlVideo_\\d+)\\s*=\\s*url_cache\\s*\\+\\s*'([^']+)'\", webpage, 'video URL')\n        video_url = prefix + video_suffix\n        thumbnail_suffix = self._search_regex(\n            r\"(?:URLMediaStill|urlFotogramaFijo_\\d+)\\s*=\\s*url_cache\\s*\\+\\s*'([^']+)'\",\n            webpage, 'thumbnail URL', default=None)\n        thumbnail = (\n            None if thumbnail_suffix is None\n            else prefix + thumbnail_suffix) or self._og_search_thumbnail(webpage)\n        title = self._html_search_regex(\n            (r\"tituloVideo\\s*=\\s*'([^']+)'\",\n             r'<h2 class=\"entry-header entry-title.*?>(.*?)</h2>',\n             r'<h1[^>]+class=\"titulo\"[^>]*>([^<]+)'),\n            webpage, 'title', default=None) or self._og_search_title(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'<p class=\"date-header date-int updated\"\\s+title=\"([^\"]+)\">',\n            webpage, 'upload date', default=None) or self._html_search_meta(\n            'datePublished', webpage, 'timestamp'))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 56,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.embedly.EmbedlyIE._real_extract#15",
        "src_path": "youtube_dl/extractor/embedly.py",
        "class_name": "youtube_dl.extractor.embedly.EmbedlyIE",
        "signature": "youtube_dl.extractor.embedly.EmbedlyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(compat_urllib_parse_unquote(self._match_id(url)))",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.engadget.EngadgetIE._real_extract#25",
        "src_path": "youtube_dl/extractor/engadget.py",
        "class_name": "youtube_dl.extractor.engadget.EngadgetIE",
        "signature": "youtube_dl.extractor.engadget.EngadgetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self.url_result('aol-video:%s' % video_id)",
        "begin_line": 25,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eporner.EpornerIE._real_extract#40",
        "src_path": "youtube_dl/extractor/eporner.py",
        "class_name": "youtube_dl.extractor.eporner.EpornerIE",
        "signature": "youtube_dl.extractor.eporner.EpornerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage, urlh = self._download_webpage_handle(url, display_id)\n\n        video_id = self._match_id(compat_str(urlh.geturl()))\n\n        hash = self._search_regex(\n            r'hash\\s*:\\s*[\"\\']([\\da-f]{32})', webpage, 'hash')\n\n        title = self._og_search_title(webpage, default=None) or self._html_search_regex(\n            r'<title>(.+?) - EPORNER', webpage, 'title')\n\n        # Reverse engineered from vjs.js\n        def calc_hash(s):\n            return ''.join((encode_base_n(int(s[lb:lb + 8], 16), 36) for lb in range(0, 32, 8)))\n\n        video = self._download_json(\n            'http://www.eporner.com/xhr/video/%s' % video_id,\n            display_id, note='Downloading video JSON',\n            query={\n                'hash': calc_hash(hash),\n                'device': 'generic',\n                'domain': 'www.eporner.com',\n                'fallback': 'false',\n            })\n\n        if video.get('available') is False:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, video['message']), expected=True)\n\n        sources = video['sources']\n\n        formats = []\n        for kind, formats_dict in sources.items():\n            if not isinstance(formats_dict, dict):\n                continue\n            for format_id, format_dict in formats_dict.items():\n                if not isinstance(format_dict, dict):\n                    continue\n                src = format_dict.get('src')\n                if not isinstance(src, compat_str) or not src.startswith('http'):\n                    continue\n                if kind == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        src, display_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id=kind, fatal=False))\n                else:\n                    height = int_or_none(self._search_regex(\n                        r'(\\d+)[pP]', format_id, 'height', default=None))\n                    fps = int_or_none(self._search_regex(\n                        r'(\\d+)fps', format_id, 'fps', default=None))\n\n                    formats.append({\n                        'url': src,\n                        'format_id': format_id,\n                        'height': height,\n                        'fps': fps,\n                    })\n        self._sort_formats(formats)\n\n        duration = parse_duration(self._html_search_meta('duration', webpage))\n        view_count = str_to_int(self._search_regex(\n            r'id=\"cinemaviews\">\\s*([0-9,]+)\\s*<small>views',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 40,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._login#41",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        query = compat_urllib_parse_urlencode({\n            'username': username,\n            'password': password,\n            'url': 'http://www.eroprofile.com/',\n        })\n        login_url = self._LOGIN_URL + query\n        login_page = self._download_webpage(login_url, None, False)\n\n        m = re.search(r'Your username or password was incorrect\\.', login_page)\n        if m:\n            raise ExtractorError(\n                'Wrong username and/or password.', expected=True)\n\n        self.report_login()\n        redirect_url = self._search_regex(\n            r'<script[^>]+?src=\"([^\"]+)\"', login_page, 'login redirect url')\n        self._download_webpage(redirect_url, None, False)",
        "begin_line": 41,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._real_initialize#64",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 64,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eroprofile.EroProfileIE._real_extract#67",
        "src_path": "youtube_dl/extractor/eroprofile.py",
        "class_name": "youtube_dl.extractor.eroprofile.EroProfileIE",
        "signature": "youtube_dl.extractor.eroprofile.EroProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        m = re.search(r'You must be logged in to view this video\\.', webpage)\n        if m:\n            self.raise_login_required('This video requires login')\n\n        video_id = self._search_regex(\n            [r\"glbUpdViews\\s*\\('\\d*','(\\d+)'\", r'p/report/video/(\\d+)'],\n            webpage, 'video id', default=None)\n\n        video_url = unescapeHTML(self._search_regex(\n            r'<source src=\"([^\"]+)', webpage, 'video url'))\n        title = self._html_search_regex(\n            r'Title:</th><td>([^<]+)</td>', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'onclick=\"showVideoPlayer\\(\\)\"><img src=\"([^\"]+)',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 67,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.escapist._decrypt_config#15",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist",
        "signature": "youtube_dl.extractor.escapist._decrypt_config(key, string)",
        "snippet": "def _decrypt_config(key, string):\n    a = ''\n    i = ''\n    r = ''\n\n    while len(a) < (len(string) / 2):\n        a += key\n\n    a = a[0:int(len(string) / 2)]\n\n    t = 0\n    while t < len(string):\n        i += chr(int(string[t] + string[t + 1], 16))\n        t += 2\n\n    icko = [s for s in i]\n\n    for t, c in enumerate(a):\n        r += chr(ord(c) ^ ord(icko[t]))\n\n    return r",
        "begin_line": 15,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.escapist.EscapistIE._real_extract#66",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist.EscapistIE",
        "signature": "youtube_dl.extractor.escapist.EscapistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        ims_video = self._parse_json(\n            self._search_regex(\n                r'imsVideo\\.play\\(({.+?})\\);', webpage, 'imsVideo'),\n            video_id)\n        video_id = ims_video['videoID']\n        key = ims_video['hash']\n\n        config_req = sanitized_Request(\n            'http://www.escapistmagazine.com/videos/'\n            'vidconfig.php?videoID=%s&hash=%s' % (video_id, key))\n        config_req.add_header('Referer', url)\n        config = self._download_webpage(config_req, video_id, 'Downloading video config')\n\n        data = json.loads(_decrypt_config(key, config))\n\n        video_data = data['videoData']\n\n        title = clean_html(video_data['title'])\n        duration = float_or_none(video_data.get('duration'), 1000)\n        uploader = video_data.get('publisher')\n\n        formats = [{\n            'url': video['src'],\n            'format_id': '%s-%sp' % (determine_ext(video['src']), video['res']),\n            'height': int_or_none(video.get('res')),\n        } for video in data['files']['videos']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'duration': duration,\n            'uploader': uploader,\n        }",
        "begin_line": 66,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.espn.ESPNIE._real_extract#82",
        "src_path": "youtube_dl/extractor/espn.py",
        "class_name": "youtube_dl.extractor.espn.ESPNIE",
        "signature": "youtube_dl.extractor.espn.ESPNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        clip = self._download_json(\n            'http://api-app.espn.com/v1/video/clips/%s' % video_id,\n            video_id)['videos'][0]\n\n        title = clip['headline']\n\n        format_urls = set()\n        formats = []\n\n        def traverse_source(source, base_source_id=None):\n            for source_id, source in source.items():\n                if isinstance(source, compat_str):\n                    extract_source(source, base_source_id)\n                elif isinstance(source, dict):\n                    traverse_source(\n                        source,\n                        '%s-%s' % (base_source_id, source_id)\n                        if base_source_id else source_id)\n\n        def extract_source(source_url, source_id=None):\n            if source_url in format_urls:\n                return\n            format_urls.add(source_url)\n            ext = determine_ext(source_url)\n            if ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    source_url, video_id, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    source_url, video_id, f4m_id=source_id, fatal=False))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    source_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id=source_id, fatal=False))\n            else:\n                formats.append({\n                    'url': source_url,\n                    'format_id': source_id,\n                })\n\n        traverse_source(clip['links']['source'])\n        self._sort_formats(formats)\n\n        description = clip.get('caption') or clip.get('description')\n        thumbnail = clip.get('thumbnail')\n        duration = int_or_none(clip.get('duration'))\n        timestamp = unified_timestamp(clip.get('originalPublishDate'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 82,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.espn.ESPNArticleIE.suitable#164",
        "src_path": "youtube_dl/extractor/espn.py",
        "class_name": "youtube_dl.extractor.espn.ESPNArticleIE",
        "signature": "youtube_dl.extractor.espn.ESPNArticleIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if ESPNIE.suitable(url) else super(ESPNArticleIE, cls).suitable(url)",
        "begin_line": 164,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.espn.ESPNArticleIE._real_extract#167",
        "src_path": "youtube_dl/extractor/espn.py",
        "class_name": "youtube_dl.extractor.espn.ESPNArticleIE",
        "signature": "youtube_dl.extractor.espn.ESPNArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(\n            r'class=([\"\\']).*?video-play-button.*?\\1[^>]+data-id=[\"\\'](?P<id>\\d+)',\n            webpage, 'video id', group='id')\n\n        return self.url_result(\n            'http://espn.go.com/video/clip?id=%s' % video_id, ESPNIE.ie_key())",
        "begin_line": 167,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.esri.EsriVideoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/esri.py",
        "class_name": "youtube_dl.extractor.esri.EsriVideoIE",
        "signature": "youtube_dl.extractor.esri.EsriVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for width, height, content in re.findall(\n                r'(?s)<li><strong>(\\d+)x(\\d+):</strong>(.+?)</li>', webpage):\n            for video_url, ext, filesize in re.findall(\n                    r'<a[^>]+href=\"([^\"]+)\">([^<]+)&nbsp;\\(([^<]+)\\)</a>', content):\n                formats.append({\n                    'url': compat_urlparse.urljoin(url, video_url),\n                    'ext': ext.lower(),\n                    'format_id': '%s-%s' % (ext.lower(), height),\n                    'width': int(width),\n                    'height': int(height),\n                    'filesize_approx': parse_filesize(filesize),\n                })\n        self._sort_formats(formats)\n\n        title = self._html_search_meta('title', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description', fatal=False)\n\n        thumbnail = self._html_search_meta('thumbnail', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = re.sub(r'_[st]\\.jpg$', '_x.jpg', thumbnail)\n\n        duration = int_or_none(self._search_regex(\n            [r'var\\s+videoSeconds\\s*=\\s*(\\d+)', r\"'duration'\\s*:\\s*(\\d+)\"],\n            webpage, 'duration', fatal=False))\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'last-modified', webpage, 'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'formats': formats\n        }",
        "begin_line": 31,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.etonline.ETOnlineIE._real_extract#25",
        "src_path": "youtube_dl/extractor/etonline.py",
        "class_name": "youtube_dl.extractor.etonline.ETOnlineIE",
        "signature": "youtube_dl.extractor.etonline.ETOnlineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result(\n                self.BRIGHTCOVE_URL_TEMPLATE % video_id, 'BrightcoveNew', video_id)\n            for video_id in re.findall(\n                r'site\\.brightcove\\s*\\([^,]+,\\s*[\"\\'](title_\\d+)', webpage)]\n\n        return self.playlist_result(\n            entries, playlist_id,\n            self._og_search_title(webpage, fatal=False),\n            self._og_search_description(webpage))",
        "begin_line": 25,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.europa.EuropaIE._real_extract#40",
        "src_path": "youtube_dl/extractor/europa.py",
        "class_name": "youtube_dl.extractor.europa.EuropaIE",
        "signature": "youtube_dl.extractor.europa.EuropaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        playlist = self._download_xml(\n            'http://ec.europa.eu/avservices/video/player/playlist.cfm?ID=%s' % video_id, video_id)\n\n        def get_item(type_, preference):\n            items = {}\n            for item in playlist.findall('./info/%s/item' % type_):\n                lang, label = xpath_text(item, 'lg', default=None), xpath_text(item, 'label', default=None)\n                if lang and label:\n                    items[lang] = label.strip()\n            for p in preference:\n                if items.get(p):\n                    return items[p]\n\n        query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        preferred_lang = query.get('sitelang', ('en', ))[0]\n\n        preferred_langs = orderedSet((preferred_lang, 'en', 'int'))\n\n        title = get_item('title', preferred_langs) or video_id\n        description = get_item('description', preferred_langs)\n        thumbnmail = xpath_text(playlist, './info/thumburl', 'thumbnail')\n        upload_date = unified_strdate(xpath_text(playlist, './info/date', 'upload date'))\n        duration = parse_duration(xpath_text(playlist, './info/duration', 'duration'))\n        view_count = int_or_none(xpath_text(playlist, './info/views', 'views'))\n\n        language_preference = qualities(preferred_langs[::-1])\n\n        formats = []\n        for file_ in playlist.findall('./files/file'):\n            video_url = xpath_text(file_, './url')\n            if not video_url:\n                continue\n            lang = xpath_text(file_, './lg')\n            formats.append({\n                'url': video_url,\n                'format_id': lang,\n                'format_note': xpath_text(file_, './lglabel'),\n                'language_preference': language_preference(lang)\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnmail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats\n        }",
        "begin_line": 40,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract#38",
        "src_path": "youtube_dl/extractor/everyonesmixtape.py",
        "class_name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE",
        "signature": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        pllist_url = 'http://everyonesmixtape.com/mixtape.php?a=getMixes&u=-1&linked=%s&explore=' % playlist_id\n        pllist_req = sanitized_Request(pllist_url)\n        pllist_req.add_header('X-Requested-With', 'XMLHttpRequest')\n\n        playlist_list = self._download_json(\n            pllist_req, playlist_id, note='Downloading playlist metadata')\n        try:\n            playlist_no = next(playlist['id']\n                               for playlist in playlist_list\n                               if playlist['code'] == playlist_id)\n        except StopIteration:\n            raise ExtractorError('Playlist id not found')\n\n        pl_url = 'http://everyonesmixtape.com/mixtape.php?a=getMix&id=%s&userId=null&code=' % playlist_no\n        pl_req = sanitized_Request(pl_url)\n        pl_req.add_header('X-Requested-With', 'XMLHttpRequest')\n        playlist = self._download_json(\n            pl_req, playlist_id, note='Downloading playlist info')\n\n        entries = [{\n            '_type': 'url',\n            'url': t['url'],\n            'title': t['title'],\n        } for t in playlist['tracks']]\n\n        if mobj.group('songnr'):\n            songnr = int(mobj.group('songnr')) - 1\n            return entries[songnr]\n\n        playlist_title = playlist['mixData']['name']\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'entries': entries,\n        }",
        "begin_line": 38,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract#27",
        "src_path": "youtube_dl/extractor/expotv.py",
        "class_name": "youtube_dl.extractor.expotv.ExpoTVIE",
        "signature": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        player_key = self._search_regex(\n            r'<param name=\"playerKey\" value=\"([^\"]+)\"', webpage, 'player key')\n        config = self._download_json(\n            'http://client.expotv.com/video/config/%s/%s' % (video_id, player_key),\n            video_id, 'Downloading video configuration')\n\n        formats = []\n        for fcfg in config['sources']:\n            media_url = fcfg.get('file')\n            if not media_url:\n                continue\n            if fcfg.get('type') == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls'))\n            else:\n                formats.append({\n                    'url': media_url,\n                    'height': int_or_none(fcfg.get('height')),\n                    'format_id': fcfg.get('label'),\n                    'ext': self._search_regex(\n                        r'filename=.*\\.([a-z0-9_A-Z]+)&', media_url,\n                        'file extension', default=None) or fcfg.get('type'),\n                })\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = config.get('image')\n        view_count = int_or_none(self._search_regex(\n            r'<h5>Plays: ([0-9]+)</h5>', webpage, 'view counts'))\n        uploader = self._search_regex(\n            r'<div class=\"reviewer\">\\s*<img alt=\"([^\"]+)\"', webpage, 'uploader',\n            fatal=False)\n        upload_date = unified_strdate(self._search_regex(\n            r'<h5>Reviewed on ([0-9/.]+)</h5>', webpage, 'upload date',\n            fatal=False), day_first=False)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 27,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract#31",
        "src_path": "youtube_dl/extractor/extremetube.py",
        "class_name": "youtube_dl.extractor.extremetube.ExtremeTubeIE",
        "signature": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage, info = self._extract_info(url)\n\n        if not info['title']:\n            info['title'] = self._search_regex(\n                r'<h1[^>]+title=\"([^\"]+)\"[^>]*>', webpage, 'title')\n\n        uploader = self._html_search_regex(\n            r'Uploaded by:\\s*</strong>\\s*(.+?)\\s*</div>',\n            webpage, 'uploader', fatal=False)\n        view_count = str_to_int(self._search_regex(\n            r'Views:\\s*</strong>\\s*<span>([\\d,\\.]+)</span>',\n            webpage, 'view count', fatal=False))\n\n        info.update({\n            'uploader': uploader,\n            'view_count': view_count,\n        })\n\n        return info",
        "begin_line": 31,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.eyedotv.EyedoTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/eyedotv.py",
        "class_name": "youtube_dl.extractor.eyedotv.EyedoTVIE",
        "signature": "youtube_dl.extractor.eyedotv.EyedoTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_xml('http://eyedo.tv/api/live/GetLive/%s' % video_id, video_id)\n\n        def _add_ns(path):\n            return self._xpath_ns(path, 'http://schemas.datacontract.org/2004/07/EyeDo.Core.Implementation.Web.ViewModels.Api')\n\n        title = xpath_text(video_data, _add_ns('Titre'), 'title', True)\n        state_live_code = xpath_text(video_data, _add_ns('StateLiveCode'), 'title', True)\n        if state_live_code == 'avenir':\n            raise ExtractorError(\n                '%s said: We\\'re sorry, but this video is not yet available.' % self.IE_NAME,\n                expected=True)\n\n        is_live = state_live_code == 'live'\n        m3u8_url = None\n        # http://eyedo.tv/Content/Html5/Scripts/html5view.js\n        if is_live:\n            if xpath_text(video_data, 'Cdn') == 'true':\n                m3u8_url = 'http://rrr.sz.xlcdn.com/?account=eyedo&file=A%s&type=live&service=wowza&protocol=http&output=playlist.m3u8' % video_id\n            else:\n                m3u8_url = self._ROOT_URL + 'w/%s/eyedo_720p/playlist.m3u8' % video_id\n        else:\n            m3u8_url = self._ROOT_URL + 'replay-w/%s/mp4:%s.mp4/playlist.m3u8' % (video_id, video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native'),\n            'description': xpath_text(video_data, _add_ns('Description')),\n            'duration': parse_duration(xpath_text(video_data, _add_ns('Duration'))),\n            'uploader': xpath_text(video_data, _add_ns('Createur')),\n            'uploader_id': xpath_text(video_data, _add_ns('CreateurId')),\n            'chapter': xpath_text(video_data, _add_ns('ChapitreTitre')),\n            'chapter_id': xpath_text(video_data, _add_ns('ChapitreId')),\n        }",
        "begin_line": 28,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._extract_urls#206",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        urls = []\n        for mobj in re.finditer(\n                r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://www\\.facebook\\.com/(?:video/embed|plugins/video\\.php).+?)\\1',\n                webpage):\n            urls.append(mobj.group('url'))\n        # Facebook API embed\n        # see https://developers.facebook.com/docs/plugins/embedded-video-player\n        for mobj in re.finditer(r'''(?x)<div[^>]+\n                class=(?P<q1>[\\'\"])[^\\'\"]*\\bfb-(?:video|post)\\b[^\\'\"]*(?P=q1)[^>]+\n                data-href=(?P<q2>[\\'\"])(?P<url>(?:https?:)?//(?:www\\.)?facebook.com/.+?)(?P=q2)''', webpage):\n            urls.append(mobj.group('url'))\n        return urls",
        "begin_line": 206,
        "end_line": 218,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._login#220",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._login(self)",
        "snippet": "    def _login(self):\n        (useremail, password) = self._get_login_info()\n        if useremail is None:\n            return\n\n        login_page_req = sanitized_Request(self._LOGIN_URL)\n        self._set_cookie('facebook.com', 'locale', 'en_US')\n        login_page = self._download_webpage(login_page_req, None,\n                                            note='Downloading login page',\n                                            errnote='Unable to download login page')\n        lsd = self._search_regex(\n            r'<input type=\"hidden\" name=\"lsd\" value=\"([^\"]*)\"',\n            login_page, 'lsd')\n        lgnrnd = self._search_regex(r'name=\"lgnrnd\" value=\"([^\"]*?)\"', login_page, 'lgnrnd')\n\n        login_form = {\n            'email': useremail,\n            'pass': password,\n            'lsd': lsd,\n            'lgnrnd': lgnrnd,\n            'next': 'http://facebook.com/home.php',\n            'default_persistent': '0',\n            'legacy_return': '1',\n            'timezone': '-60',\n            'trynum': '1',\n        }\n        request = sanitized_Request(self._LOGIN_URL, urlencode_postdata(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        try:\n            login_results = self._download_webpage(request, None,\n                                                   note='Logging in', errnote='unable to fetch login page')\n            if re.search(r'<form(.*)name=\"login\"(.*)</form>', login_results) is not None:\n                error = self._html_search_regex(\n                    r'(?s)<div[^>]+class=([\"\\']).*?login_error_box.*?\\1[^>]*><div[^>]*>.*?</div><div[^>]*>(?P<error>.+?)</div>',\n                    login_results, 'login error', default=None, group='error')\n                if error:\n                    raise ExtractorError('Unable to login: %s' % error, expected=True)\n                self._downloader.report_warning('unable to log in: bad username/password, or exceeded login rate limit (~3/min). Check credentials or wait.')\n                return\n\n            fb_dtsg = self._search_regex(\n                r'name=\"fb_dtsg\" value=\"(.+?)\"', login_results, 'fb_dtsg', default=None)\n            h = self._search_regex(\n                r'name=\"h\"\\s+(?:\\w+=\"[^\"]+\"\\s+)*?value=\"([^\"]+)\"', login_results, 'h', default=None)\n\n            if not fb_dtsg or not h:\n                return\n\n            check_form = {\n                'fb_dtsg': fb_dtsg,\n                'h': h,\n                'name_action_selected': 'dont_save',\n            }\n            check_req = sanitized_Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))\n            check_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            check_response = self._download_webpage(check_req, None,\n                                                    note='Confirming login')\n            if re.search(r'id=\"checkpointSubmitButton\"', check_response) is not None:\n                self._downloader.report_warning('Unable to confirm login, you have to login in your browser and authorize the login.')\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            self._downloader.report_warning('unable to log in: %s' % error_to_compat_str(err))\n            return",
        "begin_line": 220,
        "end_line": 281,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_initialize#283",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 283,
        "end_line": 284,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._extract_from_url#286",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._extract_from_url(self, url, video_id, fatal_if_no_video=True)",
        "snippet": "    def _extract_from_url(self, url, video_id, fatal_if_no_video=True):\n        req = sanitized_Request(url)\n        req.add_header('User-Agent', self._CHROME_USER_AGENT)\n        webpage = self._download_webpage(req, video_id)\n\n        video_data = None\n\n        def extract_video_data(instances):\n            for item in instances:\n                if item[1][0] == 'VideoConfig':\n                    video_item = item[2][0]\n                    if video_item.get('video_id'):\n                        return video_item['videoData']\n\n        server_js_data = self._parse_json(self._search_regex(\n            r'handleServerJS\\(({.+})(?:\\);|,\")', webpage,\n            'server js data', default='{}'), video_id, fatal=False)\n\n        if server_js_data:\n            video_data = extract_video_data(server_js_data.get('instances', []))\n\n        if not video_data:\n            server_js_data = self._parse_json(\n                self._search_regex(\n                    r'bigPipe\\.onPageletArrive\\(({.+?})\\)\\s*;\\s*}\\s*\\)\\s*,\\s*[\"\\']onPageletArrive\\s+(?:stream_pagelet|pagelet_group_mall|permalink_video_pagelet)',\n                    webpage, 'js data', default='{}'),\n                video_id, transform_source=js_to_json, fatal=False)\n            if server_js_data:\n                video_data = extract_video_data(try_get(\n                    server_js_data, lambda x: x['jsmods']['instances'],\n                    list) or [])\n\n        if not video_data:\n            if not fatal_if_no_video:\n                return webpage, False\n            m_msg = re.search(r'class=\"[^\"]*uiInterstitialContent[^\"]*\"><div>(.*?)</div>', webpage)\n            if m_msg is not None:\n                raise ExtractorError(\n                    'The video is not available, Facebook said: \"%s\"' % m_msg.group(1),\n                    expected=True)\n            elif '>You must log in to continue' in webpage:\n                self.raise_login_required()\n            else:\n                raise ExtractorError('Cannot parse data')\n\n        formats = []\n        for f in video_data:\n            format_id = f['stream_type']\n            if f and isinstance(f, dict):\n                f = [f]\n            if not f or not isinstance(f, list):\n                continue\n            for quality in ('sd', 'hd'):\n                for src_type in ('src', 'src_no_ratelimit'):\n                    src = f[0].get('%s_%s' % (quality, src_type))\n                    if src:\n                        preference = -10 if format_id == 'progressive' else 0\n                        if quality == 'hd':\n                            preference += 5\n                        formats.append({\n                            'format_id': '%s_%s_%s' % (format_id, quality, src_type),\n                            'url': src,\n                            'preference': preference,\n                        })\n            dash_manifest = f[0].get('dash_manifest')\n            if dash_manifest:\n                formats.extend(self._parse_mpd_formats(\n                    compat_etree_fromstring(compat_urllib_parse_unquote_plus(dash_manifest))))\n        if not formats:\n            raise ExtractorError('Cannot find video formats')\n\n        self._sort_formats(formats)\n\n        video_title = self._html_search_regex(\n            r'<h2\\s+[^>]*class=\"uiHeaderTitle\"[^>]*>([^<]*)</h2>', webpage,\n            'title', default=None)\n        if not video_title:\n            video_title = self._html_search_regex(\n                r'(?s)<span class=\"fbPhotosPhotoCaption\".*?id=\"fbPhotoPageCaption\"><span class=\"hasCaption\">(.*?)</span>',\n                webpage, 'alternative title', default=None)\n        if not video_title:\n            video_title = self._html_search_meta(\n                'description', webpage, 'title', default=None)\n        if video_title:\n            video_title = limit_length(video_title, 80)\n        else:\n            video_title = 'Facebook video #%s' % video_id\n        uploader = clean_html(get_element_by_id(\n            'fbPhotoPageAuthorName', webpage)) or self._search_regex(\n            r'ownerName\\s*:\\s*\"([^\"]+)\"', webpage, 'uploader', fatal=False)\n        timestamp = int_or_none(self._search_regex(\n            r'<abbr[^>]+data-utime=[\"\\'](\\d+)', webpage,\n            'timestamp', default=None))\n\n        info_dict = {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'uploader': uploader,\n            'timestamp': timestamp,\n        }\n\n        return webpage, info_dict",
        "begin_line": 286,
        "end_line": 388,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_extract#390",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        real_url = self._VIDEO_PAGE_TEMPLATE % video_id if url.startswith('facebook:') else url\n        webpage, info_dict = self._extract_from_url(real_url, video_id, fatal_if_no_video=False)\n\n        if info_dict:\n            return info_dict\n\n        if '/posts/' in url:\n            entries = [\n                self.url_result('facebook:%s' % vid, FacebookIE.ie_key())\n                for vid in self._parse_json(\n                    self._search_regex(\n                        r'([\"\\'])video_ids\\1\\s*:\\s*(?P<ids>\\[.+?\\])',\n                        webpage, 'video ids', group='ids'),\n                    video_id)]\n\n            return self.playlist_result(entries, video_id)\n        else:\n            _, info_dict = self._extract_from_url(\n                self._VIDEO_PAGE_TEMPLATE % video_id,\n                video_id, fatal_if_no_video=True)\n            return info_dict",
        "begin_line": 390,
        "end_line": 413,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookPluginsVideoIE._real_extract#439",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookPluginsVideoIE",
        "signature": "youtube_dl.extractor.facebook.FacebookPluginsVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(\n            compat_urllib_parse_unquote(self._match_id(url)),\n            FacebookIE.ie_key())",
        "begin_line": 439,
        "end_line": 442,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.faz.FazIE._real_extract#41",
        "src_path": "youtube_dl/extractor/faz.py",
        "class_name": "youtube_dl.extractor.faz.FazIE",
        "signature": "youtube_dl.extractor.faz.FazIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        description = self._og_search_description(webpage)\n        config_xml_url = self._search_regex(\n            r'videoXMLURL\\s*=\\s*\"([^\"]+)', webpage, 'config xml url')\n        config = self._download_xml(\n            config_xml_url, video_id, 'Downloading config xml')\n\n        encodings = xpath_element(config, 'ENCODINGS', 'encodings', True)\n        formats = []\n        for pref, code in enumerate(['LOW', 'HIGH', 'HQ']):\n            encoding = xpath_element(encodings, code)\n            if encoding is not None:\n                encoding_url = xpath_text(encoding, 'FILENAME')\n                if encoding_url:\n                    formats.append({\n                        'url': encoding_url,\n                        'format_id': code.lower(),\n                        'quality': pref,\n                        'tbr': int_or_none(xpath_text(encoding, 'AVERAGEBITRATE')),\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': description.strip() if description else None,\n            'thumbnail': xpath_text(config, 'STILL/STILL_BIG'),\n            'duration': int_or_none(xpath_text(config, 'DURATION')),\n        }",
        "begin_line": 41,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2IE._login#48",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2IE",
        "signature": "youtube_dl.extractor.fc2.FC2IE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            return False\n\n        # Log in\n        login_form_strs = {\n            'email': username,\n            'password': password,\n            'done': 'video',\n            'Submit': ' Login ',\n        }\n\n        login_data = urlencode_postdata(login_form_strs)\n        request = sanitized_Request(\n            'https://secure.id.fc2.com/index.php?mode=login&switch_language=en', login_data)\n\n        login_results = self._download_webpage(request, None, note='Logging in', errnote='Unable to log in')\n        if 'mode=redirect&login=done' not in login_results:\n            self.report_warning('unable to log in: bad username or password')\n            return False\n\n        # this is also needed\n        login_redir = sanitized_Request('http://id.fc2.com/?mode=redirect&login=done')\n        self._download_webpage(\n            login_redir, None, note='Login redirect', errnote='Login redirect failed')\n\n        return True",
        "begin_line": 48,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2IE._real_extract#77",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2IE",
        "signature": "youtube_dl.extractor.fc2.FC2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        self._login()\n        webpage = None\n        if not url.startswith('fc2:'):\n            webpage = self._download_webpage(url, video_id)\n            self._downloader.cookiejar.clear_session_cookies()  # must clear\n            self._login()\n\n        title = 'FC2 video %s' % video_id\n        thumbnail = None\n        if webpage is not None:\n            title = self._og_search_title(webpage)\n            thumbnail = self._og_search_thumbnail(webpage)\n        refer = url.replace('/content/', '/a/content/') if '/a/content/' not in url else url\n\n        mimi = hashlib.md5((video_id + '_gGddgPfeaf_gzyr').encode('utf-8')).hexdigest()\n\n        info_url = (\n            'http://video.fc2.com/ginfo.php?mimi={1:s}&href={2:s}&v={0:s}&fversion=WIN%2011%2C6%2C602%2C180&from=2&otag=0&upid={0:s}&tk=null&'.\n            format(video_id, mimi, compat_urllib_request.quote(refer, safe=b'').replace('.', '%2E')))\n\n        info_webpage = self._download_webpage(\n            info_url, video_id, note='Downloading info page')\n        info = compat_urlparse.parse_qs(info_webpage)\n\n        if 'err_code' in info:\n            # most of the time we can still download wideo even if err_code is 403 or 602\n            self.report_warning(\n                'Error code was: %s... but still trying' % info['err_code'][0])\n\n        if 'filepath' not in info:\n            raise ExtractorError('Cannot download file. Are you logged in?')\n\n        video_url = info['filepath'][0] + '?mid=' + info['mid'][0]\n        title_info = info.get('title')\n        if title_info:\n            title = title_info[0]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'flv',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 77,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2EmbedIE._real_extract#140",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2EmbedIE",
        "signature": "youtube_dl.extractor.fc2.FC2EmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_parse_qs(mobj.group('query'))\n\n        video_id = query['i'][-1]\n        title = query.get('tl', ['FC2 video %s' % video_id])[0]\n\n        sj = query.get('sj', [None])[0]\n        thumbnail = None\n        if sj:\n            # See thumbnailImagePath() in ServerConst.as of flv2.swf\n            thumbnail = 'http://video%s-thumbnail.fc2.com/up/pic/%s.jpg' % (\n                sj, '/'.join((video_id[:6], video_id[6:8], video_id[-2], video_id[-1], video_id)))\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': FC2IE.ie_key(),\n            'url': 'fc2:%s' % video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 140,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fczenit.FczenitIE._real_extract#20",
        "src_path": "youtube_dl/extractor/fczenit.py",
        "class_name": "youtube_dl.extractor.fczenit.FczenitIE",
        "signature": "youtube_dl.extractor.fczenit.FczenitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(\n            r'<[^>]+class=\\\"photoalbum__title\\\">([^<]+)', webpage, 'title')\n\n        video_items = self._parse_json(self._search_regex(\n            r'arrPath\\s*=\\s*JSON\\.parse\\(\\'(.+)\\'\\)', webpage, 'video items'),\n            video_id)\n\n        def merge_dicts(*dicts):\n            ret = {}\n            for a_dict in dicts:\n                ret.update(a_dict)\n            return ret\n\n        formats = [{\n            'url': compat_urlparse.urljoin(url, video_url),\n            'tbr': int(tbr),\n        } for tbr, video_url in merge_dicts(*video_items).items()]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n        }",
        "begin_line": 20,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.filmon.FilmOnIE._real_extract#38",
        "src_path": "youtube_dl/extractor/filmon.py",
        "class_name": "youtube_dl.extractor.filmon.FilmOnIE",
        "signature": "youtube_dl.extractor.filmon.FilmOnIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            response = self._download_json(\n                'https://www.filmon.com/api/vod/movie?id=%s' % video_id,\n                video_id)['response']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                errmsg = self._parse_json(e.cause.read().decode(), video_id)['reason']\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, errmsg), expected=True)\n            raise\n\n        title = response['title']\n        description = strip_or_none(response.get('description'))\n\n        if response.get('type_id') == 1:\n            entries = [self.url_result('filmon:' + episode_id) for episode_id in response.get('episodes', [])]\n            return self.playlist_result(entries, video_id, title, description)\n\n        QUALITY = qualities(('low', 'high'))\n        formats = []\n        for format_id, stream in response.get('streams', {}).items():\n            stream_url = stream.get('url')\n            if not stream_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': stream_url,\n                'ext': 'mp4',\n                'quality': QUALITY(stream.get('quality')),\n                'protocol': 'm3u8_native',\n            })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        poster = response.get('poster', {})\n        thumbs = poster.get('thumbs', {})\n        thumbs['poster'] = poster\n        for thumb_id, thumb in thumbs.items():\n            thumb_url = thumb.get('url')\n            if not thumb_url:\n                continue\n            thumbnails.append({\n                'id': thumb_id,\n                'url': thumb_url,\n                'width': int_or_none(thumb.get('width')),\n                'height': int_or_none(thumb.get('height')),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 38,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.filmon.FilmOnChannelIE._real_extract#124",
        "src_path": "youtube_dl/extractor/filmon.py",
        "class_name": "youtube_dl.extractor.filmon.FilmOnChannelIE",
        "signature": "youtube_dl.extractor.filmon.FilmOnChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        try:\n            channel_data = self._download_json(\n                'http://www.filmon.com/api-v2/channel/' + channel_id, channel_id)['data']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                errmsg = self._parse_json(e.cause.read().decode(), channel_id)['message']\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, errmsg), expected=True)\n            raise\n\n        channel_id = compat_str(channel_data['id'])\n        is_live = not channel_data.get('is_vod') and not channel_data.get('is_vox')\n        title = channel_data['title']\n\n        QUALITY = qualities(('low', 'high'))\n        formats = []\n        for stream in channel_data.get('streams', []):\n            stream_url = stream.get('url')\n            if not stream_url:\n                continue\n            if not is_live:\n                formats.extend(self._extract_wowza_formats(\n                    stream_url, channel_id, skip_protocols=['dash', 'rtmp', 'rtsp']))\n                continue\n            quality = stream.get('quality')\n            formats.append({\n                'format_id': quality,\n                # this is an m3u8 stream, but we are deliberately not using _extract_m3u8_formats\n                # because it doesn't have bitrate variants anyway\n                'url': stream_url,\n                'ext': 'mp4',\n                'quality': QUALITY(quality),\n            })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for name, width, height in self._THUMBNAIL_RES:\n            thumbnails.append({\n                'id': name,\n                'url': 'http://static.filmon.com/assets/channels/%s/%s.png' % (channel_id, name),\n                'width': width,\n                'height': height,\n            })\n\n        return {\n            'id': channel_id,\n            'display_id': channel_data.get('alias'),\n            'title': self._live_title(title) if is_live else title,\n            'description': channel_data.get('description'),\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'is_live': is_live,\n        }",
        "begin_line": 124,
        "end_line": 178,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract#20",
        "src_path": "youtube_dl/extractor/firstpost.py",
        "class_name": "youtube_dl.extractor.firstpost.FirstpostIE",
        "signature": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        page = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('twitter:title', page, 'title', fatal=True)\n        description = self._html_search_meta('twitter:description', page, 'title')\n\n        data = self._download_xml(\n            'http://www.firstpost.com/getvideoxml-%s.xml' % video_id, video_id,\n            'Downloading video XML')\n\n        item = data.find('./playlist/item')\n        thumbnail = item.find('./image').text\n\n        formats = [\n            {\n                'url': details.find('./file').text,\n                'format_id': details.find('./label').text.strip(),\n                'width': int(details.find('./width').text.strip()),\n                'height': int(details.find('./height').text.strip()),\n            } for details in item.findall('./source/file_details') if details.find('./file').text\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 20,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract#61",
        "src_path": "youtube_dl/extractor/firsttv.py",
        "class_name": "youtube_dl.extractor.firsttv.FirstTVIE",
        "signature": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n        playlist_url = compat_urlparse.urljoin(url, self._search_regex(\n            r'data-playlist-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'playlist url', group='url'))\n\n        parsed_url = compat_urlparse.urlparse(playlist_url)\n        qs = compat_urlparse.parse_qs(parsed_url.query)\n        item_ids = qs.get('videos_ids[]') or qs.get('news_ids[]')\n\n        items = self._download_json(playlist_url, display_id)\n\n        if item_ids:\n            items = [\n                item for item in items\n                if item.get('uid') and compat_str(item['uid']) in item_ids]\n        else:\n            items = [items[0]]\n\n        entries = []\n        QUALITIES = ('ld', 'sd', 'hd', )\n\n        for item in items:\n            title = item['title']\n            quality = qualities(QUALITIES)\n            formats = []\n            path = None\n            for f in item.get('mbr', []):\n                src = f.get('src')\n                if not src or not isinstance(src, compat_str):\n                    continue\n                tbr = int_or_none(self._search_regex(\n                    r'_(\\d{3,})\\.mp4', src, 'tbr', default=None))\n                if not path:\n                    path = self._search_regex(\n                        r'//[^/]+/(.+?)_\\d+\\.mp4', src,\n                        'm3u8 path', default=None)\n                formats.append({\n                    'url': src,\n                    'format_id': f.get('name'),\n                    'tbr': tbr,\n                    'source_preference': quality(f.get('name')),\n                    # quality metadata of http formats may be incorrect\n                    'preference': -1,\n                })\n            # m3u8 URL format is reverse engineered from [1] (search for\n            # master.m3u8). dashEdges (that is currently balancer-vod.1tv.ru)\n            # is taken from [2].\n            # 1. http://static.1tv.ru/player/eump1tv-current/eump-1tv.all.min.js?rnd=9097422834:formatted\n            # 2. http://static.1tv.ru/player/eump1tv-config/config-main.js?rnd=9097422834\n            if not path and len(formats) == 1:\n                path = self._search_regex(\n                    r'//[^/]+/(.+?$)', formats[0]['url'],\n                    'm3u8 path', default=None)\n            if path:\n                if len(formats) == 1:\n                    m3u8_path = ','\n                else:\n                    tbrs = [compat_str(t) for t in sorted(f['tbr'] for f in formats)]\n                    m3u8_path = '_,%s,%s' % (','.join(tbrs), '.mp4')\n                formats.extend(self._extract_m3u8_formats(\n                    'http://balancer-vod.1tv.ru/%s%s.urlset/master.m3u8'\n                    % (path, m3u8_path),\n                    display_id, 'mp4',\n                    entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n            self._sort_formats(formats)\n\n            thumbnail = item.get('poster') or self._og_search_thumbnail(webpage)\n            duration = int_or_none(item.get('duration') or self._html_search_meta(\n                'video:duration', webpage, 'video duration', fatal=False))\n            upload_date = unified_strdate(self._html_search_meta(\n                'ya:ovs:upload_date', webpage, 'upload date', default=None))\n\n            entries.append({\n                'id': compat_str(item.get('id') or item['uid']),\n                'thumbnail': thumbnail,\n                'title': title,\n                'upload_date': upload_date,\n                'duration': int_or_none(duration),\n                'formats': formats\n            })\n\n        title = self._html_search_regex(\n            (r'<div class=\"tv_translation\">\\s*<h1><a href=\"[^\"]+\">([^<]*)</a>',\n             r\"'title'\\s*:\\s*'([^']+)'\"),\n            webpage, 'title', default=None) or self._og_search_title(\n            webpage, default=None)\n        description = self._html_search_regex(\n            r'<div class=\"descr\">\\s*<div>&nbsp;</div>\\s*<p>([^<]*)</p></div>',\n            webpage, 'description', default=None) or self._html_search_meta(\n            'description', webpage, 'description', default=None)\n\n        return self.playlist_result(entries, display_id, title, description)",
        "begin_line": 61,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract#52",
        "src_path": "youtube_dl/extractor/fivemin.py",
        "class_name": "youtube_dl.extractor.fivemin.FiveMinIE",
        "signature": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self.url_result('aol-video:%s' % video_id)",
        "begin_line": 52,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fivetv.FiveTVIE._real_extract#66",
        "src_path": "youtube_dl/extractor/fivetv.py",
        "class_name": "youtube_dl.extractor.fivetv.FiveTVIE",
        "signature": "youtube_dl.extractor.fivetv.FiveTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('path')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            [r'<div[^>]+?class=\"flowplayer[^>]+?data-href=\"([^\"]+)\"',\n             r'<a[^>]+?href=\"([^\"]+)\"[^>]+?class=\"videoplayer\"'],\n            webpage, 'video url')\n\n        title = self._og_search_title(webpage, default=None) or self._search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title')\n        duration = int_or_none(self._og_search_property(\n            'video:duration', webpage, 'duration', default=None))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n        }",
        "begin_line": 66,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVIE",
        "signature": "youtube_dl.extractor.fktv.FKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        episode = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://fernsehkritik.tv/folge-%s/play' % episode, episode)\n        title = clean_html(self._html_search_regex(\n            '<h3>([^<]+)</h3>', webpage, 'title'))\n        thumbnail = self._search_regex(r'POSTER\\s*=\\s*\"([^\"]+)', webpage, 'thumbnail', fatal=False)\n        sources = self._parse_json(self._search_regex(r'(?s)MEDIA\\s*=\\s*(\\[.+?\\]);', webpage, 'media'), episode, js_to_json)\n\n        formats = []\n        for source in sources:\n            furl = source.get('src')\n            if furl:\n                formats.append({\n                    'url': furl,\n                    'format_id': determine_ext(furl),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': episode,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 26,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.flickr.FlickrIE._call_api#53",
        "src_path": "youtube_dl/extractor/flickr.py",
        "class_name": "youtube_dl.extractor.flickr.FlickrIE",
        "signature": "youtube_dl.extractor.flickr.FlickrIE._call_api(self, method, video_id, api_key, note, secret=None)",
        "snippet": "    def _call_api(self, method, video_id, api_key, note, secret=None):\n        query = {\n            'photo_id': video_id,\n            'method': 'flickr.%s' % method,\n            'api_key': api_key,\n            'format': 'json',\n            'nojsoncallback': 1,\n        }\n        if secret:\n            query['secret'] = secret\n        data = self._download_json(self._API_BASE_URL + compat_urllib_parse_urlencode(query), video_id, note)\n        if data['stat'] != 'ok':\n            raise ExtractorError(data['message'])\n        return data",
        "begin_line": 53,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.flickr.FlickrIE._real_extract#68",
        "src_path": "youtube_dl/extractor/flickr.py",
        "class_name": "youtube_dl.extractor.flickr.FlickrIE",
        "signature": "youtube_dl.extractor.flickr.FlickrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        api_key = self._download_json(\n            'https://www.flickr.com/hermes_error_beacon.gne', video_id,\n            'Downloading api key')['site_key']\n\n        video_info = self._call_api(\n            'photos.getInfo', video_id, api_key, 'Downloading video info')['photo']\n        if video_info['media'] == 'video':\n            streams = self._call_api(\n                'video.getStreamInfo', video_id, api_key,\n                'Downloading streams info', video_info['secret'])['streams']\n\n            preference = qualities(\n                ['288p', 'iphone_wifi', '100', '300', '700', '360p', 'appletv', '720p', '1080p', 'orig'])\n\n            formats = []\n            for stream in streams['stream']:\n                stream_type = compat_str(stream.get('type'))\n                formats.append({\n                    'format_id': stream_type,\n                    'url': stream['_content'],\n                    'preference': preference(stream_type),\n                })\n            self._sort_formats(formats)\n\n            owner = video_info.get('owner', {})\n            uploader_id = owner.get('nsid')\n            uploader_path = owner.get('path_alias') or uploader_id\n            uploader_url = 'https://www.flickr.com/photos/%s/' % uploader_path if uploader_path else None\n\n            return {\n                'id': video_id,\n                'title': video_info['title']['_content'],\n                'description': video_info.get('description', {}).get('_content'),\n                'formats': formats,\n                'timestamp': int_or_none(video_info.get('dateuploaded')),\n                'duration': int_or_none(video_info.get('video', {}).get('duration')),\n                'uploader_id': uploader_id,\n                'uploader': owner.get('realname'),\n                'uploader_url': uploader_url,\n                'comment_count': int_or_none(video_info.get('comments', {}).get('_content')),\n                'view_count': int_or_none(video_info.get('views')),\n                'tags': [tag.get('_content') for tag in video_info.get('tags', {}).get('tag', [])],\n                'license': self._LICENSES.get(video_info.get('license')),\n            }\n        else:\n            raise ExtractorError('not a video', expected=True)",
        "begin_line": 68,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.flipagram.FlipagramIE._real_extract#39",
        "src_path": "youtube_dl/extractor/flipagram.py",
        "class_name": "youtube_dl.extractor.flipagram.FlipagramIE",
        "signature": "youtube_dl.extractor.flipagram.FlipagramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_data = self._parse_json(\n            self._search_regex(\n                r'window\\.reactH2O\\s*=\\s*({.+});', webpage, 'video data'),\n            video_id)\n\n        flipagram = video_data['flipagram']\n        video = flipagram['video']\n\n        json_ld = self._search_json_ld(webpage, video_id, default={})\n        title = json_ld.get('title') or flipagram['captionText']\n        description = json_ld.get('description') or flipagram.get('captionText')\n\n        formats = [{\n            'url': video['url'],\n            'width': int_or_none(video.get('width')),\n            'height': int_or_none(video.get('height')),\n            'filesize': int_or_none(video_data.get('size')),\n        }]\n\n        preview_url = try_get(\n            flipagram, lambda x: x['music']['track']['previewUrl'], compat_str)\n        if preview_url:\n            formats.append({\n                'url': preview_url,\n                'ext': 'm4a',\n                'vcodec': 'none',\n            })\n\n        self._sort_formats(formats)\n\n        counts = flipagram.get('counts', {})\n        user = flipagram.get('user', {})\n        video_data = flipagram.get('video', {})\n\n        thumbnails = [{\n            'url': self._proto_relative_url(cover['url']),\n            'width': int_or_none(cover.get('width')),\n            'height': int_or_none(cover.get('height')),\n            'filesize': int_or_none(cover.get('size')),\n        } for cover in flipagram.get('covers', []) if cover.get('url')]\n\n        # Note that this only retrieves comments that are initially loaded.\n        # For videos with large amounts of comments, most won't be retrieved.\n        comments = []\n        for comment in video_data.get('comments', {}).get(video_id, {}).get('items', []):\n            text = comment.get('comment')\n            if not text or not isinstance(text, list):\n                continue\n            comments.append({\n                'author': comment.get('user', {}).get('name'),\n                'author_id': comment.get('user', {}).get('username'),\n                'id': comment.get('id'),\n                'text': text[0],\n                'timestamp': unified_timestamp(comment.get('created')),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': float_or_none(flipagram.get('duration'), 1000),\n            'thumbnails': thumbnails,\n            'timestamp': unified_timestamp(flipagram.get('iso8601Created')),\n            'uploader': user.get('name'),\n            'uploader_id': user.get('username'),\n            'creator': user.get('name'),\n            'view_count': int_or_none(counts.get('plays')),\n            'like_count': int_or_none(counts.get('likes')),\n            'repost_count': int_or_none(counts.get('reflips')),\n            'comment_count': int_or_none(counts.get('comments')),\n            'comments': comments,\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.folketinget.FolketingetIE._real_extract#39",
        "src_path": "youtube_dl/extractor/folketinget.py",
        "class_name": "youtube_dl.extractor.folketinget.FolketingetIE",
        "signature": "youtube_dl.extractor.folketinget.FolketingetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'(?s)<div class=\"video-item-agenda\"[^>]*>(.*?)<',\n            webpage, 'description', fatal=False)\n\n        player_params = compat_parse_qs(self._search_regex(\n            r'<embed src=\"http://ft\\.arkena\\.tv/flash/ftplayer\\.swf\\?([^\"]+)\"',\n            webpage, 'player params'))\n        xml_url = player_params['xml'][0]\n        doc = self._download_xml(xml_url, video_id)\n\n        timestamp = parse_iso8601(xpath_text(doc, './/date'))\n        duration = parse_duration(xpath_text(doc, './/duration'))\n        width = int_or_none(xpath_text(doc, './/width'))\n        height = int_or_none(xpath_text(doc, './/height'))\n        view_count = int_or_none(xpath_text(doc, './/views'))\n\n        formats = [{\n            'format_id': n.attrib['bitrate'],\n            'url': xpath_text(n, './url', fatal=True),\n            'tbr': int_or_none(n.attrib['bitrate']),\n        } for n in doc.findall('.//streams/stream')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'timestamp': timestamp,\n            'width': width,\n            'height': height,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 39,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.footyroom.FootyRoomIE._real_extract#28",
        "src_path": "youtube_dl/extractor/footyroom.py",
        "class_name": "youtube_dl.extractor.footyroom.FootyRoomIE",
        "signature": "youtube_dl.extractor.footyroom.FootyRoomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist = self._parse_json(self._search_regex(\n            r'DataStore\\.media\\s*=\\s*([^;]+)', webpage, 'media data'),\n            playlist_id)\n\n        playlist_title = self._og_search_title(webpage)\n\n        entries = []\n        for video in playlist:\n            payload = video.get('payload')\n            if not payload:\n                continue\n            playwire_url = self._html_search_regex(\n                r'data-config=\"([^\"]+)\"', payload,\n                'playwire url', default=None)\n            if playwire_url:\n                entries.append(self.url_result(self._proto_relative_url(\n                    playwire_url, 'http:'), 'Playwire'))\n\n            streamable_url = StreamableIE._extract_url(payload)\n            if streamable_url:\n                entries.append(self.url_result(\n                    streamable_url, StreamableIE.ie_key()))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 28,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.formula1.Formula1IE._real_extract#27",
        "src_path": "youtube_dl/extractor/formula1.py",
        "class_name": "youtube_dl.extractor.formula1.Formula1IE",
        "signature": "youtube_dl.extractor.formula1.Formula1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        ooyala_embed_code = self._search_regex(\n            r'data-videoid=\"([^\"]+)\"', webpage, 'ooyala embed code')\n        return self.url_result(\n            'ooyala:%s' % ooyala_embed_code, 'Ooyala', ooyala_embed_code)",
        "begin_line": 27,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fourtube.FourTubeBaseIE._real_extract#15",
        "src_path": "youtube_dl/extractor/fourtube.py",
        "class_name": "youtube_dl.extractor.fourtube.FourTubeBaseIE",
        "signature": "youtube_dl.extractor.fourtube.FourTubeBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        kind, video_id, display_id = mobj.group('kind', 'id', 'display_id')\n\n        if kind == 'm' or not display_id:\n            url = self._URL_TEMPLATE % video_id\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('name', webpage)\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage))\n        thumbnail = self._html_search_meta('thumbnailUrl', webpage)\n        uploader_id = self._html_search_regex(\n            r'<a class=\"item-to-subscribe\" href=\"[^\"]+/(?:channel|user)s?/([^/\"]+)\" title=\"Go to [^\"]+ page\">',\n            webpage, 'uploader id', fatal=False)\n        uploader = self._html_search_regex(\n            r'<a class=\"item-to-subscribe\" href=\"[^\"]+/(?:channel|user)s?/[^/\"]+\" title=\"Go to ([^\"]+) page\">',\n            webpage, 'uploader', fatal=False)\n\n        categories_html = self._search_regex(\n            r'(?s)><i class=\"icon icon-tag\"></i>\\s*Categories / Tags\\s*.*?<ul class=\"[^\"]*?list[^\"]*?\">(.*?)</ul>',\n            webpage, 'categories', fatal=False)\n        categories = None\n        if categories_html:\n            categories = [\n                c.strip() for c in re.findall(\n                    r'(?s)<li><a.*?>(.*?)</a>', categories_html)]\n\n        view_count = str_to_int(self._search_regex(\n            r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserPlays:([0-9,]+)\">',\n            webpage, 'view count', default=None))\n        like_count = str_to_int(self._search_regex(\n            r'<meta[^>]+itemprop=\"interactionCount\"[^>]+content=\"UserLikes:([0-9,]+)\">',\n            webpage, 'like count', default=None))\n        duration = parse_duration(self._html_search_meta('duration', webpage))\n\n        media_id = self._search_regex(\n            r'<button[^>]+data-id=([\"\\'])(?P<id>\\d+)\\1[^>]+data-quality=', webpage,\n            'media id', default=None, group='id')\n        sources = [\n            quality\n            for _, quality in re.findall(r'<button[^>]+data-quality=([\"\\'])(.+?)\\1', webpage)]\n        if not (media_id and sources):\n            player_js = self._download_webpage(\n                self._search_regex(\n                    r'<script[^>]id=([\"\\'])playerembed\\1[^>]+src=([\"\\'])(?P<url>.+?)\\2',\n                    webpage, 'player JS', group='url'),\n                video_id, 'Downloading player JS')\n            params_js = self._search_regex(\n                r'\\$\\.ajax\\(url,\\ opts\\);\\s*\\}\\s*\\}\\)\\(([0-9,\\[\\] ]+)\\)',\n                player_js, 'initialization parameters')\n            params = self._parse_json('[%s]' % params_js, video_id)\n            media_id = params[0]\n            sources = ['%s' % p for p in params[2]]\n\n        token_url = 'https://tkn.kodicdn.com/{0}/desktop/{1}'.format(\n            media_id, '+'.join(sources))\n\n        parsed_url = compat_urlparse.urlparse(url)\n        tokens = self._download_json(token_url, video_id, data=b'', headers={\n            'Origin': '%s://%s' % (parsed_url.scheme, parsed_url.hostname),\n            'Referer': url,\n        })\n        formats = [{\n            'url': tokens[format]['token'],\n            'format_id': format + 'p',\n            'resolution': format + 'p',\n            'quality': int(format),\n        } for format in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'categories': categories,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'timestamp': timestamp,\n            'like_count': like_count,\n            'view_count': view_count,\n            'duration': duration,\n            'age_limit': 18,\n        }",
        "begin_line": 15,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fox.FOXIE._real_extract#29",
        "src_path": "youtube_dl/extractor/fox.py",
        "class_name": "youtube_dl.extractor.fox.FOXIE",
        "signature": "youtube_dl.extractor.fox.FOXIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        settings = self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n            webpage, 'drupal settings'), video_id)\n        fox_pdk_player = settings['fox_pdk_player']\n        release_url = fox_pdk_player['release_url']\n        query = {\n            'mbr': 'true',\n            'switch': 'http'\n        }\n        if fox_pdk_player.get('access') == 'locked':\n            ap_p = settings['foxAdobePassProvider']\n            rating = ap_p.get('videoRating')\n            if rating == 'n/a':\n                rating = None\n            resource = self._get_mvpd_resource('fbc-fox', None, ap_p['videoGUID'], rating)\n            query['auth'] = self._extract_mvpd_auth(url, video_id, 'fbc-fox', resource)\n\n        info = self._search_json_ld(webpage, video_id, fatal=False)\n        info.update({\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(update_url_query(release_url, query), {'force_smil_url': True}),\n            'id': video_id,\n        })\n\n        return info",
        "begin_line": 29,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fox9.FOX9IE._real_extract#30",
        "src_path": "youtube_dl/extractor/fox9.py",
        "class_name": "youtube_dl.extractor.fox9.FOX9IE",
        "signature": "youtube_dl.extractor.fox9.FOX9IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._parse_json(\n            self._search_regex(\n                r'AnvatoPlaylist\\s*\\(\\s*(\\[.+?\\])\\s*\\)\\s*;',\n                webpage, 'anvato playlist'),\n            video_id, transform_source=js_to_json)[0]['video']\n\n        return self._get_anvato_videos(\n            'anvato_epfox_app_web_prod_b3373168e12f423f41504f207000188daf88251b',\n            video_id)",
        "begin_line": 30,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.foxgay.FoxgayIE._real_extract#28",
        "src_path": "youtube_dl/extractor/foxgay.py",
        "class_name": "youtube_dl.extractor.foxgay.FoxgayIE",
        "signature": "youtube_dl.extractor.foxgay.FoxgayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_end(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), ' - Foxgay.com')\n        description = get_element_by_id('inf_tit', webpage)\n\n        # The default user-agent with foxgay cookies leads to pages without videos\n        self._downloader.cookiejar.clear('.foxgay.com')\n        # Find the URL for the iFrame which contains the actual video.\n        iframe_url = self._html_search_regex(\n            r'<iframe[^>]+src=([\\'\"])(?P<url>[^\\'\"]+)\\1', webpage,\n            'video frame', group='url')\n        iframe = self._download_webpage(\n            iframe_url, video_id, headers={'User-Agent': 'curl/7.50.1'},\n            note='Downloading video frame')\n        video_data = self._parse_json(self._search_regex(\n            r'video_data\\s*=\\s*([^;]+);', iframe, 'video data'), video_id)\n\n        formats = [{\n            'url': source,\n            'height': int_or_none(resolution),\n        } for source, resolution in zip(\n            video_data['sources'], video_data.get('resolutions', itertools.repeat(None)))]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': video_data.get('act_vid', {}).get('thumb'),\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.foxnews.FoxNewsIE._real_extract#61",
        "src_path": "youtube_dl/extractor/foxnews.py",
        "class_name": "youtube_dl.extractor.foxnews.FoxNewsIE",
        "signature": "youtube_dl.extractor.foxnews.FoxNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        host, video_id = re.match(self._VALID_URL, url).groups()\n\n        info = self._extract_feed_info(\n            'http://%s/v/feed/video/%s.js?template=fox' % (host, video_id))\n        info['id'] = video_id\n        return info",
        "begin_line": 61,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.foxnews.FoxNewsArticleIE._real_extract#87",
        "src_path": "youtube_dl/extractor/foxnews.py",
        "class_name": "youtube_dl.extractor.foxnews.FoxNewsArticleIE",
        "signature": "youtube_dl.extractor.foxnews.FoxNewsArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._html_search_regex(\n            r'data-video-id=([\\'\"])(?P<id>[^\\'\"]+)\\1',\n            webpage, 'video ID', group='id')\n        return self.url_result(\n            'http://video.foxnews.com/v/' + video_id,\n            FoxNewsIE.ie_key())",
        "begin_line": 87,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.foxnews.FoxNewsInsiderIE._real_extract#123",
        "src_path": "youtube_dl/extractor/foxnews.py",
        "class_name": "youtube_dl.extractor.foxnews.FoxNewsInsiderIE",
        "signature": "youtube_dl.extractor.foxnews.FoxNewsInsiderIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        embed_url = self._html_search_meta('embedUrl', webpage, 'embed URL')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': FoxNewsIE.ie_key(),\n            'url': embed_url,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 123,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.foxsports.FoxSportsIE._real_extract#28",
        "src_path": "youtube_dl/extractor/foxsports.py",
        "class_name": "youtube_dl.extractor.foxsports.FoxSportsIE",
        "signature": "youtube_dl.extractor.foxsports.FoxSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        config = self._parse_json(\n            self._html_search_regex(\n                r\"\"\"class=\"[^\"]*(?:fs-player|platformPlayer-wrapper)[^\"]*\".+?data-player-config='([^']+)'\"\"\",\n                webpage, 'data player config'),\n            video_id)\n\n        return self.url_result(smuggle_url(update_url_query(\n            config['releaseURL'], {\n                'mbr': 'true',\n                'switch': 'http',\n            }), {'force_smil_url': True}))",
        "begin_line": 28,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract#28",
        "src_path": "youtube_dl/extractor/franceculture.py",
        "class_name": "youtube_dl.extractor.franceculture.FranceCultureIE",
        "signature": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_data = extract_attributes(self._search_regex(\n            r'(?s)<div[^>]+class=\"[^\"]*?(?:title-zone-diffusion|heading-zone-(?:wrapper|player-button))[^\"]*?\"[^>]*>.*?(<button[^>]+data-asset-source=\"[^\"]+\"[^>]+>)',\n            webpage, 'video data'))\n\n        video_url = video_data['data-asset-source']\n        title = video_data.get('data-asset-title') or self._og_search_title(webpage)\n\n        description = self._html_search_regex(\n            r'(?s)<div[^>]+class=\"intro\"[^>]*>.*?<h2>(.+?)</h2>',\n            webpage, 'description', default=None)\n        thumbnail = self._search_regex(\n            r'(?s)<figure[^>]+itemtype=\"https://schema.org/ImageObject\"[^>]*>.*?<img[^>]+(?:data-dejavu-)?src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        uploader = self._html_search_regex(\n            r'(?s)<span class=\"author\">(.*?)</span>',\n            webpage, 'uploader', default=None)\n        ext = determine_ext(video_url.lower())\n\n        return {\n            'id': display_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'ext': ext,\n            'vcodec': 'none' if ext == 'mp3' else None,\n            'uploader': uploader,\n            'timestamp': int_or_none(video_data.get('data-asset-created-date')),\n            'duration': int_or_none(video_data.get('data-duration')),\n        }",
        "begin_line": 28,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract#23",
        "src_path": "youtube_dl/extractor/franceinter.py",
        "class_name": "youtube_dl.extractor.franceinter.FranceInterIE",
        "signature": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'(?s)<div[^>]+class=[\"\\']page-diffusion[\"\\'][^>]*>.*?<button[^>]+data-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            webpage, 'video url', group='url')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n\n        upload_date_str = self._search_regex(\n            r'class=[\"\\']cover-emission-period[\"\\'][^>]*>[^<]+\\s+(\\d{1,2}\\s+[^\\s]+\\s+\\d{4})<',\n            webpage, 'upload date', fatal=False)\n        if upload_date_str:\n            upload_date_list = upload_date_str.split()\n            upload_date_list.reverse()\n            upload_date_list[1] = '%02d' % (month_by_name(upload_date_list[1], lang='fr') or 0)\n            upload_date_list[2] = '%02d' % int(upload_date_list[2])\n            upload_date = ''.join(upload_date_list)\n        else:\n            upload_date = None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'formats': [{\n                'url': video_url,\n                'vcodec': 'none',\n            }],\n        }",
        "begin_line": 23,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video#24",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor",
        "signature": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video(self, video_id, catalogue=None)",
        "snippet": "    def _extract_video(self, video_id, catalogue=None):\n        info = self._download_json(\n            'https://sivideo.webservices.francetelevisions.fr/tools/getInfosOeuvre/v2/',\n            video_id, 'Downloading video JSON', query={\n                'idDiffusion': video_id,\n                'catalogue': catalogue or '',\n            })\n\n        if info.get('status') == 'NOK':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, info['message']), expected=True)\n        allowed_countries = info['videos'][0].get('geoblocage')\n        if allowed_countries:\n            georestricted = True\n            geo_info = self._download_json(\n                'http://geo.francetv.fr/ws/edgescape.json', video_id,\n                'Downloading geo restriction info')\n            country = geo_info['reponse']['geo_info']['country_code']\n            if country not in allowed_countries:\n                raise ExtractorError(\n                    'The video is not available from your location',\n                    expected=True)\n        else:\n            georestricted = False\n\n        formats = []\n        for video in info['videos']:\n            if video['statut'] != 'ONLINE':\n                continue\n            video_url = video['url']\n            if not video_url:\n                continue\n            format_id = video['format']\n            ext = determine_ext(video_url)\n            if ext == 'f4m':\n                if georestricted:\n                    # See https://github.com/rg3/youtube-dl/issues/3963\n                    # m3u8 urls work fine\n                    continue\n                f4m_url = self._download_webpage(\n                    'http://hdfauth.francetv.fr/esi/TA?url=%s' % video_url,\n                    video_id, 'Downloading f4m manifest token', fatal=False)\n                if f4m_url:\n                    formats.extend(self._extract_f4m_formats(\n                        f4m_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44',\n                        video_id, f4m_id=format_id, fatal=False))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id=format_id, fatal=False))\n            elif video_url.startswith('rtmp'):\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'rtmp-%s' % format_id,\n                    'ext': 'flv',\n                })\n            else:\n                if self._is_valid_url(video_url, video_id, format_id):\n                    formats.append({\n                        'url': video_url,\n                        'format_id': format_id,\n                    })\n        self._sort_formats(formats)\n\n        title = info['titre']\n        subtitle = info.get('sous_titre')\n        if subtitle:\n            title += ' - %s' % subtitle\n        title = title.strip()\n\n        subtitles = {}\n        subtitles_list = [{\n            'url': subformat['url'],\n            'ext': subformat.get('format'),\n        } for subformat in info.get('subtitles', []) if subformat.get('url')]\n        if subtitles_list:\n            subtitles['fr'] = subtitles_list\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': clean_html(info['synopsis']),\n            'thumbnail': compat_urlparse.urljoin('http://pluzz.francetv.fr', info['image']),\n            'duration': int_or_none(info.get('real_duration')) or parse_duration(info['duree']),\n            'timestamp': int_or_none(info['diffusion']['timestamp']),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 24,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVIE._real_extract#165",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        catalogue = None\n        video_id = self._search_regex(\n            r'data-main-video=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'video id', default=None, group='id')\n\n        if not video_id:\n            video_id, catalogue = self._html_search_regex(\n                r'(?:href=|player\\.setVideo\\(\\s*)\"http://videos?\\.francetv\\.fr/video/([^@]+@[^\"]+)\"',\n                webpage, 'video ID').split('@')\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 165,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVEmbedIE._real_extract#197",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVEmbedIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://api-embed.webservices.francetelevisions.fr/key/%s' % video_id,\n            video_id)\n\n        return self._extract_video(video['video_id'], video.get('catalog'))",
        "begin_line": 197,
        "end_line": 204,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVInfoIE._real_extract#289",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVInfoIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVInfoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n\n        dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\n        if dmcloud_url:\n            return self.url_result(dmcloud_url, DailymotionCloudIE.ie_key())\n\n        dailymotion_urls = DailymotionIE._extract_urls(webpage)\n        if dailymotion_urls:\n            return self.playlist_result([\n                self.url_result(dailymotion_url, DailymotionIE.ie_key())\n                for dailymotion_url in dailymotion_urls])\n\n        video_id, catalogue = self._search_regex(\n            (r'id-video=([^@]+@[^\"]+)',\n             r'<a[^>]+href=\"(?:https?:)?//videos\\.francetv\\.fr/video/([^@]+@[^\"]+)\"'),\n            webpage, 'video id').split('@')\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 289,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract#329",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.GenerationQuoiIE",
        "signature": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        info_url = compat_urlparse.urljoin(url, '/medias/video/%s.json' % display_id)\n        info_json = self._download_webpage(info_url, display_id)\n        info = json.loads(info_json)\n        return self.url_result('http://www.dailymotion.com/video/%s' % info['id'],\n                               ie='Dailymotion')",
        "begin_line": 329,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.francetv.CultureboxIE._real_extract#356",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.CultureboxIE",
        "signature": "youtube_dl.extractor.francetv.CultureboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n\n        webpage = self._download_webpage(url, name)\n\n        if \">Ce live n'est plus disponible en replay<\" in webpage:\n            raise ExtractorError('Video %s is not available' % name, expected=True)\n\n        video_id, catalogue = self._search_regex(\n            r'\"http://videos\\.francetv\\.fr/video/([^@]+@[^\"]+)\"', webpage, 'video id').split('@')\n\n        return self._extract_video(video_id, catalogue)",
        "begin_line": 356,
        "end_line": 368,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.freesound.FreesoundIE._real_extract#31",
        "src_path": "youtube_dl/extractor/freesound.py",
        "class_name": "youtube_dl.extractor.freesound.FreesoundIE",
        "signature": "youtube_dl.extractor.freesound.FreesoundIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, audio_id)\n\n        audio_url = self._og_search_property('audio', webpage, 'song url')\n        title = self._og_search_property('audio:title', webpage, 'song title')\n\n        description = self._html_search_regex(\n            r'(?s)id=[\"\\']sound_description[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'description', fatal=False)\n\n        duration = float_or_none(\n            get_element_by_class('duration', webpage), scale=1000)\n\n        upload_date = unified_strdate(get_element_by_id('sound_date', webpage))\n        uploader = self._og_search_property(\n            'audio:artist', webpage, 'uploader', fatal=False)\n\n        channels = self._html_search_regex(\n            r'Channels</dt><dd>(.+?)</dd>', webpage,\n            'channels info', fatal=False)\n\n        tags_str = get_element_by_class('tags', webpage)\n        tags = re.findall(r'<a[^>]+>([^<]+)', tags_str) if tags_str else None\n\n        audio_urls = [audio_url]\n\n        LQ_FORMAT = '-lq.mp3'\n        if LQ_FORMAT in audio_url:\n            audio_urls.append(audio_url.replace(LQ_FORMAT, '-hq.mp3'))\n\n        formats = [{\n            'url': format_url,\n            'format_note': channels,\n            'quality': quality,\n        } for quality, format_url in enumerate(audio_urls)]\n        self._sort_formats(formats)\n\n        return {\n            'id': audio_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract#26",
        "src_path": "youtube_dl/extractor/freespeech.py",
        "class_name": "youtube_dl.extractor.freespeech.FreespeechIE",
        "signature": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        info_json = self._search_regex(r'jQuery.extend\\(Drupal.settings, ({.*?})\\);', webpage, 'info')\n        info = json.loads(info_json)\n\n        return {\n            '_type': 'url',\n            'url': info['jw_player']['basic_video_node_player']['file'],\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 26,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.freshlive.FreshLiveIE._real_extract#36",
        "src_path": "youtube_dl/extractor/freshlive.py",
        "class_name": "youtube_dl.extractor.freshlive.FreshLiveIE",
        "signature": "youtube_dl.extractor.freshlive.FreshLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        options = self._parse_json(\n            self._search_regex(\n                r'window\\.__CONTEXT__\\s*=\\s*({.+?});\\s*</script>',\n                webpage, 'initial context'),\n            video_id)\n\n        info = options['context']['dispatcher']['stores']['ProgramStore']['programs'][video_id]\n\n        title = info['title']\n\n        if info.get('status') == 'upcoming':\n            raise ExtractorError('Stream %s is upcoming' % video_id, expected=True)\n\n        stream_url = info.get('liveStreamUrl') or info['archiveStreamUrl']\n\n        is_live = info.get('liveStreamUrl') is not None\n\n        formats = self._extract_m3u8_formats(\n            stream_url, video_id, 'mp4',\n            'm3u8_native', m3u8_id='hls')\n\n        if is_live:\n            title = self._live_title(title)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': info.get('description'),\n            'thumbnail': info.get('thumbnailUrl'),\n            'duration': int_or_none(info.get('airTime')),\n            'timestamp': unified_timestamp(info.get('createdAt')),\n            'uploader': try_get(\n                info, lambda x: x['channel']['title'], compat_str),\n            'uploader_id': try_get(\n                info, lambda x: x['channel']['code'], compat_str),\n            'uploader_url': try_get(\n                info, lambda x: x['channel']['permalink'], compat_str),\n            'view_count': int_or_none(info.get('viewCount')),\n            'comment_count': int_or_none(info.get('commentCount')),\n            'tags': info.get('tags', []),\n            'is_live': is_live,\n        }",
        "begin_line": 36,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.funimation.FunimationIE._login#53",
        "src_path": "youtube_dl/extractor/funimation.py",
        "class_name": "youtube_dl.extractor.funimation.FunimationIE",
        "signature": "youtube_dl.extractor.funimation.FunimationIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        try:\n            data = self._download_json(\n                'https://prod-api-funimationnow.dadcdigital.com/api/auth/login/',\n                None, 'Logging in as %s' % username, data=urlencode_postdata({\n                    'username': username,\n                    'password': password,\n                }))\n            self._TOKEN = data['token']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 401:\n                error = self._parse_json(e.cause.read().decode(), None)['error']\n                raise ExtractorError(error, expected=True)\n            raise",
        "begin_line": 53,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.funimation.FunimationIE._real_initialize#71",
        "src_path": "youtube_dl/extractor/funimation.py",
        "class_name": "youtube_dl.extractor.funimation.FunimationIE",
        "signature": "youtube_dl.extractor.funimation.FunimationIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.funimation.FunimationIE._real_extract#74",
        "src_path": "youtube_dl/extractor/funimation.py",
        "class_name": "youtube_dl.extractor.funimation.FunimationIE",
        "signature": "youtube_dl.extractor.funimation.FunimationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        def _search_kane(name):\n            return self._search_regex(\n                r\"KANE_customdimensions\\.%s\\s*=\\s*'([^']+)';\" % name,\n                webpage, name, default=None)\n\n        title_data = self._parse_json(self._search_regex(\n            r'TITLE_DATA\\s*=\\s*({[^}]+})',\n            webpage, 'title data', default=''),\n            display_id, js_to_json, fatal=False) or {}\n\n        video_id = title_data.get('id') or self._search_regex([\n            r\"KANE_customdimensions.videoID\\s*=\\s*'(\\d+)';\",\n            r'<iframe[^>]+src=\"/player/(\\d+)\"',\n        ], webpage, 'video_id', default=None)\n        if not video_id:\n            player_url = self._html_search_meta([\n                'al:web:url',\n                'og:video:url',\n                'og:video:secure_url',\n            ], webpage, fatal=True)\n            video_id = self._search_regex(r'/player/(\\d+)', player_url, 'video id')\n\n        title = episode = title_data.get('title') or _search_kane('videoTitle') or self._og_search_title(webpage)\n        series = _search_kane('showName')\n        if series:\n            title = '%s - %s' % (series, title)\n        description = self._html_search_meta(['description', 'og:description'], webpage, fatal=True)\n\n        try:\n            headers = {}\n            if self._TOKEN:\n                headers['Authorization'] = 'Token %s' % self._TOKEN\n            sources = self._download_json(\n                'https://prod-api-funimationnow.dadcdigital.com/api/source/catalog/video/%s/signed/' % video_id,\n                video_id, headers=headers)['items']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403:\n                error = self._parse_json(e.cause.read(), video_id)['errors'][0]\n                raise ExtractorError('%s said: %s' % (\n                    self.IE_NAME, error.get('detail') or error.get('title')), expected=True)\n            raise\n\n        formats = []\n        for source in sources:\n            source_url = source.get('src')\n            if not source_url:\n                continue\n            source_type = source.get('videoType') or determine_ext(source_url)\n            if source_type == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    source_url, video_id, 'mp4',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'format_id': source_type,\n                    'url': source_url,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'series': series,\n            'season_number': int_or_none(title_data.get('seasonNum') or _search_kane('season')),\n            'episode_number': int_or_none(title_data.get('episodeNum')),\n            'episode': episode,\n            'season_id': title_data.get('seriesId'),\n            'formats': formats,\n        }",
        "begin_line": 74,
        "end_line": 149,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract#49",
        "src_path": "youtube_dl/extractor/funnyordie.py",
        "class_name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE",
        "signature": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        links = re.findall(r'<source src=\"([^\"]+/v)[^\"]+\\.([^\"]+)\" type=\\'video', webpage)\n        if not links:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        links.sort(key=lambda link: 1 if link[1] == 'mp4' else 0)\n\n        m3u8_url = self._search_regex(\n            r'<source[^>]+src=([\"\\'])(?P<url>.+?/master\\.m3u8[^\"\\']*)\\1',\n            webpage, 'm3u8 url', group='url')\n\n        formats = []\n\n        m3u8_formats = self._extract_m3u8_formats(\n            m3u8_url, video_id, 'mp4', 'm3u8_native',\n            m3u8_id='hls', fatal=False)\n        source_formats = list(filter(\n            lambda f: f.get('vcodec') != 'none', m3u8_formats))\n\n        bitrates = [int(bitrate) for bitrate in re.findall(r'[,/]v(\\d+)(?=[,/])', m3u8_url)]\n        bitrates.sort()\n\n        if source_formats:\n            self._sort_formats(source_formats)\n\n        for bitrate, f in zip(bitrates, source_formats or [{}] * len(bitrates)):\n            for path, ext in links:\n                ff = f.copy()\n                if ff:\n                    if ext != 'mp4':\n                        ff = dict(\n                            [(k, v) for k, v in ff.items()\n                             if k in ('height', 'width', 'format_id')])\n                    ff.update({\n                        'format_id': ff['format_id'].replace('hls', ext),\n                        'ext': ext,\n                        'protocol': 'http',\n                    })\n                else:\n                    ff.update({\n                        'format_id': '%s-%d' % (ext, bitrate),\n                        'vbr': bitrate,\n                    })\n                ff['url'] = self._proto_relative_url(\n                    '%s%d.%s' % (path, bitrate, ext))\n                formats.append(ff)\n        self._check_formats(formats, video_id)\n\n        formats.extend(m3u8_formats)\n        self._sort_formats(\n            formats, field_preference=('height', 'width', 'tbr', 'format_id'))\n\n        subtitles = {}\n        for src, src_lang in re.findall(r'<track kind=\"captions\" src=\"([^\"]+)\" srclang=\"([^\"]+)\"', webpage):\n            subtitles[src_lang] = [{\n                'ext': src.split('/')[-1],\n                'url': 'http://www.funnyordie.com%s' % src,\n            }]\n\n        timestamp = unified_timestamp(self._html_search_meta(\n            'uploadDate', webpage, 'timestamp', default=None))\n\n        uploader = self._html_search_regex(\n            r'<h\\d[^>]+\\bclass=[\"\\']channel-preview-name[^>]+>(.+?)</h',\n            webpage, 'uploader', default=None)\n\n        title, description, thumbnail, duration = [None] * 4\n\n        medium = self._parse_json(\n            self._search_regex(\n                r'jsonMedium\\s*=\\s*({.+?});', webpage, 'JSON medium',\n                default='{}'),\n            video_id, fatal=False)\n        if medium:\n            title = medium.get('title')\n            duration = float_or_none(medium.get('duration'))\n            if not timestamp:\n                timestamp = unified_timestamp(medium.get('publishDate'))\n\n        post = self._parse_json(\n            self._search_regex(\n                r'fb_post\\s*=\\s*(\\{.*?\\});', webpage, 'post details',\n                default='{}'),\n            video_id, fatal=False)\n        if post:\n            if not title:\n                title = post.get('name')\n            description = post.get('description')\n            thumbnail = post.get('picture')\n\n        if not title:\n            title = self._og_search_title(webpage)\n        if not description:\n            description = self._og_search_description(webpage)\n        if not duration:\n            duration = int_or_none(self._html_search_meta(\n                ('video:duration', 'duration'), webpage, 'duration', default=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 49,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fusion.FusionIE._real_extract#27",
        "src_path": "youtube_dl/extractor/fusion.py",
        "class_name": "youtube_dl.extractor.fusion.FusionIE",
        "signature": "youtube_dl.extractor.fusion.FusionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        ooyala_code = self._search_regex(\n            r'data-ooyala-id=([\"\\'])(?P<code>(?:(?!\\1).)+)\\1',\n            webpage, 'ooyala code', group='code')\n\n        return OoyalaIE._build_url_result(ooyala_code)",
        "begin_line": 27,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.fxnetworks.FXNetworksIE._real_extract#34",
        "src_path": "youtube_dl/extractor/fxnetworks.py",
        "class_name": "youtube_dl.extractor.fxnetworks.FXNetworksIE",
        "signature": "youtube_dl.extractor.fxnetworks.FXNetworksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        if 'The content you are trying to access is not available in your region.' in webpage:\n            self.raise_geo_restricted()\n        video_data = extract_attributes(self._search_regex(\n            r'(<a.+?rel=\"http://link\\.theplatform\\.com/s/.+?</a>)', webpage, 'video data'))\n        player_type = self._search_regex(r'playerType\\s*=\\s*[\\'\"]([^\\'\"]+)', webpage, 'player type', default=None)\n        release_url = video_data['rel']\n        title = video_data['data-title']\n        rating = video_data.get('data-rating')\n        query = {\n            'mbr': 'true',\n        }\n        if player_type == 'movies':\n            query.update({\n                'manifest': 'm3u',\n            })\n        else:\n            query.update({\n                'switch': 'http',\n            })\n        if video_data.get('data-req-auth') == '1':\n            resource = self._get_mvpd_resource(\n                video_data['data-channel'], title,\n                video_data.get('data-guid'), rating)\n            query['auth'] = self._extract_mvpd_auth(url, video_id, 'fx', resource)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'url': smuggle_url(update_url_query(release_url, query), {'force_smil_url': True}),\n            'thumbnail': video_data.get('data-large-thumb'),\n            'age_limit': parse_age_limit(rating),\n            'ie_key': 'ThePlatform',\n        }",
        "begin_line": 34,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gameinformer.GameInformerIE._real_extract#24",
        "src_path": "youtube_dl/extractor/gameinformer.py",
        "class_name": "youtube_dl.extractor.gameinformer.GameInformerIE",
        "signature": "youtube_dl.extractor.gameinformer.GameInformerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        brightcove_id = self._search_regex(r\"getVideo\\('[^']+video_id=(\\d+)\", webpage, 'brightcove id')\n        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)",
        "begin_line": 24,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOneIE._real_extract#59",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOneIE",
        "signature": "youtube_dl.extractor.gameone.GameOneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage, secure=False)\n        description = self._html_search_meta('description', webpage)\n        age_limit = int(\n            self._search_regex(\n                r'age=(\\d+)',\n                self._html_search_meta(\n                    'age-de-meta-label',\n                    webpage),\n                'age_limit',\n                '0'))\n        mrss_url = self._search_regex(r'mrss=([^&]+)', og_video, 'mrss')\n\n        mrss = self._download_xml(mrss_url, video_id, 'Downloading mrss')\n        title = mrss.find('.//item/title').text\n        thumbnail = mrss.find('.//item/image').get('url')\n        timestamp = parse_iso8601(mrss.find('.//pubDate').text, delimiter=' ')\n        content = mrss.find(xpath_with_ns('.//media:content', NAMESPACE_MAP))\n        content_url = content.get('url')\n\n        content = self._download_xml(\n            content_url,\n            video_id,\n            'Downloading media:content')\n        rendition_items = content.findall('.//rendition')\n        duration = float_or_none(rendition_items[0].get('duration'))\n        formats = [\n            {\n                'url': re.sub(r'.*/(r2)', RAW_MP4_URL + r'\\1', r.find('./src').text),\n                'width': int_or_none(r.get('width')),\n                'height': int_or_none(r.get('height')),\n                'tbr': int_or_none(r.get('bitrate')),\n            }\n            for r in rendition_items\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'description': description,\n            'age_limit': age_limit,\n            'timestamp': timestamp,\n        }",
        "begin_line": 59,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract#122",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOnePlaylistIE",
        "signature": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('http://www.gameone.de/tv', 'TV')\n        max_id = max(map(int, re.findall(r'<a href=\"/tv/(\\d+)\"', webpage)))\n        entries = [\n            self.url_result('http://www.gameone.de/tv/%d' %\n                            video_id, 'GameOne')\n            for video_id in range(max_id, 0, -1)]\n\n        return {\n            '_type': 'playlist',\n            'title': 'GameOne',\n            'entries': entries,\n        }",
        "begin_line": 122,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gamersyde.GamersydeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/gamersyde.py",
        "class_name": "youtube_dl.extractor.gamersyde.GamersydeIE",
        "signature": "youtube_dl.extractor.gamersyde.GamersydeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'(?s)playlist: \\[({.+?})\\]\\s*}\\);', webpage, 'files'),\n            display_id, transform_source=js_to_json)\n\n        formats = []\n        for source in playlist['sources']:\n            video_url = source.get('file')\n            if not video_url:\n                continue\n            format_id = source.get('label')\n            f = {\n                'url': video_url,\n                'format_id': format_id,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP](?P<fps>\\d+)fps', format_id)\n            if m:\n                f.update({\n                    'height': int(m.group('height')),\n                    'fps': int(m.group('fps')),\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        title = remove_start(playlist['title'], '%s - ' % video_id)\n        thumbnail = playlist.get('image')\n        duration = parse_duration(self._search_regex(\n            r'Length:</label>([^<]+)<', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract#40",
        "src_path": "youtube_dl/extractor/gamespot.py",
        "class_name": "youtube_dl.extractor.gamespot.GameSpotIE",
        "signature": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n        data_video_json = self._search_regex(\n            r'data-video=[\"\\'](.*?)[\"\\']', webpage, 'data video')\n        data_video = self._parse_json(unescapeHTML(data_video_json), page_id)\n        streams = data_video['videoStreams']\n\n        manifest_url = None\n        formats = []\n        f4m_url = streams.get('f4m_stream')\n        if f4m_url:\n            manifest_url = f4m_url\n            formats.extend(self._extract_f4m_formats(\n                f4m_url + '?hdcore=3.7.0', page_id, f4m_id='hds', fatal=False))\n        m3u8_url = streams.get('m3u8_stream')\n        if m3u8_url:\n            manifest_url = m3u8_url\n            m3u8_formats = self._extract_m3u8_formats(\n                m3u8_url, page_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False)\n            formats.extend(m3u8_formats)\n        progressive_url = dict_get(\n            streams, ('progressive_hd', 'progressive_high', 'progressive_low'))\n        if progressive_url and manifest_url:\n            qualities_basename = self._search_regex(\n                r'/([^/]+)\\.csmil/',\n                manifest_url, 'qualities basename', default=None)\n            if qualities_basename:\n                QUALITIES_RE = r'((,\\d+)+,?)'\n                qualities = self._search_regex(\n                    QUALITIES_RE, qualities_basename,\n                    'qualities', default=None)\n                if qualities:\n                    qualities = list(map(lambda q: int(q), qualities.strip(',').split(',')))\n                    qualities.sort()\n                    http_template = re.sub(QUALITIES_RE, r'%d', qualities_basename)\n                    http_url_basename = url_basename(progressive_url)\n                    if m3u8_formats:\n                        self._sort_formats(m3u8_formats)\n                        m3u8_formats = list(filter(\n                            lambda f: f.get('vcodec') != 'none', m3u8_formats))\n                    if len(qualities) == len(m3u8_formats):\n                        for q, m3u8_format in zip(qualities, m3u8_formats):\n                            f = m3u8_format.copy()\n                            f.update({\n                                'url': progressive_url.replace(\n                                    http_url_basename, http_template % q),\n                                'format_id': f['format_id'].replace('hls', 'http'),\n                                'protocol': 'http',\n                            })\n                            formats.append(f)\n                    else:\n                        for q in qualities:\n                            formats.append({\n                                'url': progressive_url.replace(\n                                    http_url_basename, http_template % q),\n                                'ext': 'mp4',\n                                'format_id': 'http-%d' % q,\n                                'tbr': q,\n                            })\n\n        onceux_json = self._search_regex(\n            r'data-onceux-options=[\"\\'](.*?)[\"\\']', webpage, 'data video', default=None)\n        if onceux_json:\n            onceux_url = self._parse_json(unescapeHTML(onceux_json), page_id).get('metadataUri')\n            if onceux_url:\n                formats.extend(self._extract_once_formats(re.sub(\n                    r'https?://[^/]+', 'http://once.unicornmedia.com', onceux_url).replace('ads/vmap/', '')))\n\n        if not formats:\n            for quality in ['sd', 'hd']:\n                # It's actually a link to a flv file\n                flv_url = streams.get('f4m_{0}'.format(quality))\n                if flv_url is not None:\n                    formats.append({\n                        'url': flv_url,\n                        'ext': 'flv',\n                        'format_id': quality,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': data_video['guid'],\n            'display_id': page_id,\n            'title': compat_urllib_parse_unquote(data_video['title']),\n            'formats': formats,\n            'description': self._html_search_meta('description', webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 40,
        "end_line": 129,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gamestar.GameStarIE._real_extract#28",
        "src_path": "youtube_dl/extractor/gamestar.py",
        "class_name": "youtube_dl.extractor.gamestar.GameStarIE",
        "signature": "youtube_dl.extractor.gamestar.GameStarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        url = 'http://gamestar.de/_misc/videos/portal/getVideoUrl.cfm?premium=0&videoId=' + video_id\n\n        # TODO: there are multiple ld+json objects in the webpage,\n        # while _search_json_ld finds only the first one\n        json_ld = self._parse_json(self._search_regex(\n            r'(?s)<script[^>]+type=([\"\\'])application/ld\\+json\\1[^>]*>(?P<json_ld>[^<]+VideoObject[^<]+)</script>',\n            webpage, 'JSON-LD', group='json_ld'), video_id)\n        info_dict = self._json_ld(json_ld, video_id)\n        info_dict['title'] = remove_end(info_dict['title'], ' - GameStar')\n\n        view_count = json_ld.get('interactionCount')\n        comment_count = int_or_none(self._html_search_regex(\n            r'([0-9]+) Kommentare</span>', webpage, 'comment_count',\n            fatal=False))\n\n        info_dict.update({\n            'id': video_id,\n            'url': url,\n            'ext': 'mp4',\n            'view_count': view_count,\n            'comment_count': comment_count\n        })\n\n        return info_dict",
        "begin_line": 28,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gaskrank.GaskrankIE._real_extract#45",
        "src_path": "youtube_dl/extractor/gaskrank.py",
        "class_name": "youtube_dl.extractor.gaskrank.GaskrankIE",
        "signature": "youtube_dl.extractor.gaskrank.GaskrankIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(\n            webpage, default=None) or self._html_search_meta(\n            'title', webpage, fatal=True)\n\n        categories = [re.match(self._VALID_URL, url).group('categories')]\n\n        mobj = re.search(\n            r'Video von:\\s*(?P<uploader_id>[^|]*?)\\s*\\|\\s*vom:\\s*(?P<upload_date>[0-9][0-9]\\.[0-9][0-9]\\.[0-9][0-9][0-9][0-9])',\n            webpage)\n        if mobj is not None:\n            uploader_id = mobj.groupdict().get('uploader_id')\n            upload_date = unified_strdate(mobj.groupdict().get('upload_date'))\n\n        uploader_url = self._search_regex(\n            r'Homepage:\\s*<[^>]*>(?P<uploader_url>[^<]*)',\n            webpage, 'uploader_url', default=None)\n        tags = re.findall(\n            r'/tv/tags/[^/]+/\"\\s*>(?P<tag>[^<]*?)<',\n            webpage)\n\n        view_count = self._search_regex(\n            r'class\\s*=\\s*\"gkRight\"(?:[^>]*>\\s*<[^>]*)*icon-eye-open(?:[^>]*>\\s*<[^>]*)*>\\s*(?P<view_count>[0-9\\.]*)',\n            webpage, 'view_count', default=None)\n        if view_count:\n            view_count = int_or_none(view_count.replace('.', ''))\n\n        average_rating = self._search_regex(\n            r'itemprop\\s*=\\s*\"ratingValue\"[^>]*>\\s*(?P<average_rating>[0-9,]+)',\n            webpage, 'average_rating')\n        if average_rating:\n            average_rating = float_or_none(average_rating.replace(',', '.'))\n\n        video_id = self._search_regex(\n            r'https?://movies\\.gaskrank\\.tv/([^-]*?)(-[^\\.]*)?\\.mp4',\n            webpage, 'video id', default=display_id)\n\n        entry = self._parse_html5_media_entries(url, webpage, video_id)[0]\n        entry.update({\n            'id': video_id,\n            'title': title,\n            'categories': categories,\n            'display_id': display_id,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'uploader_url': uploader_url,\n            'tags': tags,\n            'view_count': view_count,\n            'average_rating': average_rating,\n        })\n        self._sort_formats(entry['formats'])\n\n        return entry",
        "begin_line": 45,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gazeta.GazetaIE._real_extract#36",
        "src_path": "youtube_dl/extractor/gazeta.py",
        "class_name": "youtube_dl.extractor.gazeta.GazetaIE",
        "signature": "youtube_dl.extractor.gazeta.GazetaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        display_id = mobj.group('id')\n        embed_url = '%s?p=embed' % mobj.group('url')\n        embed_page = self._download_webpage(\n            embed_url, display_id, 'Downloading embed page')\n\n        video_id = self._search_regex(\n            r'<div[^>]*?class=\"eagleplayer\"[^>]*?data-id=\"([^\"]+)\"', embed_page, 'video id')\n\n        return self.url_result(\n            'eagleplatform:gazeta.media.eagleplatform.com:%s' % video_id, 'EaglePlatform')",
        "begin_line": 36,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._login#93",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._login(self, webpage_url, display_id)",
        "snippet": "    def _login(self, webpage_url, display_id):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            self.report_warning('It looks like ' + webpage_url + ' requires a login. Try specifying a username and password and try again.')\n            return None\n\n        mobj = re.match(r'(?P<root_url>https?://.*?/).*', webpage_url)\n        login_url = mobj.group('root_url') + 'api/login.php'\n        logout_url = mobj.group('root_url') + 'logout'\n\n        login_form = {\n            'email': username,\n            'password': password,\n        }\n\n        request = sanitized_Request(login_url, urlencode_postdata(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(request, display_id, 'Logging in')\n        start_page = self._download_webpage(webpage_url, display_id, 'Getting authenticated video page')\n        self._download_webpage(logout_url, display_id, 'Logging out')\n\n        return start_page",
        "begin_line": 93,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract#116",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        display_id = mobj.group('name') or video_id\n\n        webpage_url = 'http://www.gdcvault.com/play/' + video_id\n        start_page = self._download_webpage(webpage_url, display_id)\n\n        direct_url = self._search_regex(\n            r's1\\.addVariable\\(\"file\",\\s*encodeURIComponent\\(\"(/[^\"]+)\"\\)\\);',\n            start_page, 'url', default=None)\n        if direct_url:\n            title = self._html_search_regex(\n                r'<td><strong>Session Name</strong></td>\\s*<td>(.*?)</td>',\n                start_page, 'title')\n            video_url = 'http://www.gdcvault.com' + direct_url\n            # resolve the url so that we can detect the correct extension\n            head = self._request_webpage(HEADRequest(video_url), video_id)\n            video_url = head.geturl()\n\n            return {\n                'id': video_id,\n                'display_id': display_id,\n                'url': video_url,\n                'title': title,\n            }\n\n        PLAYER_REGEX = r'<iframe src=\"(?P<xml_root>.+?)/(?:gdc-)?player.*?\\.html.*?\".*?</iframe>'\n\n        xml_root = self._html_search_regex(\n            PLAYER_REGEX, start_page, 'xml root', default=None)\n        if xml_root is None:\n            # Probably need to authenticate\n            login_res = self._login(webpage_url, display_id)\n            if login_res is None:\n                self.report_warning('Could not login.')\n            else:\n                start_page = login_res\n                # Grab the url from the authenticated page\n                xml_root = self._html_search_regex(\n                    PLAYER_REGEX, start_page, 'xml root')\n\n        xml_name = self._html_search_regex(\n            r'<iframe src=\".*?\\?xml=(.+?\\.xml).*?\".*?</iframe>',\n            start_page, 'xml filename', default=None)\n        if xml_name is None:\n            # Fallback to the older format\n            xml_name = self._html_search_regex(\n                r'<iframe src=\".*?\\?xmlURL=xml/(?P<xml_file>.+?\\.xml).*?\".*?</iframe>',\n                start_page, 'xml filename')\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'display_id': display_id,\n            'url': '%s/xml/%s' % (xml_root, xml_name),\n            'ie_key': 'DigitallySpeaking',\n        }",
        "begin_line": 116,
        "end_line": 174,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_following_redirect#1888",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_following_redirect(self, new_url)",
        "snippet": "    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)",
        "begin_line": 1888,
        "end_line": 1890,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_rss#1892",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_rss(self, url, video_id, doc)",
        "snippet": "    def _extract_rss(self, url, video_id, doc):\n        playlist_title = doc.find('./channel/title').text\n        playlist_desc_el = doc.find('./channel/description')\n        playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\n\n        entries = []\n        for it in doc.findall('./channel/item'):\n            next_url = xpath_text(it, 'link', fatal=False)\n            if not next_url:\n                enclosure_nodes = it.findall('./enclosure')\n                for e in enclosure_nodes:\n                    next_url = e.attrib.get('url')\n                    if next_url:\n                        break\n\n            if not next_url:\n                continue\n\n            entries.append({\n                '_type': 'url_transparent',\n                'url': next_url,\n                'title': it.find('title').text,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': playlist_title,\n            'description': playlist_desc,\n            'entries': entries,\n        }",
        "begin_line": 1892,
        "end_line": 1922,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_camtasia#1924",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_camtasia(self, url, video_id, webpage)",
        "snippet": "    def _extract_camtasia(self, url, video_id, webpage):\n        \"\"\" Returns None if no camtasia video can be found. \"\"\"\n\n        camtasia_cfg = self._search_regex(\n            r'fo\\.addVariable\\(\\s*\"csConfigFile\",\\s*\"([^\"]+)\"\\s*\\);',\n            webpage, 'camtasia configuration file', default=None)\n        if camtasia_cfg is None:\n            return None\n\n        title = self._html_search_meta('DC.title', webpage, fatal=True)\n\n        camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\n        camtasia_cfg = self._download_xml(\n            camtasia_url, video_id,\n            note='Downloading camtasia configuration',\n            errnote='Failed to download camtasia configuration')\n        fileset_node = camtasia_cfg.find('./playlist/array/fileset')\n\n        entries = []\n        for n in fileset_node.getchildren():\n            url_n = n.find('./uri')\n            if url_n is None:\n                continue\n\n            entries.append({\n                'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\n                'title': '%s - %s' % (title, n.tag),\n                'url': compat_urlparse.urljoin(url, url_n.text),\n                'duration': float_or_none(n.find('./duration').text),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': title,\n        }",
        "begin_line": 1924,
        "end_line": 1959,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._real_extract#1961",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if url.startswith('//'):\n            return {\n                '_type': 'url',\n                'url': self.http_scheme() + url,\n            }\n\n        parsed_url = compat_urlparse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self._downloader.params.get('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if '/' in url:\n                    self._downloader.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call youtube-dl like this:  youtube-dl -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self._downloader.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    '%r is not a valid URL. '\n                    'Set --default-search \"ytsearch\" (or run  youtube-dl \"ytsearch:%s\" ) to search YouTube'\n                    % (url, url), expected=True)\n            else:\n                if ':' not in default_search:\n                    default_search += ':'\n                return self.url_result(default_search + url)\n\n        url, smuggled_data = unsmuggle_url(url)\n        force_videoid = None\n        is_intentional = smuggled_data and smuggled_data.get('to_generic')\n        if smuggled_data and 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = self._generic_id(url)\n\n        self.to_screen('%s: Requesting header' % video_id)\n\n        head_req = HEADRequest(url)\n        head_response = self._request_webpage(\n            head_req, video_id,\n            note=False, errnote='Could not send HEAD request to %s' % url,\n            fatal=False)\n\n        if head_response is not False:\n            # Check for redirect\n            new_url = compat_str(head_response.geturl())\n            if url != new_url:\n                self.report_following_redirect(new_url)\n                if force_videoid:\n                    new_url = smuggle_url(\n                        new_url, {'force_videoid': force_videoid})\n                return self.url_result(new_url)\n\n        full_response = None\n        if head_response is False:\n            request = sanitized_Request(url)\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n            head_response = full_response\n\n        info_dict = {\n            'id': video_id,\n            'title': self._generic_title(url),\n            'upload_date': unified_strdate(head_response.headers.get('Last-Modified'))\n        }\n\n        # Check for direct link to a video\n        content_type = head_response.headers.get('Content-Type', '').lower()\n        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\\.apple\\.|x-)?mpegurl)))/(?P<format_id>[^;\\s]+)', content_type)\n        if m:\n            format_id = compat_str(m.group('format_id'))\n            if format_id.endswith('mpegurl'):\n                formats = self._extract_m3u8_formats(url, video_id, 'mp4')\n            elif format_id == 'f4m':\n                formats = self._extract_f4m_formats(url, video_id)\n            else:\n                formats = [{\n                    'format_id': format_id,\n                    'url': url,\n                    'vcodec': 'none' if m.group('type') == 'audio' else None\n                }]\n                info_dict['direct'] = True\n            self._sort_formats(formats)\n            info_dict['formats'] = formats\n            return info_dict\n\n        if not self._downloader.params.get('test', False) and not is_intentional:\n            force = self._downloader.params.get('force_generic_extractor', False)\n            self._downloader.report_warning(\n                '%s on generic information extractor.' % ('Forcing' if force else 'Falling back'))\n\n        if not full_response:\n            request = sanitized_Request(url)\n            # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\n            # making it impossible to download only chunk of the file (yet we need only 512kB to\n            # test whether it's HTML or not). According to youtube-dl default Accept-Encoding\n            # that will always result in downloading the whole file that is not desirable.\n            # Therefore for extraction pass we have to override Accept-Encoding to any in order\n            # to accept raw bytes and being able to download only a chunk.\n            # It may probably better to solve this by checking Content-Type for application/octet-stream\n            # after HEAD request finishes, but not sure if we can rely on this.\n            request.add_header('Accept-Encoding', '*')\n            full_response = self._request_webpage(request, video_id)\n\n        first_bytes = full_response.read(512)\n\n        # Is it an M3U playlist?\n        if first_bytes.startswith(b'#EXTM3U'):\n            info_dict['formats'] = self._extract_m3u8_formats(url, video_id, 'mp4')\n            self._sort_formats(info_dict['formats'])\n            return info_dict\n\n        # Maybe it's a direct link to a video?\n        # Be careful not to download the whole thing!\n        if not is_html(first_bytes):\n            self._downloader.report_warning(\n                'URL could be a direct video link, returning it as such.')\n            info_dict.update({\n                'direct': True,\n                'url': url,\n            })\n            return info_dict\n\n        webpage = self._webpage_read_content(\n            full_response, url, video_id, prefix=first_bytes)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed, a SMIL file, an XSPF playlist or a MPD manifest?\n        try:\n            doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                return self._extract_rss(url, video_id, doc)\n            elif doc.tag == 'SmoothStreamingMedia':\n                info_dict['formats'] = self._parse_ism_formats(doc, url)\n                self._sort_formats(info_dict['formats'])\n                return info_dict\n            elif re.match(r'^(?:{[^}]+})?smil$', doc.tag):\n                smil = self._parse_smil(doc, url, video_id)\n                self._sort_formats(smil['formats'])\n                return smil\n            elif doc.tag == '{http://xspf.org/ns/0/}playlist':\n                return self.playlist_result(self._parse_xspf(doc, video_id), video_id)\n            elif re.match(r'(?i)^(?:{[^}]+})?MPD$', doc.tag):\n                info_dict['formats'] = self._parse_mpd_formats(\n                    doc, video_id,\n                    mpd_base_url=compat_str(full_response.geturl()).rpartition('/')[0],\n                    mpd_url=url)\n                self._sort_formats(info_dict['formats'])\n                return info_dict\n            elif re.match(r'^{http://ns\\.adobe\\.com/f4m/[12]\\.0}manifest$', doc.tag):\n                info_dict['formats'] = self._parse_f4m_formats(doc, url, video_id)\n                self._sort_formats(info_dict['formats'])\n                return info_dict\n        except compat_xml_parse_error:\n            pass\n\n        # Is it a Camtasia project?\n        camtasia_res = self._extract_camtasia(url, video_id, webpage)\n        if camtasia_res is not None:\n            return camtasia_res\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/rg3/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        webpage = compat_urllib_parse_unquote(webpage)\n\n        # it's tempting to parse this further, but you would\n        # have to take into account all the variations like\n        #   Video Title - Site Name\n        #   Site Name | Video Title\n        #   Video Title - Tagline | Site Name\n        # and so on and so forth; it's just not practical\n        video_title = self._og_search_title(\n            webpage, default=None) or self._html_search_regex(\n            r'(?s)<title>(.*?)</title>', webpage, 'video title',\n            default='video')\n\n        # Try to detect age limit automatically\n        age_limit = self._rta_search(webpage)\n        # And then there are the jokers who advertise that they use RTA,\n        # but actually don't.\n        AGE_LIMIT_MARKERS = [\n            r'Proudly Labeled <a href=\"http://www.rtalabel.org/\" title=\"Restricted to Adults\">RTA</a>',\n        ]\n        if any(re.search(marker, webpage) for marker in AGE_LIMIT_MARKERS):\n            age_limit = 18\n\n        # video uploader is domain name\n        video_uploader = self._search_regex(\n            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\n\n        video_description = self._og_search_description(webpage, default=None)\n        video_thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        info_dict.update({\n            'title': video_title,\n            'description': video_description,\n            'thumbnail': video_thumbnail,\n            'age_limit': age_limit,\n        })\n\n        # Look for Brightcove Legacy Studio embeds\n        bc_urls = BrightcoveLegacyIE._extract_brightcove_urls(webpage)\n        if bc_urls:\n            entries = [{\n                '_type': 'url',\n                'url': smuggle_url(bc_url, {'Referer': url}),\n                'ie_key': 'BrightcoveLegacy'\n            } for bc_url in bc_urls]\n\n            return {\n                '_type': 'playlist',\n                'title': video_title,\n                'id': video_id,\n                'entries': entries,\n            }\n\n        # Look for Brightcove New Studio embeds\n        bc_urls = BrightcoveNewIE._extract_urls(self, webpage)\n        if bc_urls:\n            return self.playlist_from_matches(bc_urls, video_id, video_title, ie='BrightcoveNew')\n\n        # Look for Nexx embeds\n        nexx_urls = NexxIE._extract_urls(webpage)\n        if nexx_urls:\n            return self.playlist_from_matches(nexx_urls, video_id, video_title, ie=NexxIE.ie_key())\n\n        # Look for Nexx iFrame embeds\n        nexx_embed_urls = NexxEmbedIE._extract_urls(webpage)\n        if nexx_embed_urls:\n            return self.playlist_from_matches(nexx_embed_urls, video_id, video_title, ie=NexxEmbedIE.ie_key())\n\n        # Look for ThePlatform embeds\n        tp_urls = ThePlatformIE._extract_urls(webpage)\n        if tp_urls:\n            return self.playlist_from_matches(tp_urls, video_id, video_title, ie='ThePlatform')\n\n        # Look for Vessel embeds\n        vessel_urls = VesselIE._extract_urls(webpage)\n        if vessel_urls:\n            return self.playlist_from_matches(vessel_urls, video_id, video_title, ie=VesselIE.ie_key())\n\n        # Look for embedded rtl.nl player\n        matches = re.findall(\n            r'<iframe[^>]+?src=\"((?:https?:)?//(?:www\\.)?rtl\\.nl/system/videoplayer/[^\"]+(?:video_)?embed[^\"]+)\"',\n            webpage)\n        if matches:\n            return self.playlist_from_matches(matches, video_id, video_title, ie='RtlNl')\n\n        vimeo_urls = VimeoIE._extract_urls(url, webpage)\n        if vimeo_urls:\n            return self.playlist_from_matches(vimeo_urls, video_id, video_title, ie=VimeoIE.ie_key())\n\n        vid_me_embed_url = self._search_regex(\n            r'src=[\\'\"](https?://vid\\.me/[^\\'\"]+)[\\'\"]',\n            webpage, 'vid.me embed', default=None)\n        if vid_me_embed_url is not None:\n            return self.url_result(vid_me_embed_url, 'Vidme')\n\n        # Look for embedded YouTube player\n        matches = re.findall(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*|\n                <object[^>]+data=|\n                new\\s+SWFObject\\(\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v|p)/.+?)\n            \\1''', webpage)\n        if matches:\n            return self.playlist_from_matches(\n                matches, video_id, video_title, lambda m: unescapeHTML(m[1]))\n\n        # Look for lazyYT YouTube embed\n        matches = re.findall(\n            r'class=\"lazyYT\" data-youtube-id=\"([^\"]+)\"', webpage)\n        if matches:\n            return self.playlist_from_matches(matches, video_id, video_title, lambda m: unescapeHTML(m))\n\n        # Look for Wordpress \"YouTube Video Importer\" plugin\n        matches = re.findall(r'''(?x)<div[^>]+\n            class=(?P<q1>[\\'\"])[^\\'\"]*\\byvii_single_video_player\\b[^\\'\"]*(?P=q1)[^>]+\n            data-video_id=(?P<q2>[\\'\"])([^\\'\"]+)(?P=q2)''', webpage)\n        if matches:\n            return self.playlist_from_matches(matches, video_id, video_title, lambda m: m[-1])\n\n        matches = DailymotionIE._extract_urls(webpage)\n        if matches:\n            return self.playlist_from_matches(matches, video_id, video_title)\n\n        # Look for embedded Dailymotion playlist player (#3822)\n        m = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.[a-z]{2,3}/widget/jukebox\\?.+?)\\1', webpage)\n        if m:\n            playlists = re.findall(\n                r'list\\[\\]=/playlist/([^/]+)/', unescapeHTML(m.group('url')))\n            if playlists:\n                return self.playlist_from_matches(\n                    playlists, video_id, video_title, lambda p: '//dailymotion.com/playlist/%s' % p)\n\n        # Look for DailyMail embeds\n        dailymail_urls = DailyMailIE._extract_urls(webpage)\n        if dailymail_urls:\n            return self.playlist_from_matches(\n                dailymail_urls, video_id, video_title, ie=DailyMailIE.ie_key())\n\n        # Look for embedded Wistia player\n        wistia_url = WistiaIE._extract_url(webpage)\n        if wistia_url:\n            return {\n                '_type': 'url_transparent',\n                'url': self._proto_relative_url(wistia_url),\n                'ie_key': WistiaIE.ie_key(),\n                'uploader': video_uploader,\n            }\n\n        # Look for SVT player\n        svt_url = SVTIE._extract_url(webpage)\n        if svt_url:\n            return self.url_result(svt_url, 'SVT')\n\n        # Look for Bandcamp pages with custom domain\n        mobj = re.search(r'<meta property=\"og:url\"[^>]*?content=\"(.*?bandcamp\\.com.*?)\"', webpage)\n        if mobj is not None:\n            burl = unescapeHTML(mobj.group(1))\n            # Don't set the extractor because it can be a track url or an album\n            return self.url_result(burl)\n\n        # Look for embedded Vevo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:cache\\.)?vevo\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Viddler player\n        mobj = re.search(\n            r'<(?:iframe[^>]+?src|param[^>]+?value)=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?viddler\\.com/(?:embed|player)/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NYTimes player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//graphics8\\.nytimes\\.com/bcvideo/[^/]+/iframe/embed\\.html.+?)\\1>',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Libsyn player\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//html5-player\\.libsyn\\.com/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Ooyala videos\n        mobj = (re.search(r'player\\.ooyala\\.com/[^\"?]+[?#][^\"]*?(?:embedCode|ec)=(?P<ec>[^\"&]+)', webpage) or\n                re.search(r'OO\\.Player\\.create\\([\\'\"].*?[\\'\"],\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage) or\n                re.search(r'OO\\.Player\\.create\\.apply\\(\\s*OO\\.Player\\s*,\\s*op\\(\\s*\\[\\s*[\\'\"][^\\'\"]*[\\'\"]\\s*,\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage) or\n                re.search(r'SBN\\.VideoLinkset\\.ooyala\\([\\'\"](?P<ec>.{32})[\\'\"]\\)', webpage) or\n                re.search(r'data-ooyala-video-id\\s*=\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage))\n        if mobj is not None:\n            embed_token = self._search_regex(\n                r'embedToken[\\'\"]?\\s*:\\s*[\\'\"]([^\\'\"]+)',\n                webpage, 'ooyala embed token', default=None)\n            return OoyalaIE._build_url_result(smuggle_url(\n                mobj.group('ec'), {\n                    'domain': url,\n                    'embed_token': embed_token,\n                }))\n\n        # Look for multiple Ooyala embeds on SBN network websites\n        mobj = re.search(r'SBN\\.VideoLinkset\\.entryGroup\\((\\[.*?\\])', webpage)\n        if mobj is not None:\n            embeds = self._parse_json(mobj.group(1), video_id, fatal=False)\n            if embeds:\n                return self.playlist_from_matches(\n                    embeds, video_id, video_title,\n                    getter=lambda v: OoyalaIE._url_for_embed_code(smuggle_url(v['provider_video_id'], {'domain': url})), ie='Ooyala')\n\n        # Look for Aparat videos\n        mobj = re.search(r'<iframe .*?src=\"(http://www\\.aparat\\.com/video/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Aparat')\n\n        # Look for MPORA videos\n        mobj = re.search(r'<iframe .*?src=\"(http://mpora\\.(?:com|de)/videos/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Mpora')\n\n        # Look for embedded NovaMov-based player\n        mobj = re.search(\n            r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=([\"\\'])\n                    (?P<url>http://(?:(?:embed|www)\\.)?\n                        (?:novamov\\.com|\n                           nowvideo\\.(?:ch|sx|eu|at|ag|co)|\n                           videoweed\\.(?:es|com)|\n                           movshare\\.(?:net|sx|ag)|\n                           divxstage\\.(?:eu|net|ch|co|at|ag))\n                        /embed\\.php.+?)\\1''', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Facebook player\n        facebook_urls = FacebookIE._extract_urls(webpage)\n        if facebook_urls:\n            return self.playlist_from_matches(facebook_urls, video_id, video_title)\n\n        # Look for embedded VK player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://vk\\.com/video_ext\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'VK')\n\n        # Look for embedded Odnoklassniki player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:odnoklassniki|ok)\\.ru/videoembed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Odnoklassniki')\n\n        # Look for embedded ivi player\n        mobj = re.search(r'<embed[^>]+?src=([\"\\'])(?P<url>https?://(?:www\\.)?ivi\\.ru/video/player.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ivi')\n\n        # Look for embedded Huffington Post player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed\\.live\\.huffingtonpost\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'HuffPost')\n\n        # Look for embed.ly\n        mobj = re.search(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n        mobj = re.search(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage)\n        if mobj is not None:\n            return self.url_result(compat_urllib_parse_unquote(mobj.group('url')))\n\n        # Look for funnyordie embed\n        matches = re.findall(r'<iframe[^>]+?src=\"(https?://(?:www\\.)?funnyordie\\.com/embed/[^\"]+)\"', webpage)\n        if matches:\n            return self.playlist_from_matches(\n                matches, video_id, video_title, getter=unescapeHTML, ie='FunnyOrDie')\n\n        # Look for BBC iPlayer embed\n        matches = re.findall(r'setPlaylist\\(\"(https?://www\\.bbc\\.co\\.uk/iplayer/[^/]+/[\\da-z]{8})\"\\)', webpage)\n        if matches:\n            return self.playlist_from_matches(matches, video_id, video_title, ie='BBCCoUk')\n\n        # Look for embedded RUTV player\n        rutv_url = RUTVIE._extract_url(webpage)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        # Look for embedded TVC player\n        tvc_url = TVCIE._extract_url(webpage)\n        if tvc_url:\n            return self.url_result(tvc_url, 'TVC')\n\n        # Look for embedded SportBox player\n        sportbox_urls = SportBoxEmbedIE._extract_urls(webpage)\n        if sportbox_urls:\n            return self.playlist_from_matches(sportbox_urls, video_id, video_title, ie='SportBoxEmbed')\n\n        # Look for embedded XHamster player\n        xhamster_urls = XHamsterEmbedIE._extract_urls(webpage)\n        if xhamster_urls:\n            return self.playlist_from_matches(xhamster_urls, video_id, video_title, ie='XHamsterEmbed')\n\n        # Look for embedded TNAFlixNetwork player\n        tnaflix_urls = TNAFlixNetworkEmbedIE._extract_urls(webpage)\n        if tnaflix_urls:\n            return self.playlist_from_matches(tnaflix_urls, video_id, video_title, ie=TNAFlixNetworkEmbedIE.ie_key())\n\n        # Look for embedded PornHub player\n        pornhub_urls = PornHubIE._extract_urls(webpage)\n        if pornhub_urls:\n            return self.playlist_from_matches(pornhub_urls, video_id, video_title, ie=PornHubIE.ie_key())\n\n        # Look for embedded DrTuber player\n        drtuber_urls = DrTuberIE._extract_urls(webpage)\n        if drtuber_urls:\n            return self.playlist_from_matches(drtuber_urls, video_id, video_title, ie=DrTuberIE.ie_key())\n\n        # Look for embedded RedTube player\n        redtube_urls = RedTubeIE._extract_urls(webpage)\n        if redtube_urls:\n            return self.playlist_from_matches(redtube_urls, video_id, video_title, ie=RedTubeIE.ie_key())\n\n        # Look for embedded Tvigle player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//cloud\\.tvigle\\.ru/video/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Tvigle')\n\n        # Look for embedded TED player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed(?:-ssl)?\\.ted\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'TED')\n\n        # Look for embedded Ustream videos\n        ustream_url = UstreamIE._extract_url(webpage)\n        if ustream_url:\n            return self.url_result(ustream_url, UstreamIE.ie_key())\n\n        # Look for embedded arte.tv player\n        mobj = re.search(\n            r'<(?:script|iframe) [^>]*?src=\"(?P<url>http://www\\.arte\\.tv/(?:playerv2/embed|arte_vp/index)[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'ArteTVEmbed')\n\n        # Look for embedded francetv player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?://)?embed\\.francetv\\.fr/\\?ue=.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded smotri.com player\n        smotri_url = SmotriIE._extract_url(webpage)\n        if smotri_url:\n            return self.url_result(smotri_url, 'Smotri')\n\n        # Look for embedded Myvi.ru player\n        myvi_url = MyviIE._extract_url(webpage)\n        if myvi_url:\n            return self.url_result(myvi_url)\n\n        # Look for embedded soundcloud player\n        soundcloud_urls = SoundcloudIE._extract_urls(webpage)\n        if soundcloud_urls:\n            return self.playlist_from_matches(soundcloud_urls, video_id, video_title, getter=unescapeHTML, ie=SoundcloudIE.ie_key())\n\n        # Look for tunein player\n        tunein_urls = TuneInBaseIE._extract_urls(webpage)\n        if tunein_urls:\n            return self.playlist_from_matches(tunein_urls, video_id, video_title)\n\n        # Look for embedded mtvservices player\n        mtvservices_url = MTVServicesEmbeddedIE._extract_url(webpage)\n        if mtvservices_url:\n            return self.url_result(mtvservices_url, ie='MTVServicesEmbedded')\n\n        # Look for embedded yahoo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:screen|movies)\\.yahoo\\.com/.+?\\.html\\?format=embed)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Yahoo')\n\n        # Look for embedded sbs.com.au player\n        mobj = re.search(\n            r'''(?x)\n            (?:\n                <meta\\s+property=\"og:video\"\\s+content=|\n                <iframe[^>]+?src=\n            )\n            ([\"\\'])(?P<url>https?://(?:www\\.)?sbs\\.com\\.au/ondemand/video/.+?)\\1''',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'SBS')\n\n        # Look for embedded Cinchcast player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.cinchcast\\.com/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Cinchcast')\n\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://m(?:lb)?\\.mlb\\.com/shared/video/embed/embed\\.html\\?.+?)\\1',\n            webpage)\n        if not mobj:\n            mobj = re.search(\n                r'data-video-link=[\"\\'](?P<url>http://m.mlb.com/video/[^\"\\']+)',\n                webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'MLB')\n\n        mobj = re.search(\n            r'<(?:iframe|script)[^>]+?src=([\"\\'])(?P<url>%s)\\1' % CondeNastIE.EMBED_URL,\n            webpage)\n        if mobj is not None:\n            return self.url_result(self._proto_relative_url(mobj.group('url'), scheme='http:'), 'CondeNast')\n\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://(?:new\\.)?livestream\\.com/[^\"]+/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Livestream')\n\n        # Look for Zapiks embed\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://(?:www\\.)?zapiks\\.fr/index\\.php\\?.+?)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Zapiks')\n\n        # Look for Kaltura embeds\n        kaltura_url = KalturaIE._extract_url(webpage)\n        if kaltura_url:\n            return self.url_result(smuggle_url(kaltura_url, {'source_url': url}), KalturaIE.ie_key())\n\n        # Look for EaglePlatform embeds\n        eagleplatform_url = EaglePlatformIE._extract_url(webpage)\n        if eagleplatform_url:\n            return self.url_result(smuggle_url(eagleplatform_url, {'referrer': url}), EaglePlatformIE.ie_key())\n\n        # Look for ClipYou (uses EaglePlatform) embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?P<host>media\\.clipyou\\.ru)/index/player\\?.*\\brecord_id=(?P<id>\\d+).*\"', webpage)\n        if mobj is not None:\n            return self.url_result('eagleplatform:%(host)s:%(id)s' % mobj.groupdict(), 'EaglePlatform')\n\n        # Look for Pladform embeds\n        pladform_url = PladformIE._extract_url(webpage)\n        if pladform_url:\n            return self.url_result(pladform_url)\n\n        # Look for Videomore embeds\n        videomore_url = VideomoreIE._extract_url(webpage)\n        if videomore_url:\n            return self.url_result(videomore_url)\n\n        # Look for Webcaster embeds\n        webcaster_url = WebcasterFeedIE._extract_url(self, webpage)\n        if webcaster_url:\n            return self.url_result(webcaster_url, ie=WebcasterFeedIE.ie_key())\n\n        # Look for Playwire embeds\n        mobj = re.search(\n            r'<script[^>]+data-config=([\"\\'])(?P<url>(?:https?:)?//config\\.playwire\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for 5min embeds\n        mobj = re.search(\n            r'<meta[^>]+property=\"og:video\"[^>]+content=\"https?://embed\\.5min\\.com/(?P<id>[0-9]+)/?', webpage)\n        if mobj is not None:\n            return self.url_result('5min:%s' % mobj.group('id'), 'FiveMin')\n\n        # Look for Crooks and Liars embeds\n        mobj = re.search(\n            r'<(?:iframe[^>]+src|param[^>]+value)=([\"\\'])(?P<url>(?:https?:)?//embed\\.crooksandliars\\.com/(?:embed|v)/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for NBC Sports VPlayer embeds\n        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\n        if nbc_sports_url:\n            return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')\n\n        # Look for NBC News embeds\n        nbc_news_embed_url = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//www\\.nbcnews\\.com/widget/video-embed/[^\"\\']+)\\1', webpage)\n        if nbc_news_embed_url:\n            return self.url_result(nbc_news_embed_url.group('url'), 'NBCNews')\n\n        # Look for Google Drive embeds\n        google_drive_url = GoogleDriveIE._extract_url(webpage)\n        if google_drive_url:\n            return self.url_result(google_drive_url, 'GoogleDrive')\n\n        # Look for UDN embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=\"(?P<url>%s)\"' % UDNEmbedIE._PROTOCOL_RELATIVE_VALID_URL, webpage)\n        if mobj is not None:\n            return self.url_result(\n                compat_urlparse.urljoin(url, mobj.group('url')), 'UDNEmbed')\n\n        # Look for Senate ISVP iframe\n        senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)\n        if senate_isvp_url:\n            return self.url_result(senate_isvp_url, 'SenateISVP')\n\n        # Look for Dailymotion Cloud videos\n        dmcloud_url = DailymotionCloudIE._extract_dmcloud_url(webpage)\n        if dmcloud_url:\n            return self.url_result(dmcloud_url, 'DailymotionCloud')\n\n        # Look for OnionStudios embeds\n        onionstudios_url = OnionStudiosIE._extract_url(webpage)\n        if onionstudios_url:\n            return self.url_result(onionstudios_url)\n\n        # Look for ViewLift embeds\n        viewlift_url = ViewLiftEmbedIE._extract_url(webpage)\n        if viewlift_url:\n            return self.url_result(viewlift_url)\n\n        # Look for JWPlatform embeds\n        jwplatform_url = JWPlatformIE._extract_url(webpage)\n        if jwplatform_url:\n            return self.url_result(jwplatform_url, 'JWPlatform')\n\n        # Look for Digiteka embeds\n        digiteka_url = DigitekaIE._extract_url(webpage)\n        if digiteka_url:\n            return self.url_result(self._proto_relative_url(digiteka_url), DigitekaIE.ie_key())\n\n        # Look for Arkena embeds\n        arkena_url = ArkenaIE._extract_url(webpage)\n        if arkena_url:\n            return self.url_result(arkena_url, ArkenaIE.ie_key())\n\n        # Look for Piksel embeds\n        piksel_url = PikselIE._extract_url(webpage)\n        if piksel_url:\n            return self.url_result(piksel_url, PikselIE.ie_key())\n\n        # Look for Limelight embeds\n        limelight_urls = LimelightBaseIE._extract_urls(webpage, url)\n        if limelight_urls:\n            return self.playlist_result(\n                limelight_urls, video_id, video_title, video_description)\n\n        # Look for Anvato embeds\n        anvato_urls = AnvatoIE._extract_urls(self, webpage, video_id)\n        if anvato_urls:\n            return self.playlist_result(\n                anvato_urls, video_id, video_title, video_description)\n\n        # Look for AdobeTVVideo embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=[\\'\"]((?:https?:)?//video\\.tv\\.adobe\\.com/v/\\d+[^\"]+)[\\'\"]',\n            webpage)\n        if mobj is not None:\n            return self.url_result(\n                self._proto_relative_url(unescapeHTML(mobj.group(1))),\n                'AdobeTVVideo')\n\n        # Look for Vine embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=[\\'\"]((?:https?:)?//(?:www\\.)?vine\\.co/v/[^/]+/embed/(?:simple|postcard))',\n            webpage)\n        if mobj is not None:\n            return self.url_result(\n                self._proto_relative_url(unescapeHTML(mobj.group(1))), 'Vine')\n\n        # Look for VODPlatform embeds\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vod-platform\\.net/[eE]mbed/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(\n                self._proto_relative_url(unescapeHTML(mobj.group('url'))), 'VODPlatform')\n\n        # Look for Mangomolo embeds\n        mobj = re.search(\n            r'''(?x)<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?admin\\.mangomolo\\.com/analytics/index\\.php/customers/embed/\n                (?:\n                    video\\?.*?\\bid=(?P<video_id>\\d+)|\n                    index\\?.*?\\bchannelid=(?P<channel_id>(?:[A-Za-z0-9+/=]|%2B|%2F|%3D)+)\n                ).+?)\\1''', webpage)\n        if mobj is not None:\n            info = {\n                '_type': 'url_transparent',\n                'url': self._proto_relative_url(unescapeHTML(mobj.group('url'))),\n                'title': video_title,\n                'description': video_description,\n                'thumbnail': video_thumbnail,\n                'uploader': video_uploader,\n            }\n            video_id = mobj.group('video_id')\n            if video_id:\n                info.update({\n                    'ie_key': 'MangomoloVideo',\n                    'id': video_id,\n                })\n            else:\n                info.update({\n                    'ie_key': 'MangomoloLive',\n                    'id': mobj.group('channel_id'),\n                })\n            return info\n\n        # Look for Instagram embeds\n        instagram_embed_url = InstagramIE._extract_embed_url(webpage)\n        if instagram_embed_url is not None:\n            return self.url_result(\n                self._proto_relative_url(instagram_embed_url), InstagramIE.ie_key())\n\n        # Look for LiveLeak embeds\n        liveleak_url = LiveLeakIE._extract_url(webpage)\n        if liveleak_url:\n            return self.url_result(liveleak_url, 'LiveLeak')\n\n        # Look for 3Q SDN embeds\n        threeqsdn_url = ThreeQSDNIE._extract_url(webpage)\n        if threeqsdn_url:\n            return {\n                '_type': 'url_transparent',\n                'ie_key': ThreeQSDNIE.ie_key(),\n                'url': self._proto_relative_url(threeqsdn_url),\n                'title': video_title,\n                'description': video_description,\n                'thumbnail': video_thumbnail,\n                'uploader': video_uploader,\n            }\n\n        # Look for VBOX7 embeds\n        vbox7_url = Vbox7IE._extract_url(webpage)\n        if vbox7_url:\n            return self.url_result(vbox7_url, Vbox7IE.ie_key())\n\n        # Look for DBTV embeds\n        dbtv_urls = DBTVIE._extract_urls(webpage)\n        if dbtv_urls:\n            return self.playlist_from_matches(dbtv_urls, video_id, video_title, ie=DBTVIE.ie_key())\n\n        # Look for Videa embeds\n        videa_urls = VideaIE._extract_urls(webpage)\n        if videa_urls:\n            return self.playlist_from_matches(videa_urls, video_id, video_title, ie=VideaIE.ie_key())\n\n        # Look for 20 minuten embeds\n        twentymin_urls = TwentyMinutenIE._extract_urls(webpage)\n        if twentymin_urls:\n            return self.playlist_from_matches(\n                twentymin_urls, video_id, video_title, ie=TwentyMinutenIE.ie_key())\n\n        # Look for Openload embeds\n        openload_urls = OpenloadIE._extract_urls(webpage)\n        if openload_urls:\n            return self.playlist_from_matches(\n                openload_urls, video_id, video_title, ie=OpenloadIE.ie_key())\n\n        # Look for VideoPress embeds\n        videopress_urls = VideoPressIE._extract_urls(webpage)\n        if videopress_urls:\n            return self.playlist_from_matches(\n                videopress_urls, video_id, video_title, ie=VideoPressIE.ie_key())\n\n        # Look for Rutube embeds\n        rutube_urls = RutubeIE._extract_urls(webpage)\n        if rutube_urls:\n            return self.playlist_from_matches(\n                rutube_urls, video_id, video_title, ie=RutubeIE.ie_key())\n\n        # Look for WashingtonPost embeds\n        wapo_urls = WashingtonPostIE._extract_urls(webpage)\n        if wapo_urls:\n            return self.playlist_from_matches(\n                wapo_urls, video_id, video_title, ie=WashingtonPostIE.ie_key())\n\n        # Look for Mediaset embeds\n        mediaset_urls = MediasetIE._extract_urls(webpage)\n        if mediaset_urls:\n            return self.playlist_from_matches(\n                mediaset_urls, video_id, video_title, ie=MediasetIE.ie_key())\n\n        # Look for JOJ.sk embeds\n        joj_urls = JojIE._extract_urls(webpage)\n        if joj_urls:\n            return self.playlist_from_matches(\n                joj_urls, video_id, video_title, ie=JojIE.ie_key())\n\n        # Look for megaphone.fm embeds\n        mpfn_urls = MegaphoneIE._extract_urls(webpage)\n        if mpfn_urls:\n            return self.playlist_from_matches(\n                mpfn_urls, video_id, video_title, ie=MegaphoneIE.ie_key())\n\n        # Look for vzaar embeds\n        vzaar_urls = VzaarIE._extract_urls(webpage)\n        if vzaar_urls:\n            return self.playlist_from_matches(\n                vzaar_urls, video_id, video_title, ie=VzaarIE.ie_key())\n\n        def merge_dicts(dict1, dict2):\n            merged = {}\n            for k, v in dict1.items():\n                if v is not None:\n                    merged[k] = v\n            for k, v in dict2.items():\n                if v is None:\n                    continue\n                if (k not in merged or\n                        (isinstance(v, compat_str) and v and\n                            isinstance(merged[k], compat_str) and\n                            not merged[k])):\n                    merged[k] = v\n            return merged\n\n        # Looking for http://schema.org/VideoObject\n        json_ld = self._search_json_ld(\n            webpage, video_id, default={}, expected_type='VideoObject')\n        if json_ld.get('url'):\n            return merge_dicts(json_ld, info_dict)\n\n        # Look for HTML5 media\n        entries = self._parse_html5_media_entries(url, webpage, video_id, m3u8_id='hls')\n        if entries:\n            for entry in entries:\n                entry.update({\n                    'id': video_id,\n                    'title': video_title,\n                })\n                self._sort_formats(entry['formats'])\n            return self.playlist_result(entries)\n\n        jwplayer_data = self._find_jwplayer_data(\n            webpage, video_id, transform_source=js_to_json)\n        if jwplayer_data:\n            info = self._parse_jwplayer_data(\n                jwplayer_data, video_id, require_title=False, base_url=url)\n            return merge_dicts(info, info_dict)\n\n        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            if RtmpIE.suitable(vurl):\n                return True\n            vpath = compat_urlparse.urlparse(vurl).path\n            vext = determine_ext(vpath)\n            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js', 'xml')\n\n        def filter_video(urls):\n            return list(filter(check_video, urls))\n\n        # Start with something easy: JW Player in SWFObject\n        found = filter_video(re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Look for gorilla-vid style embedding\n            found = filter_video(re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?\n                ['\"]?file['\"]?\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage))\n        if not found:\n            # Broaden the search a little bit\n            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage))\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = filter_video(re.findall(\n                r'[^A-Za-z0-9]?(?:file|video_url)[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage))\n        if not found:\n            # Flow player\n            found = filter_video(re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*\\{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage))\n        if not found:\n            # Cinerama player\n            found = re.findall(\n                r\"cinerama\\.embedPlayer\\(\\s*\\'[^']+\\',\\s*'([^']+)'\", webpage)\n        if not found:\n            # Try to find twitter cards info\n            # twitter:player:stream should be checked before twitter:player since\n            # it is expected to contain a raw stream (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            found = filter_video(re.findall(\n                r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage))\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                found = filter_video(re.findall(r'<meta.*?property=\"og:video\".*?content=\"(.*?)\"', webpage))\n        if not found:\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                webpage)\n            if not found:\n                # Look also in Refresh HTTP header\n                refresh_header = head_response.headers.get('Refresh')\n                if refresh_header:\n                    # In python 2 response HTTP headers are bytestrings\n                    if sys.version_info < (3, 0) and isinstance(refresh_header, str):\n                        refresh_header = refresh_header.decode('iso-8859-1')\n                    found = re.search(REDIRECT_REGEX, refresh_header)\n            if found:\n                new_url = compat_urlparse.urljoin(url, unescapeHTML(found.group(1)))\n                if new_url != url:\n                    self.report_following_redirect(new_url)\n                    return {\n                        '_type': 'url',\n                        'url': new_url,\n                    }\n                else:\n                    found = None\n\n        if not found:\n            # twitter:player is a https URL to iframe player that may or may not\n            # be supported by youtube-dl thus this is checked the very last (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            embed_url = self._html_search_meta('twitter:player', webpage, default=None)\n            if embed_url:\n                return self.url_result(embed_url)\n\n        if not found:\n            raise UnsupportedError(url)\n\n        entries = []\n        for video_url in orderedSet(found):\n            video_url = unescapeHTML(video_url)\n            video_url = video_url.replace('\\\\/', '/')\n            video_url = compat_urlparse.urljoin(url, video_url)\n            video_id = compat_urllib_parse_unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            # here's a fun little line of code for you:\n            video_id = os.path.splitext(video_id)[0]\n\n            entry_info_dict = {\n                'id': video_id,\n                'uploader': video_uploader,\n                'title': video_title,\n                'age_limit': age_limit,\n            }\n\n            if RtmpIE.suitable(video_url):\n                entry_info_dict.update({\n                    '_type': 'url_transparent',\n                    'ie_key': RtmpIE.ie_key(),\n                    'url': video_url,\n                })\n                entries.append(entry_info_dict)\n                continue\n\n            ext = determine_ext(video_url)\n            if ext == 'smil':\n                entry_info_dict['formats'] = self._extract_smil_formats(video_url, video_id)\n            elif ext == 'xspf':\n                return self.playlist_result(self._extract_xspf_playlist(video_url, video_id), video_id)\n            elif ext == 'm3u8':\n                entry_info_dict['formats'] = self._extract_m3u8_formats(video_url, video_id, ext='mp4')\n            elif ext == 'mpd':\n                entry_info_dict['formats'] = self._extract_mpd_formats(video_url, video_id)\n            elif ext == 'f4m':\n                entry_info_dict['formats'] = self._extract_f4m_formats(video_url, video_id)\n            elif re.search(r'(?i)\\.(?:ism|smil)/manifest', video_url) and video_url != url:\n                # Just matching .ism/manifest is not enough to be reliably sure\n                # whether it's actually an ISM manifest or some other streaming\n                # manifest since there are various streaming URL formats\n                # possible (see [1]) as well as some other shenanigans like\n                # .smil/manifest URLs that actually serve an ISM (see [2]) and\n                # so on.\n                # Thus the most reasonable way to solve this is to delegate\n                # to generic extractor in order to look into the contents of\n                # the manifest itself.\n                # 1. https://azure.microsoft.com/en-us/documentation/articles/media-services-deliver-content-overview/#streaming-url-formats\n                # 2. https://svs.itworkscdn.net/lbcivod/smil:itwfcdn/lbci/170976.smil/Manifest\n                entry_info_dict = self.url_result(\n                    smuggle_url(video_url, {'to_generic': True}),\n                    GenericIE.ie_key())\n            else:\n                entry_info_dict['url'] = video_url\n\n            if entry_info_dict.get('formats'):\n                self._sort_formats(entry_info_dict['formats'])\n\n            entries.append(entry_info_dict)\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            for num, e in enumerate(entries, start=1):\n                # 'url' results don't have a title\n                if e.get('title') is not None:\n                    e['title'] = '%s (%d)' % (e['title'], num)\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n            }",
        "begin_line": 1961,
        "end_line": 3053,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gfycat.GfycatIE._real_extract#49",
        "src_path": "youtube_dl/extractor/gfycat.py",
        "class_name": "youtube_dl.extractor.gfycat.GfycatIE",
        "signature": "youtube_dl.extractor.gfycat.GfycatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        gfy = self._download_json(\n            'http://gfycat.com/cajax/get/%s' % video_id,\n            video_id, 'Downloading video info')\n        if 'error' in gfy:\n            raise ExtractorError('Gfycat said: ' + gfy['error'], expected=True)\n        gfy = gfy['gfyItem']\n\n        title = gfy.get('title') or gfy['gfyName']\n        description = gfy.get('description')\n        timestamp = int_or_none(gfy.get('createDate'))\n        uploader = gfy.get('userName')\n        view_count = int_or_none(gfy.get('views'))\n        like_count = int_or_none(gfy.get('likes'))\n        dislike_count = int_or_none(gfy.get('dislikes'))\n        age_limit = 18 if gfy.get('nsfw') == '1' else 0\n\n        width = int_or_none(gfy.get('width'))\n        height = int_or_none(gfy.get('height'))\n        fps = int_or_none(gfy.get('frameRate'))\n        num_frames = int_or_none(gfy.get('numFrames'))\n\n        duration = float_or_none(num_frames, fps) if num_frames and fps else None\n\n        categories = gfy.get('tags') or gfy.get('extraLemmas') or []\n\n        FORMATS = ('gif', 'webm', 'mp4')\n        quality = qualities(FORMATS)\n\n        formats = []\n        for format_id in FORMATS:\n            video_url = gfy.get('%sUrl' % format_id)\n            if not video_url:\n                continue\n            filesize = int_or_none(gfy.get('%sSize' % format_id))\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'width': width,\n                'height': height,\n                'fps': fps,\n                'filesize': filesize,\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'categories': categories,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 49,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.giantbomb.GiantBombIE._real_extract#31",
        "src_path": "youtube_dl/extractor/giantbomb.py",
        "class_name": "youtube_dl.extractor.giantbomb.GiantBombIE",
        "signature": "youtube_dl.extractor.giantbomb.GiantBombIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video = json.loads(unescapeHTML(self._search_regex(\n            r'data-video=\"([^\"]+)\"', webpage, 'data-video')))\n\n        duration = int_or_none(video.get('lengthSeconds'))\n\n        quality = qualities([\n            'f4m_low', 'progressive_low', 'f4m_high',\n            'progressive_high', 'f4m_hd', 'progressive_hd'])\n\n        formats = []\n        for format_id, video_url in video['videoStreams'].items():\n            if format_id == 'f4m_stream':\n                continue\n            ext = determine_ext(video_url)\n            if ext == 'f4m':\n                f4m_formats = self._extract_f4m_formats(video_url + '?hdcore=3.3.1', display_id)\n                if f4m_formats:\n                    f4m_formats[0]['quality'] = quality(format_id)\n                    formats.extend(f4m_formats)\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, display_id, ext='mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                })\n\n        if not formats:\n            youtube_id = video.get('youtubeID')\n            if youtube_id:\n                return self.url_result(youtube_id, 'Youtube')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.giga.GigaIE._real_extract#45",
        "src_path": "youtube_dl/extractor/giga.py",
        "class_name": "youtube_dl.extractor.giga.GigaIE",
        "signature": "youtube_dl.extractor.giga.GigaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            [r'data-video-id=\"(\\d+)\"', r'/api/video/jwplayer/#v=(\\d+)'],\n            webpage, 'video id')\n\n        playlist = self._download_json(\n            'http://www.giga.de/api/syndication/video/video_id/%s/playlist.json?content=syndication/key/368b5f151da4ae05ced7fa296bdff65a/'\n            % video_id, video_id)[0]\n\n        quality = qualities(['normal', 'hd720'])\n\n        formats = []\n        for format_id in itertools.count(0):\n            fmt = playlist.get(compat_str(format_id))\n            if not fmt:\n                break\n            formats.append({\n                'url': fmt['src'],\n                'format_id': '%s-%s' % (fmt['quality'], fmt['type'].split('/')[-1]),\n                'quality': quality(fmt['quality']),\n            })\n        self._sort_formats(formats)\n\n        title = self._html_search_meta(\n            'title', webpage, 'title', fatal=True)\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'(?s)(?:data-video-id=\"{0}\"|data-video=\"[^\"]*/api/video/jwplayer/#v={0}[^\"]*\")[^>]*>.+?<span class=\"duration\">([^<]+)</span>'.format(video_id),\n            webpage, 'duration', fatal=False))\n\n        timestamp = parse_iso8601(self._search_regex(\n            r'datetime=\"([^\"]+)\"', webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'class=\"author\">([^<]+)</a>', webpage, 'uploader', fatal=False)\n\n        view_count = str_to_int(self._search_regex(\n            r'<span class=\"views\"><strong>([\\d.,]+)</strong>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.glide.GlideIE._real_extract#21",
        "src_path": "youtube_dl/extractor/glide.py",
        "class_name": "youtube_dl.extractor.glide.GlideIE",
        "signature": "youtube_dl.extractor.glide.GlideIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+?)</title>', webpage,\n            'title', default=None) or self._og_search_title(webpage)\n        video_url = self._proto_relative_url(self._search_regex(\n            r'<source[^>]+src=([\"\\'])(?P<url>.+?)\\1',\n            webpage, 'video URL', default=None,\n            group='url')) or self._og_search_video_url(webpage)\n        thumbnail = self._proto_relative_url(self._search_regex(\n            r'<img[^>]+id=[\"\\']video-thumbnail[\"\\'][^>]+src=([\"\\'])(?P<url>.+?)\\1',\n            webpage, 'thumbnail url', default=None,\n            group='url')) or self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.__init__#82",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.__init__(self)",
        "snippet": "        def __init__(self):\n            pass",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.JSArray.__getitem__#86",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.JSArray",
        "signature": "youtube_dl.extractor.globo.JSArray.__getitem__(self, y)",
        "snippet": "            def __getitem__(self, y):\n                try:\n                    return list.__getitem__(self, y)\n                except IndexError:\n                    return 0",
        "begin_line": 86,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.JSArray.__setitem__#92",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.JSArray",
        "signature": "youtube_dl.extractor.globo.JSArray.__setitem__(self, i, y)",
        "snippet": "            def __setitem__(self, i, y):\n                try:\n                    return list.__setitem__(self, i, y)\n                except IndexError:\n                    self.extend([0] * (i - len(self) + 1))\n                    self[-1] = y",
        "begin_line": 92,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.hex_md5#100",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.hex_md5(cls, param1)",
        "snippet": "        def hex_md5(cls, param1):\n            return cls.rstr2hex(cls.rstr_md5(cls.str2rstr_utf8(param1)))",
        "begin_line": 100,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.b64_md5#104",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.b64_md5(cls, param1, param2=None)",
        "snippet": "        def b64_md5(cls, param1, param2=None):\n            return cls.rstr2b64(cls.rstr_md5(cls.str2rstr_utf8(param1, param2)))",
        "begin_line": 104,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.any_md5#108",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.any_md5(cls, param1, param2)",
        "snippet": "        def any_md5(cls, param1, param2):\n            return cls.rstr2any(cls.rstr_md5(cls.str2rstr_utf8(param1)), param2)",
        "begin_line": 108,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr_md5#112",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr_md5(cls, param1)",
        "snippet": "        def rstr_md5(cls, param1):\n            return cls.binl2rstr(cls.binl_md5(cls.rstr2binl(param1), len(param1) * 8))",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2hex#116",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2hex(cls, param1)",
        "snippet": "        def rstr2hex(cls, param1):\n            _loc_2 = '0123456789ABCDEF' if cls.hexcase else '0123456789abcdef'\n            _loc_3 = ''\n            for _loc_5 in range(0, len(param1)):\n                _loc_4 = compat_ord(param1[_loc_5])\n                _loc_3 += _loc_2[_loc_4 >> 4 & 15] + _loc_2[_loc_4 & 15]\n            return _loc_3",
        "begin_line": 116,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2b64#125",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2b64(cls, param1)",
        "snippet": "        def rstr2b64(cls, param1):\n            _loc_2 = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'\n            _loc_3 = ''\n            _loc_4 = len(param1)\n            for _loc_5 in range(0, _loc_4, 3):\n                _loc_6_1 = compat_ord(param1[_loc_5]) << 16\n                _loc_6_2 = compat_ord(param1[_loc_5 + 1]) << 8 if _loc_5 + 1 < _loc_4 else 0\n                _loc_6_3 = compat_ord(param1[_loc_5 + 2]) if _loc_5 + 2 < _loc_4 else 0\n                _loc_6 = _loc_6_1 | _loc_6_2 | _loc_6_3\n                for _loc_7 in range(0, 4):\n                    if _loc_5 * 8 + _loc_7 * 6 > len(param1) * 8:\n                        _loc_3 += cls.b64pad\n                    else:\n                        _loc_3 += _loc_2[_loc_6 >> 6 * (3 - _loc_7) & 63]\n            return _loc_3",
        "begin_line": 125,
        "end_line": 139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2any#142",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2any(param1, param2)",
        "snippet": "        def rstr2any(param1, param2):\n            _loc_3 = len(param2)\n            _loc_4 = []\n            _loc_9 = [0] * ((len(param1) >> 2) + 1)\n            for _loc_5 in range(0, len(_loc_9)):\n                _loc_9[_loc_5] = compat_ord(param1[_loc_5 * 2]) << 8 | compat_ord(param1[_loc_5 * 2 + 1])\n\n            while len(_loc_9) > 0:\n                _loc_8 = []\n                _loc_7 = 0\n                for _loc_5 in range(0, len(_loc_9)):\n                    _loc_7 = (_loc_7 << 16) + _loc_9[_loc_5]\n                    _loc_6 = math.floor(_loc_7 / _loc_3)\n                    _loc_7 -= _loc_6 * _loc_3\n                    if len(_loc_8) > 0 or _loc_6 > 0:\n                        _loc_8[len(_loc_8)] = _loc_6\n\n                _loc_4[len(_loc_4)] = _loc_7\n                _loc_9 = _loc_8\n\n            _loc_10 = ''\n            _loc_5 = len(_loc_4) - 1\n            while _loc_5 >= 0:\n                _loc_10 += param2[_loc_4[_loc_5]]\n                _loc_5 -= 1\n\n            return _loc_10",
        "begin_line": 142,
        "end_line": 168,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.str2rstr_utf8#171",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.str2rstr_utf8(cls, param1, param2=None)",
        "snippet": "        def str2rstr_utf8(cls, param1, param2=None):\n            _loc_3 = ''\n            _loc_4 = -1\n            if not param2:\n                param2 = cls.PADDING\n            param1 = param1 + param2[1:9]\n            while True:\n                _loc_4 += 1\n                if _loc_4 >= len(param1):\n                    break\n                _loc_5 = compat_ord(param1[_loc_4])\n                _loc_6 = compat_ord(param1[_loc_4 + 1]) if _loc_4 + 1 < len(param1) else 0\n                if 55296 <= _loc_5 <= 56319 and 56320 <= _loc_6 <= 57343:\n                    _loc_5 = 65536 + ((_loc_5 & 1023) << 10) + (_loc_6 & 1023)\n                    _loc_4 += 1\n                if _loc_5 <= 127:\n                    _loc_3 += compat_chr(_loc_5)\n                    continue\n                if _loc_5 <= 2047:\n                    _loc_3 += compat_chr(192 | _loc_5 >> 6 & 31) + compat_chr(128 | _loc_5 & 63)\n                    continue\n                if _loc_5 <= 65535:\n                    _loc_3 += compat_chr(224 | _loc_5 >> 12 & 15) + compat_chr(128 | _loc_5 >> 6 & 63) + compat_chr(\n                        128 | _loc_5 & 63)\n                    continue\n                if _loc_5 <= 2097151:\n                    _loc_3 += compat_chr(240 | _loc_5 >> 18 & 7) + compat_chr(128 | _loc_5 >> 12 & 63) + compat_chr(\n                        128 | _loc_5 >> 6 & 63) + compat_chr(128 | _loc_5 & 63)\n            return _loc_3",
        "begin_line": 171,
        "end_line": 199,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.rstr2binl#202",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.rstr2binl(param1)",
        "snippet": "        def rstr2binl(param1):\n            _loc_2 = [0] * ((len(param1) >> 2) + 1)\n            for _loc_3 in range(0, len(_loc_2)):\n                _loc_2[_loc_3] = 0\n            for _loc_3 in range(0, len(param1) * 8, 8):\n                _loc_2[_loc_3 >> 5] |= (compat_ord(param1[_loc_3 // 8]) & 255) << _loc_3 % 32\n            return _loc_2",
        "begin_line": 202,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.binl2rstr#211",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.binl2rstr(param1)",
        "snippet": "        def binl2rstr(param1):\n            _loc_2 = ''\n            for _loc_3 in range(0, len(param1) * 32, 8):\n                _loc_2 += compat_chr(param1[_loc_3 >> 5] >> _loc_3 % 32 & 255)\n            return _loc_2",
        "begin_line": 211,
        "end_line": 215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.binl_md5#218",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.binl_md5(cls, param1, param2)",
        "snippet": "        def binl_md5(cls, param1, param2):\n            param1 = cls.JSArray(param1)\n            param1[param2 >> 5] |= 128 << param2 % 32\n            param1[(param2 + 64 >> 9 << 4) + 14] = param2\n            _loc_3 = 1732584193\n            _loc_4 = -271733879\n            _loc_5 = -1732584194\n            _loc_6 = 271733878\n            for _loc_7 in range(0, len(param1), 16):\n                _loc_8 = _loc_3\n                _loc_9 = _loc_4\n                _loc_10 = _loc_5\n                _loc_11 = _loc_6\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 0], 7, -680876936)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 1], 12, -389564586)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 2], 17, 606105819)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 3], 22, -1044525330)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 4], 7, -176418897)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 5], 12, 1200080426)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 6], 17, -1473231341)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 7], 22, -45705983)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 8], 7, 1770035416)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 9], 12, -1958414417)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 10], 17, -42063)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 11], 22, -1990404162)\n                _loc_3 = cls.md5_ff(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 12], 7, 1804603682)\n                _loc_6 = cls.md5_ff(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 13], 12, -40341101)\n                _loc_5 = cls.md5_ff(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 14], 17, -1502002290)\n                _loc_4 = cls.md5_ff(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 15], 22, 1236535329)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 1], 5, -165796510)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 6], 9, -1069501632)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 11], 14, 643717713)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 0], 20, -373897302)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 5], 5, -701558691)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 10], 9, 38016083)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 15], 14, -660478335)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 4], 20, -405537848)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 9], 5, 568446438)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 14], 9, -1019803690)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 3], 14, -187363961)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 8], 20, 1163531501)\n                _loc_3 = cls.md5_gg(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 13], 5, -1444681467)\n                _loc_6 = cls.md5_gg(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 2], 9, -51403784)\n                _loc_5 = cls.md5_gg(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 7], 14, 1735328473)\n                _loc_4 = cls.md5_gg(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 12], 20, -1926607734)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 5], 4, -378558)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 8], 11, -2022574463)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 11], 16, 1839030562)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 14], 23, -35309556)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 1], 4, -1530992060)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 4], 11, 1272893353)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 7], 16, -155497632)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 10], 23, -1094730640)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 13], 4, 681279174)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 0], 11, -358537222)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 3], 16, -722521979)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 6], 23, 76029189)\n                _loc_3 = cls.md5_hh(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 9], 4, -640364487)\n                _loc_6 = cls.md5_hh(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 12], 11, -421815835)\n                _loc_5 = cls.md5_hh(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 15], 16, 530742520)\n                _loc_4 = cls.md5_hh(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 2], 23, -995338651)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 0], 6, -198630844)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 7], 10, 1126891415)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 14], 15, -1416354905)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 5], 21, -57434055)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 12], 6, 1700485571)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 3], 10, -1894986606)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 10], 15, -1051523)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 1], 21, -2054922799)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 8], 6, 1873313359)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 15], 10, -30611744)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 6], 15, -1560198380)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 13], 21, 1309151649)\n                _loc_3 = cls.md5_ii(_loc_3, _loc_4, _loc_5, _loc_6, param1[_loc_7 + 4], 6, -145523070)\n                _loc_6 = cls.md5_ii(_loc_6, _loc_3, _loc_4, _loc_5, param1[_loc_7 + 11], 10, -1120210379)\n                _loc_5 = cls.md5_ii(_loc_5, _loc_6, _loc_3, _loc_4, param1[_loc_7 + 2], 15, 718787259)\n                _loc_4 = cls.md5_ii(_loc_4, _loc_5, _loc_6, _loc_3, param1[_loc_7 + 9], 21, -343485551)\n                _loc_3 = cls.safe_add(_loc_3, _loc_8)\n                _loc_4 = cls.safe_add(_loc_4, _loc_9)\n                _loc_5 = cls.safe_add(_loc_5, _loc_10)\n                _loc_6 = cls.safe_add(_loc_6, _loc_11)\n            return [_loc_3, _loc_4, _loc_5, _loc_6]",
        "begin_line": 218,
        "end_line": 299,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_cmn#302",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_cmn(cls, param1, param2, param3, param4, param5, param6)",
        "snippet": "        def md5_cmn(cls, param1, param2, param3, param4, param5, param6):\n            return cls.safe_add(\n                cls.bit_rol(cls.safe_add(cls.safe_add(param2, param1), cls.safe_add(param4, param6)), param5), param3)",
        "begin_line": 302,
        "end_line": 304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_ff#307",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_ff(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_ff(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 & param3 | ~param2 & param4, param1, param2, param5, param6, param7)",
        "begin_line": 307,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_gg#311",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_gg(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_gg(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 & param4 | param3 & ~param4, param1, param2, param5, param6, param7)",
        "begin_line": 311,
        "end_line": 312,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_hh#315",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_hh(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_hh(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param2 ^ param3 ^ param4, param1, param2, param5, param6, param7)",
        "begin_line": 315,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.md5_ii#319",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.md5_ii(cls, param1, param2, param3, param4, param5, param6, param7)",
        "snippet": "        def md5_ii(cls, param1, param2, param3, param4, param5, param6, param7):\n            return cls.md5_cmn(param3 ^ (param2 | ~param4), param1, param2, param5, param6, param7)",
        "begin_line": 319,
        "end_line": 320,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.safe_add#323",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.safe_add(cls, param1, param2)",
        "snippet": "        def safe_add(cls, param1, param2):\n            _loc_3 = (param1 & 65535) + (param2 & 65535)\n            _loc_4 = (param1 >> 16) + (param2 >> 16) + (_loc_3 >> 16)\n            return cls.lshift(_loc_4, 16) | _loc_3 & 65535",
        "begin_line": 323,
        "end_line": 326,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.bit_rol#329",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.bit_rol(cls, param1, param2)",
        "snippet": "        def bit_rol(cls, param1, param2):\n            return cls.lshift(param1, param2) | (param1 & 0xFFFFFFFF) >> (32 - param2)",
        "begin_line": 329,
        "end_line": 330,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.MD5.lshift#333",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.MD5",
        "signature": "youtube_dl.extractor.globo.MD5.lshift(value, count)",
        "snippet": "        def lshift(value, count):\n            r = (0xFFFFFFFF & value) << count\n            return -(~(r - 1) & 0xFFFFFFFF) if r > 0x7FFFFFFF else r",
        "begin_line": 333,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.GloboIE._real_extract#337",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.GloboIE",
        "signature": "youtube_dl.extractor.globo.GloboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            self._API_URL_TEMPLATE % video_id, video_id)['videos'][0]\n\n        title = video['title']\n\n        formats = []\n        for resource in video['resources']:\n            resource_id = resource.get('_id')\n            if not resource_id or resource_id.endswith('manifest'):\n                continue\n\n            security = self._download_json(\n                self._SECURITY_URL_TEMPLATE % (video_id, resource_id),\n                video_id, 'Downloading security hash for %s' % resource_id)\n\n            security_hash = security.get('hash')\n            if not security_hash:\n                message = security.get('message')\n                if message:\n                    raise ExtractorError(\n                        '%s returned error: %s' % (self.IE_NAME, message), expected=True)\n                continue\n\n            hash_code = security_hash[:2]\n            received_time = int(security_hash[2:12])\n            received_random = security_hash[12:22]\n            received_md5 = security_hash[22:]\n\n            sign_time = received_time + self._RESIGN_EXPIRATION\n            padding = '%010d' % random.randint(1, 10000000000)\n\n            signed_md5 = self.MD5.b64_md5(received_md5 + compat_str(sign_time) + padding)\n            signed_hash = hash_code + compat_str(received_time) + received_random + compat_str(sign_time) + padding + signed_md5\n\n            resource_url = resource['url']\n            signed_url = '%s?h=%s&k=%s' % (resource_url, signed_hash, 'flash')\n            if resource_id.endswith('m3u8') or resource_url.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(\n                    signed_url, resource_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': signed_url,\n                    'format_id': 'http-%s' % resource_id,\n                    'height': int_or_none(resource.get('height')),\n                })\n\n        self._sort_formats(formats)\n\n        duration = float_or_none(video.get('duration'), 1000)\n        uploader = video.get('channel')\n        uploader_id = str_or_none(video.get('channel_id'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats\n        }",
        "begin_line": 337,
        "end_line": 400,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.GloboArticleIE.suitable#442",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.GloboArticleIE",
        "signature": "youtube_dl.extractor.globo.GloboArticleIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if GloboIE.suitable(url) else super(GloboArticleIE, cls).suitable(url)",
        "begin_line": 442,
        "end_line": 443,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.globo.GloboArticleIE._real_extract#445",
        "src_path": "youtube_dl/extractor/globo.py",
        "class_name": "youtube_dl.extractor.globo.GloboArticleIE",
        "signature": "youtube_dl.extractor.globo.GloboArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_ids = []\n        for video_regex in self._VIDEOID_REGEXES:\n            video_ids.extend(re.findall(video_regex, webpage))\n        entries = [\n            self.url_result('globo:%s' % video_id, GloboIE.ie_key())\n            for video_id in orderedSet(video_ids)]\n        title = self._og_search_title(webpage, fatal=False)\n        description = self._html_search_meta('description', webpage)\n        return self.playlist_result(entries, display_id, title, description)",
        "begin_line": 445,
        "end_line": 456,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.go.GoIE._extract_videos#67",
        "src_path": "youtube_dl/extractor/go.py",
        "class_name": "youtube_dl.extractor.go.GoIE",
        "signature": "youtube_dl.extractor.go.GoIE._extract_videos(self, brand, video_id='-1', show_id='-1')",
        "snippet": "    def _extract_videos(self, brand, video_id='-1', show_id='-1'):\n        display_id = video_id if video_id != '-1' else show_id\n        return self._download_json(\n            'http://api.contents.watchabc.go.com/vp2/ws/contents/3000/videos/%s/001/-1/%s/-1/%s/-1/-1.json' % (brand, show_id, video_id),\n            display_id)['video']",
        "begin_line": 67,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.go.GoIE._real_extract#73",
        "src_path": "youtube_dl/extractor/go.py",
        "class_name": "youtube_dl.extractor.go.GoIE",
        "signature": "youtube_dl.extractor.go.GoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        sub_domain, video_id, display_id = re.match(self._VALID_URL, url).groups()\n        site_info = self._SITE_INFO[sub_domain]\n        brand = site_info['brand']\n        if not video_id:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._search_regex(\n                # There may be inner quotes, e.g. data-video-id=\"'VDKA3609139'\"\n                # from http://freeform.go.com/shows/shadowhunters/episodes/season-2/1-this-guilty-blood\n                r'data-video-id=[\"\\']*(VDKA\\w+)', webpage, 'video id', default=None)\n            if not video_id:\n                # show extraction works for Disney, DisneyJunior and DisneyXD\n                # ABC and Freeform has different layout\n                show_id = self._search_regex(r'data-show-id=[\"\\']*(SH\\d+)', webpage, 'show id')\n                videos = self._extract_videos(brand, show_id=show_id)\n                show_title = self._search_regex(r'data-show-title=\"([^\"]+)\"', webpage, 'show title', fatal=False)\n                entries = []\n                for video in videos:\n                    entries.append(self.url_result(\n                        video['url'], 'Go', video.get('id'), video.get('title')))\n                entries.reverse()\n                return self.playlist_result(entries, show_id, show_title)\n        video_data = self._extract_videos(brand, video_id)[0]\n        video_id = video_data['id']\n        title = video_data['title']\n\n        formats = []\n        for asset in video_data.get('assets', {}).get('asset', []):\n            asset_url = asset.get('value')\n            if not asset_url:\n                continue\n            format_id = asset.get('format')\n            ext = determine_ext(asset_url)\n            if ext == 'm3u8':\n                video_type = video_data.get('type')\n                data = {\n                    'video_id': video_data['id'],\n                    'video_type': video_type,\n                    'brand': brand,\n                    'device': '001',\n                }\n                if video_data.get('accesslevel') == '1':\n                    requestor_id = site_info['requestor_id']\n                    resource = self._get_mvpd_resource(\n                        requestor_id, title, video_id, None)\n                    auth = self._extract_mvpd_auth(\n                        url, video_id, requestor_id, resource)\n                    data.update({\n                        'token': auth,\n                        'token_type': 'ap',\n                        'adobe_requestor_id': requestor_id,\n                    })\n                else:\n                    self._initialize_geo_bypass(['US'])\n                entitlement = self._download_json(\n                    'https://api.entitlement.watchabc.go.com/vp2/ws-secure/entitlement/2020/authorize.json',\n                    video_id, data=urlencode_postdata(data))\n                errors = entitlement.get('errors', {}).get('errors', [])\n                if errors:\n                    for error in errors:\n                        if error.get('code') == 1002:\n                            self.raise_geo_restricted(\n                                error['message'], countries=['US'])\n                    error_message = ', '.join([error['message'] for error in errors])\n                    raise ExtractorError('%s said: %s' % (self.IE_NAME, error_message), expected=True)\n                asset_url += '?' + entitlement['uplynkData']['sessionKey']\n                formats.extend(self._extract_m3u8_formats(\n                    asset_url, video_id, 'mp4', m3u8_id=format_id or 'hls', fatal=False))\n            else:\n                f = {\n                    'format_id': format_id,\n                    'url': asset_url,\n                    'ext': ext,\n                }\n                if re.search(r'(?:/mp4/source/|_source\\.mp4)', asset_url):\n                    f.update({\n                        'format_id': ('%s-' % format_id if format_id else '') + 'SOURCE',\n                        'preference': 1,\n                    })\n                else:\n                    mobj = re.search(r'/(\\d+)x(\\d+)/', asset_url)\n                    if mobj:\n                        height = int(mobj.group(2))\n                        f.update({\n                            'format_id': ('%s-' % format_id if format_id else '') + '%dP' % height,\n                            'width': int(mobj.group(1)),\n                            'height': height,\n                        })\n                formats.append(f)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for cc in video_data.get('closedcaption', {}).get('src', []):\n            cc_url = cc.get('value')\n            if not cc_url:\n                continue\n            ext = determine_ext(cc_url)\n            if ext == 'xml':\n                ext = 'ttml'\n            subtitles.setdefault(cc.get('lang'), []).append({\n                'url': cc_url,\n                'ext': ext,\n            })\n\n        thumbnails = []\n        for thumbnail in video_data.get('thumbnails', {}).get('thumbnail', []):\n            thumbnail_url = thumbnail.get('value')\n            if not thumbnail_url:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int_or_none(thumbnail.get('width')),\n                'height': int_or_none(thumbnail.get('height')),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('longdescription') or video_data.get('description'),\n            'duration': int_or_none(video_data.get('duration', {}).get('value'), 1000),\n            'age_limit': parse_age_limit(video_data.get('tvrating', {}).get('rating')),\n            'episode_number': int_or_none(video_data.get('episodenumber')),\n            'series': video_data.get('show', {}).get('title'),\n            'season_number': int_or_none(video_data.get('season', {}).get('num')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 73,
        "end_line": 200,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.go90.Go90IE._real_extract#29",
        "src_path": "youtube_dl/extractor/go90.py",
        "class_name": "youtube_dl.extractor.go90.Go90IE",
        "signature": "youtube_dl.extractor.go90.Go90IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'https://www.go90.com/api/view/items/' + video_id,\n            video_id, headers={\n                'Content-Type': 'application/json; charset=utf-8',\n            }, data=b'{\"client\":\"web\",\"device_type\":\"pc\"}')\n        main_video_asset = video_data['main_video_asset']\n\n        episode_number = int_or_none(video_data.get('episode_number'))\n        series = None\n        season = None\n        season_id = None\n        season_number = None\n        for metadata in video_data.get('__children', {}).get('Item', {}).values():\n            if metadata.get('type') == 'show':\n                series = metadata.get('title')\n            elif metadata.get('type') == 'season':\n                season = metadata.get('title')\n                season_id = metadata.get('id')\n                season_number = int_or_none(metadata.get('season_number'))\n\n        title = episode = video_data.get('title') or series\n        if series and series != title:\n            title = '%s - %s' % (series, title)\n\n        thumbnails = []\n        formats = []\n        subtitles = {}\n        for asset in video_data.get('assets'):\n            if asset.get('id') == main_video_asset:\n                for source in asset.get('sources', []):\n                    source_location = source.get('location')\n                    if not source_location:\n                        continue\n                    source_type = source.get('type')\n                    if source_type == 'hls':\n                        m3u8_formats = self._extract_m3u8_formats(\n                            source_location, video_id, 'mp4',\n                            'm3u8_native', m3u8_id='hls', fatal=False)\n                        for f in m3u8_formats:\n                            mobj = re.search(r'/hls-(\\d+)-(\\d+)K', f['url'])\n                            if mobj:\n                                height, tbr = mobj.groups()\n                                height = int_or_none(height)\n                                f.update({\n                                    'height': f.get('height') or height,\n                                    'width': f.get('width') or int_or_none(height / 9.0 * 16.0 if height else None),\n                                    'tbr': f.get('tbr') or int_or_none(tbr),\n                                })\n                        formats.extend(m3u8_formats)\n                    elif source_type == 'dash':\n                        formats.extend(self._extract_mpd_formats(\n                            source_location, video_id, mpd_id='dash', fatal=False))\n                    else:\n                        formats.append({\n                            'format_id': source.get('name'),\n                            'url': source_location,\n                            'width': int_or_none(source.get('width')),\n                            'height': int_or_none(source.get('height')),\n                            'tbr': int_or_none(source.get('bitrate')),\n                        })\n\n                for caption in asset.get('caption_metadata', []):\n                    caption_url = caption.get('source_url')\n                    if not caption_url:\n                        continue\n                    subtitles.setdefault(caption.get('language', 'en'), []).append({\n                        'url': caption_url,\n                        'ext': determine_ext(caption_url, 'vtt'),\n                    })\n            elif asset.get('type') == 'image':\n                asset_location = asset.get('location')\n                if not asset_location:\n                    continue\n                thumbnails.append({\n                    'url': asset_location,\n                    'width': int_or_none(asset.get('width')),\n                    'height': int_or_none(asset.get('height')),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'description': video_data.get('short_description'),\n            'like_count': int_or_none(video_data.get('like_count')),\n            'timestamp': parse_iso8601(video_data.get('released_at')),\n            'series': series,\n            'episode': episode,\n            'season': season,\n            'season_id': season_id,\n            'season_number': season_number,\n            'episode_number': episode_number,\n            'subtitles': subtitles,\n        }",
        "begin_line": 29,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.godtube.GodTubeIE._real_extract#31",
        "src_path": "youtube_dl/extractor/godtube.py",
        "class_name": "youtube_dl.extractor.godtube.GodTubeIE",
        "signature": "youtube_dl.extractor.godtube.GodTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        config = self._download_xml(\n            'http://www.godtube.com/resource/mediaplayer/%s.xml' % video_id.lower(),\n            video_id, 'Downloading player config XML')\n\n        video_url = config.find('file').text\n        uploader = config.find('author').text\n        timestamp = parse_iso8601(config.find('date').text)\n        duration = parse_duration(config.find('duration').text)\n        thumbnail = config.find('image').text\n\n        media = self._download_xml(\n            'http://www.godtube.com/media/xml/?v=%s' % video_id, video_id, 'Downloading media XML')\n\n        title = media.find('title').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.golem.GolemIE._real_extract#31",
        "src_path": "youtube_dl/extractor/golem.py",
        "class_name": "youtube_dl.extractor.golem.GolemIE",
        "signature": "youtube_dl.extractor.golem.GolemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_xml(\n            'https://video.golem.de/xml/{0}.xml'.format(video_id), video_id)\n\n        info = {\n            'id': video_id,\n            'title': config.findtext('./title', 'golem'),\n            'duration': self._float(config.findtext('./playtime'), 'duration'),\n        }\n\n        formats = []\n        for e in config:\n            url = e.findtext('./url')\n            if not url:\n                continue\n\n            formats.append({\n                'format_id': compat_str(e.tag),\n                'url': compat_urlparse.urljoin(self._PREFIX, url),\n                'height': self._int(e.get('height'), 'height'),\n                'width': self._int(e.get('width'), 'width'),\n                'filesize': self._int(e.findtext('filesize'), 'filesize'),\n                'ext': determine_ext(e.findtext('./filename')),\n            })\n        self._sort_formats(formats)\n        info['formats'] = formats\n\n        thumbnails = []\n        for e in config.findall('.//teaser'):\n            url = e.findtext('./url')\n            if not url:\n                continue\n            thumbnails.append({\n                'url': compat_urlparse.urljoin(self._PREFIX, url),\n                'width': self._int(e.get('width'), 'thumbnail width'),\n                'height': self._int(e.get('height'), 'thumbnail height'),\n            })\n        info['thumbnails'] = thumbnails\n\n        return info",
        "begin_line": 31,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.googledrive.GoogleDriveIE._extract_url#49",
        "src_path": "youtube_dl/extractor/googledrive.py",
        "class_name": "youtube_dl.extractor.googledrive.GoogleDriveIE",
        "signature": "youtube_dl.extractor.googledrive.GoogleDriveIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?:video\\.google\\.com/get_player\\?.*?docid=|(?:docs|drive)\\.google\\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28,})',\n            webpage)\n        if mobj:\n            return 'https://drive.google.com/file/d/%s' % mobj.group('id')",
        "begin_line": 49,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.googledrive.GoogleDriveIE._real_extract#56",
        "src_path": "youtube_dl/extractor/googledrive.py",
        "class_name": "youtube_dl.extractor.googledrive.GoogleDriveIE",
        "signature": "youtube_dl.extractor.googledrive.GoogleDriveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://docs.google.com/file/d/%s' % video_id, video_id)\n\n        reason = self._search_regex(r'\"reason\"\\s*,\\s*\"([^\"]+)', webpage, 'reason', default=None)\n        if reason:\n            raise ExtractorError(reason)\n\n        title = self._search_regex(r'\"title\"\\s*,\\s*\"([^\"]+)', webpage, 'title')\n        duration = int_or_none(self._search_regex(\n            r'\"length_seconds\"\\s*,\\s*\"([^\"]+)', webpage, 'length seconds', default=None))\n        fmt_stream_map = self._search_regex(\n            r'\"fmt_stream_map\"\\s*,\\s*\"([^\"]+)', webpage, 'fmt stream map').split(',')\n        fmt_list = self._search_regex(r'\"fmt_list\"\\s*,\\s*\"([^\"]+)', webpage, 'fmt_list').split(',')\n\n        resolutions = {}\n        for fmt in fmt_list:\n            mobj = re.search(\n                r'^(?P<format_id>\\d+)/(?P<width>\\d+)[xX](?P<height>\\d+)', fmt)\n            if mobj:\n                resolutions[mobj.group('format_id')] = (\n                    int(mobj.group('width')), int(mobj.group('height')))\n\n        formats = []\n        for fmt_stream in fmt_stream_map:\n            fmt_stream_split = fmt_stream.split('|')\n            if len(fmt_stream_split) < 2:\n                continue\n            format_id, format_url = fmt_stream_split[:2]\n            f = {\n                'url': lowercase_escape(format_url),\n                'format_id': format_id,\n                'ext': self._FORMATS_EXT[format_id],\n            }\n            resolution = resolutions.get(format_id)\n            if resolution:\n                f.update({\n                    'width': resolution[0],\n                    'height': resolution[1],\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract#26",
        "src_path": "youtube_dl/extractor/googleplus.py",
        "class_name": "youtube_dl.extractor.googleplus.GooglePlusIE",
        "signature": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Step 1, Retrieve post webpage to extract further information\n        webpage = self._download_webpage(url, video_id, 'Downloading entry webpage')\n\n        title = self._og_search_description(webpage).splitlines()[0]\n        upload_date = unified_strdate(self._html_search_regex(\n            r'''(?x)<a.+?class=\"o-U-s\\s[^\"]+\"\\s+style=\"display:\\s*none\"\\s*>\n                    ([0-9]{4}-[0-9]{2}-[0-9]{2})</a>''',\n            webpage, 'upload date', fatal=False, flags=re.VERBOSE))\n        uploader = self._html_search_regex(\n            r'rel=\"author\".*?>(.*?)</a>', webpage, 'uploader', fatal=False)\n\n        # Step 2, Simulate clicking the image box to launch video\n        DOMAIN = 'https://plus.google.com/'\n        video_page = self._search_regex(\n            r'<a href=\"((?:%s)?photos/.*?)\"' % re.escape(DOMAIN),\n            webpage, 'video page URL')\n        if not video_page.startswith(DOMAIN):\n            video_page = DOMAIN + video_page\n\n        webpage = self._download_webpage(video_page, video_id, 'Downloading video page')\n\n        def unicode_escape(s):\n            decoder = codecs.getdecoder('unicode_escape')\n            return re.sub(\n                r'\\\\u[0-9a-fA-F]{4,}',\n                lambda m: decoder(m.group(0))[0],\n                s)\n\n        # Extract video links all sizes\n        formats = [{\n            'url': unicode_escape(video_url),\n            'ext': 'flv',\n            'width': int(width),\n            'height': int(height),\n        } for width, height, video_url in re.findall(\n            r'\\d+,(\\d+),(\\d+),\"(https?://[^.]+\\.googleusercontent.com.*?)\"', webpage)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results#23",
        "src_path": "youtube_dl/extractor/googlesearch.py",
        "class_name": "youtube_dl.extractor.googlesearch.GoogleSearchIE",
        "signature": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        entries = []\n        res = {\n            '_type': 'playlist',\n            'id': query,\n            'title': query,\n        }\n\n        for pagenum in itertools.count():\n            webpage = self._download_webpage(\n                'http://www.google.com/search',\n                'gvsearch:' + query,\n                note='Downloading result page %s' % (pagenum + 1),\n                query={\n                    'tbm': 'vid',\n                    'q': query,\n                    'start': pagenum * 10,\n                    'hl': 'en',\n                })\n\n            for hit_idx, mobj in enumerate(re.finditer(\n                    r'<h3 class=\"r\"><a href=\"([^\"]+)\"', webpage)):\n\n                # Skip playlists\n                if not re.search(r'id=\"vidthumb%d\"' % (hit_idx + 1), webpage):\n                    continue\n\n                entries.append({\n                    '_type': 'url',\n                    'url': mobj.group(1)\n                })\n\n            if (len(entries) >= n) or not re.search(r'id=\"pnnext\"', webpage):\n                res['entries'] = entries[:n]\n                return res",
        "begin_line": 23,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract#28",
        "src_path": "youtube_dl/extractor/goshgay.py",
        "class_name": "youtube_dl.extractor.goshgay.GoshgayIE",
        "signature": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2>(.*?)<', webpage, 'title')\n        duration = parse_duration(self._html_search_regex(\n            r'<span class=\"duration\">\\s*-?\\s*(.*?)</span>',\n            webpage, 'duration', fatal=False))\n\n        flashvars = compat_parse_qs(self._html_search_regex(\n            r'<embed.+?id=\"flash-player-embed\".+?flashvars=\"([^\"]+)\"',\n            webpage, 'flashvars'))\n        thumbnail = flashvars.get('url_bigthumb', [None])[0]\n        video_url = flashvars['flv_url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.gputechconf.GPUTechConfIE._real_extract#20",
        "src_path": "youtube_dl/extractor/gputechconf.py",
        "class_name": "youtube_dl.extractor.gputechconf.GPUTechConfIE",
        "signature": "youtube_dl.extractor.gputechconf.GPUTechConfIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        root_path = self._search_regex(\n            r'var\\s+rootPath\\s*=\\s*\"([^\"]+)', webpage, 'root path',\n            default='http://evt.dispeak.com/nvidia/events/gtc15/')\n        xml_file_id = self._search_regex(\n            r'var\\s+xmlFileId\\s*=\\s*\"([^\"]+)', webpage, 'xml file id')\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': '%sxml/%s.xml' % (root_path, xml_file_id),\n            'ie_key': 'DigitallySpeaking',\n        }",
        "begin_line": 20,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.groupon.GrouponIE._real_extract#40",
        "src_path": "youtube_dl/extractor/groupon.py",
        "class_name": "youtube_dl.extractor.groupon.GrouponIE",
        "signature": "youtube_dl.extractor.groupon.GrouponIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        payload = self._parse_json(self._search_regex(\n            r'(?:var\\s+|window\\.)payload\\s*=\\s*(.*?);\\n', webpage, 'payload'), playlist_id)\n        videos = payload['carousel'].get('dealVideos', [])\n        entries = []\n        for v in videos:\n            provider = v.get('provider')\n            video_id = v.get('media') or v.get('id') or v.get('baseURL')\n            if not provider or not video_id:\n                continue\n            url_pattern, ie_key = self._PROVIDERS.get(provider.lower())\n            if not url_pattern:\n                self.report_warning(\n                    '%s: Unsupported video provider %s, skipping video' %\n                    (playlist_id, provider))\n                continue\n            entries.append(self.url_result(url_pattern % video_id, ie_key))\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'entries': entries,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 40,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hark.HarkIE._real_extract#21",
        "src_path": "youtube_dl/extractor/hark.py",
        "class_name": "youtube_dl.extractor.hark.HarkIE",
        "signature": "youtube_dl.extractor.hark.HarkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        data = self._download_json(\n            'http://www.hark.com/clips/%s.json' % video_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': data['url'],\n            'title': data['name'],\n            'description': data.get('description'),\n            'thumbnail': data.get('image_original'),\n            'duration': data.get('duration'),\n        }",
        "begin_line": 21,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hbo.HBOBaseIE._extract_from_id#56",
        "src_path": "youtube_dl/extractor/hbo.py",
        "class_name": "youtube_dl.extractor.hbo.HBOBaseIE",
        "signature": "youtube_dl.extractor.hbo.HBOBaseIE._extract_from_id(self, video_id)",
        "snippet": "    def _extract_from_id(self, video_id):\n        video_data = self._download_xml(\n            'http://render.lv3.hbo.com/data/content/global/videos/data/%s.xml' % video_id, video_id)\n        title = xpath_text(video_data, 'title', 'title', True)\n\n        formats = []\n        for source in xpath_element(video_data, 'videos', 'sources', True):\n            if source.tag == 'size':\n                path = xpath_text(source, './/path')\n                if not path:\n                    continue\n                width = source.attrib.get('width')\n                format_info = self._FORMATS_INFO.get(width, {})\n                height = format_info.get('height')\n                fmt = {\n                    'url': path,\n                    'format_id': 'http%s' % ('-%dp' % height if height else ''),\n                    'width': format_info.get('width'),\n                    'height': height,\n                }\n                rtmp = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', path)\n                if rtmp:\n                    fmt.update({\n                        'url': rtmp.group('url'),\n                        'play_path': rtmp.group('playpath'),\n                        'app': rtmp.group('app'),\n                        'ext': 'flv',\n                        'format_id': fmt['format_id'].replace('http', 'rtmp'),\n                    })\n                formats.append(fmt)\n            else:\n                video_url = source.text\n                if not video_url:\n                    continue\n                if source.tag == 'tarball':\n                    formats.extend(self._extract_m3u8_formats(\n                        video_url.replace('.tar', '/base_index_w8.m3u8'),\n                        video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n                elif source.tag == 'hls':\n                    m3u8_formats = self._extract_m3u8_formats(\n                        video_url.replace('.tar', '/base_index.m3u8'),\n                        video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)\n                    for f in m3u8_formats:\n                        if f.get('vcodec') == 'none' and not f.get('tbr'):\n                            f['tbr'] = int_or_none(self._search_regex(\n                                r'-(\\d+)k/', f['url'], 'tbr', default=None))\n                    formats.extend(m3u8_formats)\n                elif source.tag == 'dash':\n                    formats.extend(self._extract_mpd_formats(\n                        video_url.replace('.tar', '/manifest.mpd'),\n                        video_id, mpd_id='dash', fatal=False))\n                else:\n                    format_info = self._FORMATS_INFO.get(source.tag, {})\n                    formats.append({\n                        'format_id': 'http-%s' % source.tag,\n                        'url': video_url,\n                        'width': format_info.get('width'),\n                        'height': format_info.get('height'),\n                    })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        card_sizes = xpath_element(video_data, 'titleCardSizes')\n        if card_sizes is not None:\n            for size in card_sizes:\n                path = xpath_text(size, 'path')\n                if not path:\n                    continue\n                width = int_or_none(size.get('width'))\n                thumbnails.append({\n                    'id': width,\n                    'url': path,\n                    'width': width,\n                })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': parse_duration(xpath_text(video_data, 'duration/tv14')),\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 56,
        "end_line": 137,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hbo.HBOIE._real_extract#155",
        "src_path": "youtube_dl/extractor/hbo.py",
        "class_name": "youtube_dl.extractor.hbo.HBOIE",
        "signature": "youtube_dl.extractor.hbo.HBOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._extract_from_id(video_id)",
        "begin_line": 155,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hbo.HBOEpisodeIE._real_extract#183",
        "src_path": "youtube_dl/extractor/hbo.py",
        "class_name": "youtube_dl.extractor.hbo.HBOEpisodeIE",
        "signature": "youtube_dl.extractor.hbo.HBOEpisodeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path, display_id = re.match(self._VALID_URL, url).groups()\n\n        content = self._download_json(\n            'http://www.hbo.com/api/content/' + path, display_id)['content']\n\n        video_id = compat_str((content.get('parsed', {}).get(\n            'common:FullBleedVideo', {}) or content['selectedEpisode'])['videoId'])\n\n        info_dict = self._extract_from_id(video_id)\n        info_dict['display_id'] = display_id\n\n        return info_dict",
        "begin_line": 183,
        "end_line": 195,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hearthisat.HearThisAtIE._real_extract#58",
        "src_path": "youtube_dl/extractor/hearthisat.py",
        "class_name": "youtube_dl.extractor.hearthisat.HearThisAtIE",
        "signature": "youtube_dl.extractor.hearthisat.HearThisAtIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        display_id = '{artist:s} - {title:s}'.format(**m.groupdict())\n\n        webpage = self._download_webpage(url, display_id)\n        track_id = self._search_regex(\n            r'intTrackId\\s*=\\s*(\\d+)', webpage, 'track ID')\n\n        payload = urlencode_postdata({'tracks[]': track_id})\n        req = sanitized_Request(self._PLAYLIST_URL, payload)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        track = self._download_json(req, track_id, 'Downloading playlist')[0]\n        title = '{artist:s} - {title:s}'.format(**track)\n\n        categories = None\n        if track.get('category'):\n            categories = [track['category']]\n\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        meta_span = r'<span[^>]+class=\"%s\".*?</i>([^<]+)</span>'\n        view_count = str_to_int(self._search_regex(\n            meta_span % 'plays_count', webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._search_regex(\n            meta_span % 'likes_count', webpage, 'like count', fatal=False))\n        comment_count = str_to_int(self._search_regex(\n            meta_span % 'comment_count', webpage, 'comment count', fatal=False))\n        duration = str_to_int(self._search_regex(\n            r'data-length=\"(\\d+)', webpage, 'duration', fatal=False))\n        timestamp = str_to_int(self._search_regex(\n            r'<span[^>]+class=\"calctime\"[^>]+data-time=\"(\\d+)', webpage, 'timestamp', fatal=False))\n\n        formats = []\n        mp3_url = self._search_regex(\n            r'(?s)<a class=\"player-link\"\\s+(?:[a-zA-Z0-9_:-]+=\"[^\"]+\"\\s+)*?data-mp3=\"([^\"]+)\"',\n            webpage, 'mp3 URL', fatal=False)\n        if mp3_url:\n            formats.append({\n                'format_id': 'mp3',\n                'vcodec': 'none',\n                'acodec': 'mp3',\n                'url': mp3_url,\n            })\n        download_path = self._search_regex(\n            r'<a class=\"[^\"]*download_fct[^\"]*\"\\s+href=\"([^\"]+)\"',\n            webpage, 'download URL', default=None)\n        if download_path:\n            download_url = compat_urlparse.urljoin(url, download_path)\n            ext_req = HEADRequest(download_url)\n            ext_handle = self._request_webpage(\n                ext_req, display_id, note='Determining extension')\n            ext = urlhandle_detect_ext(ext_handle)\n            if ext in KNOWN_EXTENSIONS:\n                formats.append({\n                    'format_id': 'download',\n                    'vcodec': 'none',\n                    'ext': ext,\n                    'url': download_url,\n                    'preference': 2,  # Usually better quality\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': track_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'categories': categories,\n        }",
        "begin_line": 58,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.heise.HeiseIE._real_extract#39",
        "src_path": "youtube_dl/extractor/heise.py",
        "class_name": "youtube_dl.extractor.heise.HeiseIE",
        "signature": "youtube_dl.extractor.heise.HeiseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        container_id = self._search_regex(\n            r'<div class=\"videoplayerjw\"[^>]+data-container=\"([0-9]+)\"',\n            webpage, 'container ID')\n        sequenz_id = self._search_regex(\n            r'<div class=\"videoplayerjw\"[^>]+data-sequenz=\"([0-9]+)\"',\n            webpage, 'sequenz ID')\n\n        title = self._html_search_meta('fulltitle', webpage, default=None)\n        if not title or title == \"c't\":\n            title = self._search_regex(\n                r'<div[^>]+class=\"videoplayerjw\"[^>]+data-title=\"([^\"]+)\"',\n                webpage, 'title')\n\n        doc = self._download_xml(\n            'http://www.heise.de/videout/feed', video_id, query={\n                'container': container_id,\n                'sequenz': sequenz_id,\n            })\n\n        formats = []\n        for source_node in doc.findall('.//{http://rss.jwpcdn.com/}source'):\n            label = source_node.attrib['label']\n            height = int_or_none(self._search_regex(\n                r'^(.*?_)?([0-9]+)p$', label, 'height', default=None))\n            video_url = source_node.attrib['file']\n            ext = determine_ext(video_url, '')\n            formats.append({\n                'url': video_url,\n                'format_note': label,\n                'format_id': '%s_%s' % (ext, label),\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        description = self._og_search_description(\n            webpage, default=None) or self._html_search_meta(\n            'description', webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': (xpath_text(doc, './/{http://rss.jwpcdn.com/}image') or\n                          self._og_search_thumbnail(webpage)),\n            'timestamp': parse_iso8601(\n                self._html_search_meta('date', webpage)),\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hellporno.HellPornoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/hellporno.py",
        "class_name": "youtube_dl.extractor.hellporno.HellPornoIE",
        "signature": "youtube_dl.extractor.hellporno.HellPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = remove_end(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), ' - Hell Porno')\n\n        flashvars = self._parse_json(self._search_regex(\n            r'var\\s+flashvars\\s*=\\s*({.+?});', webpage, 'flashvars'),\n            display_id, transform_source=js_to_json)\n\n        video_id = flashvars.get('video_id')\n        thumbnail = flashvars.get('preview_url')\n        ext = determine_ext(flashvars.get('postfix'), 'mp4')\n\n        formats = []\n        for video_url_key in ['video_url', 'video_alt_url']:\n            video_url = flashvars.get(video_url_key)\n            if not video_url:\n                continue\n            video_text = flashvars.get('%s_text' % video_url_key)\n            fmt = {\n                'url': video_url,\n                'ext': ext,\n                'format_id': video_text,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP]', video_text)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract#25",
        "src_path": "youtube_dl/extractor/helsinki.py",
        "class_name": "youtube_dl.extractor.helsinki.HelsinkiIE",
        "signature": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        params = self._parse_json(self._html_search_regex(\n            r'(?s)jwplayer\\(\"player\"\\).setup\\((\\{.*?\\})\\);',\n            webpage, 'player code'), video_id, transform_source=js_to_json)\n        formats = [{\n            'url': s['file'],\n            'ext': 'mp4',\n        } for s in params['sources']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage).replace('Video: ', ''),\n            'description': self._og_search_description(webpage),\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract#19",
        "src_path": "youtube_dl/extractor/hentaistigma.py",
        "class_name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE",
        "signature": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2[^>]+class=\"posttitle\"[^>]*><a[^>]*>([^<]+)</a>',\n            webpage, 'title')\n        wrap_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"([^\"]+mp4)\"', webpage, 'wrapper url')\n        wrap_webpage = self._download_webpage(wrap_url, video_id)\n\n        video_url = self._html_search_regex(\n            r'file\\s*:\\s*\"([^\"]+)\"', wrap_webpage, 'video url')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'age_limit': 18,\n        }",
        "begin_line": 19,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hgtv.HGTVComShowIE._real_extract#24",
        "src_path": "youtube_dl/extractor/hgtv.py",
        "class_name": "youtube_dl.extractor.hgtv.HGTVComShowIE",
        "signature": "youtube_dl.extractor.hgtv.HGTVComShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        config = self._parse_json(\n            self._search_regex(\n                r'(?s)data-(?:deferred-)?module=[\"\\']video[\"\\'][^>]*>.*?<script[^>]+type=[\"\\']text/x-config[\"\\'][^>]*>(.+?)</script',\n                webpage, 'video config'),\n            display_id)['channels'][0]\n\n        entries = [\n            self.url_result(video['releaseUrl'])\n            for video in config['videos'] if video.get('releaseUrl')]\n\n        return self.playlist_result(\n            entries, display_id, config.get('title'), config.get('description'))",
        "begin_line": 24,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.historicfilms.HistoricFilmsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/historicfilms.py",
        "class_name": "youtube_dl.extractor.historicfilms.HistoricFilmsIE",
        "signature": "youtube_dl.extractor.historicfilms.HistoricFilmsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        tape_id = self._search_regex(\n            [r'class=\"tapeId\"[^>]*>([^<]+)<', r'tapeId\\s*:\\s*\"([^\"]+)\"'],\n            webpage, 'tape id')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._html_search_meta(\n            'thumbnailUrl', webpage, 'thumbnails') or self._og_search_thumbnail(webpage)\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration'))\n\n        video_url = 'http://www.historicfilms.com/video/%s_%s_web.mov' % (tape_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 22,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxIE._extract_metadata#46",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxIE._extract_metadata(self, url, video_id)",
        "snippet": "    def _extract_metadata(self, url, video_id):\n        thumb_base = 'https://edge.sf.hitbox.tv'\n        metadata = self._download_json(\n            '%s/%s' % (url, video_id), video_id, 'Downloading metadata JSON')\n\n        date = 'media_live_since'\n        media_type = 'livestream'\n        if metadata.get('media_type') == 'video':\n            media_type = 'video'\n            date = 'media_date_added'\n\n        video_meta = metadata.get(media_type, [])[0]\n        title = video_meta.get('media_status')\n        alt_title = video_meta.get('media_title')\n        description = clean_html(\n            video_meta.get('media_description') or\n            video_meta.get('media_description_md'))\n        duration = float_or_none(video_meta.get('media_duration'))\n        uploader = video_meta.get('media_user_name')\n        views = int_or_none(video_meta.get('media_views'))\n        timestamp = parse_iso8601(video_meta.get(date), ' ')\n        categories = [video_meta.get('category_name')]\n        thumbs = [{\n            'url': thumb_base + video_meta.get('media_thumbnail'),\n            'width': 320,\n            'height': 180\n        }, {\n            'url': thumb_base + video_meta.get('media_thumbnail_large'),\n            'width': 768,\n            'height': 432\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'alt_title': alt_title,\n            'description': description,\n            'ext': 'mp4',\n            'thumbnails': thumbs,\n            'duration': duration,\n            'uploader': uploader,\n            'view_count': views,\n            'timestamp': timestamp,\n            'categories': categories,\n        }",
        "begin_line": 46,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxIE._real_extract#92",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_config = self._download_json(\n            'https://www.smashcast.tv/api/player/config/video/%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        formats = []\n        for video in player_config['clip']['bitrates']:\n            label = video.get('label')\n            if label == 'Auto':\n                continue\n            video_url = video.get('url')\n            if not video_url:\n                continue\n            bitrate = int_or_none(video.get('bitrate'))\n            if determine_ext(video_url) == 'm3u8':\n                if not video_url.startswith('http'):\n                    continue\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'tbr': bitrate,\n                    'format_note': label,\n                    'protocol': 'm3u8_native',\n                })\n            else:\n                formats.append({\n                    'url': video_url,\n                    'tbr': bitrate,\n                    'format_note': label,\n                })\n        self._sort_formats(formats)\n\n        metadata = self._extract_metadata(\n            'https://www.smashcast.tv/api/media/video', video_id)\n        metadata['formats'] = formats\n\n        return metadata",
        "begin_line": 92,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxLiveIE.suitable#157",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxLiveIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxLiveIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if HitboxIE.suitable(url) else super(HitboxLiveIE, cls).suitable(url)",
        "begin_line": 157,
        "end_line": 158,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract#160",
        "src_path": "youtube_dl/extractor/hitbox.py",
        "class_name": "youtube_dl.extractor.hitbox.HitboxLiveIE",
        "signature": "youtube_dl.extractor.hitbox.HitboxLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        player_config = self._download_json(\n            'https://www.smashcast.tv/api/player/config/live/%s' % video_id,\n            video_id)\n\n        formats = []\n        cdns = player_config.get('cdns')\n        servers = []\n        for cdn in cdns:\n            # Subscribe URLs are not playable\n            if cdn.get('rtmpSubscribe') is True:\n                continue\n            base_url = cdn.get('netConnectionUrl')\n            host = re.search(r'.+\\.([^\\.]+\\.[^\\./]+)/.+', base_url).group(1)\n            if base_url not in servers:\n                servers.append(base_url)\n                for stream in cdn.get('bitrates'):\n                    label = stream.get('label')\n                    if label == 'Auto':\n                        continue\n                    stream_url = stream.get('url')\n                    if not stream_url:\n                        continue\n                    bitrate = int_or_none(stream.get('bitrate'))\n                    if stream.get('provider') == 'hls' or determine_ext(stream_url) == 'm3u8':\n                        if not stream_url.startswith('http'):\n                            continue\n                        formats.append({\n                            'url': stream_url,\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'format_note': label,\n                            'rtmp_live': True,\n                        })\n                    else:\n                        formats.append({\n                            'url': '%s/%s' % (base_url, stream_url),\n                            'ext': 'mp4',\n                            'tbr': bitrate,\n                            'rtmp_live': True,\n                            'format_note': host,\n                            'page_url': url,\n                            'player_url': 'http://www.hitbox.tv/static/player/flowplayer/flowplayer.commercial-3.2.16.swf',\n                        })\n        self._sort_formats(formats)\n\n        metadata = self._extract_metadata(\n            'https://www.smashcast.tv/api/media/live', video_id)\n        metadata['formats'] = formats\n        metadata['is_live'] = True\n        metadata['title'] = self._live_title(metadata.get('title'))\n\n        return metadata",
        "begin_line": 160,
        "end_line": 214,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hitrecord.HitRecordIE._real_extract#35",
        "src_path": "youtube_dl/extractor/hitrecord.py",
        "class_name": "youtube_dl.extractor.hitrecord.HitRecordIE",
        "signature": "youtube_dl.extractor.hitrecord.HitRecordIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'https://hitrecord.org/api/web/records/%s' % video_id, video_id)\n\n        title = video['title']\n        video_url = video['source_url']['mp4_url']\n\n        tags = None\n        tags_list = try_get(video, lambda x: x['tags'], list)\n        if tags_list:\n            tags = [\n                t['text']\n                for t in tags_list\n                if isinstance(t, dict) and t.get('text') and\n                isinstance(t['text'], compat_str)]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': clean_html(video.get('body')),\n            'duration': float_or_none(video.get('duration'), 1000),\n            'timestamp': int_or_none(video.get('created_at_i')),\n            'uploader': try_get(\n                video, lambda x: x['user']['username'], compat_str),\n            'uploader_id': try_get(\n                video, lambda x: compat_str(x['user']['id'])),\n            'view_count': int_or_none(video.get('total_views_count')),\n            'like_count': int_or_none(video.get('hearts_count')),\n            'comment_count': int_or_none(video.get('comments_count')),\n            'tags': tags,\n        }",
        "begin_line": 35,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hornbunny.py",
        "class_name": "youtube_dl.extractor.hornbunny.HornBunnyIE",
        "signature": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]\n\n        duration = parse_duration(self._search_regex(\n            r'<strong>Runtime:</strong>\\s*([0-9:]+)</div>',\n            webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'<strong>Views:</strong>\\s*(\\d+)</div>',\n            webpage, 'view count', fatal=False))\n\n        info_dict.update({\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        })\n\n        return info_dict",
        "begin_line": 27,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract#26",
        "src_path": "youtube_dl/extractor/hotnewhiphop.py",
        "class_name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE",
        "signature": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url_base64 = self._search_regex(\n            r'data-path=\"(.*?)\"', webpage, 'video URL', default=None)\n\n        if video_url_base64 is None:\n            video_url = self._search_regex(\n                r'\"contentUrl\" content=\"(.*?)\"', webpage, 'content URL')\n            return self.url_result(video_url, ie='Youtube')\n\n        reqdata = urlencode_postdata([\n            ('mediaType', 's'),\n            ('mediaId', video_id),\n        ])\n        r = sanitized_Request(\n            'http://www.hotnewhiphop.com/ajax/media/getActions/', data=reqdata)\n        r.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        mkd = self._download_json(\n            r, video_id, note='Requesting media key',\n            errnote='Could not download media key')\n        if 'mediaKey' not in mkd:\n            raise ExtractorError('Did not get a media key')\n\n        redirect_url = base64.b64decode(video_url_base64).decode('utf-8')\n        redirect_req = HEADRequest(redirect_url)\n        req = self._request_webpage(\n            redirect_req, video_id,\n            note='Resolving final URL', errnote='Could not resolve final URL')\n        video_url = req.geturl()\n        if video_url.endswith('.html'):\n            raise ExtractorError('Redirect failed')\n\n        video_title = self._og_search_title(webpage).strip()\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 26,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hotstar.HotStarIE._download_json#37",
        "src_path": "youtube_dl/extractor/hotstar.py",
        "class_name": "youtube_dl.extractor.hotstar.HotStarIE",
        "signature": "youtube_dl.extractor.hotstar.HotStarIE._download_json(self, url_or_request, video_id, note='Downloading JSON metadata', fatal=True, query=None)",
        "snippet": "    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', fatal=True, query=None):\n        json_data = super(HotStarIE, self)._download_json(\n            url_or_request, video_id, note, fatal=fatal, query=query)\n        if json_data['resultCode'] != 'OK':\n            if fatal:\n                raise ExtractorError(json_data['errorDescription'])\n            return None\n        return json_data['resultObj']",
        "begin_line": 37,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hotstar.HotStarIE._real_extract#46",
        "src_path": "youtube_dl/extractor/hotstar.py",
        "class_name": "youtube_dl.extractor.hotstar.HotStarIE",
        "signature": "youtube_dl.extractor.hotstar.HotStarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'http://account.hotstar.com/AVS/besc', video_id, query={\n                'action': 'GetAggregatedContentDetails',\n                'channel': 'PCTV',\n                'contentId': video_id,\n            })['contentInfo'][0]\n        title = video_data['episodeTitle']\n\n        if video_data.get('encrypted') == 'Y':\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        formats = []\n        for f in ('JIO',):\n            format_data = self._download_json(\n                'http://getcdn.hotstar.com/AVS/besc',\n                video_id, 'Downloading %s JSON metadata' % f,\n                fatal=False, query={\n                    'action': 'GetCDN',\n                    'asJson': 'Y',\n                    'channel': f,\n                    'id': video_id,\n                    'type': 'VOD',\n                })\n            if format_data:\n                format_url = format_data.get('src')\n                if not format_url:\n                    continue\n                ext = determine_ext(format_url)\n                if ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        format_url, video_id, 'mp4',\n                        m3u8_id='hls', fatal=False))\n                elif ext == 'f4m':\n                    # produce broken files\n                    continue\n                else:\n                    formats.append({\n                        'url': format_url,\n                        'width': int_or_none(format_data.get('width')),\n                        'height': int_or_none(format_data.get('height')),\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'duration': int_or_none(video_data.get('duration')),\n            'timestamp': int_or_none(video_data.get('broadcastDate')),\n            'formats': formats,\n            'episode': title,\n            'episode_number': int_or_none(video_data.get('episodeNumber')),\n            'series': video_data.get('contentTitle'),\n        }",
        "begin_line": 46,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.howcast.HowcastIE._real_extract#27",
        "src_path": "youtube_dl/extractor/howcast.py",
        "class_name": "youtube_dl.extractor.howcast.HowcastIE",
        "signature": "youtube_dl.extractor.howcast.HowcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        embed_code = self._search_regex(\n            r'<iframe[^>]+src=\"[^\"]+\\bembed_code=([^\\b]+)\\b',\n            webpage, 'ooyala embed code')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Ooyala',\n            'url': 'ooyala:%s' % embed_code,\n            'id': video_id,\n            'timestamp': parse_iso8601(self._html_search_meta(\n                'article:published_time', webpage, 'timestamp')),\n        }",
        "begin_line": 27,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract#57",
        "src_path": "youtube_dl/extractor/howstuffworks.py",
        "class_name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE",
        "signature": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        clip_js = self._search_regex(\n            r'(?s)var clip = ({.*?});', webpage, 'clip info')\n        clip_info = self._parse_json(\n            clip_js, display_id, transform_source=js_to_json)\n\n        video_id = clip_info['content_id']\n        formats = []\n        m3u8_url = clip_info.get('m3u8')\n        if m3u8_url and determine_ext(m3u8_url) == 'm3u8':\n            formats.extend(self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', format_id='hls', fatal=True))\n        flv_url = clip_info.get('flv_url')\n        if flv_url:\n            formats.append({\n                'url': flv_url,\n                'format_id': 'flv',\n            })\n        for video in clip_info.get('mp4', []):\n            formats.append({\n                'url': video['src'],\n                'format_id': 'mp4-%s' % video['bitrate'],\n                'vbr': int_or_none(video['bitrate'].rstrip('k')),\n            })\n\n        if not formats:\n            smil = self._download_xml(\n                'http://services.media.howstuffworks.com/videos/%s/smil-service.smil' % video_id,\n                video_id, 'Downloading video SMIL')\n\n            http_base = find_xpath_attr(\n                smil,\n                './{0}head/{0}meta'.format('{http://www.w3.org/2001/SMIL20/Language}'),\n                'name',\n                'httpBase').get('content')\n\n            URL_SUFFIX = '?v=2.11.3&fp=LNX 11,2,202,356&r=A&g=A'\n\n            for video in smil.findall(\n                    './{0}body/{0}switch/{0}video'.format('{http://www.w3.org/2001/SMIL20/Language}')):\n                vbr = int_or_none(video.attrib['system-bitrate'], scale=1000)\n                formats.append({\n                    'url': '%s/%s%s' % (http_base, video.attrib['src'], URL_SUFFIX),\n                    'format_id': '%dk' % vbr,\n                    'vbr': vbr,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': '%s' % video_id,\n            'display_id': display_id,\n            'title': unescapeHTML(clip_info['clip_title']),\n            'description': unescapeHTML(clip_info.get('caption')),\n            'thumbnail': clip_info.get('video_still_url'),\n            'duration': int_or_none(clip_info.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hrti.HRTiBaseIE._initialize_api#32",
        "src_path": "youtube_dl/extractor/hrti.py",
        "class_name": "youtube_dl.extractor.hrti.HRTiBaseIE",
        "signature": "youtube_dl.extractor.hrti.HRTiBaseIE._initialize_api(self)",
        "snippet": "    def _initialize_api(self):\n        init_data = {\n            'application_publication_id': self._APP_PUBLICATION_ID\n        }\n\n        uuid = self._download_json(\n            self._API_URL, None, note='Downloading uuid',\n            errnote='Unable to download uuid',\n            data=json.dumps(init_data).encode('utf-8'))['uuid']\n\n        app_data = {\n            'uuid': uuid,\n            'application_publication_id': self._APP_PUBLICATION_ID,\n            'application_version': self._APP_VERSION\n        }\n\n        req = sanitized_Request(self._API_URL, data=json.dumps(app_data).encode('utf-8'))\n        req.get_method = lambda: 'PUT'\n\n        resources = self._download_json(\n            req, None, note='Downloading session information',\n            errnote='Unable to download session information')\n\n        self._session_id = resources['session_id']\n\n        modules = resources['modules']\n\n        self._search_url = modules['vod_catalog']['resources']['search']['uri'].format(\n            language=self._APP_LANGUAGE,\n            application_id=self._APP_PUBLICATION_ID)\n\n        self._login_url = (modules['user']['resources']['login']['uri'] +\n                           '/format/json').format(session_id=self._session_id)\n\n        self._logout_url = modules['user']['resources']['logout']['uri']",
        "begin_line": 32,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hrti.HRTiBaseIE._login#68",
        "src_path": "youtube_dl/extractor/hrti.py",
        "class_name": "youtube_dl.extractor.hrti.HRTiBaseIE",
        "signature": "youtube_dl.extractor.hrti.HRTiBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        # TODO: figure out authentication with cookies\n        if username is None or password is None:\n            self.raise_login_required()\n\n        auth_data = {\n            'username': username,\n            'password': password,\n        }\n\n        try:\n            auth_info = self._download_json(\n                self._login_url, None, note='Logging in', errnote='Unable to log in',\n                data=json.dumps(auth_data).encode('utf-8'))\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 406:\n                auth_info = self._parse_json(e.cause.read().encode('utf-8'), None)\n            else:\n                raise\n\n        error_message = auth_info.get('error', {}).get('message')\n        if error_message:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, error_message),\n                expected=True)\n\n        self._token = auth_info['secure_streaming_token']",
        "begin_line": 68,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hrti.HRTiBaseIE._real_initialize#97",
        "src_path": "youtube_dl/extractor/hrti.py",
        "class_name": "youtube_dl.extractor.hrti.HRTiBaseIE",
        "signature": "youtube_dl.extractor.hrti.HRTiBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._initialize_api()\n        self._login()",
        "begin_line": 97,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hrti.HRTiIE._real_extract#134",
        "src_path": "youtube_dl/extractor/hrti.py",
        "class_name": "youtube_dl.extractor.hrti.HRTiIE",
        "signature": "youtube_dl.extractor.hrti.HRTiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('short_id') or mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        video = self._download_json(\n            '%s/video_id/%s/format/json' % (self._search_url, video_id),\n            display_id, 'Downloading video metadata JSON')['video'][0]\n\n        title_info = video['title']\n        title = title_info['title_long']\n\n        movie = video['video_assets']['movie'][0]\n        m3u8_url = movie['url'].format(TOKEN=self._token)\n        formats = self._extract_m3u8_formats(\n            m3u8_url, display_id, 'mp4', entry_protocol='m3u8_native',\n            m3u8_id='hls')\n        self._sort_formats(formats)\n\n        description = clean_html(title_info.get('summary_long'))\n        age_limit = parse_age_limit(video.get('parental_control', {}).get('rating'))\n        view_count = int_or_none(video.get('views'))\n        average_rating = int_or_none(video.get('user_rating'))\n        duration = int_or_none(movie.get('duration'))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': view_count,\n            'average_rating': average_rating,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 134,
        "end_line": 169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hrti.HRTiPlaylistIE._real_extract#187",
        "src_path": "youtube_dl/extractor/hrti.py",
        "class_name": "youtube_dl.extractor.hrti.HRTiPlaylistIE",
        "signature": "youtube_dl.extractor.hrti.HRTiPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        category_id = mobj.group('id')\n        display_id = mobj.group('display_id') or category_id\n\n        response = self._download_json(\n            '%s/category_id/%s/format/json' % (self._search_url, category_id),\n            display_id, 'Downloading video metadata JSON')\n\n        video_ids = try_get(\n            response, lambda x: x['video_listings'][0]['alternatives'][0]['list'],\n            list) or [video['id'] for video in response.get('videos', []) if video.get('id')]\n\n        entries = [self.url_result('hrti:%s' % video_id) for video_id in video_ids]\n\n        return self.playlist_result(entries, category_id, display_id)",
        "begin_line": 187,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.huajiao.HuajiaoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/huajiao.py",
        "class_name": "youtube_dl.extractor.huajiao.HuajiaoIE",
        "signature": "youtube_dl.extractor.huajiao.HuajiaoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        feed_json = self._search_regex(\n            r'var\\s+feed\\s*=\\s*({.+})', webpage, 'feed json')\n        feed = self._parse_json(feed_json, video_id)\n\n        description = self._html_search_meta(\n            'description', webpage, 'description', fatal=False)\n\n        def get(section, field):\n            return feed.get(section, {}).get(field)\n\n        return {\n            'id': video_id,\n            'title': feed['feed']['formated_title'],\n            'description': description,\n            'duration': parse_duration(get('feed', 'duration')),\n            'thumbnail': get('feed', 'image'),\n            'timestamp': parse_iso8601(feed.get('creatime'), ' '),\n            'uploader': get('author', 'nickname'),\n            'uploader_id': get('author', 'uid'),\n            'formats': self._extract_m3u8_formats(\n                feed['feed']['m3u8'], video_id, 'mp4', 'm3u8_native'),\n        }",
        "begin_line": 31,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract#41",
        "src_path": "youtube_dl/extractor/huffpost.py",
        "class_name": "youtube_dl.extractor.huffpost.HuffPostIE",
        "signature": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        api_url = 'http://embed.live.huffingtonpost.com/api/segments/%s.json' % video_id\n        data = self._download_json(api_url, video_id)['data']\n\n        video_title = data['title']\n        duration = parse_duration(data.get('running_time'))\n        upload_date = unified_strdate(\n            data.get('schedule', {}).get('starts_at') or data.get('segment_start_date_time'))\n        description = data.get('description')\n\n        thumbnails = []\n        for url in filter(None, data['images'].values()):\n            m = re.match(r'.*-([0-9]+x[0-9]+)\\.', url)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': url,\n                'resolution': m.group(1),\n            })\n\n        formats = []\n        sources = data.get('sources', {})\n        live_sources = list(sources.get('live', {}).items()) + list(sources.get('live_again', {}).items())\n        for key, url in live_sources:\n            ext = determine_ext(url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    url, video_id, ext='mp4', m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    url + '?hdcore=2.9.5', video_id, f4m_id='hds', fatal=False))\n            else:\n                formats.append({\n                    'format': key,\n                    'format_id': key.replace('/', '.'),\n                    'ext': 'mp4',\n                    'url': url,\n                    'vcodec': 'none' if key.startswith('audio/') else None,\n                })\n\n        if not formats and data.get('fivemin_id'):\n            return self.url_result('5min:%s' % data['fivemin_id'])\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'formats': formats,\n            'duration': duration,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 41,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.hypem.HypemIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hypem.py",
        "class_name": "youtube_dl.extractor.hypem.HypemIE",
        "signature": "youtube_dl.extractor.hypem.HypemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        track_id = self._match_id(url)\n\n        data = {'ax': 1, 'ts': time.time()}\n        request = sanitized_Request(url + '?' + compat_urllib_parse_urlencode(data))\n        response, urlh = self._download_webpage_handle(\n            request, track_id, 'Downloading webpage with the url')\n\n        html_tracks = self._html_search_regex(\n            r'(?ms)<script type=\"application/json\" id=\"displayList-data\">(.+?)</script>',\n            response, 'tracks')\n        try:\n            track_list = json.loads(html_tracks)\n            track = track_list['tracks'][0]\n        except ValueError:\n            raise ExtractorError('Hypemachine contained invalid JSON.')\n\n        key = track['key']\n        track_id = track['id']\n        title = track['song']\n\n        request = sanitized_Request(\n            'http://hypem.com/serve/source/%s/%s' % (track_id, key),\n            '', {'Content-Type': 'application/json'})\n        song_data = self._download_json(request, track_id, 'Downloading metadata')\n        final_url = song_data['url']\n        artist = track.get('artist')\n\n        return {\n            'id': track_id,\n            'url': final_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': artist,\n        }",
        "begin_line": 27,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract#30",
        "src_path": "youtube_dl/extractor/iconosquare.py",
        "class_name": "youtube_dl.extractor.iconosquare.IconosquareIE",
        "signature": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        media = self._parse_json(\n            get_element_by_id('mediaJson', webpage),\n            video_id)\n\n        formats = [{\n            'url': f['url'],\n            'format_id': format_id,\n            'width': int_or_none(f.get('width')),\n            'height': int_or_none(f.get('height'))\n        } for format_id, f in media['videos'].items()]\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - via Iconosquare')\n\n        timestamp = int_or_none(media.get('created_time') or media.get('caption', {}).get('created_time'))\n        description = media.get('caption', {}).get('text')\n\n        uploader = media.get('user', {}).get('username')\n        uploader_id = media.get('user', {}).get('id')\n\n        comment_count = int_or_none(media.get('comments', {}).get('count'))\n        like_count = int_or_none(media.get('likes', {}).get('count'))\n\n        thumbnails = [{\n            'url': t['url'],\n            'id': thumbnail_id,\n            'width': int_or_none(t.get('width')),\n            'height': int_or_none(t.get('height'))\n        } for thumbnail_id, t in media.get('images', {}).items()]\n\n        comments = [{\n            'id': comment.get('id'),\n            'text': comment['text'],\n            'timestamp': int_or_none(comment.get('created_time')),\n            'author': comment.get('from', {}).get('full_name'),\n            'author_id': comment.get('from', {}).get('username'),\n        } for comment in media.get('comments', {}).get('data', []) if 'text' in comment]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'formats': formats,\n            'comments': comments,\n        }",
        "begin_line": 30,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._find_video_id#99",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._find_video_id(self, webpage)",
        "snippet": "    def _find_video_id(self, webpage):\n        res_id = [\n            r'\"video_id\"\\s*:\\s*\"(.*?)\"',\n            r'class=\"hero-poster[^\"]*?\"[^>]*id=\"(.+?)\"',\n            r'data-video-id=\"(.+?)\"',\n            r'<object id=\"vid_(.+?)\"',\n            r'<meta name=\"og:image\" content=\".*/(.+?)-(.+?)/.+.jpg\"',\n            r'videoId&quot;\\s*:\\s*&quot;(.+?)&quot;',\n            r'videoId[\"\\']\\s*:\\s*[\"\\']([^\"\\']+?)[\"\\']',\n        ]\n        return self._search_regex(res_id, webpage, 'video id', default=None)",
        "begin_line": 99,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._real_extract#111",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name_or_id = mobj.group('name_or_id')\n        page_type = mobj.group('type')\n        webpage = self._download_webpage(url, name_or_id)\n        if page_type != 'video':\n            multiple_urls = re.findall(\n                r'<param name=\"flashvars\"[^>]*value=\"[^\"]*?url=(https?://www\\.ign\\.com/videos/.*?)[\"&]',\n                webpage)\n            if multiple_urls:\n                entries = [self.url_result(u, ie='IGN') for u in multiple_urls]\n                return {\n                    '_type': 'playlist',\n                    'id': name_or_id,\n                    'entries': entries,\n                }\n\n        video_id = self._find_video_id(webpage)\n        if not video_id:\n            return self.url_result(self._search_regex(\n                self._EMBED_RE, webpage, 'embed url'))\n        return self._get_video_info(video_id)",
        "begin_line": 111,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._get_video_info#134",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._get_video_info(self, video_id)",
        "snippet": "    def _get_video_info(self, video_id):\n        api_data = self._download_json(\n            self._API_URL_TEMPLATE % video_id, video_id)\n\n        formats = []\n        m3u8_url = api_data['refs'].get('m3uUrl')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n        f4m_url = api_data['refs'].get('f4mUrl')\n        if f4m_url:\n            formats.extend(self._extract_f4m_formats(\n                f4m_url, video_id, f4m_id='hds', fatal=False))\n        for asset in api_data['assets']:\n            formats.append({\n                'url': asset['url'],\n                'tbr': asset.get('actual_bitrate_kbps'),\n                'fps': asset.get('frame_rate'),\n                'height': int_or_none(asset.get('height')),\n                'width': int_or_none(asset.get('width')),\n            })\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': thumbnail['url']\n        } for thumbnail in api_data.get('thumbnails', [])]\n\n        metadata = api_data['metadata']\n\n        return {\n            'id': api_data.get('videoId') or video_id,\n            'title': metadata.get('longTitle') or metadata.get('name') or metadata.get['title'],\n            'description': metadata.get('description'),\n            'timestamp': parse_iso8601(metadata.get('publishDate')),\n            'duration': int_or_none(metadata.get('duration')),\n            'display_id': metadata.get('slug') or video_id,\n            'uploader_id': metadata.get('creator'),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 134,
        "end_line": 174,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ign.OneUPIE._real_extract#195",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.OneUPIE",
        "signature": "youtube_dl.extractor.ign.OneUPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        result = super(OneUPIE, self)._real_extract(url)\n        result['id'] = mobj.group('name_or_id')\n        return result",
        "begin_line": 195,
        "end_line": 199,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbIE._real_extract#43",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbIE",
        "signature": "youtube_dl.extractor.imdb.ImdbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage('http://www.imdb.com/video/imdb/vi%s' % video_id, video_id)\n        descr = self._html_search_regex(\n            r'(?s)<span itemprop=\"description\">(.*?)</span>',\n            webpage, 'description', fatal=False)\n        player_url = 'http://www.imdb.com/video/imdb/vi%s/imdb/single' % video_id\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n        # the player page contains the info for the default format, we have to\n        # fetch other pages for the rest of the formats\n        extra_formats = re.findall(r'href=\"(?P<url>%s.*?)\".*?>(?P<name>.*?)<' % re.escape(player_url), player_page)\n        format_pages = [\n            self._download_webpage(\n                f_url, video_id, 'Downloading info for %s format' % f_name)\n            for f_url, f_name in extra_formats]\n        format_pages.append(player_page)\n\n        quality = qualities(('SD', '480p', '720p', '1080p'))\n        formats = []\n        for format_page in format_pages:\n            json_data = self._search_regex(\n                r'<script[^>]+class=\"imdb-player-data\"[^>]*?>(.*?)</script>',\n                format_page, 'json data', flags=re.DOTALL)\n            info = self._parse_json(json_data, video_id, fatal=False)\n            if not info:\n                continue\n            format_info = info.get('videoPlayerObject', {}).get('video', {})\n            if not format_info:\n                continue\n            video_info_list = format_info.get('videoInfoList')\n            if not video_info_list or not isinstance(video_info_list, list):\n                continue\n            video_info = video_info_list[0]\n            if not video_info or not isinstance(video_info, dict):\n                continue\n            video_url = video_info.get('videoUrl')\n            if not video_url:\n                continue\n            format_id = format_info.get('ffname')\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n                'ext': mimetype2ext(video_info.get('videoMimeType')),\n                'quality': quality(format_id),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': remove_end(self._og_search_title(webpage), ' - IMDb'),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': format_info.get('slate'),\n        }",
        "begin_line": 43,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbListIE._real_extract#113",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbListIE",
        "signature": "youtube_dl.extractor.imdb.ImdbListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n        webpage = self._download_webpage(url, list_id)\n        entries = [\n            self.url_result('http://www.imdb.com' + m, 'Imdb')\n            for m in re.findall(r'href=\"(/video/imdb/vi[^\"]+)\"\\s+data-type=\"playlist\"', webpage)]\n\n        list_title = self._html_search_regex(\n            r'<h1 class=\"header\">(.*?)</h1>', webpage, 'list title')\n\n        return self.playlist_result(entries, list_id, list_title)",
        "begin_line": 113,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.imgur.ImgurIE._real_extract#51",
        "src_path": "youtube_dl/extractor/imgur.py",
        "class_name": "youtube_dl.extractor.imgur.ImgurIE",
        "signature": "youtube_dl.extractor.imgur.ImgurIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            compat_urlparse.urljoin(url, video_id), video_id)\n\n        width = int_or_none(self._og_search_property(\n            'video:width', webpage, default=None))\n        height = int_or_none(self._og_search_property(\n            'video:height', webpage, default=None))\n\n        video_elements = self._search_regex(\n            r'(?s)<div class=\"video-elements\">(.*?)</div>',\n            webpage, 'video elements', default=None)\n        if not video_elements:\n            raise ExtractorError(\n                'No sources found for video %s. Maybe an image?' % video_id,\n                expected=True)\n\n        formats = []\n        for m in re.finditer(r'<source\\s+src=\"(?P<src>[^\"]+)\"\\s+type=\"(?P<type>[^\"]+)\"', video_elements):\n            formats.append({\n                'format_id': m.group('type').partition('/')[2],\n                'url': self._proto_relative_url(m.group('src')),\n                'ext': mimetype2ext(m.group('type')),\n                'acodec': 'none',\n                'width': width,\n                'height': height,\n                'http_headers': {\n                    'User-Agent': 'youtube-dl (like wget)',\n                },\n            })\n\n        gif_json = self._search_regex(\n            r'(?s)var\\s+videoItem\\s*=\\s*(\\{.*?\\})',\n            webpage, 'GIF code', fatal=False)\n        if gif_json:\n            gifd = self._parse_json(\n                gif_json, video_id, transform_source=js_to_json)\n            formats.append({\n                'format_id': 'gif',\n                'preference': -10,\n                'width': width,\n                'height': height,\n                'ext': 'gif',\n                'acodec': 'none',\n                'vcodec': 'gif',\n                'container': 'gif',\n                'url': self._proto_relative_url(gifd['gifUrl']),\n                'filesize': gifd.get('size'),\n                'http_headers': {\n                    'User-Agent': 'youtube-dl (like wget)',\n                },\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 51,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.imgur.ImgurAlbumIE._real_extract#132",
        "src_path": "youtube_dl/extractor/imgur.py",
        "class_name": "youtube_dl.extractor.imgur.ImgurAlbumIE",
        "signature": "youtube_dl.extractor.imgur.ImgurAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        album_images = self._download_json(\n            'http://imgur.com/gallery/%s/album_images/hit.json?all=true' % album_id,\n            album_id, fatal=False)\n\n        if album_images:\n            data = album_images.get('data')\n            if data and isinstance(data, dict):\n                images = data.get('images')\n                if images and isinstance(images, list):\n                    entries = [\n                        self.url_result('http://imgur.com/%s' % image['hash'])\n                        for image in images if image.get('hash')]\n                    return self.playlist_result(entries, album_id)\n\n        # Fallback to single video\n        return self.url_result('http://imgur.com/%s' % album_id, ImgurIE.ie_key())",
        "begin_line": 132,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ina.InaIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ina.py",
        "class_name": "youtube_dl.extractor.ina.InaIE",
        "signature": "youtube_dl.extractor.ina.InaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        mrss_url = 'http://player.ina.fr/notices/%s.mrss' % video_id\n        info_doc = self._download_xml(mrss_url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = info_doc.find('.//{http://search.yahoo.com/mrss/}player').attrib['url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': info_doc.find('.//title').text,\n        }",
        "begin_line": 21,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.inc.IncIE._real_extract#29",
        "src_path": "youtube_dl/extractor/inc.py",
        "class_name": "youtube_dl.extractor.inc.IncIE",
        "signature": "youtube_dl.extractor.inc.IncIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        partner_id = self._search_regex(\n            r'var\\s+_?bizo_data_partner_id\\s*=\\s*[\"\\'](\\d+)', webpage, 'partner id')\n\n        kaltura_id = self._parse_json(self._search_regex(\n            r'pageInfo\\.videos\\s*=\\s*\\[(.+)\\];', webpage, 'kaltura id'),\n            display_id)['vid_kaltura_id']\n\n        return self.url_result(\n            'kaltura:%s:%s' % (partner_id, kaltura_id), KalturaIE.ie_key())",
        "begin_line": 29,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.indavideo.IndavideoEmbedIE._real_extract#39",
        "src_path": "youtube_dl/extractor/indavideo.py",
        "class_name": "youtube_dl.extractor.indavideo.IndavideoEmbedIE",
        "signature": "youtube_dl.extractor.indavideo.IndavideoEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://amfphp.indavideo.hu/SYm0json.php/player.playerHandler.getVideoData/%s' % video_id,\n            video_id)['data']\n\n        title = video['title']\n\n        video_urls = video.get('video_files', [])\n        video_file = video.get('video_file')\n        if video:\n            video_urls.append(video_file)\n        video_urls = list(set(video_urls))\n\n        video_prefix = video_urls[0].rsplit('/', 1)[0]\n\n        for flv_file in video.get('flv_files', []):\n            flv_url = '%s/%s' % (video_prefix, flv_file)\n            if flv_url not in video_urls:\n                video_urls.append(flv_url)\n\n        formats = [{\n            'url': video_url,\n            'height': int_or_none(self._search_regex(\n                r'\\.(\\d{3,4})\\.mp4(?:\\?|$)', video_url, 'height', default=None)),\n        } for video_url in video_urls]\n        self._sort_formats(formats)\n\n        timestamp = video.get('date')\n        if timestamp:\n            # upload date is in CEST\n            timestamp = parse_iso8601(timestamp + ' +0200', ' ')\n\n        thumbnails = [{\n            'url': self._proto_relative_url(thumbnail)\n        } for thumbnail in video.get('thumbnails', [])]\n\n        tags = [tag['title'] for tag in video.get('tags') or []]\n\n        return {\n            'id': video.get('id') or video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnails': thumbnails,\n            'uploader': video.get('user_name'),\n            'uploader_id': video.get('user_id'),\n            'timestamp': timestamp,\n            'duration': int_or_none(video.get('length')),\n            'age_limit': parse_age_limit(video.get('age_limit')),\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.indavideo.IndavideoIE._real_extract#131",
        "src_path": "youtube_dl/extractor/indavideo.py",
        "class_name": "youtube_dl.extractor.indavideo.IndavideoIE",
        "signature": "youtube_dl.extractor.indavideo.IndavideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n        embed_url = self._search_regex(\n            r'<link[^>]+rel=\"video_src\"[^>]+href=\"(.+?)\"', webpage, 'embed url')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'IndavideoEmbed',\n            'url': embed_url,\n            'display_id': display_id,\n        }",
        "begin_line": 131,
        "end_line": 143,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._extract_rtmp_video#53",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._extract_rtmp_video(self, webpage)",
        "snippet": "    def _extract_rtmp_video(self, webpage):\n        # The server URL is hardcoded\n        video_url = 'rtmpe://video.infoq.com/cfx/st/'\n\n        # Extract video URL\n        encoded_id = self._search_regex(\n            r\"jsclassref\\s*=\\s*'([^']*)'\", webpage, 'encoded id', default=None)\n\n        real_id = compat_urllib_parse_unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))\n        playpath = 'mp4:' + real_id\n\n        return [{\n            'format_id': 'rtmp_video',\n            'url': video_url,\n            'ext': determine_ext(playpath),\n            'play_path': playpath,\n        }]",
        "begin_line": 53,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._extract_cookies#71",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._extract_cookies(self, webpage)",
        "snippet": "    def _extract_cookies(self, webpage):\n        policy = self._search_regex(r'InfoQConstants.scp\\s*=\\s*\\'([^\\']+)\\'', webpage, 'policy')\n        signature = self._search_regex(r'InfoQConstants.scs\\s*=\\s*\\'([^\\']+)\\'', webpage, 'signature')\n        key_pair_id = self._search_regex(r'InfoQConstants.sck\\s*=\\s*\\'([^\\']+)\\'', webpage, 'key-pair-id')\n        return 'CloudFront-Policy=%s; CloudFront-Signature=%s; CloudFront-Key-Pair-Id=%s' % (\n            policy, signature, key_pair_id)",
        "begin_line": 71,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._extract_http_video#78",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._extract_http_video(self, webpage)",
        "snippet": "    def _extract_http_video(self, webpage):\n        http_video_url = self._search_regex(r'P\\.s\\s*=\\s*\\'([^\\']+)\\'', webpage, 'video URL')\n        return [{\n            'format_id': 'http_video',\n            'url': http_video_url,\n            'http_headers': {\n                'Cookie': self._extract_cookies(webpage)\n            },\n        }]",
        "begin_line": 78,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._extract_http_audio#88",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._extract_http_audio(self, webpage, video_id)",
        "snippet": "    def _extract_http_audio(self, webpage, video_id):\n        fields = self._hidden_inputs(webpage)\n        http_audio_url = fields.get('filename')\n        if not http_audio_url:\n            return []\n\n        cookies_header = {'Cookie': self._extract_cookies(webpage)}\n\n        # base URL is found in the Location header in the response returned by\n        # GET https://www.infoq.com/mp3download.action?filename=... when logged in.\n        http_audio_url = compat_urlparse.urljoin('http://res.infoq.com/downloads/mp3downloads/', http_audio_url)\n\n        # audio file seem to be missing some times even if there is a download link\n        # so probe URL to make sure\n        if not self._is_valid_url(http_audio_url, video_id, headers=cookies_header):\n            return []\n\n        return [{\n            'format_id': 'http_audio',\n            'url': http_audio_url,\n            'vcodec': 'none',\n            'http_headers': cookies_header,\n        }]",
        "begin_line": 88,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._real_extract#112",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        video_description = self._html_search_meta('description', webpage, 'description')\n\n        if '/cn/' in url:\n            # for China videos, HTTP video URL exists but always fails with 403\n            formats = self._extract_bokecc_formats(webpage, video_id)\n        else:\n            formats = (\n                self._extract_rtmp_video(webpage) +\n                self._extract_http_video(webpage) +\n                self._extract_http_audio(webpage, video_id))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'formats': formats,\n        }",
        "begin_line": 112,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramIE._extract_embed_url#90",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramIE",
        "signature": "youtube_dl.extractor.instagram.InstagramIE._extract_embed_url(webpage)",
        "snippet": "    def _extract_embed_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?instagram\\.com/p/[^/]+/embed.*?)\\1',\n            webpage)\n        if mobj:\n            return mobj.group('url')\n\n        blockquote_el = get_element_by_attribute(\n            'class', 'instagram-media', webpage)\n        if blockquote_el is None:\n            return\n\n        mobj = re.search(\n            r'<a[^>]+href=([\\'\"])(?P<link>[^\\'\"]+)\\1', blockquote_el)\n        if mobj:\n            return mobj.group('link')",
        "begin_line": 90,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramIE._real_extract#107",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramIE",
        "signature": "youtube_dl.extractor.instagram.InstagramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        url = mobj.group('url')\n\n        webpage = self._download_webpage(url, video_id)\n\n        (video_url, description, thumbnail, timestamp, uploader,\n         uploader_id, like_count, comment_count, comments, height,\n         width) = [None] * 11\n\n        shared_data = self._parse_json(\n            self._search_regex(\n                r'window\\._sharedData\\s*=\\s*({.+?});',\n                webpage, 'shared data', default='{}'),\n            video_id, fatal=False)\n        if shared_data:\n            media = try_get(\n                shared_data,\n                (lambda x: x['entry_data']['PostPage'][0]['graphql']['shortcode_media'],\n                 lambda x: x['entry_data']['PostPage'][0]['media']),\n                dict)\n            if media:\n                video_url = media.get('video_url')\n                height = int_or_none(media.get('dimensions', {}).get('height'))\n                width = int_or_none(media.get('dimensions', {}).get('width'))\n                description = media.get('caption')\n                thumbnail = media.get('display_src')\n                timestamp = int_or_none(media.get('date'))\n                uploader = media.get('owner', {}).get('full_name')\n                uploader_id = media.get('owner', {}).get('username')\n                like_count = int_or_none(media.get('likes', {}).get('count'))\n                comment_count = int_or_none(media.get('comments', {}).get('count'))\n                comments = [{\n                    'author': comment.get('user', {}).get('username'),\n                    'author_id': comment.get('user', {}).get('id'),\n                    'id': comment.get('id'),\n                    'text': comment.get('text'),\n                    'timestamp': int_or_none(comment.get('created_at')),\n                } for comment in media.get(\n                    'comments', {}).get('nodes', []) if comment.get('text')]\n                if not video_url:\n                    edges = try_get(\n                        media, lambda x: x['edge_sidecar_to_children']['edges'],\n                        list) or []\n                    if edges:\n                        entries = []\n                        for edge_num, edge in enumerate(edges, start=1):\n                            node = try_get(edge, lambda x: x['node'], dict)\n                            if not node:\n                                continue\n                            node_video_url = try_get(node, lambda x: x['video_url'], compat_str)\n                            if not node_video_url:\n                                continue\n                            entries.append({\n                                'id': node.get('shortcode') or node['id'],\n                                'title': 'Video %d' % edge_num,\n                                'url': node_video_url,\n                                'thumbnail': node.get('display_url'),\n                                'width': int_or_none(try_get(node, lambda x: x['dimensions']['width'])),\n                                'height': int_or_none(try_get(node, lambda x: x['dimensions']['height'])),\n                                'view_count': int_or_none(node.get('video_view_count')),\n                            })\n                        return self.playlist_result(\n                            entries, video_id,\n                            'Post by %s' % uploader_id if uploader_id else None,\n                            description)\n\n        if not video_url:\n            video_url = self._og_search_video_url(webpage, secure=False)\n\n        formats = [{\n            'url': video_url,\n            'width': width,\n            'height': height,\n        }]\n\n        if not uploader_id:\n            uploader_id = self._search_regex(\n                r'\"owner\"\\s*:\\s*{\\s*\"username\"\\s*:\\s*\"(.+?)\"',\n                webpage, 'uploader id', fatal=False)\n\n        if not description:\n            description = self._search_regex(\n                r'\"caption\"\\s*:\\s*\"(.+?)\"', webpage, 'description', default=None)\n            if description is not None:\n                description = lowercase_escape(description)\n\n        if not thumbnail:\n            thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'ext': 'mp4',\n            'title': 'Video by %s' % uploader_id,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader_id': uploader_id,\n            'uploader': uploader,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'comments': comments,\n        }",
        "begin_line": 107,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract#243",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramUserIE",
        "signature": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('username')\n\n        entries = []\n        page_count = 0\n        media_url = 'http://instagram.com/%s/media' % uploader_id\n        while True:\n            page = self._download_json(\n                media_url, uploader_id,\n                note='Downloading page %d ' % (page_count + 1),\n            )\n            page_count += 1\n\n            for it in page['items']:\n                if it.get('type') != 'video':\n                    continue\n                like_count = int_or_none(it.get('likes', {}).get('count'))\n                user = it.get('user', {})\n\n                formats = [{\n                    'format_id': k,\n                    'height': v.get('height'),\n                    'width': v.get('width'),\n                    'url': v['url'],\n                } for k, v in it['videos'].items()]\n                self._sort_formats(formats)\n\n                thumbnails_el = it.get('images', {})\n                thumbnail = thumbnails_el.get('thumbnail', {}).get('url')\n\n                # In some cases caption is null, which corresponds to None\n                # in python. As a result, it.get('caption', {}) gives None\n                title = (it.get('caption') or {}).get('text', it['id'])\n\n                entries.append({\n                    'id': it['id'],\n                    'title': limit_length(title, 80),\n                    'formats': formats,\n                    'thumbnail': thumbnail,\n                    'webpage_url': it.get('link'),\n                    'uploader': user.get('full_name'),\n                    'uploader_id': user.get('username'),\n                    'like_count': like_count,\n                    'timestamp': int_or_none(it.get('created_time')),\n                })\n\n            if not page['items']:\n                break\n            max_id = page['items'][-1]['id'].split('_')[0]\n            media_url = (\n                'http://instagram.com/%s/media?max_id=%s' % (\n                    uploader_id, max_id))\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': uploader_id,\n            'title': uploader_id,\n        }",
        "begin_line": 243,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_json_url#33",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_json_url(query)",
        "snippet": "    def _build_json_url(query):\n        return 'http://video.internetvideoarchive.net/player/6/configuration.ashx?' + query",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_xml_url#37",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_xml_url(query)",
        "snippet": "    def _build_xml_url(query):\n        return 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?' + query",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract#40",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        query = compat_urlparse.urlparse(url).query\n        query_dic = compat_parse_qs(query)\n        video_id = query_dic['publishedid'][0]\n\n        if '/player/' in url:\n            configuration = self._download_json(url, video_id)\n\n            # There are multiple videos in the playlist whlie only the first one\n            # matches the video played in browsers\n            video_info = configuration['playlist'][0]\n            title = video_info['title']\n\n            formats = []\n            for source in video_info['sources']:\n                file_url = source['file']\n                if determine_ext(file_url) == 'm3u8':\n                    m3u8_formats = self._extract_m3u8_formats(\n                        file_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)\n                    if m3u8_formats:\n                        formats.extend(m3u8_formats)\n                        file_url = m3u8_formats[0]['url']\n                        formats.extend(self._extract_f4m_formats(\n                            file_url.replace('.m3u8', '.f4m'),\n                            video_id, f4m_id='hds', fatal=False))\n                        formats.extend(self._extract_mpd_formats(\n                            file_url.replace('.m3u8', '.mpd'),\n                            video_id, mpd_id='dash', fatal=False))\n                else:\n                    a_format = {\n                        'url': file_url,\n                    }\n\n                    if source.get('label') and source['label'][-4:] == ' kbs':\n                        tbr = int_or_none(source['label'][:-4])\n                        a_format.update({\n                            'tbr': tbr,\n                            'format_id': 'http-%d' % tbr,\n                        })\n                        formats.append(a_format)\n\n            self._sort_formats(formats)\n\n            description = video_info.get('description')\n            thumbnail = video_info.get('image')\n        else:\n            configuration = self._download_xml(url, video_id)\n            formats = [{\n                'url': xpath_text(configuration, './file', 'file URL', fatal=True),\n            }]\n            thumbnail = xpath_text(configuration, './image', 'thumbnail')\n            title = 'InternetVideoArchive video %s' % video_id\n            description = None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 40,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iprima.IPrimaIE._real_extract#38",
        "src_path": "youtube_dl/extractor/iprima.py",
        "class_name": "youtube_dl.extractor.iprima.IPrimaIE",
        "signature": "youtube_dl.extractor.iprima.IPrimaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(r'data-product=\"([^\"]+)\">', webpage, 'real id')\n\n        playerpage = self._download_webpage(\n            'http://play.iprima.cz/prehravac/init',\n            video_id, note='Downloading player', query={\n                '_infuse': 1,\n                '_ts': round(time.time()),\n                'productId': video_id,\n            }, headers={'Referer': url})\n\n        formats = []\n\n        def extract_formats(format_url, format_key=None, lang=None):\n            ext = determine_ext(format_url)\n            new_formats = []\n            if format_key == 'hls' or ext == 'm3u8':\n                new_formats = self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False)\n            elif format_key == 'dash' or ext == 'mpd':\n                return\n                new_formats = self._extract_mpd_formats(\n                    format_url, video_id, mpd_id='dash', fatal=False)\n            if lang:\n                for f in new_formats:\n                    if not f.get('language'):\n                        f['language'] = lang\n            formats.extend(new_formats)\n\n        options = self._parse_json(\n            self._search_regex(\n                r'(?s)(?:TDIPlayerOptions|playerOptions)\\s*=\\s*({.+?});\\s*\\]\\]',\n                playerpage, 'player options', default='{}'),\n            video_id, transform_source=js_to_json, fatal=False)\n        if options:\n            for key, tracks in options.get('tracks', {}).items():\n                if not isinstance(tracks, list):\n                    continue\n                for track in tracks:\n                    src = track.get('src')\n                    if src:\n                        extract_formats(src, key.lower(), track.get('lang'))\n\n        if not formats:\n            for _, src in re.findall(r'src[\"\\']\\s*:\\s*([\"\\'])(.+?)\\1', playerpage):\n                extract_formats(src)\n\n        if not formats and '>GEO_IP_NOT_ALLOWED<' in playerpage:\n            self.raise_geo_restricted(countries=['CZ'])\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 38,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.md5_text#25",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi",
        "signature": "youtube_dl.extractor.iqiyi.md5_text(text)",
        "snippet": "def md5_text(text):\n    return hashlib.md5(text.encode('utf-8')).hexdigest()",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.__init__#30",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.__init__(self, target, ip, timestamp)",
        "snippet": "    def __init__(self, target, ip, timestamp):\n        self.target = target\n        self.ip = ip\n        self.timestamp = timestamp",
        "begin_line": 30,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_sum#36",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_sum(data)",
        "snippet": "    def split_sum(data):\n        return compat_str(sum(map(lambda p: int(p, 16), list(data))))",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.digit_sum#40",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.digit_sum(num)",
        "snippet": "    def digit_sum(num):\n        if isinstance(num, int):\n            num = compat_str(num)\n        return compat_str(sum(map(int, num)))",
        "begin_line": 40,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.even_odd#45",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.even_odd(self)",
        "snippet": "    def even_odd(self):\n        even = self.digit_sum(compat_str(self.timestamp)[::2])\n        odd = self.digit_sum(compat_str(self.timestamp)[1::2])\n        return even, odd",
        "begin_line": 45,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.preprocess#50",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.preprocess(self, chunksize)",
        "snippet": "    def preprocess(self, chunksize):\n        self.target = md5_text(self.target)\n        chunks = []\n        for i in range(32 // chunksize):\n            chunks.append(self.target[chunksize * i:chunksize * (i + 1)])\n        if 32 % chunksize:\n            chunks.append(self.target[32 - 32 % chunksize:])\n        return chunks, list(map(int, self.ip.split('.')))",
        "begin_line": 50,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.mod#59",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.mod(self, modulus)",
        "snippet": "    def mod(self, modulus):\n        chunks, ip = self.preprocess(32)\n        self.target = chunks[0] + ''.join(map(lambda p: compat_str(p % modulus), ip))",
        "begin_line": 59,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split#63",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split(self, chunksize)",
        "snippet": "    def split(self, chunksize):\n        modulus_map = {\n            4: 256,\n            5: 10,\n            8: 100,\n        }\n\n        chunks, ip = self.preprocess(chunksize)\n        ret = ''\n        for i in range(len(chunks)):\n            ip_part = compat_str(ip[i] % modulus_map[chunksize]) if i < 4 else ''\n            if chunksize == 8:\n                ret += ip_part + chunks[i]\n            else:\n                ret += chunks[i] + ip_part\n        self.target = ret",
        "begin_line": 63,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.handle_input16#80",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.handle_input16(self)",
        "snippet": "    def handle_input16(self):\n        self.target = md5_text(self.target)\n        self.target = self.split_sum(self.target[:16]) + self.target + self.split_sum(self.target[16:])",
        "begin_line": 80,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.handle_input8#84",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.handle_input8(self)",
        "snippet": "    def handle_input8(self):\n        self.target = md5_text(self.target)\n        ret = ''\n        for i in range(4):\n            part = self.target[8 * i:8 * (i + 1)]\n            ret += self.split_sum(part) + part\n        self.target = ret",
        "begin_line": 84,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.handleSum#92",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.handleSum(self)",
        "snippet": "    def handleSum(self):\n        self.target = md5_text(self.target)\n        self.target = self.split_sum(self.target) + self.target",
        "begin_line": 92,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.date#96",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.date(self, scheme)",
        "snippet": "    def date(self, scheme):\n        self.target = md5_text(self.target)\n        d = time.localtime(self.timestamp)\n        strings = {\n            'y': compat_str(d.tm_year),\n            'm': '%02d' % d.tm_mon,\n            'd': '%02d' % d.tm_mday,\n        }\n        self.target += ''.join(map(lambda c: strings[c], list(scheme)))",
        "begin_line": 96,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_even_odd#106",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_even_odd(self)",
        "snippet": "    def split_time_even_odd(self):\n        even, odd = self.even_odd()\n        self.target = odd + md5_text(self.target) + even",
        "begin_line": 106,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_odd_even#110",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_odd_even(self)",
        "snippet": "    def split_time_odd_even(self):\n        even, odd = self.even_odd()\n        self.target = even + md5_text(self.target) + odd",
        "begin_line": 110,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_ip_time_sum#114",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_ip_time_sum(self)",
        "snippet": "    def split_ip_time_sum(self):\n        chunks, ip = self.preprocess(32)\n        self.target = compat_str(sum(ip)) + chunks[0] + self.digit_sum(self.timestamp)",
        "begin_line": 114,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_ip_sum#118",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDK",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDK.split_time_ip_sum(self)",
        "snippet": "    def split_time_ip_sum(self):\n        chunks, ip = self.preprocess(32)\n        self.target = self.digit_sum(self.timestamp) + chunks[0] + compat_str(sum(ip))",
        "begin_line": 118,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter.__init__#124",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter.__init__(self, sdk_code)",
        "snippet": "    def __init__(self, sdk_code):\n        self.sdk_code = sdk_code",
        "begin_line": 124,
        "end_line": 125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter.run#127",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiSDKInterpreter.run(self, target, ip, timestamp)",
        "snippet": "    def run(self, target, ip, timestamp):\n        self.sdk_code = decode_packed_codes(self.sdk_code)\n\n        functions = re.findall(r'input=([a-zA-Z0-9]+)\\(input', self.sdk_code)\n\n        sdk = IqiyiSDK(target, ip, timestamp)\n\n        other_functions = {\n            'handleSum': sdk.handleSum,\n            'handleInput8': sdk.handle_input8,\n            'handleInput16': sdk.handle_input16,\n            'splitTimeEvenOdd': sdk.split_time_even_odd,\n            'splitTimeOddEven': sdk.split_time_odd_even,\n            'splitIpTimeSum': sdk.split_ip_time_sum,\n            'splitTimeIpSum': sdk.split_time_ip_sum,\n        }\n        for function in functions:\n            if re.match(r'mod\\d+', function):\n                sdk.mod(int(function[3:]))\n            elif re.match(r'date[ymd]{3}', function):\n                sdk.date(function[4:])\n            elif re.match(r'split\\d+', function):\n                sdk.split(int(function[5:]))\n            elif function in other_functions:\n                other_functions[function]()\n            else:\n                raise ExtractorError('Unknown funcion %s' % function)\n\n        return sdk.target",
        "begin_line": 127,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._real_initialize#230",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 230,
        "end_line": 231,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._rsa_fun#234",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._rsa_fun(data)",
        "snippet": "    def _rsa_fun(data):\n        # public key extracted from http://static.iqiyi.com/js/qiyiV2/20160129180840/jobs/i18n/i18nIndex.js\n        N = 0xab86b6371b5318aaa1d3c9e612a9f1264f372323c8c0f19875b5fc3b3fd3afcc1e5bec527aa94bfa85bffc157e4245aebda05389a5357b75115ac94f074aefcd\n        e = 65537\n\n        return ohdave_rsa_encrypt(data, e, N)",
        "begin_line": 234,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._login#241",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n\n        # No authentication to be performed\n        if not username:\n            return True\n\n        data = self._download_json(\n            'http://kylin.iqiyi.com/get_token', None,\n            note='Get token for logging', errnote='Unable to get token for logging')\n        sdk = data['sdk']\n        timestamp = int(time.time())\n        target = '/apis/reglogin/login.action?lang=zh_TW&area_code=null&email=%s&passwd=%s&agenttype=1&from=undefined&keeplogin=0&piccode=&fromurl=&_pos=1' % (\n            username, self._rsa_fun(password.encode('utf-8')))\n\n        interp = IqiyiSDKInterpreter(sdk)\n        sign = interp.run(target, data['ip'], timestamp)\n\n        validation_params = {\n            'target': target,\n            'server': 'BEA3AA1908656AABCCFF76582C4C6660',\n            'token': data['token'],\n            'bird_src': 'f8d91d57af224da7893dd397d52d811a',\n            'sign': sign,\n            'bird_t': timestamp,\n        }\n        validation_result = self._download_json(\n            'http://kylin.iqiyi.com/validate?' + compat_urllib_parse_urlencode(validation_params), None,\n            note='Validate credentials', errnote='Unable to validate credentials')\n\n        MSG_MAP = {\n            'P00107': 'please login via the web interface and enter the CAPTCHA code',\n            'P00117': 'bad username or password',\n        }\n\n        code = validation_result['code']\n        if code != 'A00000':\n            msg = MSG_MAP.get(code)\n            if not msg:\n                msg = 'error %s' % code\n                if validation_result.get('msg'):\n                    msg += ': ' + validation_result['msg']\n            self._downloader.report_warning('unable to log in: ' + msg)\n            return False\n\n        return True",
        "begin_line": 241,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE.get_raw_data#288",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE.get_raw_data(self, tvid, video_id)",
        "snippet": "    def get_raw_data(self, tvid, video_id):\n        tm = int(time.time() * 1000)\n\n        key = 'd5fb4bd9d50c4be6948c97edd7254b0e'\n        sc = md5_text(compat_str(tm) + key + tvid)\n        params = {\n            'tvid': tvid,\n            'vid': video_id,\n            'src': '76f90cbd92f94a2e925d83e8ccd22cb7',\n            'sc': sc,\n            't': tm,\n        }\n\n        return self._download_json(\n            'http://cache.m.iqiyi.com/jp/tmts/%s/%s/' % (tvid, video_id),\n            video_id, transform_source=lambda s: remove_start(s, 'var tvInfoJs='),\n            query=params, headers=self.geo_verification_headers())",
        "begin_line": 288,
        "end_line": 304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._extract_playlist#306",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._extract_playlist(self, webpage)",
        "snippet": "    def _extract_playlist(self, webpage):\n        PAGE_SIZE = 50\n\n        links = re.findall(\n            r'<a[^>]+class=\"site-piclist_pic_link\"[^>]+href=\"(http://www\\.iqiyi\\.com/.+\\.html)\"',\n            webpage)\n        if not links:\n            return\n\n        album_id = self._search_regex(\n            r'albumId\\s*:\\s*(\\d+),', webpage, 'album ID')\n        album_title = self._search_regex(\n            r'data-share-title=\"([^\"]+)\"', webpage, 'album title', fatal=False)\n\n        entries = list(map(self.url_result, links))\n\n        # Start from 2 because links in the first page are already on webpage\n        for page_num in itertools.count(2):\n            pagelist_page = self._download_webpage(\n                'http://cache.video.qiyi.com/jp/avlist/%s/%d/%d/' % (album_id, page_num, PAGE_SIZE),\n                album_id,\n                note='Download playlist page %d' % page_num,\n                errnote='Failed to download playlist page %d' % page_num)\n            pagelist = self._parse_json(\n                remove_start(pagelist_page, 'var tvInfoJs='), album_id)\n            vlist = pagelist['data']['vlist']\n            for item in vlist:\n                entries.append(self.url_result(item['vurl']))\n            if len(vlist) < PAGE_SIZE:\n                break\n\n        return self.playlist_result(entries, album_id, album_title)",
        "begin_line": 306,
        "end_line": 337,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iqiyi.IqiyiIE._real_extract#339",
        "src_path": "youtube_dl/extractor/iqiyi.py",
        "class_name": "youtube_dl.extractor.iqiyi.IqiyiIE",
        "signature": "youtube_dl.extractor.iqiyi.IqiyiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(\n            url, 'temp_id', note='download video page')\n\n        # There's no simple way to determine whether an URL is a playlist or not\n        # Sometimes there are playlist links in individual videos, so treat it\n        # as a single video first\n        tvid = self._search_regex(\n            r'data-(?:player|shareplattrigger)-tvid\\s*=\\s*[\\'\"](\\d+)', webpage, 'tvid', default=None)\n        if tvid is None:\n            playlist_result = self._extract_playlist(webpage)\n            if playlist_result:\n                return playlist_result\n            raise ExtractorError('Can\\'t find any video')\n\n        video_id = self._search_regex(\n            r'data-(?:player|shareplattrigger)-videoid\\s*=\\s*[\\'\"]([a-f\\d]+)', webpage, 'video_id')\n\n        formats = []\n        for _ in range(5):\n            raw_data = self.get_raw_data(tvid, video_id)\n\n            if raw_data['code'] != 'A00000':\n                if raw_data['code'] == 'A00111':\n                    self.raise_geo_restricted()\n                raise ExtractorError('Unable to load data. Error code: ' + raw_data['code'])\n\n            data = raw_data['data']\n\n            for stream in data['vidl']:\n                if 'm3utx' not in stream:\n                    continue\n                vd = compat_str(stream['vd'])\n                formats.append({\n                    'url': stream['m3utx'],\n                    'format_id': vd,\n                    'ext': 'mp4',\n                    'preference': self._FORMATS_MAP.get(vd, -1),\n                    'protocol': 'm3u8_native',\n                })\n\n            if formats:\n                break\n\n            self._sleep(5, video_id)\n\n        self._sort_formats(formats)\n        title = (get_element_by_id('widget-videotitle', webpage) or\n                 clean_html(get_element_by_attribute('class', 'mod-play-tit', webpage)) or\n                 self._html_search_regex(r'<span[^>]+data-videochanged-title=\"word\"[^>]*>([^<]+)</span>', webpage, 'title'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 339,
        "end_line": 394,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ir90tv.Ir90TvIE._real_extract#24",
        "src_path": "youtube_dl/extractor/ir90tv.py",
        "class_name": "youtube_dl.extractor.ir90tv.Ir90TvIE",
        "signature": "youtube_dl.extractor.ir90tv.Ir90TvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_start(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), '90tv.ir :: ')\n\n        video_url = self._search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', webpage, 'video url')\n\n        thumbnail = self._search_regex(r'poster=\"([^\"]+)\"', webpage, 'thumbnail url', fatal=False)\n\n        return {\n            'url': video_url,\n            'id': video_id,\n            'title': title,\n            'video_url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.itv.ITVIE._real_extract#41",
        "src_path": "youtube_dl/extractor/itv.py",
        "class_name": "youtube_dl.extractor.itv.ITVIE",
        "signature": "youtube_dl.extractor.itv.ITVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        params = extract_attributes(self._search_regex(\n            r'(?s)(<[^>]+id=\"video\"[^>]*>)', webpage, 'params'))\n\n        ns_map = {\n            'soapenv': 'http://schemas.xmlsoap.org/soap/envelope/',\n            'tem': 'http://tempuri.org/',\n            'itv': 'http://schemas.datacontract.org/2004/07/Itv.BB.Mercury.Common.Types',\n            'com': 'http://schemas.itv.com/2009/05/Common',\n        }\n        for ns, full_ns in ns_map.items():\n            compat_etree_register_namespace(ns, full_ns)\n\n        def _add_ns(name):\n            return xpath_with_ns(name, ns_map)\n\n        def _add_sub_element(element, name):\n            return etree.SubElement(element, _add_ns(name))\n\n        production_id = (\n            params.get('data-video-autoplay-id') or\n            '%s#001' % (\n                params.get('data-video-episode-id') or\n                video_id.replace('a', '/')))\n\n        req_env = etree.Element(_add_ns('soapenv:Envelope'))\n        _add_sub_element(req_env, 'soapenv:Header')\n        body = _add_sub_element(req_env, 'soapenv:Body')\n        get_playlist = _add_sub_element(body, ('tem:GetPlaylist'))\n        request = _add_sub_element(get_playlist, 'tem:request')\n        _add_sub_element(request, 'itv:ProductionId').text = production_id\n        _add_sub_element(request, 'itv:RequestGuid').text = compat_str(uuid.uuid4()).upper()\n        vodcrid = _add_sub_element(request, 'itv:Vodcrid')\n        _add_sub_element(vodcrid, 'com:Id')\n        _add_sub_element(request, 'itv:Partition')\n        user_info = _add_sub_element(get_playlist, 'tem:userInfo')\n        _add_sub_element(user_info, 'itv:Broadcaster').text = 'Itv'\n        _add_sub_element(user_info, 'itv:DM')\n        _add_sub_element(user_info, 'itv:RevenueScienceValue')\n        _add_sub_element(user_info, 'itv:SessionId')\n        _add_sub_element(user_info, 'itv:SsoToken')\n        _add_sub_element(user_info, 'itv:UserToken')\n        site_info = _add_sub_element(get_playlist, 'tem:siteInfo')\n        _add_sub_element(site_info, 'itv:AdvertisingRestriction').text = 'None'\n        _add_sub_element(site_info, 'itv:AdvertisingSite').text = 'ITV'\n        _add_sub_element(site_info, 'itv:AdvertisingType').text = 'Any'\n        _add_sub_element(site_info, 'itv:Area').text = 'ITVPLAYER.VIDEO'\n        _add_sub_element(site_info, 'itv:Category')\n        _add_sub_element(site_info, 'itv:Platform').text = 'DotCom'\n        _add_sub_element(site_info, 'itv:Site').text = 'ItvCom'\n        device_info = _add_sub_element(get_playlist, 'tem:deviceInfo')\n        _add_sub_element(device_info, 'itv:ScreenSize').text = 'Big'\n        player_info = _add_sub_element(get_playlist, 'tem:playerInfo')\n        _add_sub_element(player_info, 'itv:Version').text = '2'\n\n        headers = self.geo_verification_headers()\n        headers.update({\n            'Content-Type': 'text/xml; charset=utf-8',\n            'SOAPAction': 'http://tempuri.org/PlaylistService/GetPlaylist',\n        })\n        resp_env = self._download_xml(\n            params['data-playlist-url'], video_id,\n            headers=headers, data=etree.tostring(req_env))\n        playlist = xpath_element(resp_env, './/Playlist')\n        if playlist is None:\n            fault_code = xpath_text(resp_env, './/faultcode')\n            fault_string = xpath_text(resp_env, './/faultstring')\n            if fault_code == 'InvalidGeoRegion':\n                self.raise_geo_restricted(\n                    msg=fault_string, countries=self._GEO_COUNTRIES)\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, fault_string))\n        title = xpath_text(playlist, 'EpisodeTitle', fatal=True)\n        video_element = xpath_element(playlist, 'VideoEntries/Video', fatal=True)\n        media_files = xpath_element(video_element, 'MediaFiles', fatal=True)\n        rtmp_url = media_files.attrib['base']\n\n        formats = []\n        for media_file in media_files.findall('MediaFile'):\n            play_path = xpath_text(media_file, 'URL')\n            if not play_path:\n                continue\n            tbr = int_or_none(media_file.get('bitrate'), 1000)\n            f = {\n                'format_id': 'rtmp' + ('-%d' % tbr if tbr else ''),\n                'play_path': play_path,\n                # Providing this swfVfy allows to avoid truncated downloads\n                'player_url': 'http://www.itv.com/mercury/Mercury_VideoPlayer.swf',\n                'page_url': url,\n                'tbr': tbr,\n                'ext': 'flv',\n            }\n            app = self._search_regex(\n                'rtmpe?://[^/]+/(.+)$', rtmp_url, 'app', default=None)\n            if app:\n                f.update({\n                    'url': rtmp_url.split('?', 1)[0],\n                    'app': app,\n                })\n            else:\n                f['url'] = rtmp_url\n            formats.append(f)\n\n        ios_playlist_url = params.get('data-video-playlist')\n        hmac = params.get('data-video-hmac')\n        if ios_playlist_url and hmac:\n            headers = self.geo_verification_headers()\n            headers.update({\n                'Accept': 'application/vnd.itv.vod.playlist.v2+json',\n                'Content-Type': 'application/json',\n                'hmac': hmac.upper(),\n            })\n            ios_playlist = self._download_json(\n                ios_playlist_url, video_id, data=json.dumps({\n                    'user': {\n                        'itvUserId': '',\n                        'entitlements': [],\n                        'token': ''\n                    },\n                    'device': {\n                        'manufacturer': 'Apple',\n                        'model': 'iPad',\n                        'os': {\n                            'name': 'iPhone OS',\n                            'version': '9.3',\n                            'type': 'ios'\n                        }\n                    },\n                    'client': {\n                        'version': '4.1',\n                        'id': 'browser'\n                    },\n                    'variantAvailability': {\n                        'featureset': {\n                            'min': ['hls', 'aes'],\n                            'max': ['hls', 'aes']\n                        },\n                        'platformTag': 'mobile'\n                    }\n                }).encode(), headers=headers, fatal=False)\n            if ios_playlist:\n                video_data = ios_playlist.get('Playlist', {}).get('Video', {})\n                ios_base_url = video_data.get('Base')\n                for media_file in video_data.get('MediaFiles', []):\n                    href = media_file.get('Href')\n                    if not href:\n                        continue\n                    if ios_base_url:\n                        href = ios_base_url + href\n                    ext = determine_ext(href)\n                    if ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            href, video_id, 'mp4', entry_protocol='m3u8_native',\n                            m3u8_id='hls', fatal=False))\n                    else:\n                        formats.append({\n                            'url': href,\n                        })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for caption_url in video_element.findall('ClosedCaptioningURIs/URL'):\n            if not caption_url.text:\n                continue\n            ext = determine_ext(caption_url.text, 'ttml')\n            subtitles.setdefault('en', []).append({\n                'url': caption_url.text,\n                'ext': 'ttml' if ext == 'xml' else ext,\n            })\n\n        info = self._search_json_ld(webpage, video_id, default={})\n        info.update({\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'episode_title': title,\n            'episode_number': int_or_none(xpath_text(playlist, 'EpisodeNumber')),\n            'series': xpath_text(playlist, 'ProgrammeTitle'),\n            'duartion': parse_duration(xpath_text(playlist, 'Duration')),\n        })\n        return info",
        "begin_line": 41,
        "end_line": 223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._real_extract#76",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = {\n            'method': 'da.content.get',\n            'params': [\n                video_id, {\n                    'site': 's183',\n                    'referrer': 'http://www.ivi.ru/watch/%s' % video_id,\n                    'contentid': video_id\n                }\n            ]\n        }\n\n        video_json = self._download_json(\n            'http://api.digitalaccess.ru/api/json/', video_id,\n            'Downloading video JSON', data=json.dumps(data))\n\n        if 'error' in video_json:\n            error = video_json['error']\n            origin = error['origin']\n            if origin == 'NotAllowedForLocation':\n                self.raise_geo_restricted(\n                    msg=error['message'], countries=self._GEO_COUNTRIES)\n            elif origin == 'NoRedisValidData':\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n            raise ExtractorError(\n                'Unable to download video %s: %s' % (video_id, error['message']),\n                expected=True)\n\n        result = video_json['result']\n\n        quality = qualities(self._KNOWN_FORMATS)\n\n        formats = [{\n            'url': x['url'],\n            'format_id': x.get('content_format'),\n            'quality': quality(x.get('content_format')),\n        } for x in result['files'] if x.get('url')]\n\n        self._sort_formats(formats)\n\n        title = result['title']\n\n        duration = int_or_none(result.get('duration'))\n        compilation = result.get('compilation')\n        episode = title if compilation else None\n\n        title = '%s - %s' % (compilation, title) if compilation is not None else title\n\n        thumbnails = [{\n            'url': preview['url'],\n            'id': preview.get('content_format'),\n        } for preview in result.get('preview', []) if preview.get('url')]\n\n        webpage = self._download_webpage(url, video_id)\n\n        season = self._search_regex(\n            r'<li[^>]+class=\"season active\"[^>]*><a[^>]+>([^<]+)',\n            webpage, 'season', default=None)\n        season_number = int_or_none(self._search_regex(\n            r'<li[^>]+class=\"season active\"[^>]*><a[^>]+data-season(?:-index)?=\"(\\d+)\"',\n            webpage, 'season number', default=None))\n\n        episode_number = int_or_none(self._search_regex(\n            r'[^>]+itemprop=\"episode\"[^>]*>\\s*<meta[^>]+itemprop=\"episodeNumber\"[^>]+content=\"(\\d+)',\n            webpage, 'episode number', default=None))\n\n        description = self._og_search_description(webpage, default=None) or self._html_search_meta(\n            'description', webpage, 'description', default=None)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'series': compilation,\n            'season': season,\n            'season_number': season_number,\n            'episode': episode,\n            'episode_number': episode_number,\n            'thumbnails': thumbnails,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 76,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries#182",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries(self, html, compilation_id)",
        "snippet": "    def _extract_entries(self, html, compilation_id):\n        return [\n            self.url_result(\n                'http://www.ivi.ru/watch/%s/%s' % (compilation_id, serie), IviIE.ie_key())\n            for serie in re.findall(\n                r'<a href=\"/watch/%s/(\\d+)\"[^>]+data-id=\"\\1\"' % compilation_id, html)]",
        "begin_line": 182,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract#189",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        compilation_id = mobj.group('compilationid')\n        season_id = mobj.group('seasonid')\n\n        if season_id is not None:  # Season link\n            season_page = self._download_webpage(\n                url, compilation_id, 'Downloading season %s web page' % season_id)\n            playlist_id = '%s/season%s' % (compilation_id, season_id)\n            playlist_title = self._html_search_meta('title', season_page, 'title')\n            entries = self._extract_entries(season_page, compilation_id)\n        else:  # Compilation link\n            compilation_page = self._download_webpage(url, compilation_id, 'Downloading compilation web page')\n            playlist_id = compilation_id\n            playlist_title = self._html_search_meta('title', compilation_page, 'title')\n            seasons = re.findall(\n                r'<a href=\"/watch/%s/season(\\d+)' % compilation_id, compilation_page)\n            if not seasons:  # No seasons in this compilation\n                entries = self._extract_entries(compilation_page, compilation_id)\n            else:\n                entries = []\n                for season_id in seasons:\n                    season_page = self._download_webpage(\n                        'http://www.ivi.ru/watch/%s/season%s' % (compilation_id, season_id),\n                        compilation_id, 'Downloading season %s web page' % season_id)\n                    entries.extend(self._extract_entries(season_page, compilation_id))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 189,
        "end_line": 216,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ivideon.IvideonIE._real_extract#40",
        "src_path": "youtube_dl/extractor/ivideon.py",
        "class_name": "youtube_dl.extractor.ivideon.IvideonIE",
        "signature": "youtube_dl.extractor.ivideon.IvideonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        server_id, camera_id = mobj.group('id'), mobj.group('camera_id')\n        camera_name, description = None, None\n        camera_url = compat_urlparse.urljoin(\n            url, '/tv/camera/%s/%s/' % (server_id, camera_id))\n\n        webpage = self._download_webpage(camera_url, server_id, fatal=False)\n        if webpage:\n            config_string = self._search_regex(\n                r'var\\s+config\\s*=\\s*({.+?});', webpage, 'config', default=None)\n            if config_string:\n                config = self._parse_json(config_string, server_id, fatal=False)\n                camera_info = config.get('ivTvAppOptions', {}).get('currentCameraInfo')\n                if camera_info:\n                    camera_name = camera_info.get('camera_name')\n                    description = camera_info.get('misc', {}).get('description')\n            if not camera_name:\n                camera_name = self._html_search_meta(\n                    'name', webpage, 'camera name', default=None) or self._search_regex(\n                    r'<h1[^>]+class=\"b-video-title\"[^>]*>([^<]+)', webpage, 'camera name', default=None)\n\n        quality = qualities(self._QUALITIES)\n\n        formats = [{\n            'url': 'https://streaming.ivideon.com/flv/live?%s' % compat_urllib_parse_urlencode({\n                'server': server_id,\n                'camera': camera_id,\n                'sessionId': 'demo',\n                'q': quality(format_id),\n            }),\n            'format_id': format_id,\n            'ext': 'flv',\n            'quality': quality(format_id),\n        } for format_id in self._QUALITIES]\n        self._sort_formats(formats)\n\n        return {\n            'id': server_id,\n            'title': self._live_title(camera_name or server_id),\n            'description': description,\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.iwara.IwaraIE._real_extract#50",
        "src_path": "youtube_dl/extractor/iwara.py",
        "class_name": "youtube_dl.extractor.iwara.IwaraIE",
        "signature": "youtube_dl.extractor.iwara.IwaraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n\n        hostname = compat_urllib_parse_urlparse(urlh.geturl()).hostname\n        # ecchi is 'sexy' in Japanese\n        age_limit = 18 if hostname.split('.')[0] == 'ecchi' else 0\n\n        video_data = self._download_json('http://www.iwara.tv/api/video/%s' % video_id, video_id)\n\n        if not video_data:\n            iframe_url = self._html_search_regex(\n                r'<iframe[^>]+src=([\\'\"])(?P<url>[^\\'\"]+)\\1',\n                webpage, 'iframe URL', group='url')\n            return {\n                '_type': 'url_transparent',\n                'url': iframe_url,\n                'age_limit': age_limit,\n            }\n\n        title = remove_end(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), ' | Iwara')\n\n        formats = []\n        for a_format in video_data:\n            format_id = a_format.get('resolution')\n            height = int_or_none(self._search_regex(\n                r'(\\d+)p', format_id, 'height', default=None))\n            formats.append({\n                'url': a_format['uri'],\n                'format_id': format_id,\n                'ext': mimetype2ext(a_format.get('mime')) or 'mp4',\n                'height': height,\n                'width': int_or_none(height / 9.0 * 16.0 if height else None),\n                'quality': 1 if format_id == 'Source' else 0,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 50,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract#57",
        "src_path": "youtube_dl/extractor/izlesene.py",
        "class_name": "youtube_dl.extractor.izlesene.IzleseneIE",
        "signature": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        url = 'http://www.izlesene.com/video/%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._proto_relative_url(\n            self._og_search_thumbnail(webpage), scheme='http:')\n\n        uploader = self._html_search_regex(\n            r\"adduserUsername\\s*=\\s*'([^']+)';\",\n            webpage, 'uploader', fatal=False)\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date'))\n\n        duration = float_or_none(self._html_search_regex(\n            r'\"videoduration\"\\s*:\\s*\"([^\"]+)\"',\n            webpage, 'duration', fatal=False), scale=1000)\n\n        view_count = str_to_int(get_element_by_id('videoViewCount', webpage))\n        comment_count = self._html_search_regex(\n            r'comment_count\\s*=\\s*\\'([^\\']+)\\';',\n            webpage, 'comment_count', fatal=False)\n\n        content_url = self._html_search_meta(\n            'contentURL', webpage, 'content URL', fatal=False)\n        ext = determine_ext(content_url, 'mp4')\n\n        # Might be empty for some videos.\n        streams = self._html_search_regex(\n            r'\"qualitylevel\"\\s*:\\s*\"([^\"]+)\"', webpage, 'streams', default='')\n\n        formats = []\n        if streams:\n            for stream in streams.split('|'):\n                quality, url = re.search(r'\\[(\\w+)\\](.+)', stream).groups()\n                formats.append({\n                    'format_id': '%sp' % quality if quality else 'sd',\n                    'url': compat_urllib_parse_unquote(url),\n                    'ext': ext,\n                })\n        else:\n            stream_url = self._search_regex(\n                r'\"streamurl\"\\s*:\\s*\"([^\"]+)\"', webpage, 'stream URL')\n            formats.append({\n                'format_id': 'sd',\n                'url': compat_urllib_parse_unquote(stream_url),\n                'ext': ext,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader_id': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': self._family_friendly_search(webpage),\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jamendo.JamendoBaseIE._extract_meta#12",
        "src_path": "youtube_dl/extractor/jamendo.py",
        "class_name": "youtube_dl.extractor.jamendo.JamendoBaseIE",
        "signature": "youtube_dl.extractor.jamendo.JamendoBaseIE._extract_meta(self, webpage, fatal=True)",
        "snippet": "    def _extract_meta(self, webpage, fatal=True):\n        title = self._og_search_title(\n            webpage, default=None) or self._search_regex(\n            r'<title>([^<]+)', webpage,\n            'title', default=None)\n        if title:\n            title = self._search_regex(\n                r'(.+?)\\s*\\|\\s*Jamendo Music', title, 'title', default=None)\n        if not title:\n            title = self._html_search_meta(\n                'name', webpage, 'title', fatal=fatal)\n        mobj = re.search(r'(.+) - (.+)', title or '')\n        artist, second = mobj.groups() if mobj else [None] * 2\n        return title, artist, second",
        "begin_line": 12,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jamendo.JamendoIE._real_extract#45",
        "src_path": "youtube_dl/extractor/jamendo.py",
        "class_name": "youtube_dl.extractor.jamendo.JamendoIE",
        "signature": "youtube_dl.extractor.jamendo.JamendoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = self._VALID_URL_RE.match(url)\n        track_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title, artist, track = self._extract_meta(webpage)\n\n        formats = [{\n            'url': 'https://%s.jamendo.com/?trackid=%s&format=%s&from=app-97dab294'\n                   % (sub_domain, track_id, format_id),\n            'format_id': format_id,\n            'ext': ext,\n            'quality': quality,\n        } for quality, (format_id, sub_domain, ext) in enumerate((\n            ('mp31', 'mp3l', 'mp3'),\n            ('mp32', 'mp3d', 'mp3'),\n            ('ogg1', 'ogg', 'ogg'),\n            ('flac', 'flac', 'flac'),\n        ))]\n        self._sort_formats(formats)\n\n        thumbnail = self._html_search_meta(\n            'image', webpage, 'thumbnail', fatal=False)\n        duration = parse_duration(self._search_regex(\n            r'<span[^>]+itemprop=[\"\\']duration[\"\\'][^>]+content=[\"\\'](.+?)[\"\\']',\n            webpage, 'duration', fatal=False))\n\n        return {\n            'id': track_id,\n            'display_id': display_id,\n            'thumbnail': thumbnail,\n            'title': title,\n            'duration': duration,\n            'artist': artist,\n            'track': track,\n            'formats': formats\n        }",
        "begin_line": 45,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jamendo.JamendoAlbumIE._real_extract#118",
        "src_path": "youtube_dl/extractor/jamendo.py",
        "class_name": "youtube_dl.extractor.jamendo.JamendoAlbumIE",
        "signature": "youtube_dl.extractor.jamendo.JamendoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = self._VALID_URL_RE.match(url)\n        album_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, mobj.group('display_id'))\n\n        title, artist, album = self._extract_meta(webpage, fatal=False)\n\n        entries = [{\n            '_type': 'url_transparent',\n            'url': compat_urlparse.urljoin(url, m.group('path')),\n            'ie_key': JamendoIE.ie_key(),\n            'id': self._search_regex(\n                r'/track/(\\d+)', m.group('path'), 'track id', default=None),\n            'artist': artist,\n            'album': album,\n        } for m in re.finditer(\n            r'<a[^>]+href=([\"\\'])(?P<path>(?:(?!\\1).)+)\\1[^>]+class=[\"\\'][^>]*js-trackrow-albumpage-link',\n            webpage)]\n\n        return self.playlist_result(entries, album_id, title)",
        "begin_line": 118,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract#27",
        "src_path": "youtube_dl/extractor/jeuxvideo.py",
        "class_name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE",
        "signature": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group(1)\n        webpage = self._download_webpage(url, title)\n        title = self._html_search_meta('name', webpage) or self._og_search_title(webpage)\n        config_url = self._html_search_regex(\n            r'data-src(?:set-video)?=\"(/contenu/medias/video.php.*?)\"',\n            webpage, 'config URL')\n        config_url = 'http://www.jeuxvideo.com' + config_url\n\n        video_id = self._search_regex(\n            r'id=(\\d+)',\n            config_url, 'video ID')\n\n        config = self._download_json(\n            config_url, title, 'Downloading JSON config')\n\n        formats = [{\n            'url': source['file'],\n            'format_id': source['label'],\n            'resolution': source['label'],\n        } for source in reversed(config['sources'])]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': config.get('image'),\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.joj.JojIE._extract_urls#38",
        "src_path": "youtube_dl/extractor/joj.py",
        "class_name": "youtube_dl.extractor.joj.JojIE",
        "signature": "youtube_dl.extractor.joj.JojIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe\\b[^>]+\\bsrc=[\"\\'](?P<url>(?:https?:)?//media\\.joj\\.sk/embed/[\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})',\n            webpage)",
        "begin_line": 38,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.joj.JojIE._real_extract#43",
        "src_path": "youtube_dl/extractor/joj.py",
        "class_name": "youtube_dl.extractor.joj.JojIE",
        "signature": "youtube_dl.extractor.joj.JojIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://media.joj.sk/embed/%s' % video_id, video_id)\n\n        title = self._search_regex(\n            (r'videoTitle\\s*:\\s*([\"\\'])(?P<title>(?:(?!\\1).)+)\\1',\n             r'<title>(?P<title>[^<]+)'), webpage, 'title',\n            default=None, group='title') or self._og_search_title(webpage)\n\n        bitrates = self._parse_json(\n            self._search_regex(\n                r'(?s)bitrates\\s*=\\s*({.+?});', webpage, 'bitrates',\n                default='{}'),\n            video_id, transform_source=js_to_json, fatal=False)\n\n        formats = []\n        for format_url in try_get(bitrates, lambda x: x['mp4'], list) or []:\n            if isinstance(format_url, compat_str):\n                height = self._search_regex(\n                    r'(\\d+)[pP]\\.', format_url, 'height', default=None)\n                formats.append({\n                    'url': format_url,\n                    'format_id': '%sp' % height if height else None,\n                    'height': int(height),\n                })\n        if not formats:\n            playlist = self._download_xml(\n                'https://media.joj.sk/services/Video.php?clip=%s' % video_id,\n                video_id)\n            for file_el in playlist.findall('./files/file'):\n                path = file_el.get('path')\n                if not path:\n                    continue\n                format_id = file_el.get('id') or file_el.get('label')\n                formats.append({\n                    'url': 'http://n16.joj.sk/storage/%s' % path.replace(\n                        'dat/', '', 1),\n                    'format_id': format_id,\n                    'height': int_or_none(self._search_regex(\n                        r'(\\d+)[pP]', format_id or path, 'height',\n                        default=None)),\n                })\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        duration = int_or_none(self._search_regex(\n            r'videoDuration\\s*:\\s*(\\d+)', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 43,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jove.JoveIE._real_extract#43",
        "src_path": "youtube_dl/extractor/jove.py",
        "class_name": "youtube_dl.extractor.jove.JoveIE",
        "signature": "youtube_dl.extractor.jove.JoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        chapters_id = self._html_search_regex(\n            r'/video-chapters\\?videoid=([0-9]+)', webpage, 'chapters id')\n\n        chapters_xml = self._download_xml(\n            self._CHAPTERS_URL.format(video_id=chapters_id),\n            video_id, note='Downloading chapters XML',\n            errnote='Failed to download chapters XML')\n\n        video_url = chapters_xml.attrib.get('video')\n        if not video_url:\n            raise ExtractorError('Failed to get the video URL')\n\n        title = self._html_search_meta('citation_title', webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._html_search_regex(\n            r'<div id=\"section_body_summary\"><p class=\"jove_content\">(.+?)</p>',\n            webpage, 'description', fatal=False)\n        publish_date = unified_strdate(self._html_search_meta(\n            'citation_publication_date', webpage, 'publish date', fatal=False))\n        comment_count = int(self._html_search_regex(\n            r'<meta name=\"num_comments\" content=\"(\\d+) Comments?\"',\n            webpage, 'comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': publish_date,\n            'comment_count': comment_count,\n        }",
        "begin_line": 43,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract#30",
        "src_path": "youtube_dl/extractor/jpopsukitv.py",
        "class_name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE",
        "signature": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://www.jpopsuki.tv' + self._html_search_regex(\n            r'<source src=\"(.*?)\" type', webpage, 'video url')\n\n        video_title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/(.*?)/uid/',\n            webpage, 'video uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/\\S*?/uid/(\\d*)',\n            webpage, 'video uploader_id', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<li>uploaded: (.*?)</li>', webpage, 'video upload_date',\n            fatal=False))\n        view_count_str = self._html_search_regex(\n            r'<li>Hits: ([0-9]+?)</li>', webpage, 'video view_count',\n            fatal=False)\n        comment_count_str = self._html_search_regex(\n            r'<h2>([0-9]+?) comments</h2>', webpage, 'video comment_count',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': int_or_none(view_count_str),\n            'comment_count': int_or_none(comment_count_str),\n        }",
        "begin_line": 30,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jwplatform.JWPlatformIE._extract_url#25",
        "src_path": "youtube_dl/extractor/jwplatform.py",
        "class_name": "youtube_dl.extractor.jwplatform.JWPlatformIE",
        "signature": "youtube_dl.extractor.jwplatform.JWPlatformIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<script[^>]+?src=[\"\\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.jwplatform.JWPlatformIE._real_extract#32",
        "src_path": "youtube_dl/extractor/jwplatform.py",
        "class_name": "youtube_dl.extractor.jwplatform.JWPlatformIE",
        "signature": "youtube_dl.extractor.jwplatform.JWPlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        json_data = self._download_json('http://content.jwplatform.com/feeds/%s.json' % video_id, video_id)\n        return self._parse_jwplayer_data(json_data, video_id)",
        "begin_line": 32,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._extract_url#110",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        # Embed codes: https://knowledge.kaltura.com/embedding-kaltura-media-players-your-site\n        mobj = (\n            re.search(\n                r\"\"\"(?xs)\n                    kWidget\\.(?:thumb)?[Ee]mbed\\(\n                    \\{.*?\n                        (?P<q1>['\"])wid(?P=q1)\\s*:\\s*\n                        (?P<q2>['\"])_?(?P<partner_id>(?:(?!(?P=q2)).)+)(?P=q2),.*?\n                        (?P<q3>['\"])entry_?[Ii]d(?P=q3)\\s*:\\s*\n                        (?P<q4>['\"])(?P<id>(?:(?!(?P=q4)).)+)(?P=q4)(?:,|\\s*\\})\n                \"\"\", webpage) or\n            re.search(\n                r'''(?xs)\n                    (?P<q1>[\"'])\n                        (?:https?:)?//cdnapi(?:sec)?\\.kaltura\\.com(?::\\d+)?/(?:(?!(?P=q1)).)*\\b(?:p|partner_id)/(?P<partner_id>\\d+)(?:(?!(?P=q1)).)*\n                    (?P=q1).*?\n                    (?:\n                        entry_?[Ii]d|\n                        (?P<q2>[\"'])entry_?[Ii]d(?P=q2)\n                    )\\s*:\\s*\n                    (?P<q3>[\"'])(?P<id>(?:(?!(?P=q3)).)+)(?P=q3)\n                ''', webpage) or\n            re.search(\n                r'''(?xs)\n                    <iframe[^>]+src=(?P<q1>[\"'])\n                      (?:https?:)?//(?:www\\.)?kaltura\\.com/(?:(?!(?P=q1)).)*\\b(?:p|partner_id)/(?P<partner_id>\\d+)\n                      (?:(?!(?P=q1)).)*\n                      [?&]entry_id=(?P<id>(?:(?!(?P=q1))[^&])+)\n                    (?P=q1)\n                ''', webpage)\n        )\n        if mobj:\n            embed_info = mobj.groupdict()\n            url = 'kaltura:%(partner_id)s:%(id)s' % embed_info\n            escaped_pid = re.escape(embed_info['partner_id'])\n            service_url = re.search(\n                r'<script[^>]+src=[\"\\']((?:https?:)?//.+?)/p/%s/sp/%s00/embedIframeJs' % (escaped_pid, escaped_pid),\n                webpage)\n            if service_url:\n                url = smuggle_url(url, {'service_url': service_url.group(1)})\n            return url",
        "begin_line": 110,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._kaltura_api_call#153",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._kaltura_api_call(self, video_id, actions, service_url=None, *args, **kwargs)",
        "snippet": "    def _kaltura_api_call(self, video_id, actions, service_url=None, *args, **kwargs):\n        params = actions[0]\n        if len(actions) > 1:\n            for i, a in enumerate(actions[1:], start=1):\n                for k, v in a.items():\n                    params['%d:%s' % (i, k)] = v\n\n        data = self._download_json(\n            (service_url or self._SERVICE_URL) + self._SERVICE_BASE,\n            video_id, query=params, *args, **kwargs)\n\n        status = data if len(actions) == 1 else data[0]\n        if status.get('objectType') == 'KalturaAPIException':\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, status['message']))\n\n        return data",
        "begin_line": 153,
        "end_line": 169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._get_video_info#171",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._get_video_info(self, video_id, partner_id, service_url=None)",
        "snippet": "    def _get_video_info(self, video_id, partner_id, service_url=None):\n        actions = [\n            {\n                'action': 'null',\n                'apiVersion': '3.1.5',\n                'clientTag': 'kdp:v3.8.5',\n                'format': 1,  # JSON, 2 = XML, 3 = PHP\n                'service': 'multirequest',\n            },\n            {\n                'expiry': 86400,\n                'service': 'session',\n                'action': 'startWidgetSession',\n                'widgetId': '_%s' % partner_id,\n            },\n            {\n                'action': 'get',\n                'entryId': video_id,\n                'service': 'baseentry',\n                'ks': '{1:result:ks}',\n            },\n            {\n                'action': 'getbyentryid',\n                'entryId': video_id,\n                'service': 'flavorAsset',\n                'ks': '{1:result:ks}',\n            },\n            {\n                'action': 'list',\n                'filter:entryIdEqual': video_id,\n                'service': 'caption_captionasset',\n                'ks': '{1:result:ks}',\n            },\n        ]\n        return self._kaltura_api_call(\n            video_id, actions, service_url, note='Downloading video info JSON')",
        "begin_line": 171,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kaltura.KalturaIE._real_extract#208",
        "src_path": "youtube_dl/extractor/kaltura.py",
        "class_name": "youtube_dl.extractor.kaltura.KalturaIE",
        "signature": "youtube_dl.extractor.kaltura.KalturaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        partner_id, entry_id = mobj.group('partner_id', 'id')\n        ks = None\n        captions = None\n        if partner_id and entry_id:\n            _, info, flavor_assets, captions = self._get_video_info(entry_id, partner_id, smuggled_data.get('service_url'))\n        else:\n            path, query = mobj.group('path', 'query')\n            if not path and not query:\n                raise ExtractorError('Invalid URL', expected=True)\n            params = {}\n            if query:\n                params = compat_parse_qs(query)\n            if path:\n                splitted_path = path.split('/')\n                params.update(dict((zip(splitted_path[::2], [[v] for v in splitted_path[1::2]]))))\n            if 'wid' in params:\n                partner_id = params['wid'][0][1:]\n            elif 'p' in params:\n                partner_id = params['p'][0]\n            elif 'partner_id' in params:\n                partner_id = params['partner_id'][0]\n            else:\n                raise ExtractorError('Invalid URL', expected=True)\n            if 'entry_id' in params:\n                entry_id = params['entry_id'][0]\n                _, info, flavor_assets, captions = self._get_video_info(entry_id, partner_id)\n            elif 'uiconf_id' in params and 'flashvars[referenceId]' in params:\n                reference_id = params['flashvars[referenceId]'][0]\n                webpage = self._download_webpage(url, reference_id)\n                entry_data = self._parse_json(self._search_regex(\n                    r'window\\.kalturaIframePackageData\\s*=\\s*({.*});',\n                    webpage, 'kalturaIframePackageData'),\n                    reference_id)['entryResult']\n                info, flavor_assets = entry_data['meta'], entry_data['contextData']['flavorAssets']\n                entry_id = info['id']\n                # Unfortunately, data returned in kalturaIframePackageData lacks\n                # captions so we will try requesting the complete data using\n                # regular approach since we now know the entry_id\n                try:\n                    _, info, flavor_assets, captions = self._get_video_info(\n                        entry_id, partner_id)\n                except ExtractorError:\n                    # Regular scenario failed but we already have everything\n                    # extracted apart from captions and can process at least\n                    # with this\n                    pass\n            else:\n                raise ExtractorError('Invalid URL', expected=True)\n            ks = params.get('flashvars[ks]', [None])[0]\n\n        source_url = smuggled_data.get('source_url')\n        if source_url:\n            referrer = base64.b64encode(\n                '://'.join(compat_urlparse.urlparse(source_url)[:2])\n                .encode('utf-8')).decode('utf-8')\n        else:\n            referrer = None\n\n        def sign_url(unsigned_url):\n            if ks:\n                unsigned_url += '/ks/%s' % ks\n            if referrer:\n                unsigned_url += '?referrer=%s' % referrer\n            return unsigned_url\n\n        data_url = info['dataUrl']\n        if '/flvclipper/' in data_url:\n            data_url = re.sub(r'/flvclipper/.*', '/serveFlavor', data_url)\n\n        formats = []\n        for f in flavor_assets:\n            # Continue if asset is not ready\n            if f.get('status') != 2:\n                continue\n            # Original format that's not available (e.g. kaltura:1926081:0_c03e1b5g)\n            # skip for now.\n            if f.get('fileExt') == 'chun':\n                continue\n            if not f.get('fileExt'):\n                # QT indicates QuickTime; some videos have broken fileExt\n                if f.get('containerFormat') == 'qt':\n                    f['fileExt'] = 'mov'\n                else:\n                    f['fileExt'] = 'mp4'\n            video_url = sign_url(\n                '%s/flavorId/%s' % (data_url, f['id']))\n            # audio-only has no videoCodecId (e.g. kaltura:1926081:0_c03e1b5g\n            # -f mp4-56)\n            vcodec = 'none' if 'videoCodecId' not in f and f.get(\n                'frameRate') == 0 else f.get('videoCodecId')\n            formats.append({\n                'format_id': '%(fileExt)s-%(bitrate)s' % f,\n                'ext': f.get('fileExt'),\n                'tbr': int_or_none(f['bitrate']),\n                'fps': int_or_none(f.get('frameRate')),\n                'filesize_approx': int_or_none(f.get('size'), invscale=1024),\n                'container': f.get('containerFormat'),\n                'vcodec': vcodec,\n                'height': int_or_none(f.get('height')),\n                'width': int_or_none(f.get('width')),\n                'url': video_url,\n            })\n        if '/playManifest/' in data_url:\n            m3u8_url = sign_url(data_url.replace(\n                'format/url', 'format/applehttp'))\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, entry_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if captions:\n            for caption in captions.get('objects', []):\n                # Continue if caption is not ready\n                if caption.get('status') != 2:\n                    continue\n                if not caption.get('id'):\n                    continue\n                caption_format = int_or_none(caption.get('format'))\n                subtitles.setdefault(caption.get('languageCode') or caption.get('language'), []).append({\n                    'url': '%s/api_v3/service/caption_captionasset/action/serve/captionAssetId/%s' % (self._SERVICE_URL, caption['id']),\n                    'ext': caption.get('fileExt') or self._CAPTION_TYPES.get(caption_format) or 'ttml',\n                })\n\n        return {\n            'id': entry_id,\n            'title': info['name'],\n            'formats': formats,\n            'subtitles': subtitles,\n            'description': clean_html(info.get('description')),\n            'thumbnail': info.get('thumbnailUrl'),\n            'duration': info.get('duration'),\n            'timestamp': info.get('createdAt'),\n            'uploader_id': info.get('userId') if info.get('userId') != 'None' else None,\n            'view_count': info.get('plays'),\n        }",
        "begin_line": 208,
        "end_line": 348,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kamcord.KamcordIE._real_extract#28",
        "src_path": "youtube_dl/extractor/kamcord.py",
        "class_name": "youtube_dl.extractor.kamcord.KamcordIE",
        "signature": "youtube_dl.extractor.kamcord.KamcordIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video = self._parse_json(\n            self._search_regex(\n                r'window\\.__props\\s*=\\s*({.+?});?(?:\\n|\\s*</script)',\n                webpage, 'video'),\n            video_id)['video']\n\n        title = video['title']\n\n        formats = self._extract_m3u8_formats(\n            video['play']['hls'], video_id, 'mp4', entry_protocol='m3u8_native')\n        self._sort_formats(formats)\n\n        uploader = video.get('user', {}).get('username')\n        uploader_id = video.get('user', {}).get('id')\n\n        view_count = int_or_none(video.get('viewCount'))\n        like_count = int_or_none(video.get('heartCount'))\n        comment_count = int_or_none(video.get('messageCount'))\n\n        preference_key = qualities(('small', 'medium', 'large'))\n\n        thumbnails = [{\n            'url': thumbnail_url,\n            'id': thumbnail_id,\n            'preference': preference_key(thumbnail_id),\n        } for thumbnail_id, thumbnail_url in (video.get('thumbnail') or {}).items()\n            if isinstance(thumbnail_id, compat_str) and isinstance(thumbnail_url, compat_str)]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._fix_subtitles#38",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._fix_subtitles(self, subs)",
        "snippet": "    def _fix_subtitles(self, subs):\n        return '\\r\\n\\r\\n'.join(\n            '%s\\r\\n%s --> %s\\r\\n%s'\n            % (\n                num,\n                srt_subtitles_timecode(item['startMillis'] / 1000.0),\n                srt_subtitles_timecode(item['endMillis'] / 1000.0),\n                item['text'],\n            ) for num, item in enumerate(subs, 1))",
        "begin_line": 38,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._get_subtitles#48",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._get_subtitles(self, channel_id, video_id)",
        "snippet": "    def _get_subtitles(self, channel_id, video_id):\n        subs = self._download_json(\n            'http://www.kanal%splay.se/api/subtitles/%s' % (channel_id, video_id),\n            video_id, 'Downloading subtitles JSON', fatal=False)\n        return {'sv': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]} if subs else {}",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kanalplay.KanalPlayIE._real_extract#54",
        "src_path": "youtube_dl/extractor/kanalplay.py",
        "class_name": "youtube_dl.extractor.kanalplay.KanalPlayIE",
        "signature": "youtube_dl.extractor.kanalplay.KanalPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel_id = mobj.group('channel_id')\n\n        video = self._download_json(\n            'http://www.kanal%splay.se/api/getVideo?format=FLASH&videoId=%s' % (channel_id, video_id),\n            video_id)\n\n        reasons_for_no_streams = video.get('reasonsForNoStreams')\n        if reasons_for_no_streams:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, '\\n'.join(reasons_for_no_streams)),\n                expected=True)\n\n        title = video['title']\n        description = video.get('description')\n        duration = float_or_none(video.get('length'), 1000)\n        thumbnail = video.get('posterUrl')\n\n        stream_base_url = video['streamBaseUrl']\n\n        formats = [{\n            'url': stream_base_url,\n            'play_path': stream['source'],\n            'ext': 'flv',\n            'tbr': float_or_none(stream.get('bitrate'), 1000),\n            'rtmp_real_time': True,\n        } for stream in video['streams']]\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if video.get('hasSubtitle'):\n            subtitles = self.extract_subtitles(channel_id, video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 54,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kankan.KankanIE._real_extract#25",
        "src_path": "youtube_dl/extractor/kankan.py",
        "class_name": "youtube_dl.extractor.kankan.KankanIE",
        "signature": "youtube_dl.extractor.kankan.KankanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\\'\"](.+?)[\\'\"]', webpage, 'video title')\n        surls = re.search(r'surls:\\[\\'.+?\\'\\]|lurl:\\'.+?\\.flv\\'', webpage).group(0)\n        gcids = re.findall(r'http://.+?/.+?/(.+?)/', surls)\n        gcid = gcids[-1]\n\n        info_url = 'http://p2s.cl.kankan.com/getCdnresource_flv?gcid=%s' % gcid\n        video_info_page = self._download_webpage(\n            info_url, video_id, 'Downloading video url info')\n        ip = self._search_regex(r'ip:\"(.+?)\"', video_info_page, 'video url ip')\n        path = self._search_regex(r'path:\"(.+?)\"', video_info_page, 'video url path')\n        param1 = self._search_regex(r'param1:(\\d+)', video_info_page, 'param1')\n        param2 = self._search_regex(r'param2:(\\d+)', video_info_page, 'param2')\n        key = _md5('xl_mp43651' + param1 + param2)\n        video_url = 'http://%s%s?key=%s&key1=%s' % (ip, path, key, param2)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 25,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.karaoketv.KaraoketvIE._real_extract#22",
        "src_path": "youtube_dl/extractor/karaoketv.py",
        "class_name": "youtube_dl.extractor.karaoketv.KaraoketvIE",
        "signature": "youtube_dl.extractor.karaoketv.KaraoketvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        api_page_url = self._search_regex(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>https?://www\\.karaoke\\.co\\.il/api_play\\.php\\?.+?)\\1',\n            webpage, 'API play URL', group='url')\n\n        api_page = self._download_webpage(api_page_url, video_id)\n        video_cdn_url = self._search_regex(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>https?://www\\.video-cdn\\.com/embed/iframe/.+?)\\1',\n            api_page, 'video cdn URL', group='url')\n\n        video_cdn = self._download_webpage(video_cdn_url, video_id)\n        play_path = self._parse_json(\n            self._search_regex(\n                r'var\\s+options\\s*=\\s*({.+?});', video_cdn, 'options'),\n            video_id)['clip']['url']\n\n        settings = self._parse_json(\n            self._search_regex(\n                r'var\\s+settings\\s*=\\s*({.+?});', video_cdn, 'servers', default='{}'),\n            video_id, fatal=False) or {}\n\n        servers = settings.get('servers')\n        if not servers or not isinstance(servers, list):\n            servers = ('wowzail.video-cdn.com:80/vodcdn', )\n\n        formats = [{\n            'url': 'rtmp://%s' % server if not server.startswith('rtmp') else server,\n            'play_path': play_path,\n            'app': 'vodcdn',\n            'page_url': video_cdn_url,\n            'player_url': 'http://www.video-cdn.com/assets/flowplayer/flowplayer.commercial-3.2.18.swf',\n            'rtmp_real_time': True,\n            'ext': 'flv',\n        } for server in servers]\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.karrierevideos.KarriereVideosIE._real_extract#45",
        "src_path": "youtube_dl/extractor/karrierevideos.py",
        "class_name": "youtube_dl.extractor.karrierevideos.KarriereVideosIE",
        "signature": "youtube_dl.extractor.karrierevideos.KarriereVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = (self._html_search_meta('title', webpage, default=None) or\n                 self._search_regex(r'<h1 class=\"title\">([^<]+)</h1>', webpage, 'video title'))\n\n        video_id = self._search_regex(\n            r'/config/video/(.+?)\\.xml', webpage, 'video id')\n        # Server returns malformed headers\n        # Force Accept-Encoding: * to prevent gzipped results\n        playlist = self._download_xml(\n            'http://www.karrierevideos.at/player-playlist.xml.php?p=%s' % video_id,\n            video_id, transform_source=fix_xml_ampersands,\n            headers={'Accept-Encoding': '*'})\n\n        NS_MAP = {\n            'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'\n        }\n\n        def ns(path):\n            return xpath_with_ns(path, NS_MAP)\n\n        item = playlist.find('./tracklist/item')\n        video_file = xpath_text(\n            item, ns('./jwplayer:file'), 'video url', fatal=True)\n        streamer = xpath_text(\n            item, ns('./jwplayer:streamer'), 'streamer', fatal=True)\n\n        uploader = xpath_text(\n            item, ns('./jwplayer:author'), 'uploader')\n        duration = float_or_none(\n            xpath_text(item, ns('./jwplayer:duration'), 'duration'))\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"leadtext\">(.+?)</div>',\n            webpage, 'description')\n\n        thumbnail = self._html_search_meta(\n            'thumbnail', webpage, 'thumbnail')\n        if thumbnail:\n            thumbnail = compat_urlparse.urljoin(url, thumbnail)\n\n        return {\n            'id': video_id,\n            'url': streamer.replace('rtmpt', 'rtmp'),\n            'play_path': 'mp4:%s' % video_file,\n            'ext': 'flv',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 45,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.keek.KeekIE._real_extract#22",
        "src_path": "youtube_dl/extractor/keek.py",
        "class_name": "youtube_dl.extractor.keek.KeekIE",
        "signature": "youtube_dl.extractor.keek.KeekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage),\n            'ext': 'mp4',\n            'title': self._og_search_description(webpage).strip(),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': self._search_regex(\n                r'data-username=([\"\\'])(?P<uploader>.+?)\\1', webpage,\n                'uploader', fatal=False, group='uploader'),\n            'uploader_id': self._search_regex(\n                r'data-user-id=([\"\\'])(?P<uploader_id>.+?)\\1', webpage,\n                'uploader id', fatal=False, group='uploader_id'),\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.keezmovies.KeezMoviesIE._extract_info#39",
        "src_path": "youtube_dl/extractor/keezmovies.py",
        "class_name": "youtube_dl.extractor.keezmovies.KeezMoviesIE",
        "signature": "youtube_dl.extractor.keezmovies.KeezMoviesIE._extract_info(self, url)",
        "snippet": "    def _extract_info(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = (mobj.group('display_id')\n                      if 'display_id' in mobj.groupdict()\n                      else None) or mobj.group('id')\n\n        webpage = self._download_webpage(\n            url, display_id, headers={'Cookie': 'age_verified=1'})\n\n        formats = []\n        format_urls = set()\n\n        title = None\n        thumbnail = None\n        duration = None\n        encrypted = False\n\n        def extract_format(format_url, height=None):\n            if not isinstance(format_url, compat_str) or not format_url.startswith('http'):\n                return\n            if format_url in format_urls:\n                return\n            format_urls.add(format_url)\n            tbr = int_or_none(self._search_regex(\n                r'[/_](\\d+)[kK][/_]', format_url, 'tbr', default=None))\n            if not height:\n                height = int_or_none(self._search_regex(\n                    r'[/_](\\d+)[pP][/_]', format_url, 'height', default=None))\n            if encrypted:\n                format_url = aes_decrypt_text(\n                    video_url, title, 32).decode('utf-8')\n            formats.append({\n                'url': format_url,\n                'format_id': '%dp' % height if height else None,\n                'height': height,\n                'tbr': tbr,\n            })\n\n        flashvars = self._parse_json(\n            self._search_regex(\n                r'flashvars\\s*=\\s*({.+?});', webpage,\n                'flashvars', default='{}'),\n            display_id, fatal=False)\n\n        if flashvars:\n            title = flashvars.get('video_title')\n            thumbnail = flashvars.get('image_url')\n            duration = int_or_none(flashvars.get('video_duration'))\n            encrypted = flashvars.get('encrypted') is True\n            for key, value in flashvars.items():\n                mobj = re.search(r'quality_(\\d+)[pP]', key)\n                if mobj:\n                    extract_format(value, int(mobj.group(1)))\n            video_url = flashvars.get('video_url')\n            if video_url and determine_ext(video_url, None):\n                extract_format(video_url)\n\n        video_url = self._html_search_regex(\n            r'flashvars\\.video_url\\s*=\\s*([\"\\'])(?P<url>http.+?)\\1',\n            webpage, 'video url', default=None, group='url')\n        if video_url:\n            extract_format(compat_urllib_parse_unquote(video_url))\n\n        if not formats:\n            if 'title=\"This video is no longer available\"' in webpage:\n                raise ExtractorError(\n                    'Video %s is no longer available' % video_id, expected=True)\n\n        self._sort_formats(formats)\n\n        if not title:\n            title = self._html_search_regex(\n                r'<h1[^>]*>([^<]+)', webpage, 'title')\n\n        return webpage, {\n            'id': video_id,\n            'display_id': display_id,\n            'title': strip_or_none(title),\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract#124",
        "src_path": "youtube_dl/extractor/keezmovies.py",
        "class_name": "youtube_dl.extractor.keezmovies.KeezMoviesIE",
        "signature": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage, info = self._extract_info(url)\n        info['view_count'] = str_to_int(self._search_regex(\n            r'<b>([\\d,.]+)</b> Views?', webpage, 'view count', fatal=False))\n        return info",
        "begin_line": 124,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ketnet.KetnetIE._real_extract#30",
        "src_path": "youtube_dl/extractor/ketnet.py",
        "class_name": "youtube_dl.extractor.ketnet.KetnetIE",
        "signature": "youtube_dl.extractor.ketnet.KetnetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        config = self._parse_json(\n            self._search_regex(\n                r'(?s)playerConfig\\s*=\\s*({.+?})\\s*;', webpage,\n                'player config'),\n            video_id)\n\n        title = config['title']\n\n        formats = []\n        for source_key in ('', 'mz'):\n            source = config.get('%ssource' % source_key)\n            if not isinstance(source, dict):\n                continue\n            for format_id, format_url in source.items():\n                if format_id == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        format_url, video_id, 'mp4',\n                        entry_protocol='m3u8_native', m3u8_id=format_id,\n                        fatal=False))\n                elif format_id == 'hds':\n                    formats.extend(self._extract_f4m_formats(\n                        format_url, video_id, f4m_id=format_id, fatal=False))\n                else:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': config.get('description'),\n            'thumbnail': config.get('image'),\n            'series': config.get('program'),\n            'episode': config.get('episode'),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract#39",
        "src_path": "youtube_dl/extractor/khanacademy.py",
        "class_name": "youtube_dl.extractor.khanacademy.KhanAcademyIE",
        "signature": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        if m.group('key') == 'video':\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/videos/' + video_id,\n                video_id, 'Downloading video info')\n\n            upload_date = unified_strdate(data['date_added'])\n            uploader = ', '.join(data['author_names'])\n            return {\n                '_type': 'url_transparent',\n                'url': data['url'],\n                'id': video_id,\n                'title': data['title'],\n                'thumbnail': data['image_url'],\n                'duration': data['duration'],\n                'description': data['description'],\n                'uploader': uploader,\n                'upload_date': upload_date,\n            }\n        else:\n            # topic\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/topic/' + video_id,\n                video_id, 'Downloading topic info')\n\n            entries = [\n                {\n                    '_type': 'url',\n                    'url': c['url'],\n                    'id': c['id'],\n                    'title': c['title'],\n                }\n                for c in data['children'] if c['kind'] in ('Video', 'Topic')]\n\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': data['title'],\n                'description': data['description'],\n                'entries': entries,\n            }",
        "begin_line": 39,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract#42",
        "src_path": "youtube_dl/extractor/kickstarter.py",
        "class_name": "youtube_dl.extractor.kickstarter.KickStarterIE",
        "signature": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>\\s*(.*?)(?:\\s*&mdash;\\s*Kickstarter)?\\s*</title>',\n            webpage, 'title')\n        video_url = self._search_regex(\n            r'data-video-url=\"(.*?)\"',\n            webpage, 'video URL', default=None)\n        if video_url is None:  # No native kickstarter, look for embedded videos\n            return {\n                '_type': 'url_transparent',\n                'ie_key': 'Generic',\n                'url': smuggle_url(url, {'to_generic': True}),\n                'title': title,\n            }\n\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n        if thumbnail is None:\n            thumbnail = self._html_search_regex(\n                r'<img[^>]+class=\"[^\"]+\\s*poster\\s*[^\"]+\"[^>]+src=\"([^\"]+)\"',\n                webpage, 'thumbnail image', fatal=False)\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 42,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.konserthusetplay.KonserthusetPlayIE._real_extract#31",
        "src_path": "youtube_dl/extractor/konserthusetplay.py",
        "class_name": "youtube_dl.extractor.konserthusetplay.KonserthusetPlayIE",
        "signature": "youtube_dl.extractor.konserthusetplay.KonserthusetPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        e = self._search_regex(\n            r'https?://csp\\.picsearch\\.com/rest\\?.*\\be=(.+?)[&\"\\']', webpage, 'e')\n\n        rest = self._download_json(\n            'http://csp.picsearch.com/rest?e=%s&containerId=mediaplayer&i=object' % e,\n            video_id, transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])\n\n        media = rest['media']\n        player_config = media['playerconfig']\n        playlist = player_config['playlist']\n\n        source = next(f for f in playlist if f.get('bitrates') or f.get('provider'))\n\n        FORMAT_ID_REGEX = r'_([^_]+)_h264m\\.mp4'\n\n        formats = []\n\n        m3u8_url = source.get('url')\n        if m3u8_url and determine_ext(m3u8_url) == 'm3u8':\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        fallback_url = source.get('fallbackUrl')\n        fallback_format_id = None\n        if fallback_url:\n            fallback_format_id = self._search_regex(\n                FORMAT_ID_REGEX, fallback_url, 'format id', default=None)\n\n        connection_url = (player_config.get('rtmp', {}).get(\n            'netConnectionUrl') or player_config.get(\n            'plugins', {}).get('bwcheck', {}).get('netConnectionUrl'))\n        if connection_url:\n            for f in source['bitrates']:\n                video_url = f.get('url')\n                if not video_url:\n                    continue\n                format_id = self._search_regex(\n                    FORMAT_ID_REGEX, video_url, 'format id', default=None)\n                f_common = {\n                    'vbr': int_or_none(f.get('bitrate')),\n                    'width': int_or_none(f.get('width')),\n                    'height': int_or_none(f.get('height')),\n                }\n                f = f_common.copy()\n                f.update({\n                    'url': connection_url,\n                    'play_path': video_url,\n                    'format_id': 'rtmp-%s' % format_id if format_id else 'rtmp',\n                    'ext': 'flv',\n                })\n                formats.append(f)\n                if format_id and format_id == fallback_format_id:\n                    f = f_common.copy()\n                    f.update({\n                        'url': fallback_url,\n                        'format_id': 'http-%s' % format_id if format_id else 'http',\n                    })\n                    formats.append(f)\n\n        if not formats and fallback_url:\n            formats.append({\n                'url': fallback_url,\n            })\n\n        self._sort_formats(formats)\n\n        title = player_config.get('title') or media['title']\n        description = player_config.get('mediaInfo', {}).get('description')\n        thumbnail = media.get('image')\n        duration = float_or_none(media.get('duration'), 1000)\n\n        subtitles = {}\n        captions = source.get('captionsAvailableLanguages')\n        if isinstance(captions, dict):\n            for lang, subtitle_url in captions.items():\n                if lang != 'none' and isinstance(subtitle_url, compat_str):\n                    subtitles.setdefault(lang, []).append({'url': subtitle_url})\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 31,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/kontrtube.py",
        "class_name": "youtube_dl.extractor.kontrtube.KontrTubeIE",
        "signature": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(\n            url, display_id, 'Downloading page')\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'(.+?)/?',\", webpage, 'video URL')\n        thumbnail = self._search_regex(\n            r\"preview_url\\s*:\\s*'(.+?)/?',\", webpage, 'thumbnail', fatal=False)\n        title = self._html_search_regex(\n            r'(?s)<h2>(.+?)</h2>', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        duration = self._search_regex(\n            r'\u0414\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c: <em>([^<]+)</em>', webpage, 'duration', fatal=False)\n        if duration:\n            duration = parse_duration(duration.replace('\u043c\u0438\u043d', 'min').replace('\u0441\u0435\u043a', 'sec'))\n\n        view_count = self._search_regex(\n            r'\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432: <em>([^<]+)</em>',\n            webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = int_or_none(view_count.replace(' ', ''))\n\n        comment_count = int_or_none(self._search_regex(\n            r'\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \\((\\d+)\\)<', webpage, ' comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n        }",
        "begin_line": 32,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.krasview.KrasViewIE._real_extract#33",
        "src_path": "youtube_dl/extractor/krasview.py",
        "class_name": "youtube_dl.extractor.krasview.KrasViewIE",
        "signature": "youtube_dl.extractor.krasview.KrasViewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        flashvars = json.loads(js_to_json(self._search_regex(\n            r'video_Init\\(({.+?})', webpage, 'flashvars')))\n\n        video_url = flashvars['url']\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = flashvars.get('image') or self._og_search_thumbnail(webpage)\n        duration = int_or_none(flashvars.get('duration'))\n        width = int_or_none(self._og_search_property(\n            'video:width', webpage, 'video width', default=None))\n        height = int_or_none(self._og_search_property(\n            'video:height', webpage, 'video height', default=None))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'width': width,\n            'height': height,\n        }",
        "begin_line": 33,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ku6.Ku6IE._real_extract#18",
        "src_path": "youtube_dl/extractor/ku6.py",
        "class_name": "youtube_dl.extractor.ku6.Ku6IE",
        "signature": "youtube_dl.extractor.ku6.Ku6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1 title=.*>(.*?)</h1>', webpage, 'title')\n        dataUrl = 'http://v.ku6.com/fetchVideo4Player/%s.html' % video_id\n        jsonData = self._download_json(dataUrl, video_id)\n        downloadUrl = jsonData['data']['f']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': downloadUrl\n        }",
        "begin_line": 18,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kusi.KUSIIE._real_extract#37",
        "src_path": "youtube_dl/extractor/kusi.py",
        "class_name": "youtube_dl.extractor.kusi.KUSIIE",
        "signature": "youtube_dl.extractor.kusi.KUSIIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        clip_id = mobj.group('clipId')\n        video_id = clip_id or mobj.group('path')\n\n        webpage = self._download_webpage(url, video_id)\n\n        if clip_id is None:\n            video_id = clip_id = self._html_search_regex(\n                r'\"clipId\"\\s*,\\s*\"(\\d+)\"', webpage, 'clip id')\n\n        affiliate_id = self._search_regex(\n            r'affiliateId\\s*:\\s*\\'([^\\']+)\\'', webpage, 'affiliate id')\n\n        # See __Packages/worldnow/model/GalleryModel.as of WNGallery.swf\n        xml_url = update_url_query('http://www.kusi.com/build.asp', {\n            'buildtype': 'buildfeaturexmlrequest',\n            'featureType': 'Clip',\n            'featureid': clip_id,\n            'affiliateno': affiliate_id,\n            'clientgroupid': '1',\n            'rnd': int(round(random.random() * 1000000)),\n        })\n\n        doc = self._download_xml(xml_url, video_id)\n\n        video_title = xpath_text(doc, 'HEADLINE', fatal=True)\n        duration = float_or_none(xpath_text(doc, 'DURATION'), scale=1000)\n        description = xpath_text(doc, 'ABSTRACT')\n        thumbnail = xpath_text(doc, './THUMBNAILIMAGE/FILENAME')\n        createtion_time = timeconvert(xpath_text(doc, 'rfc822creationdate'))\n\n        quality_options = doc.find('{http://search.yahoo.com/mrss/}group').findall('{http://search.yahoo.com/mrss/}content')\n        formats = []\n        for quality in quality_options:\n            formats.append({\n                'url': compat_urllib_parse_unquote_plus(quality.attrib['url']),\n                'height': int_or_none(quality.attrib.get('height')),\n                'width': int_or_none(quality.attrib.get('width')),\n                'vbr': float_or_none(quality.attrib.get('bitratebits'), scale=1000),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'timestamp': createtion_time,\n        }",
        "begin_line": 37,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoBaseIE._get_formats#27",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoBaseIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoBaseIE._get_formats(self, song_id, tolerate_ip_deny=False)",
        "snippet": "    def _get_formats(self, song_id, tolerate_ip_deny=False):\n        formats = []\n        for file_format in self._FORMATS:\n            query = {\n                'format': file_format['ext'],\n                'br': file_format.get('br', ''),\n                'rid': 'MUSIC_%s' % song_id,\n                'type': 'convert_url',\n                'response': 'url'\n            }\n\n            song_url = self._download_webpage(\n                'http://antiserver.kuwo.cn/anti.s',\n                song_id, note='Download %s url info' % file_format['format'],\n                query=query, headers=self.geo_verification_headers(),\n            )\n\n            if song_url == 'IPDeny' and not tolerate_ip_deny:\n                raise ExtractorError('This song is blocked in this region', expected=True)\n\n            if song_url.startswith('http://') or song_url.startswith('https://'):\n                formats.append({\n                    'url': song_url,\n                    'format_id': file_format['format'],\n                    'format': file_format['format'],\n                    'preference': file_format['preference'],\n                    'abr': file_format.get('abr'),\n                })\n\n        return formats",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoIE._real_extract#92",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n        webpage, urlh = self._download_webpage_handle(\n            url, song_id, note='Download song detail info',\n            errnote='Unable to get song detail info')\n        if song_id not in urlh.geturl() or '\u5bf9\u4e0d\u8d77\uff0c\u8be5\u6b4c\u66f2\u7531\u4e8e\u7248\u6743\u95ee\u9898\u5df2\u88ab\u4e0b\u7ebf\uff0c\u5c06\u8fd4\u56de\u7f51\u7ad9\u9996\u9875' in webpage:\n            raise ExtractorError('this song has been offline because of copyright issues', expected=True)\n\n        song_name = self._html_search_regex(\n            r'<p[^>]+id=\"lrcName\">([^<]+)</p>', webpage, 'song name')\n        singer_name = remove_start(self._html_search_regex(\n            r'<a[^>]+href=\"http://www\\.kuwo\\.cn/artist/content\\?name=([^\"]+)\">',\n            webpage, 'singer name', fatal=False), '\u6b4c\u624b')\n        lrc_content = clean_html(get_element_by_id('lrcContent', webpage))\n        if lrc_content == '\u6682\u65e0':     # indicates no lyrics\n            lrc_content = None\n\n        formats = self._get_formats(song_id)\n        self._sort_formats(formats)\n\n        album_id = self._html_search_regex(\n            r'<a[^>]+href=\"http://www\\.kuwo\\.cn/album/(\\d+)/\"',\n            webpage, 'album id', fatal=False)\n\n        publish_time = None\n        if album_id is not None:\n            album_info_page = self._download_webpage(\n                'http://www.kuwo.cn/album/%s/' % album_id, song_id,\n                note='Download album detail info',\n                errnote='Unable to get album detail info')\n\n            publish_time = self._html_search_regex(\n                r'\u53d1\u884c\u65f6\u95f4\uff1a(\\d{4}-\\d{2}-\\d{2})', album_info_page,\n                'publish time', fatal=False)\n            if publish_time:\n                publish_time = publish_time.replace('-', '')\n\n        return {\n            'id': song_id,\n            'title': song_name,\n            'creator': singer_name,\n            'upload_date': publish_time,\n            'description': lrc_content,\n            'formats': formats,\n        }",
        "begin_line": 92,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoAlbumIE._real_extract#153",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoAlbumIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, album_id, note='Download album info',\n            errnote='Unable to get album info')\n\n        album_name = self._html_search_regex(\n            r'<div[^>]+class=\"comm\"[^<]+<h1[^>]+title=\"([^\"]+)\"', webpage,\n            'album name')\n        album_intro = remove_start(\n            clean_html(get_element_by_id('intro', webpage)),\n            '%s\u7b80\u4ecb\uff1a' % album_name)\n\n        entries = [\n            self.url_result(song_url, 'Kuwo') for song_url in re.findall(\n                r'<p[^>]+class=\"listen\"><a[^>]+href=\"(http://www\\.kuwo\\.cn/yinyue/\\d+/)\"',\n                webpage)\n        ]\n        return self.playlist_result(entries, album_id, album_name, album_intro)",
        "begin_line": 153,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoChartIE._real_extract#187",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoChartIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoChartIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        chart_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, chart_id, note='Download chart info',\n            errnote='Unable to get chart info')\n\n        entries = [\n            self.url_result(song_url, 'Kuwo') for song_url in re.findall(\n                r'<a[^>]+href=\"(http://www\\.kuwo\\.cn/yinyue/\\d+)', webpage)\n        ]\n        return self.playlist_result(entries, chart_id)",
        "begin_line": 187,
        "end_line": 197,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoSingerIE._real_extract#223",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoSingerIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        singer_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, singer_id, note='Download singer info',\n            errnote='Unable to get singer info')\n\n        singer_name = self._html_search_regex(\n            r'<h1>([^<]+)</h1>', webpage, 'singer name')\n\n        artist_id = self._html_search_regex(\n            r'data-artistid=\"(\\d+)\"', webpage, 'artist id')\n\n        page_count = int(self._html_search_regex(\n            r'data-page=\"(\\d+)\"', webpage, 'page count'))\n\n        def page_func(page_num):\n            webpage = self._download_webpage(\n                'http://www.kuwo.cn/artist/contentMusicsAjax',\n                singer_id, note='Download song list page #%d' % (page_num + 1),\n                errnote='Unable to get song list page #%d' % (page_num + 1),\n                query={'artistId': artist_id, 'pn': page_num, 'rn': self.PAGE_SIZE})\n\n            return [\n                self.url_result(compat_urlparse.urljoin(url, song_url), 'Kuwo')\n                for song_url in re.findall(\n                    r'<div[^>]+class=\"name\"><a[^>]+href=\"(/yinyue/\\d+)',\n                    webpage)\n            ]\n\n        entries = InAdvancePagedList(page_func, page_count, self.PAGE_SIZE)\n\n        return self.playlist_result(entries, singer_id, singer_name)",
        "begin_line": 223,
        "end_line": 254,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoCategoryIE._real_extract#271",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoCategoryIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoCategoryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        category_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, category_id, note='Download category info',\n            errnote='Unable to get category info')\n\n        category_name = self._html_search_regex(\n            r'<h1[^>]+title=\"([^<>]+?)\">[^<>]+?</h1>', webpage, 'category name')\n\n        category_desc = remove_start(\n            get_element_by_id('intro', webpage).strip(),\n            '%s\u7b80\u4ecb\uff1a' % category_name)\n        if category_desc == '\u6682\u65e0':\n            category_desc = None\n\n        jsonm = self._parse_json(self._html_search_regex(\n            r'var\\s+jsonm\\s*=\\s*([^;]+);', webpage, 'category songs'), category_id)\n\n        entries = [\n            self.url_result('http://www.kuwo.cn/yinyue/%s/' % song['musicrid'], 'Kuwo')\n            for song in jsonm['musiclist']\n        ]\n        return self.playlist_result(entries, category_id, category_name, category_desc)",
        "begin_line": 271,
        "end_line": 293,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.kuwo.KuwoMvIE._real_extract#320",
        "src_path": "youtube_dl/extractor/kuwo.py",
        "class_name": "youtube_dl.extractor.kuwo.KuwoMvIE",
        "signature": "youtube_dl.extractor.kuwo.KuwoMvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, song_id, note='Download mv detail info: %s' % song_id,\n            errnote='Unable to get mv detail info: %s' % song_id)\n\n        mobj = re.search(\n            r'<h1[^>]+title=\"(?P<song>[^\"]+)\">[^<]+<span[^>]+title=\"(?P<singer>[^\"]+)\"',\n            webpage)\n        if mobj:\n            song_name = mobj.group('song')\n            singer_name = mobj.group('singer')\n        else:\n            raise ExtractorError('Unable to find song or singer names')\n\n        formats = self._get_formats(song_id, tolerate_ip_deny=True)\n\n        mv_url = self._download_webpage(\n            'http://www.kuwo.cn/yy/st/mvurl?rid=MUSIC_%s' % song_id,\n            song_id, note='Download %s MV URL' % song_id)\n        formats.append({\n            'url': mv_url,\n            'format_id': 'mv',\n        })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': song_id,\n            'title': song_name,\n            'creator': singer_name,\n            'formats': formats,\n        }",
        "begin_line": 320,
        "end_line": 352,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.la7.LA7IE._real_extract#46",
        "src_path": "youtube_dl/extractor/la7.py",
        "class_name": "youtube_dl.extractor.la7.LA7IE",
        "signature": "youtube_dl.extractor.la7.LA7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        player_data = self._parse_json(\n            self._search_regex(r'videoLa7\\(({[^;]+})\\);', webpage, 'player data'),\n            video_id, transform_source=js_to_json)\n\n        return {\n            '_type': 'url_transparent',\n            'url': smuggle_url('kaltura:103:%s' % player_data['vid'], {\n                'service_url': 'http://kdam.iltrovatore.it',\n            }),\n            'id': video_id,\n            'title': player_data['title'],\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': player_data.get('poster'),\n            'ie_key': 'Kaltura',\n        }",
        "begin_line": 46,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._extract_token_url#33",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE",
        "signature": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._extract_token_url(self, stream_access_url, video_id, data)",
        "snippet": "    def _extract_token_url(self, stream_access_url, video_id, data):\n        return self._download_json(\n            stream_access_url, video_id, headers={\n                'Content-Type': 'application/json',\n            }, data=json.dumps(data).encode())['data']['stream-access'][0]",
        "begin_line": 33,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._extract_formats#39",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE",
        "signature": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._extract_formats(self, token_url, video_id)",
        "snippet": "    def _extract_formats(self, token_url, video_id):\n        token_doc = self._download_xml(\n            token_url, video_id, 'Downloading token',\n            headers=self.geo_verification_headers())\n\n        token_attrib = xpath_element(token_doc, './/token').attrib\n\n        if token_attrib['status'] != '0':\n            raise ExtractorError(\n                'Token error: %s' % token_attrib['comment'], expected=True)\n\n        formats = self._extract_akamai_formats(\n            '%s?hdnea=%s' % (token_attrib['url'], token_attrib['auth']),\n            video_id)\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 39,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._real_extract#56",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE",
        "signature": "youtube_dl.extractor.laola1tv.Laola1TvEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        flash_vars = self._search_regex(\n            r'(?s)flashvars\\s*=\\s*({.+?});', webpage, 'flash vars')\n\n        def get_flashvar(x, *args, **kwargs):\n            flash_var = self._search_regex(\n                r'%s\\s*:\\s*\"([^\"]+)\"' % x,\n                flash_vars, x, default=None)\n            if not flash_var:\n                flash_var = self._search_regex([\n                    r'flashvars\\.%s\\s*=\\s*\"([^\"]+)\"' % x,\n                    r'%s\\s*=\\s*\"([^\"]+)\"' % x],\n                    webpage, x, *args, **kwargs)\n            return flash_var\n\n        hd_doc = self._download_xml(\n            'http://www.laola1.tv/server/hd_video.php', video_id, query={\n                'play': get_flashvar('streamid'),\n                'partner': get_flashvar('partnerid'),\n                'portal': get_flashvar('portalid'),\n                'lang': get_flashvar('sprache'),\n                'v5ident': '',\n            })\n\n        _v = lambda x, **k: xpath_text(hd_doc, './/video/' + x, **k)\n        title = _v('title', fatal=True)\n\n        token_url = None\n        premium = get_flashvar('premium', default=None)\n        if premium:\n            token_url = update_url_query(\n                _v('url', fatal=True), {\n                    'timestamp': get_flashvar('timestamp'),\n                    'auth': get_flashvar('auth'),\n                })\n        else:\n            data_abo = urlencode_postdata(\n                dict((i, v) for i, v in enumerate(_v('req_liga_abos').split(','))))\n            stream_access_url = update_url_query(\n                'https://club.laola1.tv/sp/laola1/api/v3/user/session/premium/player/stream-access', {\n                    'videoId': _v('id'),\n                    'target': self._search_regex(r'vs_target = (\\d+);', webpage, 'vs target'),\n                    'label': _v('label'),\n                    'area': _v('area'),\n                })\n            token_url = self._extract_token_url(stream_access_url, video_id, data_abo)\n\n        formats = self._extract_formats(token_url, video_id)\n\n        categories_str = _v('meta_sports')\n        categories = categories_str.split(',') if categories_str else []\n        is_live = _v('islive') == 'true'\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'upload_date': unified_strdate(_v('time_date')),\n            'uploader': _v('meta_organisation'),\n            'categories': categories,\n            'is_live': is_live,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.laola1tv.Laola1TvIE._real_extract#171",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.Laola1TvIE",
        "signature": "youtube_dl.extractor.laola1tv.Laola1TvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        if 'Dieser Livestream ist bereits beendet.' in webpage:\n            raise ExtractorError('This live stream has already finished.', expected=True)\n\n        conf = self._parse_json(self._search_regex(\n            r'(?s)conf\\s*=\\s*({.+?});', webpage, 'conf'),\n            display_id, js_to_json)\n\n        video_id = conf['videoid']\n\n        config = self._download_json(conf['configUrl'], video_id, query={\n            'videoid': video_id,\n            'partnerid': conf['partnerid'],\n            'language': conf.get('language', ''),\n            'portal': conf.get('portalid', ''),\n        })\n        error = config.get('error')\n        if error:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)\n\n        video_data = config['video']\n        title = video_data['title']\n        is_live = video_data.get('isLivestream') and video_data.get('isLive')\n        meta = video_data.get('metaInformation')\n        sports = meta.get('sports')\n        categories = sports.split(',') if sports else []\n\n        token_url = self._extract_token_url(\n            video_data['streamAccess'], video_id,\n            video_data['abo']['required'])\n\n        formats = self._extract_formats(token_url, video_id)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('image'),\n            'categories': categories,\n            'formats': formats,\n            'is_live': is_live,\n        }",
        "begin_line": 171,
        "end_line": 217,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.laola1tv.ITTFIE._real_extract#227",
        "src_path": "youtube_dl/extractor/laola1tv.py",
        "class_name": "youtube_dl.extractor.laola1tv.ITTFIE",
        "signature": "youtube_dl.extractor.laola1tv.ITTFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(\n            update_url_query('https://www.laola1.tv/titanplayer.php', {\n                'videoid': self._match_id(url),\n                'type': 'V',\n                'lang': 'en',\n                'portal': 'int',\n                'customer': 1024,\n            }), Laola1TvEmbedIE.ie_key())",
        "begin_line": 227,
        "end_line": 235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lci.LCIIE._real_extract#20",
        "src_path": "youtube_dl/extractor/lci.py",
        "class_name": "youtube_dl.extractor.lci.LCIIE",
        "signature": "youtube_dl.extractor.lci.LCIIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        wat_id = self._search_regex(r'data-watid=[\\'\"](\\d+)', webpage, 'wat id')\n        return self.url_result('wat:' + wat_id, 'Wat', wat_id)",
        "begin_line": 20,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lcp.LcpIE._real_extract#66",
        "src_path": "youtube_dl/extractor/lcp.py",
        "class_name": "youtube_dl.extractor.lcp.LcpIE",
        "signature": "youtube_dl.extractor.lcp.LcpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        play_url = self._search_regex(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>%s?(?:(?!\\1).)*)\\1' % LcpPlayIE._VALID_URL,\n            webpage, 'play iframe', default=None, group='url')\n\n        if not play_url:\n            return self.url_result(url, 'Generic')\n\n        title = self._og_search_title(webpage, default=None) or self._html_search_meta(\n            'twitter:title', webpage, fatal=True)\n        description = self._html_search_meta(\n            ('description', 'twitter:description'), webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': LcpPlayIE.ie_key(),\n            'url': play_url,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 66,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.learnr.LearnrIE._real_extract#24",
        "src_path": "youtube_dl/extractor/learnr.py",
        "class_name": "youtube_dl.extractor.learnr.LearnrIE",
        "signature": "youtube_dl.extractor.learnr.LearnrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            '_type': 'url_transparent',\n            'url': self._search_regex(\n                r\"videoId\\s*:\\s*'([^']+)'\", webpage, 'youtube id'),\n            'id': video_id,\n        }",
        "begin_line": 24,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lecture2go.Lecture2GoIE._real_extract#33",
        "src_path": "youtube_dl/extractor/lecture2go.py",
        "class_name": "youtube_dl.extractor.lecture2go.Lecture2GoIE",
        "signature": "youtube_dl.extractor.lecture2go.Lecture2GoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<em[^>]+class=\"title\">(.+)</em>', webpage, 'title')\n\n        formats = []\n        for url in set(re.findall(r'var\\s+playerUri\\d+\\s*=\\s*\"([^\"]+)\"', webpage)):\n            ext = determine_ext(url)\n            protocol = determine_protocol({'url': url})\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(url, video_id, f4m_id='hds'))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(url, video_id, ext='mp4', m3u8_id='hls'))\n            else:\n                if protocol == 'rtmp':\n                    continue  # XXX: currently broken\n                formats.append({\n                    'format_id': protocol,\n                    'url': url,\n                })\n\n        self._sort_formats(formats)\n\n        creator = self._html_search_regex(\n            r'<div[^>]+id=\"description\">([^<]+)</div>', webpage, 'creator', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'Duration:\\s*</em>\\s*<em[^>]*>([^<]+)</em>', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'Views:\\s*</em>\\s*<em[^>]+>(\\d+)</em>', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'creator': creator,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 33,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LeIE.ror#83",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LeIE",
        "signature": "youtube_dl.extractor.leeco.LeIE.ror(self, param1, param2)",
        "snippet": "    def ror(self, param1, param2):\n        _loc3_ = 0\n        while _loc3_ < param2:\n            param1 = urshift(param1, 1) + ((param1 & 1) << 31)\n            _loc3_ += 1\n        return param1",
        "begin_line": 83,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LeIE.calc_time_key#90",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LeIE",
        "signature": "youtube_dl.extractor.leeco.LeIE.calc_time_key(self, param1)",
        "snippet": "    def calc_time_key(self, param1):\n        _loc2_ = 185025305\n        return self.ror(param1, _loc2_ % 17) ^ _loc2_",
        "begin_line": 90,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LeIE.decrypt_m3u8#96",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LeIE",
        "signature": "youtube_dl.extractor.leeco.LeIE.decrypt_m3u8(encrypted_data)",
        "snippet": "    def decrypt_m3u8(encrypted_data):\n        if encrypted_data[:5].decode('utf-8').lower() != 'vc_01':\n            return encrypted_data\n        encrypted_data = encrypted_data[5:]\n\n        _loc4_ = bytearray(2 * len(encrypted_data))\n        for idx, val in enumerate(encrypted_data):\n            b = compat_ord(val)\n            _loc4_[2 * idx] = b // 16\n            _loc4_[2 * idx + 1] = b % 16\n        idx = len(_loc4_) - 11\n        _loc4_ = _loc4_[idx:] + _loc4_[:idx]\n        _loc7_ = bytearray(len(encrypted_data))\n        for i in range(len(encrypted_data)):\n            _loc7_[i] = _loc4_[2 * i] * 16 + _loc4_[2 * i + 1]\n\n        return bytes(_loc7_)",
        "begin_line": 96,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LeIE._check_errors#114",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LeIE",
        "signature": "youtube_dl.extractor.leeco.LeIE._check_errors(self, play_json)",
        "snippet": "    def _check_errors(self, play_json):\n        # Check for errors\n        playstatus = play_json['msgs']['playstatus']\n        if playstatus['status'] == 0:\n            flag = playstatus['flag']\n            if flag == 1:\n                self.raise_geo_restricted()\n            else:\n                raise ExtractorError('Generic error. flag = %d' % flag, expected=True)",
        "begin_line": 114,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LeIE._real_extract#124",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LeIE",
        "signature": "youtube_dl.extractor.leeco.LeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n        page = self._download_webpage(url, media_id)\n\n        play_json_flash = self._download_json(\n            'http://player-pc.le.com/mms/out/video/playJson',\n            media_id, 'Downloading flash playJson data', query={\n                'id': media_id,\n                'platid': 1,\n                'splatid': 101,\n                'format': 1,\n                'source': 1000,\n                'tkey': self.calc_time_key(int(time.time())),\n                'domain': 'www.le.com',\n                'region': 'cn',\n            },\n            headers=self.geo_verification_headers())\n        self._check_errors(play_json_flash)\n\n        def get_flash_urls(media_url, format_id):\n            nodes_data = self._download_json(\n                media_url, media_id,\n                'Download JSON metadata for format %s' % format_id,\n                query={\n                    'm3v': 1,\n                    'format': 1,\n                    'expect': 3,\n                    'tss': 'ios',\n                })\n\n            req = self._request_webpage(\n                nodes_data['nodelist'][0]['location'], media_id,\n                note='Downloading m3u8 information for format %s' % format_id)\n\n            m3u8_data = self.decrypt_m3u8(req.read())\n\n            return {\n                'hls': encode_data_uri(m3u8_data, 'application/vnd.apple.mpegurl'),\n            }\n\n        extracted_formats = []\n        formats = []\n        playurl = play_json_flash['msgs']['playurl']\n        play_domain = playurl['domain'][0]\n\n        for format_id, format_data in playurl.get('dispatch', []).items():\n            if format_id in extracted_formats:\n                continue\n            extracted_formats.append(format_id)\n\n            media_url = play_domain + format_data[0]\n            for protocol, format_url in get_flash_urls(media_url, format_id).items():\n                f = {\n                    'url': format_url,\n                    'ext': determine_ext(format_data[1]),\n                    'format_id': '%s-%s' % (protocol, format_id),\n                    'protocol': 'm3u8_native' if protocol == 'hls' else 'http',\n                    'quality': int_or_none(format_id),\n                }\n\n                if format_id[-1:] == 'p':\n                    f['height'] = int_or_none(format_id[:-1])\n\n                formats.append(f)\n        self._sort_formats(formats, ('height', 'quality', 'format_id'))\n\n        publish_time = parse_iso8601(self._html_search_regex(\n            r'\u53d1\u5e03\u65f6\u95f4&nbsp;([^<>]+) ', page, 'publish time', default=None),\n            delimiter=' ', timezone=datetime.timedelta(hours=8))\n        description = self._html_search_meta('description', page, fatal=False)\n\n        return {\n            'id': media_id,\n            'formats': formats,\n            'title': playurl['title'],\n            'thumbnail': playurl['pic'],\n            'description': description,\n            'timestamp': publish_time,\n        }",
        "begin_line": 124,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LePlaylistIE.suitable#238",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LePlaylistIE",
        "signature": "youtube_dl.extractor.leeco.LePlaylistIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if LeIE.suitable(url) else super(LePlaylistIE, cls).suitable(url)",
        "begin_line": 238,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LePlaylistIE._real_extract#241",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LePlaylistIE",
        "signature": "youtube_dl.extractor.leeco.LePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        page = self._download_webpage(url, playlist_id)\n\n        # Currently old domain names are still used in playlists\n        media_ids = orderedSet(re.findall(\n            r'<a[^>]+href=\"http://www\\.letv\\.com/ptv/vplay/(\\d+)\\.html', page))\n        entries = [self.url_result(LeIE._URL_TEMPLATE % media_id, ie='Le')\n                   for media_id in media_ids]\n\n        title = self._html_search_meta('keywords', page,\n                                       fatal=False).split('\uff0c')[0]\n        description = self._html_search_meta('description', page, fatal=False)\n\n        return self.playlist_result(entries, playlist_id, playlist_title=title,\n                                    playlist_description=description)",
        "begin_line": 241,
        "end_line": 256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LetvCloudIE.sign_data#292",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LetvCloudIE",
        "signature": "youtube_dl.extractor.leeco.LetvCloudIE.sign_data(obj)",
        "snippet": "    def sign_data(obj):\n        if obj['cf'] == 'flash':\n            salt = '2f9d6924b33a165a6d8b5d3d42f4f987'\n            items = ['cf', 'format', 'ran', 'uu', 'ver', 'vu']\n        elif obj['cf'] == 'html5':\n            salt = 'fbeh5player12c43eccf2bec3300344'\n            items = ['cf', 'ran', 'uu', 'bver', 'vu']\n        input_data = ''.join([item + obj[item] for item in items]) + salt\n        obj['sign'] = hashlib.md5(input_data.encode('utf-8')).hexdigest()",
        "begin_line": 292,
        "end_line": 300,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LetvCloudIE._get_formats#302",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LetvCloudIE",
        "signature": "youtube_dl.extractor.leeco.LetvCloudIE._get_formats(self, cf, uu, vu, media_id)",
        "snippet": "    def _get_formats(self, cf, uu, vu, media_id):\n        def get_play_json(cf, timestamp):\n            data = {\n                'cf': cf,\n                'ver': '2.2',\n                'bver': 'firefox44.0',\n                'format': 'json',\n                'uu': uu,\n                'vu': vu,\n                'ran': compat_str(timestamp),\n            }\n            self.sign_data(data)\n            return self._download_json(\n                'http://api.letvcloud.com/gpc.php?' + compat_urllib_parse_urlencode(data),\n                media_id, 'Downloading playJson data for type %s' % cf)\n\n        play_json = get_play_json(cf, time.time())\n        # The server time may be different from local time\n        if play_json.get('code') == 10071:\n            play_json = get_play_json(cf, play_json['timestamp'])\n\n        if not play_json.get('data'):\n            if play_json.get('message'):\n                raise ExtractorError('Letv cloud said: %s' % play_json['message'], expected=True)\n            elif play_json.get('code'):\n                raise ExtractorError('Letv cloud returned error %d' % play_json['code'], expected=True)\n            else:\n                raise ExtractorError('Letv cloud returned an unknwon error')\n\n        def b64decode(s):\n            return base64.b64decode(s.encode('utf-8')).decode('utf-8')\n\n        formats = []\n        for media in play_json['data']['video_info']['media'].values():\n            play_url = media['play_url']\n            url = b64decode(play_url['main_url'])\n            decoded_url = b64decode(url_basename(url))\n            formats.append({\n                'url': url,\n                'ext': determine_ext(decoded_url),\n                'format_id': str_or_none(play_url.get('vtype')),\n                'format_note': str_or_none(play_url.get('definition')),\n                'width': int_or_none(play_url.get('vwidth')),\n                'height': int_or_none(play_url.get('vheight')),\n            })\n\n        return formats",
        "begin_line": 302,
        "end_line": 348,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.leeco.LetvCloudIE._real_extract#350",
        "src_path": "youtube_dl/extractor/leeco.py",
        "class_name": "youtube_dl.extractor.leeco.LetvCloudIE",
        "signature": "youtube_dl.extractor.leeco.LetvCloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        uu_mobj = re.search(r'uu=([\\w]+)', url)\n        vu_mobj = re.search(r'vu=([\\w]+)', url)\n\n        if not uu_mobj or not vu_mobj:\n            raise ExtractorError('Invalid URL: %s' % url, expected=True)\n\n        uu = uu_mobj.group(1)\n        vu = vu_mobj.group(1)\n        media_id = uu + '_' + vu\n\n        formats = self._get_formats('flash', uu, vu, media_id) + self._get_formats('html5', uu, vu, media_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': media_id,\n            'title': 'Video %s' % media_id,\n            'formats': formats,\n        }",
        "begin_line": 350,
        "end_line": 368,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lego.LEGOIE._real_extract#51",
        "src_path": "youtube_dl/extractor/lego.py",
        "class_name": "youtube_dl.extractor.lego.LEGOIE",
        "signature": "youtube_dl.extractor.lego.LEGOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        locale, video_id = re.match(self._VALID_URL, url).groups()\n        webpage = self._download_webpage(url, video_id)\n        title = get_element_by_class('video-header', webpage).strip()\n        progressive_base = 'https://lc-mediaplayerns-live-s.legocdn.com/'\n        streaming_base = 'http://legoprod-f.akamaihd.net/'\n        content_url = self._html_search_meta('contentUrl', webpage)\n        path = self._search_regex(\n            r'(?:https?:)?//[^/]+/(?:[iz]/s/)?public/(.+)_[0-9,]+\\.(?:mp4|webm)',\n            content_url, 'video path', default=None)\n        if not path:\n            player_url = self._proto_relative_url(self._search_regex(\n                r'<iframe[^>]+src=\"((?:https?)?//(?:www\\.)?lego\\.com/[^/]+/mediaplayer/video/[^\"]+)',\n                webpage, 'player url', default=None))\n            if not player_url:\n                base_url = self._proto_relative_url(self._search_regex(\n                    r'data-baseurl=\"([^\"]+)\"', webpage, 'base url',\n                    default='http://www.lego.com/%s/mediaplayer/video/' % locale))\n                player_url = base_url + video_id\n            player_webpage = self._download_webpage(player_url, video_id)\n            video_data = self._parse_json(unescapeHTML(self._search_regex(\n                r\"video='([^']+)'\", player_webpage, 'video data')), video_id)\n            progressive_base = self._search_regex(\n                r'data-video-progressive-url=\"([^\"]+)\"',\n                player_webpage, 'progressive base', default='https://lc-mediaplayerns-live-s.legocdn.com/')\n            streaming_base = self._search_regex(\n                r'data-video-streaming-url=\"([^\"]+)\"',\n                player_webpage, 'streaming base', default='http://legoprod-f.akamaihd.net/')\n            item_id = video_data['ItemId']\n\n            net_storage_path = video_data.get('NetStoragePath') or '/'.join([item_id[:2], item_id[2:4]])\n            base_path = '_'.join([item_id, video_data['VideoId'], video_data['Locale'], compat_str(video_data['VideoVersion'])])\n            path = '/'.join([net_storage_path, base_path])\n        streaming_path = ','.join(map(lambda bitrate: compat_str(bitrate), self._BITRATES))\n\n        formats = self._extract_akamai_formats(\n            '%si/s/public/%s_,%s,.mp4.csmil/master.m3u8' % (streaming_base, path, streaming_path), video_id)\n        m3u8_formats = list(filter(\n            lambda f: f.get('protocol') == 'm3u8_native' and f.get('vcodec') != 'none',\n            formats))\n        if len(m3u8_formats) == len(self._BITRATES):\n            self._sort_formats(m3u8_formats)\n            for bitrate, m3u8_format in zip(self._BITRATES, m3u8_formats):\n                progressive_base_url = '%spublic/%s_%d.' % (progressive_base, path, bitrate)\n                mp4_f = m3u8_format.copy()\n                mp4_f.update({\n                    'url': progressive_base_url + 'mp4',\n                    'format_id': m3u8_format['format_id'].replace('hls', 'mp4'),\n                    'protocol': 'http',\n                })\n                web_f = {\n                    'url': progressive_base_url + 'webm',\n                    'format_id': m3u8_format['format_id'].replace('hls', 'webm'),\n                    'width': m3u8_format['width'],\n                    'height': m3u8_format['height'],\n                    'tbr': m3u8_format.get('tbr'),\n                    'ext': 'webm',\n                }\n                formats.extend([web_f, mp4_f])\n        else:\n            for bitrate in self._BITRATES:\n                for ext in ('web', 'mp4'):\n                    formats.append({\n                        'format_id': '%s-%s' % (ext, bitrate),\n                        'url': '%spublic/%s_%d.%s' % (progressive_base, path, bitrate, ext),\n                        'tbr': bitrate,\n                        'ext': ext,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': self._html_search_meta('description', webpage),\n            'thumbnail': self._html_search_meta('thumbnail', webpage),\n            'duration': parse_duration(self._html_search_meta('duration', webpage)),\n            'formats': formats,\n        }",
        "begin_line": 51,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lemonde.LemondeIE._real_extract#46",
        "src_path": "youtube_dl/extractor/lemonde.py",
        "class_name": "youtube_dl.extractor.lemonde.LemondeIE",
        "signature": "youtube_dl.extractor.lemonde.LemondeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        digiteka_url = self._proto_relative_url(self._search_regex(\n            r'url\\s*:\\s*([\"\\'])(?P<url>(?:https?://)?//(?:www\\.)?(?:digiteka\\.net|ultimedia\\.com)/deliver/.+?)\\1',\n            webpage, 'digiteka url', group='url', default=None))\n\n        if digiteka_url:\n            return self.url_result(digiteka_url, 'Digiteka')\n\n        return self.url_result(url, 'Generic')",
        "begin_line": 46,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.libraryofcongress.LibraryOfCongressIE._real_extract#62",
        "src_path": "youtube_dl/extractor/libraryofcongress.py",
        "class_name": "youtube_dl.extractor.libraryofcongress.LibraryOfCongressIE",
        "signature": "youtube_dl.extractor.libraryofcongress.LibraryOfCongressIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        media_id = self._search_regex(\n            (r'id=([\"\\'])media-player-(?P<id>.+?)\\1',\n             r'<video[^>]+id=([\"\\'])uuid-(?P<id>.+?)\\1',\n             r'<video[^>]+data-uuid=([\"\\'])(?P<id>.+?)\\1',\n             r'mediaObjectId\\s*:\\s*([\"\\'])(?P<id>.+?)\\1'),\n            webpage, 'media id', group='id')\n\n        data = self._download_json(\n            'https://media.loc.gov/services/v1/media?id=%s&context=json' % media_id,\n            video_id)['mediaObject']\n\n        derivative = data['derivatives'][0]\n        media_url = derivative['derivativeUrl']\n\n        title = derivative.get('shortName') or data.get('shortName') or self._og_search_title(\n            webpage)\n\n        # Following algorithm was extracted from setAVSource js function\n        # found in webpage\n        media_url = media_url.replace('rtmp', 'https')\n\n        is_video = data.get('mediaType', 'v').lower() == 'v'\n        ext = determine_ext(media_url)\n        if ext not in ('mp4', 'mp3'):\n            media_url += '.mp4' if is_video else '.mp3'\n\n        if 'vod/mp4:' in media_url:\n            formats = [{\n                'url': media_url.replace('vod/mp4:', 'hls-vod/media/') + '.m3u8',\n                'format_id': 'hls',\n                'ext': 'mp4',\n                'protocol': 'm3u8_native',\n                'quality': 1,\n            }]\n        elif 'vod/mp3:' in media_url:\n            formats = [{\n                'url': media_url.replace('vod/mp3:', ''),\n                'vcodec': 'none',\n            }]\n\n        download_urls = set()\n        for m in re.finditer(\n                r'<option[^>]+value=([\"\\'])(?P<url>.+?)\\1[^>]+data-file-download=[^>]+>\\s*(?P<id>.+?)(?:(?:&nbsp;|\\s+)\\((?P<size>.+?)\\))?\\s*<', webpage):\n            format_id = m.group('id').lower()\n            if format_id == 'gif':\n                continue\n            download_url = m.group('url')\n            if download_url in download_urls:\n                continue\n            download_urls.add(download_url)\n            formats.append({\n                'url': download_url,\n                'format_id': format_id,\n                'filesize_approx': parse_filesize(m.group('size')),\n            })\n\n        self._sort_formats(formats)\n\n        duration = float_or_none(data.get('duration'))\n        view_count = int_or_none(data.get('viewCount'))\n\n        subtitles = {}\n        cc_url = data.get('ccUrl')\n        if cc_url:\n            subtitles.setdefault('en', []).append({\n                'url': cc_url,\n                'ext': 'ttml',\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 62,
        "end_line": 143,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.libsyn.LibsynIE._real_extract#36",
        "src_path": "youtube_dl/extractor/libsyn.py",
        "class_name": "youtube_dl.extractor.libsyn.LibsynIE",
        "signature": "youtube_dl.extractor.libsyn.LibsynIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n        url = m.group('mainurl')\n        webpage = self._download_webpage(url, video_id)\n\n        formats = [{\n            'url': media_url,\n        } for media_url in set(re.findall(r'var\\s+mediaURL(?:Libsyn)?\\s*=\\s*\"([^\"]+)\"', webpage))]\n\n        podcast_title = self._search_regex(\n            r'<h2>([^<]+)</h2>', webpage, 'podcast title', default=None)\n        episode_title = self._search_regex(\n            r'(?:<div class=\"episode-title\">|<h3>)([^<]+)</', webpage, 'episode title')\n\n        title = '%s - %s' % (podcast_title, episode_title) if podcast_title else episode_title\n\n        description = self._html_search_regex(\n            r'<div id=\"info_text_body\">(.+?)</div>', webpage,\n            'description', default=None)\n        thumbnail = self._search_regex(\n            r'<img[^>]+class=\"info-show-icon\"[^>]+src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        release_date = unified_strdate(self._search_regex(\n            r'<div class=\"release_date\">Released: ([^<]+)<', webpage, 'release date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': release_date,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract#93",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeNewsIE",
        "signature": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_urls = re.findall(\n            r'<video[^>]+><source[^>]+src=[\"\\'](.+?)[\"\\']', webpage)\n\n        iframe_links = re.findall(\n            r'<iframe[^>]+src=[\"\\']((?:https?:)?//embed\\.life\\.ru/(?:embed|video)/.+?)[\"\\']',\n            webpage)\n\n        if not video_urls and not iframe_links:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        title = remove_end(\n            self._og_search_title(webpage),\n            ' - Life.ru')\n\n        description = self._og_search_description(webpage)\n\n        view_count = self._html_search_regex(\n            r'<div[^>]+class=([\"\\']).*?\\bhits-count\\b.*?\\1[^>]*>\\s*(?P<value>\\d+)\\s*</div>',\n            webpage, 'view count', fatal=False, group='value')\n\n        timestamp = parse_iso8601(self._search_regex(\n            r'<time[^>]+datetime=([\"\\'])(?P<value>.+?)\\1',\n            webpage, 'upload date', fatal=False, group='value'))\n\n        common_info = {\n            'description': description,\n            'view_count': int_or_none(view_count),\n            'timestamp': timestamp,\n        }\n\n        def make_entry(video_id, video_url, index=None):\n            cur_info = dict(common_info)\n            cur_info.update({\n                'id': video_id if not index else '%s-video%s' % (video_id, index),\n                'url': video_url,\n                'title': title if not index else '%s (\u0412\u0438\u0434\u0435\u043e %s)' % (title, index),\n            })\n            return cur_info\n\n        def make_video_entry(video_id, video_url, index=None):\n            video_url = compat_urlparse.urljoin(url, video_url)\n            return make_entry(video_id, video_url, index)\n\n        def make_iframe_entry(video_id, video_url, index=None):\n            video_url = self._proto_relative_url(video_url, 'http:')\n            cur_info = make_entry(video_id, video_url, index)\n            cur_info['_type'] = 'url_transparent'\n            return cur_info\n\n        if len(video_urls) == 1 and not iframe_links:\n            return make_video_entry(video_id, video_urls[0])\n\n        if len(iframe_links) == 1 and not video_urls:\n            return make_iframe_entry(video_id, iframe_links[0])\n\n        entries = []\n\n        if video_urls:\n            for num, video_url in enumerate(video_urls, 1):\n                entries.append(make_video_entry(video_id, video_url, num))\n\n        if iframe_links:\n            for num, iframe_link in enumerate(iframe_links, len(video_urls) + 1):\n                entries.append(make_iframe_entry(video_id, iframe_link, num))\n\n        playlist = common_info.copy()\n        playlist.update(self.playlist_result(entries, video_id, title, description))\n        return playlist",
        "begin_line": 93,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeEmbedIE._real_extract#187",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeEmbedIE",
        "signature": "youtube_dl.extractor.lifenews.LifeEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        thumbnail = None\n        formats = []\n\n        def extract_m3u8(manifest_url):\n            formats.extend(self._extract_m3u8_formats(\n                manifest_url, video_id, 'mp4',\n                entry_protocol='m3u8_native', m3u8_id='m3u8'))\n\n        def extract_original(original_url):\n            formats.append({\n                'url': original_url,\n                'format_id': determine_ext(original_url, None),\n                'preference': 1,\n            })\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'options\\s*=\\s*({.+?});', webpage, 'options', default='{}'),\n            video_id).get('playlist', {})\n        if playlist:\n            master = playlist.get('master')\n            if isinstance(master, compat_str) and determine_ext(master) == 'm3u8':\n                extract_m3u8(compat_urlparse.urljoin(url, master))\n            original = playlist.get('original')\n            if isinstance(original, compat_str):\n                extract_original(original)\n            thumbnail = playlist.get('image')\n\n        # Old rendition fallback\n        if not formats:\n            for video_url in re.findall(r'\"file\"\\s*:\\s*\"([^\"]+)', webpage):\n                video_url = compat_urlparse.urljoin(url, video_url)\n                if determine_ext(video_url) == 'm3u8':\n                    extract_m3u8(video_url)\n                else:\n                    extract_original(video_url)\n\n        self._sort_formats(formats)\n\n        thumbnail = thumbnail or self._search_regex(\n            r'\"image\"\\s*:\\s*\"([^\"]+)', webpage, 'thumbnail', default=None)\n\n        return {\n            'id': video_id,\n            'title': video_id,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 187,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_urls#23",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_urls(cls, webpage, source_url)",
        "snippet": "    def _extract_urls(cls, webpage, source_url):\n        lm = {\n            'Media': 'media',\n            'Channel': 'channel',\n            'ChannelList': 'channel_list',\n        }\n\n        def smuggle(url):\n            return smuggle_url(url, {'source_url': source_url})\n\n        entries = []\n        for kind, video_id in re.findall(\n                r'LimelightPlayer\\.doLoad(Media|Channel|ChannelList)\\([\"\\'](?P<id>[a-z0-9]{32})',\n                webpage):\n            entries.append(cls.url_result(\n                smuggle('limelight:%s:%s' % (lm[kind], video_id)),\n                'Limelight%s' % kind, video_id))\n        for mobj in re.finditer(\n                # As per [1] class attribute should be exactly equal to\n                # LimelightEmbeddedPlayerFlash but numerous examples seen\n                # that don't exactly match it (e.g. [2]).\n                # 1. http://support.3playmedia.com/hc/en-us/articles/227732408-Limelight-Embedding-the-Captions-Plugin-with-the-Limelight-Player-on-Your-Webpage\n                # 2. http://www.sedona.com/FacilitatorTraining2017\n                r'''(?sx)\n                    <object[^>]+class=([\"\\'])(?:(?!\\1).)*\\bLimelightEmbeddedPlayerFlash\\b(?:(?!\\1).)*\\1[^>]*>.*?\n                        <param[^>]+\n                            name=([\"\\'])flashVars\\2[^>]+\n                            value=([\"\\'])(?:(?!\\3).)*(?P<kind>media|channel(?:List)?)Id=(?P<id>[a-z0-9]{32})\n                ''', webpage):\n            kind, video_id = mobj.group('kind'), mobj.group('id')\n            entries.append(cls.url_result(\n                smuggle('limelight:%s:%s' % (kind, video_id)),\n                'Limelight%s' % kind.capitalize(), video_id))\n        # http://support.3playmedia.com/hc/en-us/articles/115009517327-Limelight-Embedding-the-Audio-Description-Plugin-with-the-Limelight-Player-on-Your-Web-Page)\n        for video_id in re.findall(\n                r'(?s)LimelightPlayerUtil\\.embed\\s*\\(\\s*{.*?\\bmediaId[\"\\']\\s*:\\s*[\"\\'](?P<id>[a-z0-9]{32})',\n                webpage):\n            entries.append(cls.url_result(\n                smuggle('limelight:media:%s' % video_id),\n                LimelightMediaIE.ie_key(), video_id))\n        return entries",
        "begin_line": 23,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._call_playlist_service#65",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._call_playlist_service(self, item_id, method, fatal=True, referer=None)",
        "snippet": "    def _call_playlist_service(self, item_id, method, fatal=True, referer=None):\n        headers = {}\n        if referer:\n            headers['Referer'] = referer\n        try:\n            return self._download_json(\n                self._PLAYLIST_SERVICE_URL % (self._PLAYLIST_SERVICE_PATH, item_id, method),\n                item_id, 'Downloading PlaylistService %s JSON' % method, fatal=fatal, headers=headers)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403:\n                error = self._parse_json(e.cause.read().decode(), item_id)['detail']['contentAccessPermission']\n                if error == 'CountryDisabled':\n                    self.raise_geo_restricted()\n                raise ExtractorError(error, expected=True)\n            raise",
        "begin_line": 65,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._call_api#81",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._call_api(self, organization_id, item_id, method)",
        "snippet": "    def _call_api(self, organization_id, item_id, method):\n        return self._download_json(\n            self._API_URL % (organization_id, self._API_PATH, item_id, method),\n            item_id, 'Downloading API %s JSON' % method)",
        "begin_line": 81,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._extract#86",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._extract(self, item_id, pc_method, mobile_method, meta_method, referer=None)",
        "snippet": "    def _extract(self, item_id, pc_method, mobile_method, meta_method, referer=None):\n        pc = self._call_playlist_service(item_id, pc_method, referer=referer)\n        metadata = self._call_api(pc['orgId'], item_id, meta_method)\n        mobile = self._call_playlist_service(item_id, mobile_method, fatal=False, referer=referer)\n        return pc, mobile, metadata",
        "begin_line": 86,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_info#92",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightBaseIE",
        "signature": "youtube_dl.extractor.limelight.LimelightBaseIE._extract_info(self, streams, mobile_urls, properties)",
        "snippet": "    def _extract_info(self, streams, mobile_urls, properties):\n        video_id = properties['media_id']\n        formats = []\n        urls = []\n        for stream in streams:\n            stream_url = stream.get('url')\n            if not stream_url or stream.get('drmProtected') or stream_url in urls:\n                continue\n            urls.append(stream_url)\n            ext = determine_ext(stream_url)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    stream_url, video_id, f4m_id='hds', fatal=False))\n            else:\n                fmt = {\n                    'url': stream_url,\n                    'abr': float_or_none(stream.get('audioBitRate')),\n                    'fps': float_or_none(stream.get('videoFrameRate')),\n                    'ext': ext,\n                }\n                width = int_or_none(stream.get('videoWidthInPixels'))\n                height = int_or_none(stream.get('videoHeightInPixels'))\n                vbr = float_or_none(stream.get('videoBitRate'))\n                if width or height or vbr:\n                    fmt.update({\n                        'width': width,\n                        'height': height,\n                        'vbr': vbr,\n                    })\n                else:\n                    fmt['vcodec'] = 'none'\n                rtmp = re.search(r'^(?P<url>rtmpe?://(?P<host>[^/]+)/(?P<app>.+))/(?P<playpath>mp[34]:.+)$', stream_url)\n                if rtmp:\n                    format_id = 'rtmp'\n                    if stream.get('videoBitRate'):\n                        format_id += '-%d' % int_or_none(stream['videoBitRate'])\n                    http_format_id = format_id.replace('rtmp', 'http')\n\n                    CDN_HOSTS = (\n                        ('delvenetworks.com', 'cpl.delvenetworks.com'),\n                        ('video.llnw.net', 's2.content.video.llnw.net'),\n                    )\n                    for cdn_host, http_host in CDN_HOSTS:\n                        if cdn_host not in rtmp.group('host').lower():\n                            continue\n                        http_url = 'http://%s/%s' % (http_host, rtmp.group('playpath')[4:])\n                        urls.append(http_url)\n                        if self._is_valid_url(http_url, video_id, http_format_id):\n                            http_fmt = fmt.copy()\n                            http_fmt.update({\n                                'url': http_url,\n                                'format_id': http_format_id,\n                            })\n                            formats.append(http_fmt)\n                            break\n\n                    fmt.update({\n                        'url': rtmp.group('url'),\n                        'play_path': rtmp.group('playpath'),\n                        'app': rtmp.group('app'),\n                        'ext': 'flv',\n                        'format_id': format_id,\n                    })\n                formats.append(fmt)\n\n        for mobile_url in mobile_urls:\n            media_url = mobile_url.get('mobileUrl')\n            format_id = mobile_url.get('targetMediaPlatform')\n            if not media_url or format_id in ('Widevine', 'SmoothStreaming') or media_url in urls:\n                continue\n            urls.append(media_url)\n            ext = determine_ext(media_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=format_id, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    stream_url, video_id, f4m_id=format_id, fatal=False))\n            else:\n                formats.append({\n                    'url': media_url,\n                    'format_id': format_id,\n                    'preference': -1,\n                    'ext': ext,\n                })\n\n        self._sort_formats(formats)\n\n        title = properties['title']\n        description = properties.get('description')\n        timestamp = int_or_none(properties.get('publish_date') or properties.get('create_date'))\n        duration = float_or_none(properties.get('duration_in_milliseconds'), 1000)\n        filesize = int_or_none(properties.get('total_storage_in_bytes'))\n        categories = [properties.get('category')]\n        tags = properties.get('tags', [])\n        thumbnails = [{\n            'url': thumbnail['url'],\n            'width': int_or_none(thumbnail.get('width')),\n            'height': int_or_none(thumbnail.get('height')),\n        } for thumbnail in properties.get('thumbnails', []) if thumbnail.get('url')]\n\n        subtitles = {}\n        for caption in properties.get('captions', []):\n            lang = caption.get('language_code')\n            subtitles_url = caption.get('url')\n            if lang and subtitles_url:\n                subtitles.setdefault(lang, []).append({\n                    'url': subtitles_url,\n                })\n        closed_captions_url = properties.get('closed_captions_url')\n        if closed_captions_url:\n            subtitles.setdefault('en', []).append({\n                'url': closed_captions_url,\n                'ext': 'ttml',\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'timestamp': timestamp,\n            'duration': duration,\n            'filesize': filesize,\n            'categories': categories,\n            'tags': tags,\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n        }",
        "begin_line": 92,
        "end_line": 221,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightMediaIE._real_extract#275",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightMediaIE",
        "signature": "youtube_dl.extractor.limelight.LimelightMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        video_id = self._match_id(url)\n        self._initialize_geo_bypass(smuggled_data.get('geo_countries'))\n\n        pc, mobile, metadata = self._extract(\n            video_id, 'getPlaylistByMediaId',\n            'getMobilePlaylistByMediaId', 'properties',\n            smuggled_data.get('source_url'))\n\n        return self._extract_info(\n            pc['playlistItems'][0].get('streams', []),\n            mobile['mediaList'][0].get('mobileUrls', []) if mobile else [],\n            metadata)",
        "begin_line": 275,
        "end_line": 288,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightChannelIE._real_extract#319",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightChannelIE",
        "signature": "youtube_dl.extractor.limelight.LimelightChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        channel_id = self._match_id(url)\n\n        pc, mobile, medias = self._extract(\n            channel_id, 'getPlaylistByChannelId',\n            'getMobilePlaylistWithNItemsByChannelId?begin=0&count=-1',\n            'media', smuggled_data.get('source_url'))\n\n        entries = [\n            self._extract_info(\n                pc['playlistItems'][i].get('streams', []),\n                mobile['mediaList'][i].get('mobileUrls', []) if mobile else [],\n                medias['media_list'][i])\n            for i in range(len(medias['media_list']))]\n\n        return self.playlist_result(entries, channel_id, pc['title'])",
        "begin_line": 319,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.limelight.LimelightChannelListIE._real_extract#365",
        "src_path": "youtube_dl/extractor/limelight.py",
        "class_name": "youtube_dl.extractor.limelight.LimelightChannelListIE",
        "signature": "youtube_dl.extractor.limelight.LimelightChannelListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_list_id = self._match_id(url)\n\n        channel_list = self._call_playlist_service(channel_list_id, 'getMobileChannelListById')\n\n        entries = [\n            self.url_result('limelight:channel:%s' % channel['id'], 'LimelightChannel')\n            for channel in channel_list['channelList']]\n\n        return self.playlist_result(entries, channel_list_id, channel_list['title'])",
        "begin_line": 365,
        "end_line": 374,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.litv.LiTVIE._extract_playlist#54",
        "src_path": "youtube_dl/extractor/litv.py",
        "class_name": "youtube_dl.extractor.litv.LiTVIE",
        "signature": "youtube_dl.extractor.litv.LiTVIE._extract_playlist(self, season_list, video_id, program_info, prompt=True)",
        "snippet": "    def _extract_playlist(self, season_list, video_id, program_info, prompt=True):\n        episode_title = program_info['title']\n        content_id = season_list['contentId']\n\n        if prompt:\n            self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (content_id, video_id))\n\n        all_episodes = [\n            self.url_result(smuggle_url(\n                self._URL_TEMPLATE % (program_info['contentType'], episode['contentId']),\n                {'force_noplaylist': True}))  # To prevent infinite recursion\n            for episode in season_list['episode']]\n\n        return self.playlist_result(all_episodes, content_id, episode_title)",
        "begin_line": 54,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.litv.LiTVIE._real_extract#69",
        "src_path": "youtube_dl/extractor/litv.py",
        "class_name": "youtube_dl.extractor.litv.LiTVIE",
        "signature": "youtube_dl.extractor.litv.LiTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url, {})\n\n        video_id = self._match_id(url)\n\n        noplaylist = self._downloader.params.get('noplaylist')\n        noplaylist_prompt = True\n        if 'force_noplaylist' in data:\n            noplaylist = data['force_noplaylist']\n            noplaylist_prompt = False\n\n        webpage = self._download_webpage(url, video_id)\n\n        program_info = self._parse_json(self._search_regex(\n            r'var\\s+programInfo\\s*=\\s*([^;]+)', webpage, 'VOD data', default='{}'),\n            video_id)\n\n        season_list = list(program_info.get('seasonList', {}).values())\n        if season_list:\n            if not noplaylist:\n                return self._extract_playlist(\n                    season_list[0], video_id, program_info,\n                    prompt=noplaylist_prompt)\n\n            if noplaylist_prompt:\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n\n        # In browsers `getMainUrl` request is always issued. Usually this\n        # endpoint gives the same result as the data embedded in the webpage.\n        # If georestricted, there are no embedded data, so an extra request is\n        # necessary to get the error code\n        if 'assetId' not in program_info:\n            program_info = self._download_json(\n                'https://www.litv.tv/vod/ajax/getProgramInfo', video_id,\n                query={'contentId': video_id},\n                headers={'Accept': 'application/json'})\n        video_data = self._parse_json(self._search_regex(\n            r'uiHlsUrl\\s*=\\s*testBackendData\\(([^;]+)\\);',\n            webpage, 'video data', default='{}'), video_id)\n        if not video_data:\n            payload = {\n                'assetId': program_info['assetId'],\n                'watchDevices': program_info['watchDevices'],\n                'contentType': program_info['contentType'],\n            }\n            video_data = self._download_json(\n                'https://www.litv.tv/vod/getMainUrl', video_id,\n                data=json.dumps(payload).encode('utf-8'),\n                headers={'Content-Type': 'application/json'})\n\n        if not video_data.get('fullpath'):\n            error_msg = video_data.get('errorMessage')\n            if error_msg == 'vod.error.outsideregionerror':\n                self.raise_geo_restricted('This video is available in Taiwan only')\n            if error_msg:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, error_msg), expected=True)\n            raise ExtractorError('Unexpected result from %s' % self.IE_NAME)\n\n        formats = self._extract_m3u8_formats(\n            video_data['fullpath'], video_id, ext='mp4',\n            entry_protocol='m3u8_native', m3u8_id='hls')\n        for a_format in formats:\n            # LiTV HLS segments doesn't like compressions\n            a_format.setdefault('http_headers', {})['Youtubedl-no-compression'] = True\n\n        title = program_info['title'] + program_info.get('secondaryMark', '')\n        description = program_info.get('description')\n        thumbnail = program_info.get('imageFile')\n        categories = [item['name'] for item in program_info.get('category', [])]\n        episode = int_or_none(program_info.get('episode'))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'episode_number': episode,\n        }",
        "begin_line": 69,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.liveleak.LiveLeakIE._extract_url#78",
        "src_path": "youtube_dl/extractor/liveleak.py",
        "class_name": "youtube_dl.extractor.liveleak.LiveLeakIE",
        "signature": "youtube_dl.extractor.liveleak.LiveLeakIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?:\\w+\\.)?liveleak\\.com/ll_embed\\?(?:.*?)i=(?P<id>[\\w_]+)(?:.*)',\n            webpage)\n        if mobj:\n            return 'http://www.liveleak.com/view?i=%s' % mobj.group('id')",
        "begin_line": 78,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract#85",
        "src_path": "youtube_dl/extractor/liveleak.py",
        "class_name": "youtube_dl.extractor.liveleak.LiveLeakIE",
        "signature": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._og_search_title(webpage).replace('LiveLeak.com -', '').strip()\n        video_description = self._og_search_description(webpage)\n        video_uploader = self._html_search_regex(\n            r'By:.*?(\\w+)</a>', webpage, 'uploader', fatal=False)\n        age_limit = int_or_none(self._search_regex(\n            r'you confirm that you are ([0-9]+) years and over.',\n            webpage, 'age limit', default=None))\n        video_thumbnail = self._og_search_thumbnail(webpage)\n\n        entries = self._parse_html5_media_entries(url, webpage, video_id)\n        if not entries:\n            # Maybe an embed?\n            embed_url = self._search_regex(\n                r'<iframe[^>]+src=\"((?:https?:)?//(?:www\\.)?(?:prochan|youtube)\\.com/embed[^\"]+)\"',\n                webpage, 'embed URL')\n            return {\n                '_type': 'url_transparent',\n                'url': embed_url,\n                'id': video_id,\n                'title': video_title,\n                'description': video_description,\n                'uploader': video_uploader,\n                'age_limit': age_limit,\n            }\n\n        info_dict = entries[0]\n\n        for a_format in info_dict['formats']:\n            if not a_format.get('height'):\n                a_format['height'] = int_or_none(self._search_regex(\n                    r'([0-9]+)p\\.mp4', a_format['url'], 'height label',\n                    default=None))\n\n        self._sort_formats(info_dict['formats'])\n\n        info_dict.update({\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'uploader': video_uploader,\n            'age_limit': age_limit,\n            'thumbnail': video_thumbnail,\n        })\n\n        return info_dict",
        "begin_line": 85,
        "end_line": 133,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil_formats#65",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None)",
        "snippet": "    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):\n        base_ele = find_xpath_attr(\n            smil, self._xpath_ns('.//meta', namespace), 'name', 'httpBase')\n        base = base_ele.get('content') if base_ele is not None else 'http://livestreamvod-f.akamaihd.net/'\n\n        formats = []\n        video_nodes = smil.findall(self._xpath_ns('.//video', namespace))\n\n        for vn in video_nodes:\n            tbr = int_or_none(vn.attrib.get('system-bitrate'), 1000)\n            furl = (\n                update_url_query(compat_urlparse.urljoin(base, vn.attrib['src']), {\n                    'v': '3.0.3',\n                    'fp': 'WIN% 14,0,0,145',\n                }))\n            if 'clipBegin' in vn.attrib:\n                furl += '&ssek=' + vn.attrib['clipBegin']\n            formats.append({\n                'url': furl,\n                'format_id': 'smil_%d' % tbr,\n                'ext': 'flv',\n                'tbr': tbr,\n                'preference': -1000,\n            })\n        return formats",
        "begin_line": 65,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info#91",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info(self, video_data)",
        "snippet": "    def _extract_video_info(self, video_data):\n        video_id = compat_str(video_data['id'])\n\n        FORMAT_KEYS = (\n            ('sd', 'progressive_url'),\n            ('hd', 'progressive_url_hd'),\n        )\n\n        formats = []\n        for format_id, key in FORMAT_KEYS:\n            video_url = video_data.get(key)\n            if video_url:\n                ext = determine_ext(video_url)\n                if ext == 'm3u8':\n                    continue\n                bitrate = int_or_none(self._search_regex(\n                    r'(\\d+)\\.%s' % ext, video_url, 'bitrate', default=None))\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'tbr': bitrate,\n                    'ext': ext,\n                })\n\n        smil_url = video_data.get('smil_url')\n        if smil_url:\n            formats.extend(self._extract_smil_formats(smil_url, video_id))\n\n        m3u8_url = video_data.get('m3u8_url')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        f4m_url = video_data.get('f4m_url')\n        if f4m_url:\n            formats.extend(self._extract_f4m_formats(\n                f4m_url, video_id, f4m_id='hds', fatal=False))\n        self._sort_formats(formats)\n\n        comments = [{\n            'author_id': comment.get('author_id'),\n            'author': comment.get('author', {}).get('full_name'),\n            'id': comment.get('id'),\n            'text': comment['text'],\n            'timestamp': parse_iso8601(comment.get('created_at')),\n        } for comment in video_data.get('comments', {}).get('data', [])]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_data['caption'],\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnail_url'),\n            'duration': float_or_none(video_data.get('duration'), 1000),\n            'timestamp': parse_iso8601(video_data.get('publish_at')),\n            'like_count': video_data.get('likes', {}).get('total'),\n            'comment_count': video_data.get('comments', {}).get('total'),\n            'view_count': video_data.get('views'),\n            'comments': comments,\n        }",
        "begin_line": 91,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_stream_info#153",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_stream_info(self, stream_info)",
        "snippet": "    def _extract_stream_info(self, stream_info):\n        broadcast_id = compat_str(stream_info['broadcast_id'])\n        is_live = stream_info.get('is_live')\n\n        formats = []\n        smil_url = stream_info.get('play_url')\n        if smil_url:\n            formats.extend(self._extract_smil_formats(smil_url, broadcast_id))\n\n        m3u8_url = stream_info.get('m3u8_url')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, broadcast_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        rtsp_url = stream_info.get('rtsp_url')\n        if rtsp_url:\n            formats.append({\n                'url': rtsp_url,\n                'format_id': 'rtsp',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': broadcast_id,\n            'formats': formats,\n            'title': self._live_title(stream_info['stream_title']) if is_live else stream_info['stream_title'],\n            'thumbnail': stream_info.get('thumbnail_url'),\n            'is_live': is_live,\n        }",
        "begin_line": 153,
        "end_line": 182,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_event#184",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_event(self, event_data)",
        "snippet": "    def _extract_event(self, event_data):\n        event_id = compat_str(event_data['id'])\n        account_id = compat_str(event_data['owner_account_id'])\n        feed_root_url = self._API_URL_TEMPLATE % (account_id, event_id) + '/feed.json'\n\n        stream_info = event_data.get('stream_info')\n        if stream_info:\n            return self._extract_stream_info(stream_info)\n\n        last_video = None\n        entries = []\n        for i in itertools.count(1):\n            if last_video is None:\n                info_url = feed_root_url\n            else:\n                info_url = '{root}?&id={id}&newer=-1&type=video'.format(\n                    root=feed_root_url, id=last_video)\n            videos_info = self._download_json(\n                info_url, event_id, 'Downloading page {0}'.format(i))['data']\n            videos_info = [v['data'] for v in videos_info if v['type'] == 'video']\n            if not videos_info:\n                break\n            for v in videos_info:\n                v_id = compat_str(v['id'])\n                entries.append(self.url_result(\n                    'http://livestream.com/accounts/%s/events/%s/videos/%s' % (account_id, event_id, v_id),\n                    'Livestream', v_id, v.get('caption')))\n            last_video = videos_info[-1]['id']\n        return self.playlist_result(entries, event_id, event_data['full_name'])",
        "begin_line": 184,
        "end_line": 212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._real_extract#214",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        event = mobj.group('event_id') or mobj.group('event_name')\n        account = mobj.group('account_id') or mobj.group('account_name')\n        api_url = self._API_URL_TEMPLATE % (account, event)\n        if video_id:\n            video_data = self._download_json(\n                api_url + '/videos/%s' % video_id, video_id)\n            return self._extract_video_info(video_data)\n        else:\n            event_data = self._download_json(api_url, video_id)\n            return self._extract_event(event_data)",
        "begin_line": 214,
        "end_line": 226,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video_info#257",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video_info(self, user, video_id)",
        "snippet": "    def _extract_video_info(self, user, video_id):\n        api_url = 'http://x%sx.api.channel.livestream.com/2.0/clipdetails?extendedInfo=true&id=%s' % (user, video_id)\n        info = self._download_xml(api_url, video_id)\n\n        item = info.find('channel').find('item')\n        title = xpath_text(item, 'title')\n        media_ns = {'media': 'http://search.yahoo.com/mrss'}\n        thumbnail_url = xpath_attr(\n            item, xpath_with_ns('media:thumbnail', media_ns), 'url')\n        duration = float_or_none(xpath_attr(\n            item, xpath_with_ns('media:content', media_ns), 'duration'))\n        ls_ns = {'ls': 'http://api.channel.livestream.com/2.0'}\n        view_count = int_or_none(xpath_text(\n            item, xpath_with_ns('ls:viewsCount', ls_ns)))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 257,
        "end_line": 278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video_formats#280",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video_formats(self, video_data, video_id)",
        "snippet": "    def _extract_video_formats(self, video_data, video_id):\n        formats = []\n\n        progressive_url = video_data.get('progressiveUrl')\n        if progressive_url:\n            formats.append({\n                'url': progressive_url,\n                'format_id': 'http',\n            })\n\n        m3u8_url = video_data.get('httpUrl')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        rtsp_url = video_data.get('rtspUrl')\n        if rtsp_url:\n            formats.append({\n                'url': rtsp_url,\n                'format_id': 'rtsp',\n            })\n\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 280,
        "end_line": 304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder#306",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder(self, url, folder_id)",
        "snippet": "    def _extract_folder(self, url, folder_id):\n        webpage = self._download_webpage(url, folder_id)\n        paths = orderedSet(re.findall(\n            r'''(?x)(?:\n                <li\\s+class=\"folder\">\\s*<a\\s+href=\"|\n                <a\\s+href=\"(?=https?://livestre\\.am/)\n            )([^\"]+)\"''', webpage))\n\n        entries = [{\n            '_type': 'url',\n            'url': compat_urlparse.urljoin(url, p),\n        } for p in paths]\n\n        return self.playlist_result(entries, folder_id)",
        "begin_line": 306,
        "end_line": 319,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract#321",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        url_type = mobj.group('type')\n        content_id = mobj.group('id')\n        if url_type == 'folder':\n            return self._extract_folder(url, content_id)\n        else:\n            # this url is used on mobile devices\n            stream_url = 'http://x%sx.api.channel.livestream.com/3.0/getstream.json' % user\n            info = {}\n            if content_id:\n                stream_url += '?id=%s' % content_id\n                info = self._extract_video_info(user, content_id)\n            else:\n                content_id = user\n                webpage = self._download_webpage(url, content_id)\n                info = {\n                    'title': self._og_search_title(webpage),\n                    'description': self._og_search_description(webpage),\n                    'thumbnail': self._search_regex(r'channelLogo.src\\s*=\\s*\"([^\"]+)\"', webpage, 'thumbnail', None),\n                }\n            video_data = self._download_json(stream_url, content_id)\n            is_live = video_data.get('isLive')\n            info.update({\n                'id': content_id,\n                'title': self._live_title(info['title']) if is_live else info['title'],\n                'formats': self._extract_video_formats(video_data, content_id),\n                'is_live': is_live,\n            })\n            return info",
        "begin_line": 321,
        "end_line": 351,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract#361",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamShortenerIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        webpage = self._download_webpage(url, id)\n\n        return {\n            '_type': 'url',\n            'url': self._og_search_url(webpage),\n        }",
        "begin_line": 361,
        "end_line": 369,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lnkgo.LnkGoIE._real_extract#52",
        "src_path": "youtube_dl/extractor/lnkgo.py",
        "class_name": "youtube_dl.extractor.lnkgo.LnkGoIE",
        "signature": "youtube_dl.extractor.lnkgo.LnkGoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, display_id, 'Downloading player webpage')\n\n        video_id = self._search_regex(\n            r'data-ep=\"([^\"]+)\"', webpage, 'video ID')\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"[^\"]*meta-item[^\"]*air-time[^\"]*\">.*?<strong>([^<]+)</strong>', webpage, 'upload date', fatal=False))\n\n        thumbnail_w = int_or_none(\n            self._og_search_property('image:width', webpage, 'thumbnail width', fatal=False))\n        thumbnail_h = int_or_none(\n            self._og_search_property('image:height', webpage, 'thumbnail height', fatal=False))\n        thumbnail = {\n            'url': self._og_search_thumbnail(webpage),\n        }\n        if thumbnail_w and thumbnail_h:\n            thumbnail.update({\n                'width': thumbnail_w,\n                'height': thumbnail_h,\n            })\n\n        config = self._parse_json(self._search_regex(\n            r'episodePlayer\\((\\{.*?\\}),\\s*\\{', webpage, 'sources'), video_id)\n\n        if config.get('pGeo'):\n            self.report_warning(\n                'This content might not be available in your country due to copyright reasons')\n\n        formats = [{\n            'format_id': 'hls',\n            'ext': 'mp4',\n            'url': config['EpisodeVideoLink_HLS'],\n        }]\n\n        m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<play_path>.+)$', config['EpisodeVideoLink'])\n        if m:\n            formats.append({\n                'format_id': 'rtmp',\n                'ext': 'flv',\n                'url': m.group('url'),\n                'play_path': m.group('play_path'),\n                'page_url': url,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnails': [thumbnail],\n            'duration': int_or_none(config.get('VideoTime')),\n            'description': description,\n            'age_limit': self._AGE_LIMITS.get(config.get('PGRating'), 0),\n            'upload_date': upload_date,\n        }",
        "begin_line": 52,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.localnews8.LocalNews8IE._real_extract#27",
        "src_path": "youtube_dl/extractor/localnews8.py",
        "class_name": "youtube_dl.extractor.localnews8.LocalNews8IE",
        "signature": "youtube_dl.extractor.localnews8.LocalNews8IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        partner_id = self._search_regex(\n            r'partnerId\\s*[:=]\\s*([\"\\'])(?P<id>\\d+)\\1',\n            webpage, 'partner id', group='id')\n        kaltura_id = self._search_regex(\n            r'videoIdString\\s*[:=]\\s*([\"\\'])kaltura:(?P<id>[0-9a-z_]+)\\1',\n            webpage, 'videl id', group='id')\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'kaltura:%s:%s' % (partner_id, kaltura_id),\n            'ie_key': 'Kaltura',\n            'id': video_id,\n            'display_id': display_id,\n        }",
        "begin_line": 27,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lovehomeporn.LoveHomePornIE._real_extract#25",
        "src_path": "youtube_dl/extractor/lovehomeporn.py",
        "class_name": "youtube_dl.extractor.lovehomeporn.LoveHomePornIE",
        "signature": "youtube_dl.extractor.lovehomeporn.LoveHomePornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        info = self._extract_nuevo(\n            'http://lovehomeporn.com/media/nuevo/config.php?key=%s' % video_id,\n            video_id)\n        info.update({\n            'display_id': display_id,\n            'age_limit': 18\n        })\n        return info",
        "begin_line": 25,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lrt.LRTIE._real_extract#46",
        "src_path": "youtube_dl/extractor/lrt.py",
        "class_name": "youtube_dl.extractor.lrt.LRTIE",
        "signature": "youtube_dl.extractor.lrt.LRTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_end(self._og_search_title(webpage), ' - LRT')\n\n        formats = []\n        for _, file_url in re.findall(\n                r'file\\s*:\\s*([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', webpage):\n            ext = determine_ext(file_url)\n            if ext not in ('m3u8', 'mp3'):\n                continue\n            # mp3 served as m3u8 produces stuttered media file\n            if ext == 'm3u8' and '.mp3' in file_url:\n                continue\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    file_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    fatal=False))\n            elif ext == 'mp3':\n                formats.append({\n                    'url': file_url,\n                    'vcodec': 'none',\n                })\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n        duration = parse_duration(self._search_regex(\n            r'var\\s+record_len\\s*=\\s*([\"\\'])(?P<duration>[0-9]+:[0-9]+:[0-9]+)\\1',\n            webpage, 'duration', default=None, group='duration'))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<div[^>]+class=([\"\\']).*?record-desc-seen.*?\\1[^>]*>(?P<count>.+?)</div>',\n            webpage, 'view count', fatal=False, group='count'))\n        like_count = int_or_none(self._search_regex(\n            r'<span[^>]+id=([\"\\'])flikesCount.*?\\1>(?P<count>\\d+)<',\n            webpage, 'like count', fatal=False, group='count'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n        }",
        "begin_line": 46,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._real_initialize#25",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._check_error#29",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._check_error(json_string, key_or_keys)",
        "snippet": "    def _check_error(json_string, key_or_keys):\n        keys = [key_or_keys] if isinstance(key_or_keys, compat_str) else key_or_keys\n        for key in keys:\n            error = json_string.get(key)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)",
        "begin_line": 29,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._login_step#36",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._login_step(self, form_html, fallback_action_url, extra_form_data, note, referrer_url)",
        "snippet": "    def _login_step(self, form_html, fallback_action_url, extra_form_data, note, referrer_url):\n        action_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', form_html,\n            'post url', default=fallback_action_url, group='url')\n\n        if not action_url.startswith('http'):\n            action_url = compat_urlparse.urljoin(self._SIGNIN_URL, action_url)\n\n        form_data = self._hidden_inputs(form_html)\n        form_data.update(extra_form_data)\n\n        try:\n            response = self._download_json(\n                action_url, None, note,\n                data=urlencode_postdata(form_data),\n                headers={\n                    'Referer': referrer_url,\n                    'X-Requested-With': 'XMLHttpRequest',\n                })\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 500:\n                response = self._parse_json(e.cause.read().decode('utf-8'), None)\n                self._check_error(response, ('email', 'password'))\n            raise\n\n        self._check_error(response, 'ErrorMessage')\n\n        return response, action_url",
        "begin_line": 36,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaBaseIE._login#65",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaBaseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaBaseIE._login(self)",
        "snippet": "    def _login(self):\n        username, password = self._get_login_info()\n        if username is None:\n            return\n\n        # Step 1: download signin page\n        signin_page = self._download_webpage(\n            self._SIGNIN_URL, None, 'Downloading signin page')\n\n        # Already logged in\n        if any(re.search(p, signin_page) for p in (\n                r'isLoggedIn\\s*:\\s*true', r'logout\\.aspx', r'>Log out<')):\n            return\n\n        # Step 2: submit email\n        signin_form = self._search_regex(\n            r'(?s)(<form[^>]+data-form-name=[\"\\']signin[\"\\'][^>]*>.+?</form>)',\n            signin_page, 'signin form')\n        signin_page, signin_url = self._login_step(\n            signin_form, self._PASSWORD_URL, {'email': username},\n            'Submitting email', self._SIGNIN_URL)\n\n        # Step 3: submit password\n        password_form = signin_page['body']\n        self._login_step(\n            password_form, self._USER_URL, {'email': username, 'password': password},\n            'Submitting password', signin_url)",
        "begin_line": 65,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._raise_unavailable#115",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._raise_unavailable(self, video_id)",
        "snippet": "    def _raise_unavailable(self, video_id):\n        self.raise_login_required(\n            'Video %s is only available for members' % video_id)",
        "begin_line": 115,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_extract#119",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        course_id = mobj.group('course_id')\n\n        query = {\n            'videoId': video_id,\n            'type': 'video',\n        }\n\n        video = self._download_json(\n            'https://www.lynda.com/ajax/player', video_id,\n            'Downloading video JSON', fatal=False, query=query)\n\n        # Fallback scenario\n        if not video:\n            query['courseId'] = course_id\n\n            play = self._download_json(\n                'https://www.lynda.com/ajax/course/%s/%s/play'\n                % (course_id, video_id), video_id, 'Downloading play JSON')\n\n            if not play:\n                self._raise_unavailable(video_id)\n\n            formats = []\n            for formats_dict in play:\n                urls = formats_dict.get('urls')\n                if not isinstance(urls, dict):\n                    continue\n                cdn = formats_dict.get('name')\n                for format_id, format_url in urls.items():\n                    if not format_url:\n                        continue\n                    formats.append({\n                        'url': format_url,\n                        'format_id': '%s-%s' % (cdn, format_id) if cdn else format_id,\n                        'height': int_or_none(format_id),\n                    })\n            self._sort_formats(formats)\n\n            conviva = self._download_json(\n                'https://www.lynda.com/ajax/player/conviva', video_id,\n                'Downloading conviva JSON', query=query)\n\n            return {\n                'id': video_id,\n                'title': conviva['VideoTitle'],\n                'description': conviva.get('VideoDescription'),\n                'release_year': int_or_none(conviva.get('ReleaseYear')),\n                'duration': int_or_none(conviva.get('Duration')),\n                'creator': conviva.get('Author'),\n                'formats': formats,\n            }\n\n        if 'Status' in video:\n            raise ExtractorError(\n                'lynda returned error: %s' % video['Message'], expected=True)\n\n        if video.get('HasAccess') is False:\n            self._raise_unavailable(video_id)\n\n        video_id = compat_str(video.get('ID') or video_id)\n        duration = int_or_none(video.get('DurationInSeconds'))\n        title = video['Title']\n\n        formats = []\n\n        fmts = video.get('Formats')\n        if fmts:\n            formats.extend([{\n                'url': f['Url'],\n                'ext': f.get('Extension'),\n                'width': int_or_none(f.get('Width')),\n                'height': int_or_none(f.get('Height')),\n                'filesize': int_or_none(f.get('FileSize')),\n                'format_id': compat_str(f.get('Resolution')) if f.get('Resolution') else None,\n            } for f in fmts if f.get('Url')])\n\n        prioritized_streams = video.get('PrioritizedStreams')\n        if prioritized_streams:\n            for prioritized_stream_id, prioritized_stream in prioritized_streams.items():\n                formats.extend([{\n                    'url': video_url,\n                    'height': int_or_none(format_id),\n                    'format_id': '%s-%s' % (prioritized_stream_id, format_id),\n                } for format_id, video_url in prioritized_stream.items()])\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        subtitles = self.extract_subtitles(video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'subtitles': subtitles,\n            'formats': formats\n        }",
        "begin_line": 119,
        "end_line": 218,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles#220",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles(self, subs)",
        "snippet": "    def _fix_subtitles(self, subs):\n        srt = ''\n        seq_counter = 0\n        for pos in range(0, len(subs) - 1):\n            seq_current = subs[pos]\n            m_current = re.match(self._TIMECODE_REGEX, seq_current['Timecode'])\n            if m_current is None:\n                continue\n            seq_next = subs[pos + 1]\n            m_next = re.match(self._TIMECODE_REGEX, seq_next['Timecode'])\n            if m_next is None:\n                continue\n            appear_time = m_current.group('timecode')\n            disappear_time = m_next.group('timecode')\n            text = seq_current['Caption'].strip()\n            if text:\n                seq_counter += 1\n                srt += '%s\\r\\n%s --> %s\\r\\n%s\\r\\n\\r\\n' % (seq_counter, appear_time, disappear_time, text)\n        if srt:\n            return srt",
        "begin_line": 220,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._get_subtitles#241",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._get_subtitles(self, video_id)",
        "snippet": "    def _get_subtitles(self, video_id):\n        url = 'https://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id\n        subs = self._download_json(url, None, False)\n        if subs:\n            return {'en': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]}\n        else:\n            return {}",
        "begin_line": 241,
        "end_line": 247,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract#258",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaCourseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n        course_id = mobj.group('courseid')\n\n        item_template = 'https://www.lynda.com/%s/%%s-4.html' % course_path\n\n        course = self._download_json(\n            'https://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,\n            course_id, 'Downloading course JSON', fatal=False)\n\n        if not course:\n            webpage = self._download_webpage(url, course_id)\n            entries = [\n                self.url_result(\n                    item_template % video_id, ie=LyndaIE.ie_key(),\n                    video_id=video_id)\n                for video_id in re.findall(\n                    r'data-video-id=[\"\\'](\\d+)', webpage)]\n            return self.playlist_result(\n                entries, course_id,\n                self._og_search_title(webpage, fatal=False),\n                self._og_search_description(webpage))\n\n        if course.get('Status') == 'NotFound':\n            raise ExtractorError(\n                'Course %s does not exist' % course_id, expected=True)\n\n        unaccessible_videos = 0\n        entries = []\n\n        # Might want to extract videos right here from video['Formats'] as it seems 'Formats' is not provided\n        # by single video API anymore\n\n        for chapter in course['Chapters']:\n            for video in chapter.get('Videos', []):\n                if video.get('HasAccess') is False:\n                    unaccessible_videos += 1\n                    continue\n                video_id = video.get('ID')\n                if video_id:\n                    entries.append({\n                        '_type': 'url_transparent',\n                        'url': item_template % video_id,\n                        'ie_key': LyndaIE.ie_key(),\n                        'chapter': chapter.get('Title'),\n                        'chapter_number': int_or_none(chapter.get('ChapterIndex')),\n                        'chapter_id': compat_str(chapter.get('ID')),\n                    })\n\n        if unaccessible_videos > 0:\n            self._downloader.report_warning(\n                '%s videos are only available for members (or paid members) and will not be downloaded. '\n                % unaccessible_videos + self._ACCOUNT_CREDENTIALS_HINT)\n\n        course_title = course.get('Title')\n        course_description = course.get('Description')\n\n        return self.playlist_result(entries, course_id, course_title, course_description)",
        "begin_line": 258,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.m6.M6IE._real_extract#23",
        "src_path": "youtube_dl/extractor/m6.py",
        "class_name": "youtube_dl.extractor.m6.M6IE",
        "signature": "youtube_dl.extractor.m6.M6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self.url_result('6play:%s' % video_id, 'SixPlay', video_id)",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract#22",
        "src_path": "youtube_dl/extractor/macgamestore.py",
        "class_name": "youtube_dl.extractor.macgamestore.MacGameStoreIE",
        "signature": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, video_id, 'Downloading trailer page')\n\n        if '>Missing Media<' in webpage:\n            raise ExtractorError(\n                'Trailer %s does not exist' % video_id, expected=True)\n\n        video_title = self._html_search_regex(\n            r'<title>MacGameStore: (.*?) Trailer</title>', webpage, 'title')\n\n        video_url = self._html_search_regex(\n            r'(?s)<div\\s+id=\"video-player\".*?href=\"([^\"]+)\"\\s*>',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mailru.MailRuIE._real_extract#71",
        "src_path": "youtube_dl/extractor/mailru.py",
        "class_name": "youtube_dl.extractor.mailru.MailRuIE",
        "signature": "youtube_dl.extractor.mailru.MailRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('idv1')\n\n        if not video_id:\n            video_id = mobj.group('idv2prefix') + mobj.group('idv2suffix')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_data = None\n\n        page_config = self._parse_json(self._search_regex(\n            r'(?s)<script[^>]+class=\"sp-video__page-config\"[^>]*>(.+?)</script>',\n            webpage, 'page config', default='{}'), video_id, fatal=False)\n        if page_config:\n            meta_url = page_config.get('metaUrl') or page_config.get('video', {}).get('metaUrl')\n            if meta_url:\n                video_data = self._download_json(\n                    meta_url, video_id, 'Downloading video meta JSON', fatal=False)\n\n        # Fallback old approach\n        if not video_data:\n            video_data = self._download_json(\n                'http://api.video.mail.ru/videos/%s.json?new=1' % video_id,\n                video_id, 'Downloading video JSON')\n\n        formats = []\n        for f in video_data['videos']:\n            video_url = f.get('url')\n            if not video_url:\n                continue\n            format_id = f.get('key')\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None)) if format_id else None\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        meta_data = video_data['meta']\n        title = remove_end(meta_data['title'], '.mp4')\n\n        author = video_data.get('author')\n        uploader = author.get('name')\n        uploader_id = author.get('id') or author.get('email')\n        view_count = int_or_none(video_data.get('viewsCount') or video_data.get('views_count'))\n\n        acc_id = meta_data.get('accId')\n        item_id = meta_data.get('itemId')\n        content_id = '%s_%s' % (acc_id, item_id) if acc_id and item_id else video_id\n\n        thumbnail = meta_data.get('poster')\n        duration = int_or_none(meta_data.get('duration'))\n        timestamp = int_or_none(meta_data.get('timestamp'))\n\n        return {\n            'id': content_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 71,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.makerschannel.MakersChannelIE._real_extract#23",
        "src_path": "youtube_dl/extractor/makerschannel.py",
        "class_name": "youtube_dl.extractor.makerschannel.MakersChannelIE",
        "signature": "youtube_dl.extractor.makerschannel.MakersChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        id_type, url_id = re.match(self._VALID_URL, url).groups()\n        webpage = self._download_webpage(url, url_id)\n        video_data = self._html_search_regex(r'<div([^>]+data-%s-id=\"%s\"[^>]+)>' % (id_type, url_id), webpage, 'video data')\n\n        def extract_data_val(attr, fatal=False):\n            return self._html_search_regex(r'data-%s\\s*=\\s*\"([^\"]+)\"' % attr, video_data, attr, fatal=fatal)\n        minoto_id = self._search_regex(r'/id/([a-zA-Z0-9]+)', extract_data_val('video-src', True), 'minoto id')\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'minoto:%s' % minoto_id,\n            'id': extract_data_val('video-id', True),\n            'title': extract_data_val('title', True),\n            'description': extract_data_val('description'),\n            'thumbnail': extract_data_val('image'),\n            'uploader': extract_data_val('channel'),\n        }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.makertv.MakerTVIE._real_extract#22",
        "src_path": "youtube_dl/extractor/makertv.py",
        "class_name": "youtube_dl.extractor.makertv.MakerTVIE",
        "signature": "youtube_dl.extractor.makertv.MakerTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        jwplatform_id = self._search_regex(r'jw_?id=\"([^\"]+)\"', webpage, 'jwplatform id')\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': 'jwplatform:%s' % jwplatform_id,\n            'ie_key': 'JWPlatform',\n        }",
        "begin_line": 22,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mangomolo.MangomoloBaseIE._get_real_id#14",
        "src_path": "youtube_dl/extractor/mangomolo.py",
        "class_name": "youtube_dl.extractor.mangomolo.MangomoloBaseIE",
        "signature": "youtube_dl.extractor.mangomolo.MangomoloBaseIE._get_real_id(self, page_id)",
        "snippet": "    def _get_real_id(self, page_id):\n        return page_id",
        "begin_line": 14,
        "end_line": 15,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mangomolo.MangomoloBaseIE._real_extract#17",
        "src_path": "youtube_dl/extractor/mangomolo.py",
        "class_name": "youtube_dl.extractor.mangomolo.MangomoloBaseIE",
        "signature": "youtube_dl.extractor.mangomolo.MangomoloBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._get_real_id(self._match_id(url))\n        webpage = self._download_webpage(url, page_id)\n        hidden_inputs = self._hidden_inputs(webpage)\n        m3u8_entry_protocol = 'm3u8' if self._IS_LIVE else 'm3u8_native'\n\n        format_url = self._html_search_regex(\n            [\n                r'file\\s*:\\s*\"(https?://[^\"]+?/playlist.m3u8)',\n                r'<a[^>]+href=\"(rtsp://[^\"]+)\"'\n            ], webpage, 'format url')\n        formats = self._extract_wowza_formats(\n            format_url, page_id, m3u8_entry_protocol, ['smil'])\n        self._sort_formats(formats)\n\n        return {\n            'id': page_id,\n            'title': self._live_title(page_id) if self._IS_LIVE else page_id,\n            'uploader_id': hidden_inputs.get('userid'),\n            'duration': int_or_none(hidden_inputs.get('duration')),\n            'is_live': self._IS_LIVE,\n            'formats': formats,\n        }",
        "begin_line": 17,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mangomolo.MangomoloLiveIE._get_real_id#53",
        "src_path": "youtube_dl/extractor/mangomolo.py",
        "class_name": "youtube_dl.extractor.mangomolo.MangomoloLiveIE",
        "signature": "youtube_dl.extractor.mangomolo.MangomoloLiveIE._get_real_id(self, page_id)",
        "snippet": "    def _get_real_id(self, page_id):\n        return base64.b64decode(compat_urllib_parse_unquote(page_id).encode()).decode()",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.matchtv.MatchTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/matchtv.py",
        "class_name": "youtube_dl.extractor.matchtv.MatchTVIE",
        "signature": "youtube_dl.extractor.matchtv.MatchTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = 'matchtv-live'\n        video_url = self._download_json(\n            'http://player.matchtv.ntvplus.tv/player/smil', video_id,\n            query={\n                'ts': '',\n                'quality': 'SD',\n                'contentId': '561d2c0df7159b37178b4567',\n                'sign': '',\n                'includeHighlights': '0',\n                'userId': '',\n                'sessionId': random.randint(1, 1000000000),\n                'contentType': 'channel',\n                'timeShift': '0',\n                'platform': 'portal',\n            },\n            headers={\n                'Referer': 'http://player.matchtv.ntvplus.tv/embed-player/NTVEmbedPlayer.swf',\n            })['data']['videoUrl']\n        f4m_url = xpath_text(self._download_xml(video_url, video_id), './to')\n        formats = self._extract_f4m_formats(f4m_url, video_id)\n        self._sort_formats(formats)\n        return {\n            'id': video_id,\n            'title': self._live_title('\u041c\u0430\u0442\u0447 \u0422\u0412 - \u041f\u0440\u044f\u043c\u043e\u0439 \u044d\u0444\u0438\u0440'),\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mdr.MDRIE._real_extract#80",
        "src_path": "youtube_dl/extractor/mdr.py",
        "class_name": "youtube_dl.extractor.mdr.MDRIE",
        "signature": "youtube_dl.extractor.mdr.MDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        data_url = self._search_regex(\n            r'(?:dataURL|playerXml(?:[\"\\'])?)\\s*:\\s*([\"\\'])(?P<url>.+?-avCustom\\.xml)\\1',\n            webpage, 'data url', group='url').replace(r'\\/', '/')\n\n        doc = self._download_xml(\n            compat_urlparse.urljoin(url, data_url), video_id)\n\n        title = xpath_text(doc, ['./title', './broadcast/broadcastName'], 'title', fatal=True)\n\n        formats = []\n        processed_urls = []\n        for asset in doc.findall('./assets/asset'):\n            for source in (\n                    'progressiveDownload',\n                    'dynamicHttpStreamingRedirector',\n                    'adaptiveHttpStreamingRedirector'):\n                url_el = asset.find('./%sUrl' % source)\n                if url_el is None:\n                    continue\n\n                video_url = url_el.text\n                if video_url in processed_urls:\n                    continue\n\n                processed_urls.append(video_url)\n\n                vbr = int_or_none(xpath_text(asset, './bitrateVideo', 'vbr'), 1000)\n                abr = int_or_none(xpath_text(asset, './bitrateAudio', 'abr'), 1000)\n\n                ext = determine_ext(url_el.text)\n                if ext == 'm3u8':\n                    url_formats = self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                        preference=0, m3u8_id='HLS', fatal=False)\n                elif ext == 'f4m':\n                    url_formats = self._extract_f4m_formats(\n                        video_url + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id,\n                        preference=0, f4m_id='HDS', fatal=False)\n                else:\n                    media_type = xpath_text(asset, './mediaType', 'media type', default='MP4')\n                    vbr = int_or_none(xpath_text(asset, './bitrateVideo', 'vbr'), 1000)\n                    abr = int_or_none(xpath_text(asset, './bitrateAudio', 'abr'), 1000)\n                    filesize = int_or_none(xpath_text(asset, './fileSize', 'file size'))\n\n                    f = {\n                        'url': video_url,\n                        'format_id': '%s-%d' % (media_type, vbr or abr),\n                        'filesize': filesize,\n                        'abr': abr,\n                        'preference': 1,\n                    }\n\n                    if vbr:\n                        width = int_or_none(xpath_text(asset, './frameWidth', 'width'))\n                        height = int_or_none(xpath_text(asset, './frameHeight', 'height'))\n                        f.update({\n                            'vbr': vbr,\n                            'width': width,\n                            'height': height,\n                        })\n\n                    url_formats = [f]\n\n                if not url_formats:\n                    continue\n\n                if not vbr:\n                    for f in url_formats:\n                        abr = f.get('tbr') or abr\n                        if 'tbr' in f:\n                            del f['tbr']\n                        f.update({\n                            'abr': abr,\n                            'vcodec': 'none',\n                        })\n\n                formats.extend(url_formats)\n\n        self._sort_formats(formats)\n\n        description = xpath_text(doc, './broadcast/broadcastDescription', 'description')\n        timestamp = parse_iso8601(\n            xpath_text(\n                doc, [\n                    './broadcast/broadcastDate',\n                    './broadcast/broadcastStartDate',\n                    './broadcast/broadcastEndDate'],\n                'timestamp', default=None))\n        duration = parse_duration(xpath_text(doc, './duration', 'duration'))\n        uploader = xpath_text(doc, './rights', 'uploader')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 80,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.medialaan.MedialaanIE._real_initialize#106",
        "src_path": "youtube_dl/extractor/medialaan.py",
        "class_name": "youtube_dl.extractor.medialaan.MedialaanIE",
        "signature": "youtube_dl.extractor.medialaan.MedialaanIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._logged_in = False",
        "begin_line": 106,
        "end_line": 107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.medialaan.MedialaanIE._login#109",
        "src_path": "youtube_dl/extractor/medialaan.py",
        "class_name": "youtube_dl.extractor.medialaan.MedialaanIE",
        "signature": "youtube_dl.extractor.medialaan.MedialaanIE._login(self)",
        "snippet": "    def _login(self):\n        username, password = self._get_login_info()\n        if username is None:\n            self.raise_login_required()\n\n        auth_data = {\n            'APIKey': self._APIKEY,\n            'sdk': 'js_6.1',\n            'format': 'json',\n            'loginID': username,\n            'password': password,\n        }\n\n        auth_info = self._download_json(\n            'https://accounts.eu1.gigya.com/accounts.login', None,\n            note='Logging in', errnote='Unable to log in',\n            data=urlencode_postdata(auth_data))\n\n        error_message = auth_info.get('errorDetails') or auth_info.get('errorMessage')\n        if error_message:\n            raise ExtractorError(\n                'Unable to login: %s' % error_message, expected=True)\n\n        self._uid = auth_info['UID']\n        self._uid_signature = auth_info['UIDSignature']\n        self._signature_timestamp = auth_info['signatureTimestamp']\n\n        self._logged_in = True",
        "begin_line": 109,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.medialaan.MedialaanIE._real_extract#138",
        "src_path": "youtube_dl/extractor/medialaan.py",
        "class_name": "youtube_dl.extractor.medialaan.MedialaanIE",
        "signature": "youtube_dl.extractor.medialaan.MedialaanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, site_id = mobj.group('id', 'site_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        config = self._parse_json(\n            self._search_regex(\n                r'videoJSConfig\\s*=\\s*JSON\\.parse\\(\\'({.+?})\\'\\);',\n                webpage, 'config', default='{}'), video_id,\n            transform_source=lambda s: s.replace(\n                '\\\\\\\\', '\\\\').replace(r'\\\"', '\"').replace(r\"\\'\", \"'\"))\n\n        vod_id = config.get('vodId') or self._search_regex(\n            (r'\\\\\"vodId\\\\\"\\s*:\\s*\\\\\"(.+?)\\\\\"',\n             r'<[^>]+id=[\"\\']vod-(\\d+)'),\n            webpage, 'video_id', default=None)\n\n        # clip, no authentication required\n        if not vod_id:\n            player = self._parse_json(\n                self._search_regex(\n                    r'vmmaplayer\\(({.+?})\\);', webpage, 'vmma player',\n                    default=''),\n                video_id, transform_source=lambda s: '[%s]' % s, fatal=False)\n            if player:\n                video = player[-1]\n                if video['videoUrl'] in ('http', 'https'):\n                    return self.url_result(video['url'], MedialaanIE.ie_key())\n                info = {\n                    'id': video_id,\n                    'url': video['videoUrl'],\n                    'title': video['title'],\n                    'thumbnail': video.get('imageUrl'),\n                    'timestamp': int_or_none(video.get('createdDate')),\n                    'duration': int_or_none(video.get('duration')),\n                }\n            else:\n                info = self._parse_html5_media_entries(\n                    url, webpage, video_id, m3u8_id='hls')[0]\n                info.update({\n                    'id': video_id,\n                    'title': self._html_search_meta('description', webpage),\n                    'duration': parse_duration(self._html_search_meta('duration', webpage)),\n                })\n        # vod, authentication required\n        else:\n            if not self._logged_in:\n                self._login()\n\n            settings = self._parse_json(\n                self._search_regex(\n                    r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n                    webpage, 'drupal settings', default='{}'),\n                video_id)\n\n            def get(container, item):\n                return try_get(\n                    settings, lambda x: x[container][item],\n                    compat_str) or self._search_regex(\n                    r'\"%s\"\\s*:\\s*\"([^\"]+)' % item, webpage, item,\n                    default=None)\n\n            app_id = get('vod', 'app_id') or self._SITE_TO_APP_ID.get(site_id, 'vtm_watch')\n            sso = get('vod', 'gigyaDatabase') or 'vtm-sso'\n\n            data = self._download_json(\n                'http://vod.medialaan.io/api/1.0/item/%s/video' % vod_id,\n                video_id, query={\n                    'app_id': app_id,\n                    'user_network': sso,\n                    'UID': self._uid,\n                    'UIDSignature': self._uid_signature,\n                    'signatureTimestamp': self._signature_timestamp,\n                })\n\n            formats = self._extract_m3u8_formats(\n                data['response']['uri'], video_id, entry_protocol='m3u8_native',\n                ext='mp4', m3u8_id='hls')\n\n            self._sort_formats(formats)\n\n            info = {\n                'id': vod_id,\n                'formats': formats,\n            }\n\n            api_key = get('vod', 'apiKey')\n            channel = get('medialaanGigya', 'channel')\n\n            if api_key:\n                videos = self._download_json(\n                    'http://vod.medialaan.io/vod/v2/videos', video_id, fatal=False,\n                    query={\n                        'channels': channel,\n                        'ids': vod_id,\n                        'limit': 1,\n                        'apikey': api_key,\n                    })\n                if videos:\n                    video = try_get(\n                        videos, lambda x: x['response']['videos'][0], dict)\n                    if video:\n                        def get(container, item, expected_type=None):\n                            return try_get(\n                                video, lambda x: x[container][item], expected_type)\n\n                        def get_string(container, item):\n                            return get(container, item, compat_str)\n\n                        info.update({\n                            'series': get_string('program', 'title'),\n                            'season': get_string('season', 'title'),\n                            'season_number': int_or_none(get('season', 'number')),\n                            'season_id': get_string('season', 'id'),\n                            'episode': get_string('episode', 'title'),\n                            'episode_number': int_or_none(get('episode', 'number')),\n                            'episode_id': get_string('episode', 'id'),\n                            'duration': int_or_none(\n                                video.get('duration')) or int_or_none(\n                                video.get('durationMillis'), scale=1000),\n                            'title': get_string('episode', 'title'),\n                            'description': get_string('episode', 'text'),\n                            'timestamp': unified_timestamp(get_string(\n                                'publication', 'begin')),\n                        })\n\n            if not info.get('title'):\n                info['title'] = try_get(\n                    config, lambda x: x['videoConfig']['title'],\n                    compat_str) or self._html_search_regex(\n                    r'\\\\\"title\\\\\"\\s*:\\s*\\\\\"(.+?)\\\\\"', webpage, 'title',\n                    default=None) or self._og_search_title(webpage)\n\n        if not info.get('description'):\n            info['description'] = self._html_search_regex(\n                r'<div[^>]+class=\"field-item\\s+even\">\\s*<p>(.+?)</p>',\n                webpage, 'description', default=None)\n\n        return info",
        "begin_line": 138,
        "end_line": 277,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mediaset.MediasetIE._extract_urls#63",
        "src_path": "youtube_dl/extractor/mediaset.py",
        "class_name": "youtube_dl.extractor.mediaset.MediasetIE",
        "signature": "youtube_dl.extractor.mediaset.MediasetIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [\n            mobj.group('url')\n            for mobj in re.finditer(\n                r'<iframe\\b[^>]+\\bsrc=([\"\\'])(?P<url>https?://(?:www\\.)?video\\.mediaset\\.it/player/playerIFrame(?:Twitter)?\\.shtml\\?.*?\\bid=\\d+.*?)\\1',\n                webpage)]",
        "begin_line": 63,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mediaset.MediasetIE._real_extract#70",
        "src_path": "youtube_dl/extractor/mediaset.py",
        "class_name": "youtube_dl.extractor.mediaset.MediasetIE",
        "signature": "youtube_dl.extractor.mediaset.MediasetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_list = self._download_json(\n            'http://cdnsel01.mediaset.net/GetCdn.aspx',\n            video_id, 'Downloading video CDN JSON', query={\n                'streamid': video_id,\n                'format': 'json',\n            })['videoList']\n\n        formats = []\n        for format_url in video_list:\n            if '.ism' in format_url:\n                formats.extend(self._extract_ism_formats(\n                    format_url, video_id, ism_id='mss', fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': determine_ext(format_url),\n                })\n        self._sort_formats(formats)\n\n        mediainfo = self._download_json(\n            'http://plr.video.mediaset.it/html/metainfo.sjson',\n            video_id, 'Downloading video info JSON', query={\n                'id': video_id,\n            })['video']\n\n        title = mediainfo['title']\n\n        creator = try_get(\n            mediainfo, lambda x: x['brand-info']['publisher'], compat_str)\n        category = try_get(\n            mediainfo, lambda x: x['brand-info']['category'], compat_str)\n        categories = [category] if category else None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': mediainfo.get('short-description'),\n            'thumbnail': mediainfo.get('thumbnail'),\n            'duration': parse_duration(mediainfo.get('duration')),\n            'creator': creator,\n            'upload_date': unified_strdate(mediainfo.get('production-date')),\n            'webpage_url': mediainfo.get('url'),\n            'series': mediainfo.get('brand-value'),\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 70,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.medici.MediciIE._real_extract#27",
        "src_path": "youtube_dl/extractor/medici.py",
        "class_name": "youtube_dl.extractor.medici.MediciIE",
        "signature": "youtube_dl.extractor.medici.MediciIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Sets csrftoken cookie\n        self._download_webpage(url, video_id)\n\n        MEDICI_URL = 'http://www.medici.tv/'\n\n        data = self._download_json(\n            MEDICI_URL, video_id,\n            data=urlencode_postdata({\n                'json': 'true',\n                'page': '/%s' % video_id,\n                'timezone_offset': -420,\n            }), headers={\n                'X-CSRFToken': self._get_cookies(url)['csrftoken'].value,\n                'X-Requested-With': 'XMLHttpRequest',\n                'Referer': MEDICI_URL,\n                'Content-Type': 'application/x-www-form-urlencoded',\n            })\n\n        video = data['video']['videos']['video1']\n\n        title = video.get('nom') or data['title']\n\n        video_id = video.get('id') or video_id\n        formats = self._extract_f4m_formats(\n            update_url_query(video['url_akamai'], {\n                'hdcore': '3.1.0',\n                'plugin=aasp': '3.1.0.43.124',\n            }), video_id, f4m_id='hds')\n\n        description = data.get('meta_description')\n        thumbnail = video.get('url_thumbnail') or data.get('main_image')\n        upload_date = unified_strdate(data['video'].get('date'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.megaphone.MegaphoneIE._real_extract#27",
        "src_path": "youtube_dl/extractor/megaphone.py",
        "class_name": "youtube_dl.extractor.megaphone.MegaphoneIE",
        "signature": "youtube_dl.extractor.megaphone.MegaphoneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_property('audio:title', webpage)\n        author = self._og_search_property('audio:artist', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        episode_json = self._search_regex(r'(?s)var\\s+episode\\s*=\\s*(\\{.+?\\});', webpage, 'episode JSON')\n        episode_data = self._parse_json(episode_json, video_id, js_to_json)\n        video_url = self._proto_relative_url(episode_data['mediaUrl'], 'https:')\n\n        formats = [{\n            'url': video_url,\n        }]\n\n        return {\n            'id': video_id,\n            'thumbnail': thumbnail,\n            'title': title,\n            'author': author,\n            'duration': episode_data['duration'],\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.megaphone.MegaphoneIE._extract_urls#53",
        "src_path": "youtube_dl/extractor/megaphone.py",
        "class_name": "youtube_dl.extractor.megaphone.MegaphoneIE",
        "signature": "youtube_dl.extractor.megaphone.MegaphoneIE._extract_urls(cls, webpage)",
        "snippet": "    def _extract_urls(cls, webpage):\n        return [m[0] for m in re.findall(\n            r'<iframe[^>]*?\\ssrc=[\"\\'](%s)' % cls._VALID_URL, webpage)]",
        "begin_line": 53,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.meipai.MeipaiIE._real_extract#50",
        "src_path": "youtube_dl/extractor/meipai.py",
        "class_name": "youtube_dl.extractor.meipai.MeipaiIE",
        "signature": "youtube_dl.extractor.meipai.MeipaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(\n            webpage, default=None) or self._html_search_regex(\n            r'<title[^>]*>([^<]+)</title>', webpage, 'title')\n\n        formats = []\n\n        # recorded playback of live streaming\n        m3u8_url = self._html_search_regex(\n            r'file:\\s*encodeURIComponent\\(([\"\\'])(?P<url>(?:(?!\\1).)+)\\1\\)',\n            webpage, 'm3u8 url', group='url', default=None)\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        if not formats:\n            # regular uploaded video\n            video_url = self._search_regex(\n                r'data-video=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', webpage, 'video url',\n                group='url', default=None)\n            if video_url:\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'http',\n                })\n\n        timestamp = unified_timestamp(self._og_search_property(\n            'video:release_date', webpage, 'release date', fatal=False))\n\n        tags = self._og_search_property(\n            'video:tag', webpage, 'tags', default='').split(',')\n\n        view_count = int_or_none(self._html_search_meta(\n            'interactionCount', webpage, 'view count'))\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration'))\n        creator = self._og_search_property(\n            'video:director', webpage, 'creator', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'creator': creator,\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 50,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.melonvod.MelonVODIE._real_extract#29",
        "src_path": "youtube_dl/extractor/melonvod.py",
        "class_name": "youtube_dl.extractor.melonvod.MelonVODIE",
        "signature": "youtube_dl.extractor.melonvod.MelonVODIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        play_info = self._download_json(\n            'http://vod.melon.com/video/playerInfo.json', video_id,\n            note='Downloading player info JSON', query={'mvId': video_id})\n\n        title = play_info['mvInfo']['MVTITLE']\n\n        info = self._download_json(\n            'http://vod.melon.com/delivery/streamingInfo.json', video_id,\n            note='Downloading streaming info JSON',\n            query={\n                'contsId': video_id,\n                'contsType': 'VIDEO',\n            })\n\n        stream_info = info['streamingInfo']\n\n        formats = self._extract_m3u8_formats(\n            stream_info['encUrl'], video_id, 'mp4', m3u8_id='hls')\n        self._sort_formats(formats)\n\n        artist_list = play_info.get('artistList')\n        artist = None\n        if isinstance(artist_list, list):\n            artist = ', '.join(\n                [a['ARTISTNAMEWEBLIST']\n                 for a in artist_list if a.get('ARTISTNAMEWEBLIST')])\n\n        thumbnail = urljoin(info.get('staticDomain'), stream_info.get('imgPath'))\n\n        duration = int_or_none(stream_info.get('playTime'))\n        upload_date = stream_info.get('mvSvcOpenDt', '')[:8] or None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'artist': artist,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 29,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.meta.METAIE._real_extract#37",
        "src_path": "youtube_dl/extractor/meta.py",
        "class_name": "youtube_dl.extractor.meta.METAIE",
        "signature": "youtube_dl.extractor.meta.METAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        st_html5 = self._search_regex(\n            r\"st_html5\\s*=\\s*'#([^']+)'\", webpage, 'uppod html5 st', default=None)\n\n        if st_html5:\n            # uppod st decryption algorithm is reverse engineered from function un(s) at uppod.js\n            json_str = ''\n            for i in range(0, len(st_html5), 3):\n                json_str += '&#x0%s;' % st_html5[i:i + 3]\n            uppod_data = self._parse_json(unescapeHTML(json_str), video_id)\n            error = uppod_data.get('customnotfound')\n            if error:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)\n\n            video_url = uppod_data['file']\n            info = {\n                'id': video_id,\n                'url': video_url,\n                'title': uppod_data.get('comment') or self._og_search_title(webpage),\n                'description': self._og_search_description(webpage, default=None),\n                'thumbnail': uppod_data.get('poster') or self._og_search_thumbnail(webpage),\n                'duration': int_or_none(self._og_search_property(\n                    'video:duration', webpage, default=None)),\n            }\n            if 'youtube.com/' in video_url:\n                info.update({\n                    '_type': 'url_transparent',\n                    'ie_key': 'Youtube',\n                })\n            return info\n\n        pladform_url = PladformIE._extract_url(webpage)\n        if pladform_url:\n            return self.url_result(pladform_url)",
        "begin_line": 37,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer#127",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer(self)",
        "snippet": "    def report_disclaimer(self):\n        self.to_screen('Retrieving disclaimer')",
        "begin_line": 127,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract#130",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        video_id, display_id = re.match(self._VALID_URL, url).groups()\n\n        # the video may come from an external site\n        m_external = re.match(r'^(\\w{2})-(.*)$', video_id)\n        if m_external is not None:\n            prefix, ext_id = m_external.groups()\n            # Check if video comes from YouTube\n            if prefix == 'yt':\n                return self.url_result('http://www.youtube.com/watch?v=%s' % ext_id, 'Youtube')\n            # CBS videos use theplatform.com\n            if prefix == 'cb':\n                return self.url_result('theplatform:%s' % ext_id, 'ThePlatform')\n\n        headers = {\n            # Disable family filter\n            'Cookie': 'user=%s; ' % compat_urllib_parse_urlencode({'ffilter': False})\n        }\n\n        # AnyClip videos require the flashversion cookie so that we get the link\n        # to the mp4 file\n        if video_id.startswith('an-'):\n            headers['Cookie'] += 'flashVersion=0; '\n\n        # Retrieve video webpage to extract further information\n        webpage = self._download_webpage(url, video_id, headers=headers)\n\n        error = get_element_by_attribute(\n            'class', 'notfound-page-title', webpage)\n        if error:\n            raise ExtractorError(error, expected=True)\n\n        video_title = self._html_search_meta(\n            ['og:title', 'twitter:title'], webpage, 'title', default=None) or self._search_regex(r'<h1>(.*?)</h1>', webpage, 'title')\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n        video_url = None\n        mobj = re.search(r'(?m)&(?:media|video)URL=([^&]+)', webpage)\n        if mobj is not None:\n            mediaURL = compat_urllib_parse_unquote(mobj.group(1))\n            video_ext = determine_ext(mediaURL)\n\n            # Extract gdaKey if available\n            mobj = re.search(r'(?m)&gdaKey=(.*?)&', webpage)\n            if mobj is None:\n                video_url = mediaURL\n            else:\n                gdaKey = mobj.group(1)\n                video_url = '%s?__gda__=%s' % (mediaURL, gdaKey)\n        if video_url is None:\n            mobj = re.search(r'<video src=\"([^\"]+)\"', webpage)\n            if mobj:\n                video_url = mobj.group(1)\n                video_ext = 'mp4'\n        if video_url is None:\n            flashvars = self._search_regex(\n                r' name=\"flashvars\" value=\"(.*?)\"', webpage, 'flashvars',\n                default=None)\n            if flashvars:\n                vardict = compat_parse_qs(flashvars)\n                if 'mediaData' not in vardict:\n                    raise ExtractorError('Unable to extract media URL')\n                mobj = re.search(\n                    r'\"mediaURL\":\"(?P<mediaURL>http.*?)\",(.*?)\"key\":\"(?P<key>.*?)\"', vardict['mediaData'][0])\n                if mobj is None:\n                    raise ExtractorError('Unable to extract media URL')\n                mediaURL = mobj.group('mediaURL').replace('\\\\/', '/')\n                video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))\n                video_ext = determine_ext(video_url)\n        if video_url is None:\n            player_url = self._search_regex(\n                r\"swfobject\\.embedSWF\\('([^']+)'\",\n                webpage, 'config URL', default=None)\n            if player_url:\n                config_url = self._search_regex(\n                    r'config=(.+)$', player_url, 'config URL')\n                config_doc = self._download_xml(\n                    config_url, video_id,\n                    note='Downloading video config')\n                smil_url = config_doc.find('.//properties').attrib['smil_file']\n                smil_doc = self._download_xml(\n                    smil_url, video_id,\n                    note='Downloading SMIL document')\n                base_url = smil_doc.find('./head/meta').attrib['base']\n                video_url = []\n                for vn in smil_doc.findall('.//video'):\n                    br = int(vn.attrib['system-bitrate'])\n                    play_path = vn.attrib['src']\n                    video_url.append({\n                        'format_id': 'smil-%d' % br,\n                        'url': base_url,\n                        'play_path': play_path,\n                        'page_url': url,\n                        'player_url': player_url,\n                        'ext': play_path.partition(':')[0],\n                    })\n        if video_url is None:\n            flashvars = self._parse_json(self._search_regex(\n                r'flashvars\\s*=\\s*({.*});', webpage, 'flashvars',\n                default=None), video_id, fatal=False)\n            if flashvars:\n                video_url = []\n                for source in flashvars.get('sources'):\n                    source_url = source.get('src')\n                    if not source_url:\n                        continue\n                    ext = mimetype2ext(source.get('type')) or determine_ext(source_url)\n                    if ext == 'm3u8':\n                        video_url.extend(self._extract_m3u8_formats(\n                            source_url, video_id, 'mp4',\n                            'm3u8_native', m3u8_id='hls', fatal=False))\n                    else:\n                        video_url.append({\n                            'url': source_url,\n                            'ext': ext,\n                        })\n\n        if video_url is None:\n            raise ExtractorError('Unsupported video type')\n\n        description = self._html_search_meta(\n            ['og:description', 'twitter:description', 'description'],\n            webpage, 'title', fatal=False)\n        thumbnail = self._html_search_meta(\n            ['og:image', 'twitter:image'], webpage, 'title', fatal=False)\n        video_uploader = self._html_search_regex(\n            r'submitter=(.*?);|googletag\\.pubads\\(\\)\\.setTargeting\\(\"(?:channel|submiter)\",\"([^\"]+)\"\\);',\n            webpage, 'uploader nickname', fatal=False)\n        duration = int_or_none(\n            self._html_search_meta('video:duration', webpage, default=None))\n        age_limit = (\n            18\n            if re.search(r'(?:\"contentRating\":|\"rating\",)\"restricted\"', webpage)\n            else 0)\n\n        if isinstance(video_url, list):\n            formats = video_url\n        else:\n            formats = [{\n                'url': video_url,\n                'ext': video_ext,\n            }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'description': description,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'formats': formats,\n            'duration': duration,\n        }",
        "begin_line": 130,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract#35",
        "src_path": "youtube_dl/extractor/metacritic.py",
        "class_name": "youtube_dl.extractor.metacritic.MetacriticIE",
        "signature": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        # The xml is not well formatted, there are raw '&'\n        info = self._download_xml('http://www.metacritic.com/video_data?video=' + video_id,\n                                  video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)\n\n        clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n        formats = []\n        for videoFile in clip.findall('httpURI/videoFile'):\n            rate_str = videoFile.find('rate').text\n            video_url = videoFile.find('filePath').text\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': rate_str,\n                'tbr': int(rate_str),\n            })\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(r'<b>Description:</b>(.*?)</p>',\n                                              webpage, 'description', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': clip.find('title').text,\n            'formats': formats,\n            'description': description,\n            'duration': int(clip.find('duration').text),\n        }",
        "begin_line": 35,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mgoon.MgoonIE._real_extract#43",
        "src_path": "youtube_dl/extractor/mgoon.py",
        "class_name": "youtube_dl.extractor.mgoon.MgoonIE",
        "signature": "youtube_dl.extractor.mgoon.MgoonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        data = self._download_json(self._API_URL.format(video_id), video_id)\n\n        if data.get('errorInfo', {}).get('code') != 'NONE':\n            raise ExtractorError('%s encountered an error: %s' % (\n                self.IE_NAME, data['errorInfo']['message']), expected=True)\n\n        v_info = data['videoInfo']\n        title = v_info.get('v_title')\n        thumbnail = v_info.get('v_thumbnail')\n        duration = v_info.get('v_duration')\n        upload_date = unified_strdate(v_info.get('v_reg_date'))\n        uploader_id = data.get('userInfo', {}).get('u_alias')\n        if duration:\n            duration /= 1000.0\n\n        age_limit = None\n        if data.get('accessInfo', {}).get('code') == 'VIDEO_STATUS_ADULT':\n            age_limit = 18\n\n        formats = []\n        get_quality = qualities(['360p', '480p', '720p', '1080p'])\n        for fmt in data['videoFiles']:\n            formats.append({\n                'format_id': fmt['label'],\n                'quality': get_quality(fmt['label']),\n                'url': fmt['url'],\n                'ext': fmt['format'],\n\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'age_limit': age_limit,\n        }",
        "begin_line": 43,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mgtv.MGTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/mgtv.py",
        "class_name": "youtube_dl.extractor.mgtv.MGTVIE",
        "signature": "youtube_dl.extractor.mgtv.MGTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        api_data = self._download_json(\n            'http://pcweb.api.mgtv.com/player/video', video_id,\n            query={'video_id': video_id},\n            headers=self.geo_verification_headers())['data']\n        info = api_data['info']\n        title = info['title'].strip()\n        stream_domain = api_data['stream_domain'][0]\n\n        formats = []\n        for idx, stream in enumerate(api_data['stream']):\n            stream_path = stream.get('url')\n            if not stream_path:\n                continue\n            format_data = self._download_json(\n                stream_domain + stream_path, video_id,\n                note='Download video info for format #%d' % idx)\n            format_url = format_data.get('info')\n            if not format_url:\n                continue\n            tbr = int_or_none(self._search_regex(\n                r'_(\\d+)_mp4/', format_url, 'tbr', default=None))\n            formats.append({\n                'format_id': compat_str(tbr or idx),\n                'url': format_url,\n                'ext': 'mp4',\n                'tbr': tbr,\n                'protocol': 'm3u8_native',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': info.get('desc'),\n            'duration': int_or_none(info.get('duration')),\n            'thumbnail': info.get('thumb'),\n        }",
        "begin_line": 29,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.miaopai.MiaoPaiIE._real_extract#22",
        "src_path": "youtube_dl/extractor/miaopai.py",
        "class_name": "youtube_dl.extractor.miaopai.MiaoPaiIE",
        "signature": "youtube_dl.extractor.miaopai.MiaoPaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, video_id, headers={'User-Agent': self._USER_AGENT_IPAD})\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title')\n        thumbnail = self._html_search_regex(\n            r'<div[^>]+class=(?P<q1>[\\'\"]).*\\bvideo_img\\b.*(?P=q1)[^>]+data-url=(?P<q2>[\\'\"])(?P<url>[^\\'\"]+)(?P=q2)',\n            webpage, 'thumbnail', fatal=False, group='url')\n        videos = self._parse_html5_media_entries(url, webpage, video_id)\n        info = videos[0]\n\n        info.update({\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n        })\n        return info",
        "begin_line": 22,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE._extract_base_url#19",
        "src_path": "youtube_dl/extractor/microsoftvirtualacademy.py",
        "class_name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE",
        "signature": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE._extract_base_url(self, course_id, display_id)",
        "snippet": "    def _extract_base_url(self, course_id, display_id):\n        return self._download_json(\n            'https://api-mlxprod.microsoft.com/services/products/anonymous/%s' % course_id,\n            display_id, 'Downloading course base URL')",
        "begin_line": 19,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE._extract_chapter_and_title#24",
        "src_path": "youtube_dl/extractor/microsoftvirtualacademy.py",
        "class_name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE",
        "signature": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyBaseIE._extract_chapter_and_title(self, title)",
        "snippet": "    def _extract_chapter_and_title(self, title):\n        if not title:\n            return None, None\n        m = re.search(r'(?P<chapter>\\d+)\\s*\\|\\s*(?P<title>.+)', title)\n        return (int(m.group('chapter')), m.group('title')) if m else (None, title)",
        "begin_line": 24,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyIE._real_extract#55",
        "src_path": "youtube_dl/extractor/microsoftvirtualacademy.py",
        "class_name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyIE",
        "signature": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        course_id = mobj.group('course_id')\n        video_id = mobj.group('id')\n\n        base_url = smuggled_data.get('base_url') or self._extract_base_url(course_id, video_id)\n\n        settings = self._download_xml(\n            '%s/content/content_%s/videosettings.xml?v=1' % (base_url, video_id),\n            video_id, 'Downloading video settings XML')\n\n        _, title = self._extract_chapter_and_title(xpath_text(\n            settings, './/Title', 'title', fatal=True))\n\n        formats = []\n\n        for sources in settings.findall(compat_xpath('.//MediaSources')):\n            sources_type = sources.get('videoType')\n            for source in sources.findall(compat_xpath('./MediaSource')):\n                video_url = source.text\n                if not video_url or not video_url.startswith('http'):\n                    continue\n                if sources_type == 'smoothstreaming':\n                    formats.extend(self._extract_ism_formats(\n                        video_url, video_id, 'mss', fatal=False))\n                    continue\n                video_mode = source.get('videoMode')\n                height = int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]$', video_mode or '', 'height', default=None))\n                codec = source.get('codec')\n                acodec, vcodec = [None] * 2\n                if codec:\n                    codecs = codec.split(',')\n                    if len(codecs) == 2:\n                        acodec, vcodec = codecs\n                    elif len(codecs) == 1:\n                        vcodec = codecs[0]\n                formats.append({\n                    'url': video_url,\n                    'format_id': video_mode,\n                    'height': height,\n                    'acodec': acodec,\n                    'vcodec': vcodec,\n                })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for source in settings.findall(compat_xpath('.//MarkerResourceSource')):\n            subtitle_url = source.text\n            if not subtitle_url:\n                continue\n            subtitles.setdefault('en', []).append({\n                'url': '%s/%s' % (base_url, subtitle_url),\n                'ext': source.get('type'),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'subtitles': subtitles,\n            'formats': formats\n        }",
        "begin_line": 55,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE.suitable#150",
        "src_path": "youtube_dl/extractor/microsoftvirtualacademy.py",
        "class_name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE",
        "signature": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if MicrosoftVirtualAcademyIE.suitable(url) else super(\n            MicrosoftVirtualAcademyCourseIE, cls).suitable(url)",
        "begin_line": 150,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE._real_extract#154",
        "src_path": "youtube_dl/extractor/microsoftvirtualacademy.py",
        "class_name": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE",
        "signature": "youtube_dl.extractor.microsoftvirtualacademy.MicrosoftVirtualAcademyCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        base_url = self._extract_base_url(course_id, display_id)\n\n        manifest = self._download_json(\n            '%s/imsmanifestlite.json' % base_url,\n            display_id, 'Downloading course manifest JSON')['manifest']\n\n        organization = manifest['organizations']['organization'][0]\n\n        entries = []\n        for chapter in organization['item']:\n            chapter_number, chapter_title = self._extract_chapter_and_title(chapter.get('title'))\n            chapter_id = chapter.get('@identifier')\n            for item in chapter.get('item', []):\n                item_id = item.get('@identifier')\n                if not item_id:\n                    continue\n                metadata = item.get('resource', {}).get('metadata') or {}\n                if metadata.get('learningresourcetype') != 'Video':\n                    continue\n                _, title = self._extract_chapter_and_title(item.get('title'))\n                duration = parse_duration(metadata.get('duration'))\n                description = metadata.get('description')\n                entries.append({\n                    '_type': 'url_transparent',\n                    'url': smuggle_url(\n                        'mva:%s:%s' % (course_id, item_id), {'base_url': base_url}),\n                    'title': title,\n                    'description': description,\n                    'duration': duration,\n                    'chapter': chapter_title,\n                    'chapter_number': chapter_number,\n                    'chapter_id': chapter_id,\n                })\n\n        title = organization.get('title') or manifest.get('metadata', {}).get('title')\n\n        return self.playlist_result(entries, course_id, title)",
        "begin_line": 154,
        "end_line": 195,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.minhateca.MinhatecaIE._real_extract#29",
        "src_path": "youtube_dl/extractor/minhateca.py",
        "class_name": "youtube_dl.extractor.minhateca.MinhatecaIE",
        "signature": "youtube_dl.extractor.minhateca.MinhatecaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        token = self._html_search_regex(\n            r'<input name=\"__RequestVerificationToken\".*?value=\"([^\"]+)\"',\n            webpage, 'request token')\n        token_data = [\n            ('fileId', video_id),\n            ('__RequestVerificationToken', token),\n        ]\n        req = sanitized_Request(\n            'http://minhateca.com.br/action/License/Download',\n            data=urlencode_postdata(token_data))\n        req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        data = self._download_json(\n            req, video_id, note='Downloading metadata')\n\n        video_url = data['redirectUrl']\n        title_str = self._html_search_regex(\n            r'<h1.*?>(.*?)</h1>', webpage, 'title')\n        title, _, ext = title_str.rpartition('.')\n        filesize_approx = parse_filesize(self._html_search_regex(\n            r'<p class=\"fileSize\">(.*?)</p>',\n            webpage, 'file size approximation', fatal=False))\n        duration = parse_duration(self._html_search_regex(\n            r'(?s)<p class=\"fileLeng[ht][th]\">.*?class=\"bold\">(.*?)<',\n            webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<p class=\"downloadsCounter\">([0-9]+)</p>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': ext,\n            'filesize_approx': filesize_approx,\n            'duration': duration,\n            'view_count': view_count,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 29,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract#33",
        "src_path": "youtube_dl/extractor/ministrygrid.py",
        "class_name": "youtube_dl.extractor.ministrygrid.MinistryGridIE",
        "signature": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        portlets = self._parse_json(self._search_regex(\n            r'Liferay\\.Portlet\\.list=(\\[.+?\\])', webpage, 'portlet list'),\n            video_id)\n        pl_id = self._search_regex(\n            r'getPlid:function\\(\\){return\"(\\d+)\"}', webpage, 'p_l_id')\n\n        for i, portlet in enumerate(portlets):\n            portlet_url = 'http://www.ministrygrid.com/c/portal/render_portlet?p_l_id=%s&p_p_id=%s' % (pl_id, portlet)\n            portlet_code = self._download_webpage(\n                portlet_url, video_id,\n                note='Looking in portlet %s (%d/%d)' % (portlet, i + 1, len(portlets)),\n                fatal=False)\n            video_iframe_url = self._search_regex(\n                r'<iframe.*?src=\"([^\"]+)\"', portlet_code, 'video iframe',\n                default=None)\n            if video_iframe_url:\n                return self.url_result(\n                    smuggle_url(video_iframe_url, {'force_videoid': video_id}),\n                    video_id=video_id)\n\n        raise ExtractorError('Could not find video iframe in any portlets')",
        "begin_line": 33,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.minoto.MinotoIE._real_extract#13",
        "src_path": "youtube_dl/extractor/minoto.py",
        "class_name": "youtube_dl.extractor.minoto.MinotoIE",
        "signature": "youtube_dl.extractor.minoto.MinotoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        player_id = mobj.group('player_id') or '1'\n        video_id = mobj.group('id')\n        video_data = self._download_json('http://play.minoto-video.com/%s/%s.js' % (player_id, video_id), video_id)\n        video_metadata = video_data['video-metadata']\n        formats = []\n        for fmt in video_data['video-files']:\n            fmt_url = fmt.get('url')\n            if not fmt_url:\n                continue\n            container = fmt.get('container')\n            if container == 'hls':\n                formats.extend(fmt_url, video_id, 'mp4', m3u8_id='hls', fatal=False)\n            else:\n                fmt_profile = fmt.get('profile') or {}\n                f = {\n                    'format_id': fmt_profile.get('name-short'),\n                    'format_note': fmt_profile.get('name'),\n                    'url': fmt_url,\n                    'container': container,\n                    'tbr': int_or_none(fmt.get('bitrate')),\n                    'filesize': int_or_none(fmt.get('filesize')),\n                    'width': int_or_none(fmt.get('width')),\n                    'height': int_or_none(fmt.get('height')),\n                }\n                codecs = fmt.get('codecs')\n                if codecs:\n                    codecs = codecs.split(',')\n                    if len(codecs) == 2:\n                        f.update({\n                            'vcodec': codecs[0],\n                            'acodec': codecs[1],\n                        })\n                formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_metadata['title'],\n            'description': video_metadata.get('description'),\n            'thumbnail': video_metadata.get('video-poster', {}).get('url'),\n            'formats': formats,\n        }",
        "begin_line": 13,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.miomio.MioMioIE._extract_mioplayer#57",
        "src_path": "youtube_dl/extractor/miomio.py",
        "class_name": "youtube_dl.extractor.miomio.MioMioIE",
        "signature": "youtube_dl.extractor.miomio.MioMioIE._extract_mioplayer(self, webpage, video_id, title, http_headers)",
        "snippet": "    def _extract_mioplayer(self, webpage, video_id, title, http_headers):\n        xml_config = self._search_regex(\n            r'flashvars=\"type=(?:sina|video)&amp;(.+?)&amp;',\n            webpage, 'xml config')\n\n        # skipping the following page causes lags and eventually connection drop-outs\n        self._request_webpage(\n            'http://www.miomio.tv/mioplayer/mioplayerconfigfiles/xml.php?id=%s&r=%s' % (id, random.randint(100, 999)),\n            video_id)\n\n        vid_config_request = sanitized_Request(\n            'http://www.miomio.tv/mioplayer/mioplayerconfigfiles/sina.php?{0}'.format(xml_config),\n            headers=http_headers)\n\n        # the following xml contains the actual configuration information on the video file(s)\n        vid_config = self._download_xml(vid_config_request, video_id)\n\n        if not int_or_none(xpath_text(vid_config, 'timelength')):\n            raise ExtractorError('Unable to load videos!', expected=True)\n\n        entries = []\n        for f in vid_config.findall('./durl'):\n            segment_url = xpath_text(f, 'url', 'video url')\n            if not segment_url:\n                continue\n            order = xpath_text(f, 'order', 'order')\n            segment_id = video_id\n            segment_title = title\n            if order:\n                segment_id += '-%s' % order\n                segment_title += ' part %s' % order\n            entries.append({\n                'id': segment_id,\n                'url': segment_url,\n                'title': segment_title,\n                'duration': int_or_none(xpath_text(f, 'length', 'duration'), 1000),\n                'http_headers': http_headers,\n            })\n\n        return entries",
        "begin_line": 57,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.miomio.MioMioIE._download_chinese_webpage#98",
        "src_path": "youtube_dl/extractor/miomio.py",
        "class_name": "youtube_dl.extractor.miomio.MioMioIE",
        "signature": "youtube_dl.extractor.miomio.MioMioIE._download_chinese_webpage(self, *args, **kwargs)",
        "snippet": "    def _download_chinese_webpage(self, *args, **kwargs):\n        # Requests with English locales return garbage\n        headers = {\n            'Accept-Language': 'zh-TW,en-US;q=0.7,en;q=0.3',\n        }\n        kwargs.setdefault('headers', {}).update(headers)\n        return self._download_webpage(*args, **kwargs)",
        "begin_line": 98,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.miomio.MioMioIE._real_extract#106",
        "src_path": "youtube_dl/extractor/miomio.py",
        "class_name": "youtube_dl.extractor.miomio.MioMioIE",
        "signature": "youtube_dl.extractor.miomio.MioMioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_chinese_webpage(\n            url, video_id)\n\n        title = self._html_search_meta(\n            'description', webpage, 'title', fatal=True)\n\n        mioplayer_path = self._search_regex(\n            r'src=\"(/mioplayer(?:_h5)?/[^\"]+)\"', webpage, 'ref_path')\n\n        if '_h5' in mioplayer_path:\n            player_url = compat_urlparse.urljoin(url, mioplayer_path)\n            player_webpage = self._download_chinese_webpage(\n                player_url, video_id,\n                note='Downloading player webpage', headers={'Referer': url})\n            entries = self._parse_html5_media_entries(player_url, player_webpage, video_id)\n            http_headers = {'Referer': player_url}\n        else:\n            http_headers = {'Referer': 'http://www.miomio.tv%s' % mioplayer_path}\n            entries = self._extract_mioplayer(webpage, video_id, title, http_headers)\n\n        if len(entries) == 1:\n            segment = entries[0]\n            segment['id'] = video_id\n            segment['title'] = title\n            segment['http_headers'] = http_headers\n            return segment\n\n        return {\n            '_type': 'multi_video',\n            'id': video_id,\n            'entries': entries,\n            'title': title,\n            'http_headers': http_headers,\n        }",
        "begin_line": 106,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mit.TechTVMITIE._real_extract#30",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.TechTVMITIE",
        "signature": "youtube_dl.extractor.mit.TechTVMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raw_page = self._download_webpage(\n            'http://techtv.mit.edu/videos/%s' % video_id, video_id)\n        clean_page = re.compile(r'<!--.*?-->', re.S).sub('', raw_page)\n\n        base_url = self._proto_relative_url(self._search_regex(\n            r'ipadUrl: \\'(.+?cloudfront.net/)', raw_page, 'base url'), 'http:')\n        formats_json = self._search_regex(\n            r'bitrates: (\\[.+?\\])', raw_page, 'video formats')\n        formats_mit = json.loads(formats_json)\n        formats = [\n            {\n                'format_id': f['label'],\n                'url': base_url + f['url'].partition(':')[2],\n                'ext': f['url'].partition(':')[0],\n                'format': f['label'],\n                'width': f['width'],\n                'vbr': f['bitrate'],\n            }\n            for f in formats_mit\n        ]\n\n        title = get_element_by_id('edit-title', clean_page)\n        description = clean_html(get_element_by_id('edit-description', clean_page))\n        thumbnail = self._search_regex(\n            r'playlist:.*?url: \\'(.+?)\\'',\n            raw_page, 'thumbnail', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mit.MITIE._real_extract#83",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.MITIE",
        "signature": "youtube_dl.extractor.mit.MITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        embed_url = self._search_regex(\n            r'<iframe .*?src=\"(.+?)\"', webpage, 'embed url')\n        return self.url_result(embed_url)",
        "begin_line": 83,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mit.OCWMITIE._real_extract#124",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.OCWMITIE",
        "signature": "youtube_dl.extractor.mit.OCWMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        topic = mobj.group('topic')\n\n        webpage = self._download_webpage(url, topic)\n        title = self._html_search_meta('WT.cg_s', webpage)\n        description = self._html_search_meta('Description', webpage)\n\n        # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, start, stop, captions_file)\n        embed_chapter_media = re.search(r'ocw_embed_chapter_media\\((.+?)\\)', webpage)\n        if embed_chapter_media:\n            metadata = re.sub(r'[\\'\"]', '', embed_chapter_media.group(1))\n            metadata = re.split(r', ?', metadata)\n            yt = metadata[1]\n        else:\n            # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, captions_file)\n            embed_media = re.search(r'ocw_embed_media\\((.+?)\\)', webpage)\n            if embed_media:\n                metadata = re.sub(r'[\\'\"]', '', embed_media.group(1))\n                metadata = re.split(r', ?', metadata)\n                yt = metadata[1]\n            else:\n                raise ExtractorError('Unable to find embedded YouTube video.')\n        video_id = YoutubeIE.extract_id(yt)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'url': yt,\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 124,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mitele.MiTeleBaseIE._get_player_info#23",
        "src_path": "youtube_dl/extractor/mitele.py",
        "class_name": "youtube_dl.extractor.mitele.MiTeleBaseIE",
        "signature": "youtube_dl.extractor.mitele.MiTeleBaseIE._get_player_info(self, url, webpage)",
        "snippet": "    def _get_player_info(self, url, webpage):\n        player_data = extract_attributes(self._search_regex(\n            r'(?s)(<ms-video-player.+?</ms-video-player>)',\n            webpage, 'ms video player'))\n        video_id = player_data['data-media-id']\n        if player_data.get('data-cms-id') == 'ooyala':\n            return self.url_result(\n                'ooyala:%s' % video_id, ie=OoyalaIE.ie_key(), video_id=video_id)\n        config_url = compat_urlparse.urljoin(url, player_data['data-config'])\n        config = self._download_json(\n            config_url, video_id, 'Downloading config JSON')\n        mmc_url = config['services']['mmc']\n\n        duration = None\n        formats = []\n        for m_url in (mmc_url, mmc_url.replace('/flash.json', '/html5.json')):\n            mmc = self._download_json(\n                m_url, video_id, 'Downloading mmc JSON')\n            if not duration:\n                duration = int_or_none(mmc.get('duration'))\n            for location in mmc['locations']:\n                gat = self._proto_relative_url(location.get('gat'), 'http:')\n                bas = location.get('bas')\n                loc = location.get('loc')\n                ogn = location.get('ogn')\n                if None in (gat, bas, loc, ogn):\n                    continue\n                token_data = {\n                    'bas': bas,\n                    'icd': loc,\n                    'ogn': ogn,\n                    'sta': '0',\n                }\n                media = self._download_json(\n                    '%s/?%s' % (gat, compat_urllib_parse_urlencode(token_data)),\n                    video_id, 'Downloading %s JSON' % location['loc'])\n                file_ = media.get('file')\n                if not file_:\n                    continue\n                ext = determine_ext(file_)\n                if ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        file_ + '&hdcore=3.2.0&plugin=aasp-3.2.0.77.18',\n                        video_id, f4m_id='hds', fatal=False))\n                elif ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        file_, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'thumbnail': player_data.get('data-poster') or config.get('poster', {}).get('imageUrl'),\n            'duration': duration,\n        }",
        "begin_line": 23,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mitele.MiTeleIE._real_extract#127",
        "src_path": "youtube_dl/extractor/mitele.py",
        "class_name": "youtube_dl.extractor.mitele.MiTeleIE",
        "signature": "youtube_dl.extractor.mitele.MiTeleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        gigya_url = self._search_regex(\n            r'<gigya-api>[^>]*</gigya-api>[^>]*<script\\s+src=\"([^\"]*)\">[^>]*</script>',\n            webpage, 'gigya', default=None)\n        gigya_sc = self._download_webpage(\n            compat_urlparse.urljoin('http://www.mitele.es/', gigya_url),\n            video_id, 'Downloading gigya script')\n\n        # Get a appKey/uuid for getting the session key\n        appKey = self._search_regex(\n            r'constant\\s*\\(\\s*[\"\\']_appGridApplicationKey[\"\\']\\s*,\\s*[\"\\']([0-9a-f]+)',\n            gigya_sc, 'appKey')\n\n        session_json = self._download_json(\n            'https://appgrid-api.cloud.accedo.tv/session',\n            video_id, 'Downloading session keys', query={\n                'appKey': appKey,\n                'uuid': compat_str(uuid.uuid4()),\n            })\n\n        paths = self._download_json(\n            'https://appgrid-api.cloud.accedo.tv/metadata/general_configuration,%20web_configuration',\n            video_id, 'Downloading paths JSON',\n            query={'sessionKey': compat_str(session_json['sessionKey'])})\n\n        ooyala_s = paths['general_configuration']['api_configuration']['ooyala_search']\n        source = self._download_json(\n            'http://%s%s%s/docs/%s' % (\n                ooyala_s['base_url'], ooyala_s['full_path'],\n                ooyala_s['provider_id'], video_id),\n            video_id, 'Downloading data JSON', query={\n                'include_titles': 'Series,Season',\n                'product_name': 'test',\n                'format': 'full',\n            })['hits']['hits'][0]['_source']\n\n        embedCode = source['offers'][0]['embed_codes'][0]\n        titles = source['localizable_titles'][0]\n\n        title = titles.get('title_medium') or titles['title_long']\n\n        description = titles.get('summary_long') or titles.get('summary_medium')\n\n        def get(key1, key2):\n            value1 = source.get(key1)\n            if not value1 or not isinstance(value1, list):\n                return\n            if not isinstance(value1[0], dict):\n                return\n            return value1[0].get(key2)\n\n        series = get('localizable_titles_series', 'title_medium')\n\n        season = get('localizable_titles_season', 'title_medium')\n        season_number = int_or_none(source.get('season_number'))\n        season_id = source.get('season_id')\n\n        episode = titles.get('title_sort_name')\n        episode_number = int_or_none(source.get('episode_number'))\n\n        duration = parse_duration(get('videos', 'duration'))\n\n        return {\n            '_type': 'url_transparent',\n            # for some reason only HLS is supported\n            'url': smuggle_url('ooyala:' + embedCode, {'supportedformats': 'm3u8,dash'}),\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'series': series,\n            'season': season,\n            'season_number': season_number,\n            'season_id': season_id,\n            'episode': episode,\n            'episode_number': episode_number,\n            'duration': duration,\n            'thumbnail': get('images', 'url'),\n        }",
        "begin_line": 127,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._decrypt_play_info#66",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._decrypt_play_info(self, play_info, video_id)",
        "snippet": "    def _decrypt_play_info(self, play_info, video_id):\n        play_info = base64.b64decode(play_info.encode('ascii'))\n        for num, key in enumerate(self._keys, start=1):\n            try:\n                return self._parse_json(\n                    ''.join([\n                        compat_chr(compat_ord(ch) ^ compat_ord(key[idx % len(key)]))\n                        for idx, ch in enumerate(play_info)]),\n                    video_id)\n            except ExtractorError:\n                if num == len(self._keys):\n                    raise",
        "begin_line": 66,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract#79",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group(1)\n        cloudcast_name = mobj.group(2)\n        track_id = compat_urllib_parse_unquote('-'.join((uploader, cloudcast_name)))\n\n        webpage = self._download_webpage(url, track_id)\n\n        if not self._current_key:\n            js_url = self._search_regex(\n                r'<script[^>]+\\bsrc=[\"\\\"](https://(?:www\\.)?mixcloud\\.com/media/js2/www_js_4\\.[^>]+\\.js)',\n                webpage, 'js url', default=None)\n            if js_url:\n                js = self._download_webpage(js_url, track_id, fatal=False)\n                if js:\n                    KEY_RE_TEMPLATE = r'player\\s*:\\s*{.*?\\b%s\\s*:\\s*([\"\\'])(?P<key>(?:(?!\\1).)+)\\1'\n                    for key_name in ('value', 'key_value'):\n                        key = self._search_regex(\n                            KEY_RE_TEMPLATE % key_name, js, 'key',\n                            default=None, group='key')\n                        if key and isinstance(key, compat_str):\n                            self._keys.insert(0, key)\n                            self._current_key = key\n\n        message = self._html_search_regex(\n            r'(?s)<div[^>]+class=\"global-message cloudcast-disabled-notice-light\"[^>]*>(.+?)<(?:a|/div)',\n            webpage, 'error message', default=None)\n\n        encrypted_play_info = self._search_regex(\n            r'm-play-info=\"([^\"]+)\"', webpage, 'play info')\n\n        play_info = self._decrypt_play_info(encrypted_play_info, track_id)\n\n        if message and 'stream_url' not in play_info:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, message), expected=True)\n\n        song_url = play_info['stream_url']\n\n        title = self._html_search_regex(r'm-title=\"([^\"]+)\"', webpage, 'title')\n        thumbnail = self._proto_relative_url(self._html_search_regex(\n            r'm-thumbnail-url=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False))\n        uploader = self._html_search_regex(\n            r'm-owner-name=\"([^\"]+)\"', webpage, 'uploader', fatal=False)\n        uploader_id = self._search_regex(\n            r'\\s+\"profile\": \"([^\"]+)\",', webpage, 'uploader id', fatal=False)\n        description = self._og_search_description(webpage)\n        view_count = str_to_int(self._search_regex(\n            [r'<meta itemprop=\"interactionCount\" content=\"UserPlays:([0-9]+)\"',\n             r'/listeners/?\">([0-9,.]+)</a>',\n             r'(?:m|data)-tooltip=[\"\\']([\\d,.]+) plays'],\n            webpage, 'play count', default=None))\n\n        return {\n            'id': track_id,\n            'title': title,\n            'url': song_url,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n        }",
        "begin_line": 79,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._find_urls_in_page#146",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._find_urls_in_page(self, page)",
        "snippet": "    def _find_urls_in_page(self, page):\n        for url in re.findall(r'm-play-button m-url=\"(?P<url>[^\"]+)\"', page):\n            yield self.url_result(\n                compat_urlparse.urljoin('https://www.mixcloud.com', clean_html(url)),\n                MixcloudIE.ie_key())",
        "begin_line": 146,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._fetch_tracks_page#152",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._fetch_tracks_page(self, path, video_id, page_name, current_page, real_page_number=None)",
        "snippet": "    def _fetch_tracks_page(self, path, video_id, page_name, current_page, real_page_number=None):\n        real_page_number = real_page_number or current_page + 1\n        return self._download_webpage(\n            'https://www.mixcloud.com/%s/' % path, video_id,\n            note='Download %s (page %d)' % (page_name, current_page + 1),\n            errnote='Unable to download %s' % page_name,\n            query={'page': real_page_number, 'list': 'main', '_ajax': '1'},\n            headers={'X-Requested-With': 'XMLHttpRequest'})",
        "begin_line": 152,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._tracks_page_func#161",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._tracks_page_func(self, page, video_id, page_name, current_page)",
        "snippet": "    def _tracks_page_func(self, page, video_id, page_name, current_page):\n        resp = self._fetch_tracks_page(page, video_id, page_name, current_page)\n\n        for item in self._find_urls_in_page(resp):\n            yield item",
        "begin_line": 161,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._get_user_description#167",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudPlaylistBaseIE._get_user_description(self, page_content)",
        "snippet": "    def _get_user_description(self, page_content):\n        return self._html_search_regex(\n            r'<div[^>]+class=\"profile-bio\"[^>]*>(.+?)</div>',\n            page_content, 'user description', fatal=False)",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudUserIE._real_extract#217",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudUserIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user')\n        list_type = mobj.group('type')\n\n        # if only a profile URL was supplied, default to download all uploads\n        if list_type is None:\n            list_type = 'uploads'\n\n        video_id = '%s_%s' % (user_id, list_type)\n\n        profile = self._download_webpage(\n            'https://www.mixcloud.com/%s/' % user_id, video_id,\n            note='Downloading user profile',\n            errnote='Unable to download user profile')\n\n        username = self._og_search_title(profile)\n        description = self._get_user_description(profile)\n\n        entries = OnDemandPagedList(\n            functools.partial(\n                self._tracks_page_func,\n                '%s/%s' % (user_id, list_type), video_id, 'list of %s' % list_type),\n            self._PAGE_SIZE, use_cache=True)\n\n        return self.playlist_result(\n            entries, video_id, '%s (%s)' % (username, list_type), description)",
        "begin_line": 217,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistIE._real_extract#263",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudPlaylistIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user')\n        playlist_id = mobj.group('playlist')\n        video_id = '%s_%s' % (user_id, playlist_id)\n\n        webpage = self._download_webpage(\n            url, user_id,\n            note='Downloading playlist page',\n            errnote='Unable to download playlist page')\n\n        title = self._html_search_regex(\n            r'<a[^>]+class=\"parent active\"[^>]*><b>\\d+</b><span[^>]*>([^<]+)',\n            webpage, 'playlist title',\n            default=None) or self._og_search_title(webpage, fatal=False)\n        description = self._get_user_description(webpage)\n\n        entries = OnDemandPagedList(\n            functools.partial(\n                self._tracks_page_func,\n                '%s/playlists/%s' % (user_id, playlist_id), video_id, 'tracklist'),\n            self._PAGE_SIZE)\n\n        return self.playlist_result(entries, video_id, title, description)",
        "begin_line": 263,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudStreamIE._real_extract#303",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudStreamIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudStreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, user_id)\n\n        entries = []\n        prev_page_url = None\n\n        def _handle_page(page):\n            entries.extend(self._find_urls_in_page(page))\n            return self._search_regex(\n                r'm-next-page-url=\"([^\"]+)\"', page,\n                'next page URL', default=None)\n\n        next_page_url = _handle_page(webpage)\n\n        for idx in itertools.count(0):\n            if not next_page_url or prev_page_url == next_page_url:\n                break\n\n            prev_page_url = next_page_url\n            current_page = int(self._search_regex(\n                r'\\?page=(\\d+)', next_page_url, 'next page number'))\n\n            next_page_url = _handle_page(self._fetch_tracks_page(\n                '%s/stream' % user_id, user_id, 'stream', idx,\n                real_page_number=current_page))\n\n        username = self._og_search_title(webpage)\n        description = self._get_user_description(webpage)\n\n        return self.playlist_result(entries, user_id, username, description)",
        "begin_line": 303,
        "end_line": 334,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mlb.MLBIE._real_extract#128",
        "src_path": "youtube_dl/extractor/mlb.py",
        "class_name": "youtube_dl.extractor.mlb.MLBIE",
        "signature": "youtube_dl.extractor.mlb.MLBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if not video_id:\n            video_path = mobj.group('path')\n            webpage = self._download_webpage(url, video_path)\n            video_id = self._search_regex(\n                [r'data-video-?id=\"(\\d+)\"', r'content_id=(\\d+)'], webpage, 'video id')\n\n        detail = self._download_xml(\n            'http://m.mlb.com/gen/multimedia/detail/%s/%s/%s/%s.xml'\n            % (video_id[-3], video_id[-2], video_id[-1], video_id), video_id)\n\n        title = detail.find('./headline').text\n        description = detail.find('./big-blurb').text\n        duration = parse_duration(detail.find('./duration').text)\n        timestamp = parse_iso8601(detail.attrib['date'][:-5])\n\n        thumbnails = [{\n            'url': thumbnail.text,\n        } for thumbnail in detail.findall('./thumbnailScenarios/thumbnailScenario')]\n\n        formats = []\n        for media_url in detail.findall('./url'):\n            playback_scenario = media_url.attrib['playback_scenario']\n            fmt = {\n                'url': media_url.text,\n                'format_id': playback_scenario,\n            }\n            m = re.search(r'(?P<vbr>\\d+)K_(?P<width>\\d+)X(?P<height>\\d+)', playback_scenario)\n            if m:\n                fmt.update({\n                    'vbr': int(m.group('vbr')) * 1000,\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 128,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mnet.MnetIE._real_extract#40",
        "src_path": "youtube_dl/extractor/mnet.py",
        "class_name": "youtube_dl.extractor.mnet.MnetIE",
        "signature": "youtube_dl.extractor.mnet.MnetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://content.api.mnet.com/player/vodConfig?id=%s&ctype=CLIP' % video_id,\n            video_id, 'Downloading vod config JSON')['data']['info']\n\n        title = info['title']\n\n        rtmp_info = self._download_json(\n            info['cdn'], video_id, 'Downloading vod cdn JSON')\n\n        formats = [{\n            'url': rtmp_info['serverurl'] + rtmp_info['fileurl'],\n            'ext': 'flv',\n            'page_url': url,\n            'player_url': 'http://flvfile.mnet.com/service/player/201602/cjem_player_tv.swf?v=201602191318',\n        }]\n\n        description = info.get('ment')\n        duration = parse_duration(info.get('time'))\n        timestamp = parse_iso8601(info.get('date'), delimiter=' ')\n        age_limit = info.get('adult')\n        if age_limit is not None:\n            age_limit = 0 if age_limit == 'N' else 18\n        thumbnails = [{\n            'id': thumb_format,\n            'url': thumb['url'],\n            'width': int_or_none(thumb.get('width')),\n            'height': int_or_none(thumb.get('height')),\n        } for thumb_format, thumb in info.get('cover', {}).items() if thumb.get('url')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'age_limit': age_limit,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract#59",
        "src_path": "youtube_dl/extractor/moevideo.py",
        "class_name": "youtube_dl.extractor.moevideo.MoeVideoIE",
        "signature": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(\n            'http://%s/video/%s' % (mobj.group('host'), video_id),\n            video_id, 'Downloading webpage')\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        r = [\n            self._API_KEY,\n            [\n                'preview/flv_link',\n                {\n                    'uid': video_id,\n                },\n            ],\n        ]\n        r_json = json.dumps(r)\n        post = urlencode_postdata({'r': r_json})\n        req = sanitized_Request(self._API_URL, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        response = self._download_json(req, video_id)\n        if response['status'] != 'OK':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, response['data']),\n                expected=True\n            )\n        item = response['data'][0]\n        video_url = item['link']\n        duration = int_or_none(item['length'])\n        width = int_or_none(item['width'])\n        height = int_or_none(item['height'])\n        filesize = int_or_none(item['convert_size'])\n\n        formats = [{\n            'format_id': 'sd',\n            'http_headers': {'Range': 'bytes=0-'},  # Required to download\n            'url': video_url,\n            'width': width,\n            'height': height,\n            'filesize': filesize,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 59,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mofosex.MofosexIE._real_extract#34",
        "src_path": "youtube_dl/extractor/mofosex.py",
        "class_name": "youtube_dl.extractor.mofosex.MofosexIE",
        "signature": "youtube_dl.extractor.mofosex.MofosexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage, info = self._extract_info(url)\n\n        view_count = str_to_int(self._search_regex(\n            r'VIEWS:</span>\\s*([\\d,.]+)', webpage, 'view count', fatal=False))\n        like_count = int_or_none(self._search_regex(\n            r'id=[\"\\']amountLikes[\"\\'][^>]*>(\\d+)', webpage,\n            'like count', fatal=False))\n        dislike_count = int_or_none(self._search_regex(\n            r'id=[\"\\']amountDislikes[\"\\'][^>]*>(\\d+)', webpage,\n            'like count', fatal=False))\n        upload_date = unified_strdate(self._html_search_regex(\n            r'Added:</span>([^<]+)', webpage, 'upload date', fatal=False))\n\n        info.update({\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'upload_date': upload_date,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        })\n\n        return info",
        "begin_line": 34,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract#28",
        "src_path": "youtube_dl/extractor/mojvideo.py",
        "class_name": "youtube_dl.extractor.mojvideo.MojvideoIE",
        "signature": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        # XML is malformed\n        playerapi = self._download_webpage(\n            'http://www.mojvideo.com/playerapi.php?v=%s&t=1' % video_id, display_id)\n\n        if '<error>true</error>' in playerapi:\n            error_desc = self._html_search_regex(\n                r'<errordesc>([^<]*)</errordesc>', playerapi, 'error description', fatal=False)\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error_desc), expected=True)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', playerapi, 'title')\n        video_url = self._html_search_regex(\n            r'<file>([^<]+)</file>', playerapi, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<preview>([^<]+)</preview>', playerapi, 'thumbnail', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'<duration>([^<]+)</duration>', playerapi, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.moniker.MonikerIE._real_extract#61",
        "src_path": "youtube_dl/extractor/moniker.py",
        "class_name": "youtube_dl.extractor.moniker.MonikerIE",
        "signature": "youtube_dl.extractor.moniker.MonikerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        orig_video_id = self._match_id(url)\n        video_id = remove_start(orig_video_id, 'embed-')\n        url = url.replace(orig_video_id, video_id)\n        assert re.match(self._VALID_URL, url) is not None\n        orig_webpage = self._download_webpage(url, video_id)\n\n        if '>File Not Found<' in orig_webpage:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        error = self._search_regex(\n            r'class=\"err\">([^<]+)<', orig_webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        builtin_url = self._search_regex(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>.+?/builtin-.+?)\\1',\n            orig_webpage, 'builtin URL', default=None, group='url')\n\n        if builtin_url:\n            req = sanitized_Request(builtin_url)\n            req.add_header('Referer', url)\n            webpage = self._download_webpage(req, video_id, 'Downloading builtin page')\n            title = self._og_search_title(orig_webpage).strip()\n            description = self._og_search_description(orig_webpage).strip()\n        else:\n            fields = re.findall(r'type=\"hidden\" name=\"(.+?)\"\\s* value=\"?(.+?)\">', orig_webpage)\n            data = dict(fields)\n\n            post = urlencode_postdata(data)\n            headers = {\n                b'Content-Type': b'application/x-www-form-urlencoded',\n            }\n            req = sanitized_Request(url, post, headers)\n            webpage = self._download_webpage(\n                req, video_id, note='Downloading video page ...')\n\n            title = os.path.splitext(data['fname'])[0]\n            description = None\n\n        # Could be several links with different quality\n        links = re.findall(r'\"file\" : \"?(.+?)\",', webpage)\n        # Assume the links are ordered in quality\n        formats = [{\n            'url': l,\n            'quality': i,\n        } for i, l in enumerate(links)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 61,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract#24",
        "src_path": "youtube_dl/extractor/morningstar.py",
        "class_name": "youtube_dl.extractor.morningstar.MorningstarIE",
        "signature": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<h1 id=\"titleLink\">(.*?)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidVideoUrl\" value=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidSnapshot\" value=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        description = self._html_search_regex(\n            r'<div id=\"mstarDeck\".*?>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.motherless.MotherlessIE._real_extract#63",
        "src_path": "youtube_dl/extractor/motherless.py",
        "class_name": "youtube_dl.extractor.motherless.MotherlessIE",
        "signature": "youtube_dl.extractor.motherless.MotherlessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if any(p in webpage for p in (\n                '<title>404 - MOTHERLESS.COM<',\n                \">The page you're looking for cannot be found.<\")):\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        if '>The content you are trying to view is for friends only.' in webpage:\n            raise ExtractorError('Video %s is for friends only' % video_id, expected=True)\n\n        title = self._html_search_regex(\n            r'id=\"view-upload-title\">\\s+([^<]+)<', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'setup\\(\\{\\s+\"file\".+: \"([^\"]+)\",', webpage, 'video URL')\n        age_limit = self._rta_search(webpage)\n        view_count = str_to_int(self._html_search_regex(\n            r'<strong>Views</strong>\\s+([^<]+)<',\n            webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._html_search_regex(\n            r'<strong>Favorited</strong>\\s+([^<]+)<',\n            webpage, 'like count', fatal=False))\n\n        upload_date = self._html_search_regex(\n            r'<strong>Uploaded</strong>\\s+([^<]+)<', webpage, 'upload date')\n        if 'Ago' in upload_date:\n            days = int(re.search(r'([0-9]+)', upload_date).group(1))\n            upload_date = (datetime.datetime.now() - datetime.timedelta(days=days)).strftime('%Y%m%d')\n        else:\n            upload_date = unified_strdate(upload_date)\n\n        comment_count = webpage.count('class=\"media-comment-contents\"')\n        uploader_id = self._html_search_regex(\n            r'\"thumb-member-username\">\\s+<a href=\"/m/([^\"]+)\"',\n            webpage, 'uploader_id')\n\n        categories = self._html_search_meta('keywords', webpage, default=None)\n        if categories:\n            categories = [cat.strip() for cat in categories.split(',')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'categories': categories,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'age_limit': age_limit,\n            'url': video_url,\n        }",
        "begin_line": 63,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract#32",
        "src_path": "youtube_dl/extractor/motorsport.py",
        "class_name": "youtube_dl.extractor.motorsport.MotorsportIE",
        "signature": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        iframe_path = self._html_search_regex(\n            r'<iframe id=\"player_iframe\"[^>]+src=\"([^\"]+)\"', webpage,\n            'iframe path')\n        iframe = self._download_webpage(\n            compat_urlparse.urljoin(url, iframe_path), display_id,\n            'Downloading iframe')\n        youtube_id = self._search_regex(\n            r'www.youtube.com/embed/(.{11})', iframe, 'youtube id')\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'url': 'https://youtube.com/watch?v=%s' % youtube_id,\n        }",
        "begin_line": 32,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract#31",
        "src_path": "youtube_dl/extractor/movieclips.py",
        "class_name": "youtube_dl.extractor.movieclips.MovieClipsIE",
        "signature": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video = next(v for v in self._parse_json(self._search_regex(\n            r'var\\s+__REACT_ENGINE__\\s*=\\s*({.+});',\n            webpage, 'react engine'), video_id)['playlist']['videos'] if v['id'] == video_id)\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(update_url_query(\n                video['contentUrl'], {'mbr': 'true'}), {'force_smil_url': True}),\n            'title': self._og_search_title(webpage),\n            'description': self._html_search_meta('description', webpage),\n            'duration': float_or_none(video.get('duration')),\n            'timestamp': parse_iso8601(video.get('dateCreated')),\n            'thumbnail': video.get('defaultImage'),\n            'uploader': video.get('provider'),\n        }",
        "begin_line": 31,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract#23",
        "src_path": "youtube_dl/extractor/moviezine.py",
        "class_name": "youtube_dl.extractor.moviezine.MoviezineIE",
        "signature": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        jsplayer = self._download_webpage('http://www.moviezine.se/api/player.js?video=%s' % video_id, video_id, 'Downloading js api player')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': self._html_search_regex(r'file: \"(.+?)\",', jsplayer, 'file'),\n            'quality': 0,\n            'ext': 'mp4',\n        }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._search_regex(r'title: \"(.+?)\",', jsplayer, 'title'),\n            'thumbnail': self._search_regex(r'image: \"(.+?)\",', jsplayer, 'image'),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 23,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.movingimage.MovingImageIE._real_extract#25",
        "src_path": "youtube_dl/extractor/movingimage.py",
        "class_name": "youtube_dl.extractor.movingimage.MovingImageIE",
        "signature": "youtube_dl.extractor.movingimage.MovingImageIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = self._extract_m3u8_formats(\n            self._html_search_regex(r'file\\s*:\\s*\"([^\"]+)\"', webpage, 'm3u8 manifest URL'),\n            video_id, ext='mp4', entry_protocol='m3u8_native')\n\n        def search_field(field_name, fatal=False):\n            return self._search_regex(\n                r'<span\\s+class=\"field_title\">%s:</span>\\s*<span\\s+class=\"field_content\">([^<]+)</span>' % field_name,\n                webpage, 'title', fatal=fatal)\n\n        title = unescapeHTML(search_field('Title', fatal=True)).strip('()[]')\n        description = unescapeHTML(search_field('Description'))\n        duration = parse_duration(search_field('Running time'))\n        thumbnail = self._search_regex(\n            r\"image\\s*:\\s*'([^']+)'\", webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 25,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.msn.MSNIE._real_extract#46",
        "src_path": "youtube_dl/extractor/msn.py",
        "class_name": "youtube_dl.extractor.msn.MSNIE",
        "signature": "youtube_dl.extractor.msn.MSNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, display_id = mobj.group('id', 'display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video = self._parse_json(\n            self._search_regex(\n                r'data-metadata\\s*=\\s*([\"\\'])(?P<data>.+?)\\1',\n                webpage, 'video data', default='{}', group='data'),\n            display_id, transform_source=unescapeHTML)\n\n        if not video:\n            error = unescapeHTML(self._search_regex(\n                r'data-error=([\"\\'])(?P<error>.+?)\\1',\n                webpage, 'error', group='error'))\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)\n\n        title = video['title']\n\n        formats = []\n        for file_ in video.get('videoFiles', []):\n            format_url = file_.get('url')\n            if not format_url:\n                continue\n            if 'm3u8' in format_url:\n                # m3u8_native should not be used here until\n                # https://github.com/rg3/youtube-dl/issues/9913 is fixed\n                m3u8_formats = self._extract_m3u8_formats(\n                    format_url, display_id, 'mp4',\n                    m3u8_id='hls', fatal=False)\n                formats.extend(m3u8_formats)\n            elif determine_ext(format_url) == 'ism':\n                formats.extend(self._extract_ism_formats(\n                    format_url + '/Manifest', display_id, 'mss', fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'ext': 'mp4',\n                    'format_id': 'http',\n                    'width': int_or_none(file_.get('width')),\n                    'height': int_or_none(file_.get('height')),\n                })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for file_ in video.get('files', []):\n            format_url = file_.get('url')\n            format_code = file_.get('formatCode')\n            if not format_url or not format_code:\n                continue\n            if compat_str(format_code) == '3100':\n                subtitles.setdefault(file_.get('culture', 'en'), []).append({\n                    'ext': determine_ext(format_url, 'ttml'),\n                    'url': format_url,\n                })\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnail': video.get('headlineImage', {}).get('url'),\n            'duration': int_or_none(video.get('durationSecs')),\n            'uploader': video.get('sourceFriendly'),\n            'uploader_id': video.get('providerId'),\n            'creator': video.get('creator'),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv._media_xml_tag#28",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv",
        "signature": "youtube_dl.extractor.mtv._media_xml_tag(tag)",
        "snippet": "def _media_xml_tag(tag):\n    return '{http://search.yahoo.com/mrss/}%s' % tag",
        "begin_line": 28,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri#37",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri(uri)",
        "snippet": "    def _id_from_uri(uri):\n        return uri.split(':')[-1]",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._remove_template_parameter#41",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._remove_template_parameter(url)",
        "snippet": "    def _remove_template_parameter(url):\n        # Remove the templates, like &device={device}\n        return re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', url)",
        "begin_line": 41,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url#45",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        return self._FEED_URL",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url#48",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        search_path = '%s/%s' % (_media_xml_tag('group'), _media_xml_tag('thumbnail'))\n        thumb_node = itemdoc.find(search_path)\n        if thumb_node is None:\n            return None\n        return thumb_node.get('url') or thumb_node.text or None",
        "begin_line": 48,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats#55",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats(self, mtvn_id)",
        "snippet": "    def _extract_mobile_video_formats(self, mtvn_id):\n        webpage_url = self._MOBILE_TEMPLATE % mtvn_id\n        req = sanitized_Request(webpage_url)\n        # Otherwise we get a webpage that would execute some javascript\n        req.add_header('User-Agent', 'curl/7')\n        webpage = self._download_webpage(req, mtvn_id,\n                                         'Downloading mobile page')\n        metrics_url = unescapeHTML(self._search_regex(r'<a href=\"(http://metrics.+?)\"', webpage, 'url'))\n        req = HEADRequest(metrics_url)\n        response = self._request_webpage(req, mtvn_id, 'Resolving url')\n        url = response.geturl()\n        # Transform the url to get the best quality:\n        url = re.sub(r'.+pxE=mp4', 'http://mtvnmobile.vo.llnwd.net/kip0/_pxn=0+_pxK=18639+_pxE=mp4', url, 1)\n        return [{'url': url, 'ext': 'mp4'}]",
        "begin_line": 55,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats#70",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats(self, mdoc, mtvn_id, video_id)",
        "snippet": "    def _extract_video_formats(self, mdoc, mtvn_id, video_id):\n        if re.match(r'.*/(error_country_block\\.swf|geoblock\\.mp4|copyright_error\\.flv(?:\\?geo\\b.+?)?)$', mdoc.find('.//src').text) is not None:\n            if mtvn_id is not None and self._MOBILE_TEMPLATE is not None:\n                self.to_screen('The normal version is not available from your '\n                               'country, trying with the mobile version')\n                return self._extract_mobile_video_formats(mtvn_id)\n            raise ExtractorError('This video is not available from your country.',\n                                 expected=True)\n\n        formats = []\n        for rendition in mdoc.findall('.//rendition'):\n            if rendition.get('method') == 'hls':\n                hls_url = rendition.find('./src').text\n                formats.extend(self._extract_m3u8_formats(\n                    hls_url, video_id, ext='mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                # fms\n                try:\n                    _, _, ext = rendition.attrib['type'].partition('/')\n                    rtmp_video_url = rendition.find('./src').text\n                    if 'error_not_available.swf' in rtmp_video_url:\n                        raise ExtractorError(\n                            '%s said: video is not available' % self.IE_NAME,\n                            expected=True)\n                    if rtmp_video_url.endswith('siteunavail.png'):\n                        continue\n                    formats.extend([{\n                        'ext': 'flv' if rtmp_video_url.startswith('rtmp') else ext,\n                        'url': rtmp_video_url,\n                        'format_id': '-'.join(filter(None, [\n                            'rtmp' if rtmp_video_url.startswith('rtmp') else None,\n                            rendition.get('bitrate')])),\n                        'width': int(rendition.get('width')),\n                        'height': int(rendition.get('height')),\n                    }])\n                except (KeyError, TypeError):\n                    raise ExtractorError('Invalid rendition field.')\n        if formats:\n            self._sort_formats(formats)\n        return formats",
        "begin_line": 70,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_subtitles#112",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_subtitles(self, mdoc, mtvn_id)",
        "snippet": "    def _extract_subtitles(self, mdoc, mtvn_id):\n        subtitles = {}\n        for transcript in mdoc.findall('.//transcript'):\n            if transcript.get('kind') != 'captions':\n                continue\n            lang = transcript.get('srclang')\n            subtitles[lang] = [{\n                'url': compat_str(typographic.get('src')),\n                'ext': typographic.get('format')\n            } for typographic in transcript.findall('./typographic')]\n        return subtitles",
        "begin_line": 112,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info#124",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info(self, itemdoc, use_hls=True)",
        "snippet": "    def _get_video_info(self, itemdoc, use_hls=True):\n        uri = itemdoc.find('guid').text\n        video_id = self._id_from_uri(uri)\n        self.report_extraction(video_id)\n        content_el = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content')))\n        mediagen_url = self._remove_template_parameter(content_el.attrib['url'])\n        mediagen_url = mediagen_url.replace('device={device}', '')\n        if 'acceptMethods' not in mediagen_url:\n            mediagen_url += '&' if '?' in mediagen_url else '?'\n            mediagen_url += 'acceptMethods='\n            mediagen_url += 'hls' if use_hls else 'fms'\n\n        mediagen_doc = self._download_xml(\n            mediagen_url, video_id, 'Downloading video urls', fatal=False)\n\n        if mediagen_doc is False:\n            return None\n\n        item = mediagen_doc.find('./video/item')\n        if item is not None and item.get('type') == 'text':\n            message = '%s returned error: ' % self.IE_NAME\n            if item.get('code') is not None:\n                message += '%s - ' % item.get('code')\n            message += item.text\n            raise ExtractorError(message, expected=True)\n\n        description = strip_or_none(xpath_text(itemdoc, 'description'))\n\n        timestamp = timeconvert(xpath_text(itemdoc, 'pubDate'))\n\n        title_el = None\n        if title_el is None:\n            title_el = find_xpath_attr(\n                itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                'scheme', 'urn:mtvn:video_title')\n        if title_el is None:\n            title_el = itemdoc.find(compat_xpath('.//{http://search.yahoo.com/mrss/}title'))\n        if title_el is None:\n            title_el = itemdoc.find(compat_xpath('.//title'))\n            if title_el.text is None:\n                title_el = None\n\n        title = title_el.text\n        if title is None:\n            raise ExtractorError('Could not find video title')\n        title = title.strip()\n\n        # This a short id that's used in the webpage urls\n        mtvn_id = None\n        mtvn_id_node = find_xpath_attr(itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                                       'scheme', 'urn:mtvn:id')\n        if mtvn_id_node is not None:\n            mtvn_id = mtvn_id_node.text\n\n        formats = self._extract_video_formats(mediagen_doc, mtvn_id, video_id)\n\n        # Some parts of complete video may be missing (e.g. missing Act 3 in\n        # http://www.southpark.de/alle-episoden/s14e01-sexual-healing)\n        if not formats:\n            return None\n\n        self._sort_formats(formats)\n\n        return {\n            'title': title,\n            'formats': formats,\n            'subtitles': self._extract_subtitles(mediagen_doc, mtvn_id),\n            'id': video_id,\n            'thumbnail': self._get_thumbnail_url(uri, itemdoc),\n            'description': description,\n            'duration': float_or_none(content_el.attrib.get('duration')),\n            'timestamp': timestamp,\n        }",
        "begin_line": 124,
        "end_line": 196,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_query#198",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_query(self, uri)",
        "snippet": "    def _get_feed_query(self, uri):\n        data = {'uri': uri}\n        if self._LANG:\n            data['lang'] = self._LANG\n        return data",
        "begin_line": 198,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info#204",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info(self, uri, use_hls=True)",
        "snippet": "    def _get_videos_info(self, uri, use_hls=True):\n        video_id = self._id_from_uri(uri)\n        feed_url = self._get_feed_url(uri)\n        info_url = update_url_query(feed_url, self._get_feed_query(uri))\n        return self._get_videos_info_from_url(info_url, video_id, use_hls)",
        "begin_line": 204,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info_from_url#210",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info_from_url(self, url, video_id, use_hls=True)",
        "snippet": "    def _get_videos_info_from_url(self, url, video_id, use_hls=True):\n        idoc = self._download_xml(\n            url, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n\n        title = xpath_text(idoc, './channel/title')\n        description = xpath_text(idoc, './channel/description')\n\n        entries = []\n        for item in idoc.findall('.//item'):\n            info = self._get_video_info(item, use_hls)\n            if info:\n                entries.append(info)\n\n        return self.playlist_result(\n            entries, playlist_title=title, playlist_description=description)",
        "begin_line": 210,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_triforce_mgid#227",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_triforce_mgid(self, webpage, data_zone=None, video_id=None)",
        "snippet": "    def _extract_triforce_mgid(self, webpage, data_zone=None, video_id=None):\n        triforce_feed = self._parse_json(self._search_regex(\n            r'triforceManifestFeed\\s*=\\s*({.+?})\\s*;\\s*\\n', webpage,\n            'triforce feed', default='{}'), video_id, fatal=False)\n\n        data_zone = self._search_regex(\n            r'data-zone=([\"\\'])(?P<zone>.+?_lc_promo.*?)\\1', webpage,\n            'data zone', default=data_zone, group='zone')\n\n        feed_url = try_get(\n            triforce_feed, lambda x: x['manifest']['zones'][data_zone]['feed'],\n            compat_str)\n        if not feed_url:\n            return\n\n        feed = self._download_json(feed_url, video_id, fatal=False)\n        if not feed:\n            return\n\n        return try_get(feed, lambda x: x['result']['data']['id'], compat_str)",
        "begin_line": 227,
        "end_line": 246,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mgid#248",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        try:\n            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf\n            # or http://media.mtvnservices.com/{mgid}\n            og_url = self._og_search_video_url(webpage)\n            mgid = url_basename(og_url)\n            if mgid.endswith('.swf'):\n                mgid = mgid[:-4]\n        except RegexNotFoundError:\n            mgid = None\n\n        if mgid is None or ':' not in mgid:\n            mgid = self._search_regex(\n                [r'data-mgid=\"(.*?)\"', r'swfobject.embedSWF\\(\".*?(mgid:.*?)\"'],\n                webpage, 'mgid', default=None)\n\n        if not mgid:\n            sm4_embed = self._html_search_meta(\n                'sm4:video:embed', webpage, 'sm4 embed', default='')\n            mgid = self._search_regex(\n                r'embed/(mgid:.+?)[\"\\'&?/]', sm4_embed, 'mgid', default=None)\n\n        if not mgid:\n            mgid = self._extract_triforce_mgid(webpage)\n\n        return mgid",
        "begin_line": 248,
        "end_line": 273,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract#275",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = url_basename(url)\n        webpage = self._download_webpage(url, title)\n        mgid = self._extract_mgid(webpage)\n        videos_info = self._get_videos_info(mgid)\n        return videos_info",
        "begin_line": 275,
        "end_line": 280,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._extract_url#302",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//media.mtvnservices.com/embed/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 302,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url#308",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        video_id = self._id_from_uri(uri)\n        config = self._download_json(\n            'http://media.mtvnservices.com/pmt/e1/access/index.html?uri=%s&configtype=edge' % uri, video_id)\n        return self._remove_template_parameter(config['feedWithQueryParams'])",
        "begin_line": 308,
        "end_line": 312,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract#314",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        mgid = mobj.group('mgid')\n        return self._get_videos_info(mgid)",
        "begin_line": 314,
        "end_line": 317,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTV81IE._extract_mgid#362",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTV81IE",
        "signature": "youtube_dl.extractor.mtv.MTV81IE._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        return self._search_regex(\n            r'getTheVideo\\(([\"\\'])(?P<id>mgid:.+?)\\1', webpage,\n            'mgid', group='id')",
        "begin_line": 362,
        "end_line": 365,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTV81IE._real_extract#367",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTV81IE",
        "signature": "youtube_dl.extractor.mtv.MTV81IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        mgid = self._extract_mgid(webpage)\n        return self.url_result('http://media.mtvnservices.com/embed/%s' % mgid)",
        "begin_line": 367,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVVideoIE._get_thumbnail_url#397",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVVideoIE",
        "signature": "youtube_dl.extractor.mtv.MTVVideoIE._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        return 'http://mtv.mtvnimages.com/uri/' + uri",
        "begin_line": 397,
        "end_line": 398,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVVideoIE._real_extract#400",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVVideoIE",
        "signature": "youtube_dl.extractor.mtv.MTVVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        uri = mobj.groupdict().get('mgid')\n        if uri is None:\n            webpage = self._download_webpage(url, video_id)\n\n            # Some videos come from Vevo.com\n            m_vevo = re.search(\n                r'(?s)isVevoVideo = true;.*?vevoVideoId = \"(.*?)\";', webpage)\n            if m_vevo:\n                vevo_id = m_vevo.group(1)\n                self.to_screen('Vevo video detected: %s' % vevo_id)\n                return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n\n            uri = self._html_search_regex(r'/uri/(.*?)\\?', webpage, 'uri')\n        return self._get_videos_info(uri)",
        "begin_line": 400,
        "end_line": 416,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVDEIE._real_extract#463",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVDEIE",
        "signature": "youtube_dl.extractor.mtv.MTVDEIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'window\\.pagePlaylist\\s*=\\s*(\\[.+?\\]);\\n', webpage, 'page playlist'),\n            video_id)\n\n        def _mrss_url(item):\n            return item['mrss'] + item.get('mrssvars', '')\n\n        # news pages contain single video in playlist with different id\n        if len(playlist) == 1:\n            return self._get_videos_info_from_url(_mrss_url(playlist[0]), video_id)\n\n        for item in playlist:\n            item_id = item.get('id')\n            if item_id and compat_str(item_id) == video_id:\n                return self._get_videos_info_from_url(_mrss_url(item), video_id)",
        "begin_line": 463,
        "end_line": 483,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.muenchentv.MuenchenTVIE._real_extract#32",
        "src_path": "youtube_dl/extractor/muenchentv.py",
        "class_name": "youtube_dl.extractor.muenchentv.MuenchenTVIE",
        "signature": "youtube_dl.extractor.muenchentv.MuenchenTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = 'live'\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._live_title(self._og_search_title(webpage))\n\n        data_js = self._search_regex(\n            r'(?s)\\nplaylist:\\s*(\\[.*?}\\]),',\n            webpage, 'playlist configuration')\n        data_json = js_to_json(data_js)\n        data = json.loads(data_json)[0]\n\n        video_id = data['mediaid']\n        thumbnail = data.get('image')\n\n        formats = []\n        for format_num, s in enumerate(data['sources']):\n            ext = determine_ext(s['file'], None)\n            label_str = s.get('label')\n            if label_str is None:\n                label_str = '_%d' % format_num\n\n            if ext is None:\n                format_id = label_str\n            else:\n                format_id = '%s-%s' % (ext, label_str)\n\n            formats.append({\n                'url': s['file'],\n                'tbr': int_or_none(s.get('label')),\n                'ext': 'mp4',\n                'format_id': format_id,\n                'preference': -100 if '.smil' in s['file'] else 0,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'is_live': True,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 32,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract#34",
        "src_path": "youtube_dl/extractor/musicplayon.py",
        "class_name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE",
        "signature": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = self._URL_TEMPLATE % video_id\n\n        page = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(page)\n        description = self._og_search_description(page)\n        thumbnail = self._og_search_thumbnail(page)\n        duration = self._html_search_meta('video:duration', page, 'duration', fatal=False)\n        view_count = self._og_search_property('count', page, fatal=False)\n        uploader = self._html_search_regex(\n            r'<div>by&nbsp;<a href=\"[^\"]+\" class=\"purple\">([^<]+)</a></div>', page, 'uploader', fatal=False)\n\n        sources = self._parse_json(\n            self._search_regex(r'setup\\[\\'_sources\\'\\]\\s*=\\s*([^;]+);', page, 'video sources'),\n            video_id, transform_source=js_to_json)\n        formats = [{\n            'url': compat_urlparse.urljoin(url, source['src']),\n            'ext': mimetype2ext(source.get('type')),\n            'format_note': source.get('data-res'),\n        } for source in sources]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': int_or_none(duration),\n            'view_count': int_or_none(view_count),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mwave.MwaveIE._real_extract#31",
        "src_path": "youtube_dl/extractor/mwave.py",
        "class_name": "youtube_dl.extractor.mwave.MwaveIE",
        "signature": "youtube_dl.extractor.mwave.MwaveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        vod_info = self._download_json(\n            'http://mwave.interest.me/onair/vod_info.m?vodtype=CL&sectorid=&endinfo=Y&id=%s' % video_id,\n            video_id, 'Download vod JSON')\n\n        formats = []\n        for num, cdn_info in enumerate(vod_info['cdn']):\n            stream_url = cdn_info.get('url')\n            if not stream_url:\n                continue\n            stream_name = cdn_info.get('name') or compat_str(num)\n            f4m_stream = self._download_json(\n                stream_url, video_id,\n                'Download %s stream JSON' % stream_name)\n            f4m_url = f4m_stream.get('fileurl')\n            if not f4m_url:\n                continue\n            formats.extend(\n                self._extract_f4m_formats(f4m_url + '&hdcore=3.0.3', video_id, f4m_id=stream_name))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': vod_info['title'],\n            'thumbnail': vod_info.get('cover'),\n            'uploader': vod_info.get('program_title'),\n            'duration': parse_duration(vod_info.get('time')),\n            'view_count': int_or_none(vod_info.get('hit')),\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.mwave.MwaveMeetGreetIE._real_extract#83",
        "src_path": "youtube_dl/extractor/mwave.py",
        "class_name": "youtube_dl.extractor.mwave.MwaveMeetGreetIE",
        "signature": "youtube_dl.extractor.mwave.MwaveMeetGreetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        clip_id = self._html_search_regex(\n            r'<iframe[^>]+src=\"/mnettv/ifr_clip\\.m\\?searchVideoDetailVO\\.clip_id=(\\d+)',\n            webpage, 'clip ID')\n        clip_url = MwaveIE._URL_TEMPLATE % clip_id\n        return self.url_result(clip_url, 'Mwave', clip_id)",
        "begin_line": 83,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceIE._real_extract#68",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id') or mobj.group('song_id')\n        is_song = mobj.group('mediatype').startswith('music/song')\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'videoSwf\":\"([^\"?]*)', webpage, 'player URL', fatal=False)\n\n        def formats_from_stream_urls(stream_url, hls_stream_url, http_stream_url, width=None, height=None):\n            formats = []\n            vcodec = 'none' if is_song else None\n            if hls_stream_url:\n                formats.append({\n                    'format_id': 'hls',\n                    'url': hls_stream_url,\n                    'protocol': 'm3u8_native',\n                    'ext': 'm4a' if is_song else 'mp4',\n                    'vcodec': vcodec,\n                })\n            if stream_url and player_url:\n                rtmp_url, play_path = stream_url.split(';', 1)\n                formats.append({\n                    'format_id': 'rtmp',\n                    'url': rtmp_url,\n                    'play_path': play_path,\n                    'player_url': player_url,\n                    'protocol': 'rtmp',\n                    'ext': 'flv',\n                    'width': width,\n                    'height': height,\n                    'vcodec': vcodec,\n                })\n            if http_stream_url:\n                formats.append({\n                    'format_id': 'http',\n                    'url': http_stream_url,\n                    'width': width,\n                    'height': height,\n                    'vcodec': vcodec,\n                })\n            return formats\n\n        if is_song:\n            # songs don't store any useful info in the 'context' variable\n            song_data = self._search_regex(\n                r'''<button.*data-song-id=([\"\\'])%s\\1.*''' % video_id,\n                webpage, 'song_data', default=None, group=0)\n            if song_data is None:\n                # some songs in an album are not playable\n                self.report_warning(\n                    '%s: No downloadable song on this page' % video_id)\n                return\n\n            def search_data(name):\n                return self._search_regex(\n                    r'''data-%s=([\\'\"])(?P<data>.*?)\\1''' % name,\n                    song_data, name, default='', group='data')\n            formats = formats_from_stream_urls(\n                search_data('stream-url'), search_data('hls-stream-url'),\n                search_data('http-stream-url'))\n            if not formats:\n                vevo_id = search_data('vevo-id')\n                youtube_id = search_data('youtube-id')\n                if vevo_id:\n                    self.to_screen('Vevo video detected: %s' % vevo_id)\n                    return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n                elif youtube_id:\n                    self.to_screen('Youtube video detected: %s' % youtube_id)\n                    return self.url_result(youtube_id, ie='Youtube')\n                else:\n                    raise ExtractorError(\n                        'Found song but don\\'t know how to download it')\n            self._sort_formats(formats)\n            return {\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'uploader': search_data('artist-name'),\n                'uploader_id': search_data('artist-username'),\n                'thumbnail': self._og_search_thumbnail(webpage),\n                'duration': int_or_none(search_data('duration')),\n                'formats': formats,\n            }\n        else:\n            video = self._parse_json(self._search_regex(\n                r'context = ({.*?});', webpage, 'context'),\n                video_id)['video']\n            formats = formats_from_stream_urls(\n                video.get('streamUrl'), video.get('hlsStreamUrl'),\n                video.get('mp4StreamUrl'), int_or_none(video.get('width')),\n                int_or_none(video.get('height')))\n            self._sort_formats(formats)\n            return {\n                'id': video_id,\n                'title': video['title'],\n                'description': video.get('description'),\n                'thumbnail': video.get('imageUrl'),\n                'uploader': video.get('artistName'),\n                'uploader_id': video.get('artistUsername'),\n                'duration': int_or_none(video.get('duration')),\n                'timestamp': parse_iso8601(video.get('dateAdded')),\n                'formats': formats,\n            }",
        "begin_line": 68,
        "end_line": 169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceAlbumIE._real_extract#193",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceAlbumIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        display_id = mobj.group('title') + playlist_id\n        webpage = self._download_webpage(url, display_id)\n        tracks_paths = re.findall(r'\"music:song\" content=\"(.*?)\"', webpage)\n        if not tracks_paths:\n            raise ExtractorError(\n                '%s: No songs found, try using proxy' % display_id,\n                expected=True)\n        entries = [\n            self.url_result(t_path, ie=MySpaceIE.ie_key())\n            for t_path in tracks_paths]\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': display_id,\n            'title': self._og_search_title(webpage),\n            'entries': entries,\n        }",
        "begin_line": 193,
        "end_line": 212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myspass.MySpassIE._real_extract#26",
        "src_path": "youtube_dl/extractor/myspass.py",
        "class_name": "youtube_dl.extractor.myspass.MySpassIE",
        "signature": "youtube_dl.extractor.myspass.MySpassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        META_DATA_URL_TEMPLATE = 'http://www.myspass.de/myspass/includes/apps/video/getvideometadataxml.php?id=%s'\n\n        # video id is the last path element of the URL\n        # usually there is a trailing slash, so also try the second but last\n        url_path = compat_urllib_parse_urlparse(url).path\n        url_parent_path, video_id = os.path.split(url_path)\n        if not video_id:\n            _, video_id = os.path.split(url_parent_path)\n\n        # get metadata\n        metadata_url = META_DATA_URL_TEMPLATE % video_id\n        metadata = self._download_xml(\n            metadata_url, video_id, transform_source=lambda s: s.strip())\n\n        # extract values from metadata\n        url_flv_el = metadata.find('url_flv')\n        if url_flv_el is None:\n            raise ExtractorError('Unable to extract download url')\n        video_url = url_flv_el.text\n        title_el = metadata.find('title')\n        if title_el is None:\n            raise ExtractorError('Unable to extract title')\n        title = title_el.text\n        format_id_el = metadata.find('format_id')\n        if format_id_el is None:\n            format = 'mp4'\n        else:\n            format = format_id_el.text\n        description_el = metadata.find('description')\n        if description_el is not None:\n            description = description_el.text\n        else:\n            description = None\n        imagePreview_el = metadata.find('imagePreview')\n        if imagePreview_el is not None:\n            thumbnail = imagePreview_el.text\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'format': format,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvi.MyviIE._extract_url#48",
        "src_path": "youtube_dl/extractor/myvi.py",
        "class_name": "youtube_dl.extractor.myvi.MyviIE",
        "signature": "youtube_dl.extractor.myvi.MyviIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//myvi\\.(?:ru/player|tv)/(?:embed/html|flash)/[^\"]+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvi.MyviIE._real_extract#54",
        "src_path": "youtube_dl/extractor/myvi.py",
        "class_name": "youtube_dl.extractor.myvi.MyviIE",
        "signature": "youtube_dl.extractor.myvi.MyviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        spruto = self._download_json(\n            'http://myvi.ru/player/api/Video/Get/%s?sig' % video_id, video_id)['sprutoData']\n\n        return self._extract_spruto(spruto, video_id)",
        "begin_line": 54,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt#38",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt(self, data, key)",
        "snippet": "    def __rc4crypt(self, data, key):\n        x = 0\n        box = list(range(256))\n        for i in list(range(256)):\n            x = (x + box[i] + compat_ord(key[i % len(key)])) % 256\n            box[i], box[x] = box[x], box[i]\n        x = 0\n        y = 0\n        out = ''\n        for char in data:\n            x = (x + 1) % 256\n            y = (y + box[x]) % 256\n            box[x], box[y] = box[y], box[x]\n            out += chr(compat_ord(char) ^ box[(box[x] + box[y]) % 256])\n        return out",
        "begin_line": 38,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__md5#54",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__md5(self, s)",
        "snippet": "    def __md5(self, s):\n        return hashlib.md5(s).hexdigest().encode()",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract#57",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        GK = (\n            b'WXpnME1EZGhNRGhpTTJNM01XVmhOREU0WldNNVpHTTJOakpt'\n            b'TW1FMU5tVTBNR05pWkRaa05XRXhNVFJoWVRVd1ptSXhaVEV3'\n            b'TnpsbA0KTVRkbU1tSTRNdz09'\n        )\n\n        # Get video webpage\n        webpage_url = 'http://www.myvideo.de/watch/%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        mobj = re.search('source src=\\'(.+?)[.]([^.]+)\\'', webpage)\n        if mobj is not None:\n            self.report_extraction(video_id)\n            video_url = mobj.group(1) + '.flv'\n\n            video_title = self._html_search_regex('<title>([^<]+)</title>',\n                                                  webpage, 'title')\n\n            return {\n                'id': video_id,\n                'url': video_url,\n                'title': video_title,\n            }\n\n        mobj = re.search(r'data-video-service=\"/service/data/video/%s/config' % video_id, webpage)\n        if mobj is not None:\n            request = sanitized_Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')\n            response = self._download_webpage(request, video_id,\n                                              'Downloading video info')\n            info = json.loads(base64.b64decode(response).decode('utf-8'))\n            return {\n                'id': video_id,\n                'title': info['title'],\n                'url': info['streaming_url'].replace('rtmpe', 'rtmpt'),\n                'play_path': info['filename'],\n                'ext': 'flv',\n                'thumbnail': info['thumbnail'][0]['url'],\n            }\n\n        # try encxml\n        mobj = re.search('var flashvars={(.+?)}', webpage)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video')\n\n        params = {}\n        encxml = ''\n        sec = mobj.group(1)\n        for (a, b) in re.findall('(.+?):\\'(.+?)\\',?', sec):\n            if not a == '_encxml':\n                params[a] = b\n            else:\n                encxml = compat_urllib_parse_unquote(b)\n        if not params.get('domain'):\n            params['domain'] = 'www.myvideo.de'\n        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse_urlencode(params))\n        if 'flash_playertype=MTV' in xmldata_url:\n            self._downloader.report_warning('avoiding MTV player')\n            xmldata_url = (\n                'http://www.myvideo.de/dynamic/get_player_video_xml.php'\n                '?flash_playertype=D&ID=%s&_countlimit=4&autorun=yes'\n            ) % video_id\n\n        # get enc data\n        enc_data = self._download_webpage(xmldata_url, video_id).split('=')[1]\n        enc_data_b = binascii.unhexlify(enc_data)\n        sk = self.__md5(\n            base64.b64decode(base64.b64decode(GK)) +\n            self.__md5(\n                str(video_id).encode('utf-8')\n            )\n        )\n        dec_data = self.__rc4crypt(enc_data_b, sk)\n\n        # extracting infos\n        self.report_extraction(video_id)\n\n        video_url = None\n        mobj = re.search('connectionurl=\\'(.*?)\\'', dec_data)\n        if mobj:\n            video_url = compat_urllib_parse_unquote(mobj.group(1))\n            if 'myvideo2flash' in video_url:\n                self.report_warning(\n                    'Rewriting URL to use unencrypted rtmp:// ...',\n                    video_id)\n                video_url = video_url.replace('rtmpe://', 'rtmp://')\n\n        if not video_url:\n            # extract non rtmp videos\n            mobj = re.search('path=\\'(http.*?)\\' source=\\'(.*?)\\'', dec_data)\n            if mobj is None:\n                raise ExtractorError('unable to extract url')\n            video_url = compat_urllib_parse_unquote(mobj.group(1)) + compat_urllib_parse_unquote(mobj.group(2))\n\n        video_file = self._search_regex('source=\\'(.*?)\\'', dec_data, 'video file')\n        video_file = compat_urllib_parse_unquote(video_file)\n\n        if not video_file.endswith('f4m'):\n            ppath, prefix = video_file.split('.')\n            video_playpath = '%s:%s' % (prefix, ppath)\n        else:\n            video_playpath = ''\n\n        video_swfobj = self._search_regex(r'swfobject.embedSWF\\(\\'(.+?)\\'', webpage, 'swfobj')\n        video_swfobj = compat_urllib_parse_unquote(video_swfobj)\n\n        video_title = self._html_search_regex(\"<h1(?: class='globalHd')?>(.*?)</h1>\",\n                                              webpage, 'title')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'tc_url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'play_path': video_playpath,\n            'player_url': video_swfobj,\n        }",
        "begin_line": 57,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.myvidster.MyVidsterIE._real_extract#23",
        "src_path": "youtube_dl/extractor/myvidster.py",
        "class_name": "youtube_dl.extractor.myvidster.MyVidsterIE",
        "signature": "youtube_dl.extractor.myvidster.MyVidsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        return self.url_result(self._html_search_regex(\n            r'rel=\"videolink\" href=\"(?P<real_url>.*)\">',\n            webpage, 'real video url'))",
        "begin_line": 23,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nationalgeographic.NationalGeographicVideoIE._real_extract#51",
        "src_path": "youtube_dl/extractor/nationalgeographic.py",
        "class_name": "youtube_dl.extractor.nationalgeographic.NationalGeographicVideoIE",
        "signature": "youtube_dl.extractor.nationalgeographic.NationalGeographicVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        name = url_basename(url)\n\n        webpage = self._download_webpage(url, name)\n        guid = self._search_regex(\n            r'id=\"(?:videoPlayer|player-container)\"[^>]+data-guid=\"([^\"]+)\"',\n            webpage, 'guid')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(\n                'http://link.theplatform.com/s/ngs/media/guid/2423130747/%s?mbr=true' % guid,\n                {'force_smil_url': True}),\n            'id': guid,\n        }",
        "begin_line": 51,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE._real_extract#108",
        "src_path": "youtube_dl/extractor/nationalgeographic.py",
        "class_name": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE",
        "signature": "youtube_dl.extractor.nationalgeographic.NationalGeographicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        release_url = self._search_regex(\n            r'video_auth_playlist_url\\s*=\\s*\"([^\"]+)\"',\n            webpage, 'release url')\n        theplatform_path = self._search_regex(r'https?://link.theplatform.com/s/([^?]+)', release_url, 'theplatform path')\n        video_id = theplatform_path.split('/')[-1]\n        query = {\n            'mbr': 'true',\n        }\n        is_auth = self._search_regex(r'video_is_auth\\s*=\\s*\"([^\"]+)\"', webpage, 'is auth', fatal=False)\n        if is_auth == 'auth':\n            auth_resource_id = self._search_regex(\n                r\"video_auth_resourceId\\s*=\\s*'([^']+)'\",\n                webpage, 'auth resource id')\n            query['auth'] = self._extract_mvpd_auth(url, video_id, 'natgeo', auth_resource_id)\n\n        formats = []\n        subtitles = {}\n        for key, value in (('switch', 'http'), ('manifest', 'm3u')):\n            tp_query = query.copy()\n            tp_query.update({\n                key: value,\n            })\n            tp_formats, tp_subtitles = self._extract_theplatform_smil(\n                update_url_query(release_url, tp_query), video_id, 'Downloading %s SMIL data' % value)\n            formats.extend(tp_formats)\n            subtitles = self._merge_subtitles(subtitles, tp_subtitles)\n        self._sort_formats(formats)\n\n        info = self._extract_theplatform_metadata(theplatform_path, display_id)\n        info.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': subtitles,\n            'display_id': display_id,\n        })\n        return info",
        "begin_line": 108,
        "end_line": 146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nationalgeographic.NationalGeographicEpisodeGuideIE._real_extract#171",
        "src_path": "youtube_dl/extractor/nationalgeographic.py",
        "class_name": "youtube_dl.extractor.nationalgeographic.NationalGeographicEpisodeGuideIE",
        "signature": "youtube_dl.extractor.nationalgeographic.NationalGeographicEpisodeGuideIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        show = get_element_by_class('show', webpage)\n        selected_season = self._search_regex(\n            r'<div[^>]+class=\"select-seasons[^\"]*\".*?<a[^>]*>(.*?)</a>',\n            webpage, 'selected season')\n        entries = [\n            self.url_result(self._proto_relative_url(entry_url), 'NationalGeographic')\n            for entry_url in re.findall('(?s)<div[^>]+class=\"col-inner\"[^>]*?>.*?<a[^>]+href=\"([^\"]+)\"', webpage)]\n        return self.playlist_result(\n            entries, '%s-%s' % (display_id, selected_season.lower().replace(' ', '-')),\n            '%s - %s' % (show, selected_season))",
        "begin_line": 171,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.naver.NaverIE._real_extract#42",
        "src_path": "youtube_dl/extractor/naver.py",
        "class_name": "youtube_dl.extractor.naver.NaverIE",
        "signature": "youtube_dl.extractor.naver.NaverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        m_id = re.search(r'var rmcPlayer = new nhn.rmcnmv.RMCVideoPlayer\\(\"(.+?)\", \"(.+?)\"',\n                         webpage)\n        if m_id is None:\n            error = self._html_search_regex(\n                r'(?s)<div class=\"(?:nation_error|nation_box|error_box)\">\\s*(?:<!--.*?-->)?\\s*<p class=\"[^\"]+\">(?P<msg>.+?)</p>\\s*</div>',\n                webpage, 'error', default=None)\n            if error:\n                raise ExtractorError(error, expected=True)\n            raise ExtractorError('couldn\\'t extract vid and key')\n        video_data = self._download_json(\n            'http://play.rmcnmv.naver.com/vod/play/v2.0/' + m_id.group(1),\n            video_id, query={\n                'key': m_id.group(2),\n            })\n        meta = video_data['meta']\n        title = meta['subject']\n        formats = []\n\n        def extract_formats(streams, stream_type, query={}):\n            for stream in streams:\n                stream_url = stream.get('source')\n                if not stream_url:\n                    continue\n                stream_url = update_url_query(stream_url, query)\n                encoding_option = stream.get('encodingOption', {})\n                bitrate = stream.get('bitrate', {})\n                formats.append({\n                    'format_id': '%s_%s' % (stream.get('type') or stream_type, encoding_option.get('id') or encoding_option.get('name')),\n                    'url': stream_url,\n                    'width': int_or_none(encoding_option.get('width')),\n                    'height': int_or_none(encoding_option.get('height')),\n                    'vbr': int_or_none(bitrate.get('video')),\n                    'abr': int_or_none(bitrate.get('audio')),\n                    'filesize': int_or_none(stream.get('size')),\n                    'protocol': 'm3u8_native' if stream_type == 'HLS' else None,\n                })\n\n        extract_formats(video_data.get('videos', {}).get('list', []), 'H264')\n        for stream_set in video_data.get('streams', []):\n            query = {}\n            for param in stream_set.get('keys', []):\n                query[param['name']] = param['value']\n            stream_type = stream_set.get('type')\n            videos = stream_set.get('videos')\n            if videos:\n                extract_formats(videos, stream_type, query)\n            elif stream_type == 'HLS':\n                stream_url = stream_set.get('source')\n                if not stream_url:\n                    continue\n                formats.extend(self._extract_m3u8_formats(\n                    update_url_query(stream_url, query), video_id,\n                    'mp4', 'm3u8_native', m3u8_id=stream_type, fatal=False))\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for caption in video_data.get('captions', {}).get('list', []):\n            caption_url = caption.get('source')\n            if not caption_url:\n                continue\n            subtitles.setdefault(caption.get('language') or caption.get('locale'), []).append({\n                'url': caption_url,\n            })\n\n        upload_date = self._search_regex(\n            r'<span[^>]+class=\"date\".*?(\\d{4}\\.\\d{2}\\.\\d{2})',\n            webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = upload_date.replace('.', '')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'description': self._og_search_description(webpage),\n            'thumbnail': meta.get('cover', {}).get('source') or self._og_search_thumbnail(webpage),\n            'view_count': int_or_none(meta.get('count')),\n            'upload_date': upload_date,\n        }",
        "begin_line": 42,
        "end_line": 125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._fetch_page#97",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._fetch_page(self, team, video_id, page)",
        "snippet": "    def _fetch_page(self, team, video_id, page):\n        search_url = 'http://searchapp2.nba.com/nba-search/query.jsp?' + compat_urllib_parse_urlencode({\n            'type': 'teamvideo',\n            'start': page * self._PAGE_SIZE + 1,\n            'npp': (page + 1) * self._PAGE_SIZE + 1,\n            'sort': 'recent',\n            'output': 'json',\n            'site': team,\n        })\n        results = self._download_json(\n            search_url, video_id, note='Download page %d of playlist data' % page)['results'][0]\n        for item in results:\n            yield self.url_result(compat_urlparse.urljoin('http://www.nba.com/', item['url']))",
        "begin_line": 97,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._extract_playlist#111",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._extract_playlist(self, orig_path, video_id, webpage)",
        "snippet": "    def _extract_playlist(self, orig_path, video_id, webpage):\n        team = orig_path.split('/')[0]\n\n        if self._downloader.params.get('noplaylist'):\n            self.to_screen('Downloading just video because of --no-playlist')\n            video_path = self._search_regex(\n                r'nbaVideoCore\\.firstVideo\\s*=\\s*\\'([^\\']+)\\';', webpage, 'video path')\n            video_url = 'http://www.nba.com/%s/video/%s' % (team, video_path)\n            return self.url_result(video_url)\n\n        self.to_screen('Downloading playlist - add --no-playlist to just download video')\n        playlist_title = self._og_search_title(webpage, fatal=False)\n        entries = OnDemandPagedList(\n            functools.partial(self._fetch_page, team, video_id),\n            self._PAGE_SIZE, use_cache=True)\n\n        return self.playlist_result(entries, team, playlist_title)",
        "begin_line": 111,
        "end_line": 127,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._real_extract#129",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path, video_id = re.match(self._VALID_URL, url).groups()\n        orig_path = path\n        if path.startswith('nba/'):\n            path = path[3:]\n\n        if 'video/' not in path:\n            webpage = self._download_webpage(url, video_id)\n            path = remove_start(self._search_regex(r'data-videoid=\"([^\"]+)\"', webpage, 'video id'), '/')\n\n            if path == '{{id}}':\n                return self._extract_playlist(orig_path, video_id, webpage)\n\n            # See prepareContentId() of pkgCvp.js\n            if path.startswith('video/teams'):\n                path = 'video/channels/proxy/' + path[6:]\n\n        return self._extract_cvp_info(\n            'http://www.nba.com/%s.xml' % path, video_id, {\n                'default': {\n                    'media_src': 'http://nba.cdn.turner.com/nba/big',\n                },\n                'm3u8': {\n                    'media_src': 'http://nbavod-f.akamaihd.net',\n                },\n            })",
        "begin_line": 129,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCIE._real_extract#73",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCIE",
        "signature": "youtube_dl.extractor.nbc.NBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        permalink, video_id = re.match(self._VALID_URL, url).groups()\n        video_data = self._download_json(\n            'https://api.nbc.com/v3/videos', video_id, query={\n                'filter[permalink]': permalink,\n            })['data'][0]['attributes']\n        query = {\n            'mbr': 'true',\n            'manifest': 'm3u',\n        }\n        video_id = video_data['guid']\n        title = video_data['title']\n        if video_data.get('entitlement') == 'auth':\n            resource = self._get_mvpd_resource(\n                'nbcentertainment', title, video_id,\n                video_data.get('vChipRating'))\n            query['auth'] = self._extract_mvpd_auth(\n                url, video_id, 'nbcentertainment', resource)\n        theplatform_url = smuggle_url(update_url_query(\n            'http://link.theplatform.com/s/NnzsPC/media/guid/2410887629/' + video_id,\n            query), {'force_smil_url': True})\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'url': theplatform_url,\n            'description': video_data.get('description'),\n            'keywords': video_data.get('keywords'),\n            'season_number': int_or_none(video_data.get('seasonNumber')),\n            'episode_number': int_or_none(video_data.get('episodeNumber')),\n            'series': video_data.get('showName'),\n            'ie_key': 'ThePlatform',\n        }",
        "begin_line": 73,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url#128",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        iframe_m = re.search(\n            r'<iframe[^>]+src=\"(?P<url>https?://vplayer\\.nbcsports\\.com/[^\"]+)\"', webpage)\n        if iframe_m:\n            return iframe_m.group('url')",
        "begin_line": 128,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._real_extract#134",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsVPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        theplatform_url = self._og_search_video_url(webpage)\n        return self.url_result(theplatform_url, 'ThePlatform')",
        "begin_line": 134,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCSportsIE._real_extract#158",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCSportsIE",
        "signature": "youtube_dl.extractor.nbc.NBCSportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(\n            NBCSportsVPlayerIE._extract_url(webpage), 'NBCSportsVPlayer')",
        "begin_line": 158,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.CSNNEIE._real_extract#181",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.CSNNEIE",
        "signature": "youtube_dl.extractor.nbc.CSNNEIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': self._html_search_meta('twitter:player:stream', webpage),\n            'display_id': display_id,\n        }",
        "begin_line": 181,
        "end_line": 189,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract#297",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCNewsIE",
        "signature": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if video_id is not None:\n            all_info = self._download_xml('http://www.nbcnews.com/id/%s/displaymode/1219' % video_id, video_id)\n            info = all_info.find('video')\n\n            return {\n                'id': video_id,\n                'title': info.find('headline').text,\n                'ext': 'flv',\n                'url': find_xpath_attr(info, 'media', 'type', 'flashVideo').text,\n                'description': info.find('caption').text,\n                'thumbnail': find_xpath_attr(info, 'media', 'type', 'thumbnail').text,\n            }\n        else:\n            # \"feature\" and \"nightly-news\" pages use theplatform.com\n            video_id = mobj.group('mpx_id')\n            webpage = self._download_webpage(url, video_id)\n\n            filter_param = 'byId'\n            bootstrap_json = self._search_regex(\n                [r'(?m)(?:var\\s+(?:bootstrapJson|playlistData)|NEWS\\.videoObj)\\s*=\\s*({.+});?\\s*$',\n                 r'videoObj\\s*:\\s*({.+})', r'data-video=\"([^\"]+)\"',\n                 r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);'],\n                webpage, 'bootstrap json', default=None)\n            if bootstrap_json:\n                bootstrap = self._parse_json(\n                    bootstrap_json, video_id, transform_source=unescapeHTML)\n\n                info = None\n                if 'results' in bootstrap:\n                    info = bootstrap['results'][0]['video']\n                elif 'video' in bootstrap:\n                    info = bootstrap['video']\n                elif 'msnbcVideoInfo' in bootstrap:\n                    info = bootstrap['msnbcVideoInfo']['meta']\n                elif 'msnbcThePlatform' in bootstrap:\n                    info = bootstrap['msnbcThePlatform']['videoPlayer']['video']\n                else:\n                    info = bootstrap\n\n                if 'guid' in info:\n                    video_id = info['guid']\n                    filter_param = 'byGuid'\n                elif 'mpxId' in info:\n                    video_id = info['mpxId']\n\n            return {\n                '_type': 'url_transparent',\n                'id': video_id,\n                # http://feed.theplatform.com/f/2E2eJC/nbcnews also works\n                'url': update_url_query('http://feed.theplatform.com/f/2E2eJC/nnd_NBCNews', {filter_param: video_id}),\n                'ie_key': 'ThePlatformFeed',\n            }",
        "begin_line": 297,
        "end_line": 351,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCOlympicsIE._real_extract#373",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCOlympicsIE",
        "signature": "youtube_dl.extractor.nbc.NBCOlympicsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        drupal_settings = self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n            webpage, 'drupal settings'), display_id)\n\n        iframe_url = drupal_settings['vod']['iframe_url']\n        theplatform_url = iframe_url.replace(\n            'vplayer.nbcolympics.com', 'player.theplatform.com')\n\n        return {\n            '_type': 'url_transparent',\n            'url': theplatform_url,\n            'ie_key': ThePlatformIE.ie_key(),\n            'display_id': display_id,\n        }",
        "begin_line": 373,
        "end_line": 391,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRBaseIE._real_extract#16",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRBaseIE",
        "signature": "youtube_dl.extractor.ndr.NDRBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = next(group for group in mobj.groups() if group)\n        webpage = self._download_webpage(url, display_id)\n        return self._extract_embed(webpage, display_id)",
        "begin_line": 16,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRIE._extract_embed#86",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRIE",
        "signature": "youtube_dl.extractor.ndr.NDRIE._extract_embed(self, webpage, display_id)",
        "snippet": "    def _extract_embed(self, webpage, display_id):\n        embed_url = self._html_search_meta(\n            'embedURL', webpage, 'embed URL', fatal=True)\n        description = self._search_regex(\n            r'<p[^>]+itemprop=\"description\">([^<]+)</p>',\n            webpage, 'description', default=None) or self._og_search_description(webpage)\n        timestamp = parse_iso8601(\n            self._search_regex(\n                r'<span[^>]+itemprop=\"(?:datePublished|uploadDate)\"[^>]+content=\"([^\"]+)\"',\n                webpage, 'upload date', fatal=False))\n        return {\n            '_type': 'url_transparent',\n            'url': embed_url,\n            'display_id': display_id,\n            'description': description,\n            'timestamp': timestamp,\n        }",
        "begin_line": 86,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ndr.NJoyIE._extract_embed#148",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NJoyIE",
        "signature": "youtube_dl.extractor.ndr.NJoyIE._extract_embed(self, webpage, display_id)",
        "snippet": "    def _extract_embed(self, webpage, display_id):\n        video_id = self._search_regex(\n            r'<iframe[^>]+id=\"pp_([\\da-z]+)\"', webpage, 'embed id')\n        description = self._search_regex(\n            r'<div[^>]+class=\"subline\"[^>]*>[^<]+</div>\\s*<p>([^<]+)</p>',\n            webpage, 'description', fatal=False)\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'NDREmbedBase',\n            'url': 'ndr:%s' % video_id,\n            'display_id': display_id,\n            'description': description,\n        }",
        "begin_line": 148,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ndr.NDREmbedBaseIE._real_extract#174",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDREmbedBaseIE",
        "signature": "youtube_dl.extractor.ndr.NDREmbedBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('id_s')\n\n        ppjson = self._download_json(\n            'http://www.ndr.de/%s-ppjson.json' % video_id, video_id)\n\n        playlist = ppjson['playlist']\n\n        formats = []\n        quality_key = qualities(('xs', 's', 'm', 'l', 'xl'))\n\n        for format_id, f in playlist.items():\n            src = f.get('src')\n            if not src:\n                continue\n            ext = determine_ext(src, None)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    src + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id, f4m_id='hds'))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, 'mp4', m3u8_id='hls', entry_protocol='m3u8_native'))\n            else:\n                quality = f.get('quality')\n                ff = {\n                    'url': src,\n                    'format_id': quality or format_id,\n                    'quality': quality_key(quality),\n                }\n                type_ = f.get('type')\n                if type_ and type_.split('/')[0] == 'audio':\n                    ff['vcodec'] = 'none'\n                    ff['ext'] = ext or 'mp3'\n                formats.append(ff)\n        self._sort_formats(formats)\n\n        config = playlist['config']\n\n        live = playlist.get('config', {}).get('streamType') in ['httpVideoLive', 'httpAudioLive']\n        title = config['title']\n        if live:\n            title = self._live_title(title)\n        uploader = ppjson.get('config', {}).get('branding')\n        upload_date = ppjson.get('config', {}).get('publicationDate')\n        duration = int_or_none(config.get('duration'))\n\n        thumbnails = [{\n            'id': thumbnail.get('quality') or thumbnail_id,\n            'url': thumbnail['src'],\n            'preference': quality_key(thumbnail.get('quality')),\n        } for thumbnail_id, thumbnail in config.get('poster', {}).items() if thumbnail.get('src')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'is_live': live,\n            'uploader': uploader if uploader != '-' else None,\n            'upload_date': upload_date[0:8] if upload_date else None,\n            'duration': duration,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 174,
        "end_line": 236,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ndtv.NDTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ndtv.py",
        "class_name": "youtube_dl.extractor.ndtv.NDTVIE",
        "signature": "youtube_dl.extractor.ndtv.NDTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = remove_end(self._og_search_title(webpage), ' - NDTV')\n\n        filename = self._search_regex(\n            r\"__filename='([^']+)'\", webpage, 'video filename')\n        video_url = 'http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' % filename\n\n        duration = int_or_none(self._search_regex(\n            r\"__duration='([^']+)'\", webpage, 'duration', fatal=False))\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'publish-date', webpage, 'upload date', fatal=False))\n\n        description = remove_end(self._og_search_description(webpage), ' (Read more)')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 28,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE._real_extract#20",
        "src_path": "youtube_dl/extractor/nerdcubed.py",
        "class_name": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE",
        "signature": "youtube_dl.extractor.nerdcubed.NerdCubedFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        feed = self._download_json(url, url, 'Downloading NerdCubed JSON feed')\n\n        entries = [{\n            '_type': 'url',\n            'title': feed_entry['title'],\n            'uploader': feed_entry['source']['name'] if feed_entry['source'] else None,\n            'upload_date': datetime.datetime.strptime(feed_entry['date'], '%Y-%m-%d').strftime('%Y%m%d'),\n            'url': 'http://www.youtube.com/watch?v=' + feed_entry['youtube_id'],\n        } for feed_entry in feed]\n\n        return {\n            '_type': 'playlist',\n            'title': 'nerdcubed.co.uk feed',\n            'id': 'nerdcubed-feed',\n            'entries': entries,\n        }",
        "begin_line": 20,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE._encrypt#27",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE._encrypt(cls, dfsid)",
        "snippet": "    def _encrypt(cls, dfsid):\n        salt_bytes = bytearray(cls._NETEASE_SALT.encode('utf-8'))\n        string_bytes = bytearray(compat_str(dfsid).encode('ascii'))\n        salt_len = len(salt_bytes)\n        for i in range(len(string_bytes)):\n            string_bytes[i] = string_bytes[i] ^ salt_bytes[i % salt_len]\n        m = md5()\n        m.update(bytes(string_bytes))\n        result = b64encode(m.digest()).decode('ascii')\n        return result.replace('/', '_').replace('+', '-')",
        "begin_line": 27,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.extract_formats#38",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.extract_formats(self, info)",
        "snippet": "    def extract_formats(self, info):\n        formats = []\n        for song_format in self._FORMATS:\n            details = info.get(song_format)\n            if not details:\n                continue\n            song_file_path = '/%s/%s.%s' % (\n                self._encrypt(details['dfsId']), details['dfsId'], details['extension'])\n\n            # 203.130.59.9, 124.40.233.182, 115.231.74.139, etc is a reverse proxy-like feature\n            # from NetEase's CDN provider that can be used if m5.music.126.net does not\n            # work, especially for users outside of Mainland China\n            # via: https://github.com/JixunMoe/unblock-163/issues/3#issuecomment-163115880\n            for host in ('http://m5.music.126.net', 'http://115.231.74.139/m1.music.126.net',\n                         'http://124.40.233.182/m1.music.126.net', 'http://203.130.59.9/m1.music.126.net'):\n                song_url = host + song_file_path\n                if self._is_valid_url(song_url, info['id'], 'song'):\n                    formats.append({\n                        'url': song_url,\n                        'ext': details.get('extension'),\n                        'abr': float_or_none(details.get('bitrate'), scale=1000),\n                        'format_id': song_format,\n                        'filesize': details.get('size'),\n                        'asr': details.get('sr')\n                    })\n                    break\n        return formats",
        "begin_line": 38,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.convert_milliseconds#67",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.convert_milliseconds(cls, ms)",
        "snippet": "    def convert_milliseconds(cls, ms):\n        return int(round(ms / 1000.0))",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.query_api#70",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicBaseIE.query_api(self, endpoint, video_id, note)",
        "snippet": "    def query_api(self, endpoint, video_id, note):\n        req = sanitized_Request('%s%s' % (self._API_BASE, endpoint))\n        req.add_header('Referer', self._API_BASE)\n        return self._download_json(req, video_id, note)",
        "begin_line": 70,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._process_lyrics#134",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._process_lyrics(self, lyrics_info)",
        "snippet": "    def _process_lyrics(self, lyrics_info):\n        original = lyrics_info.get('lrc', {}).get('lyric')\n        translated = lyrics_info.get('tlyric', {}).get('lyric')\n\n        if not translated:\n            return original\n\n        lyrics_expr = r'(\\[[0-9]{2}:[0-9]{2}\\.[0-9]{2,}\\])([^\\n]+)'\n        original_ts_texts = re.findall(lyrics_expr, original)\n        translation_ts_dict = dict(\n            (time_stamp, text) for time_stamp, text in re.findall(lyrics_expr, translated)\n        )\n        lyrics = '\\n'.join([\n            '%s%s / %s' % (time_stamp, text, translation_ts_dict.get(time_stamp, ''))\n            for time_stamp, text in original_ts_texts\n        ])\n        return lyrics",
        "begin_line": 134,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._real_extract#152",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        params = {\n            'id': song_id,\n            'ids': '[%s]' % song_id\n        }\n        info = self.query_api(\n            'song/detail?' + compat_urllib_parse_urlencode(params),\n            song_id, 'Downloading song info')['songs'][0]\n\n        formats = self.extract_formats(info)\n        self._sort_formats(formats)\n\n        lyrics_info = self.query_api(\n            'song/lyric?id=%s&lv=-1&tv=-1' % song_id,\n            song_id, 'Downloading lyrics data')\n        lyrics = self._process_lyrics(lyrics_info)\n\n        alt_title = None\n        if info.get('transNames'):\n            alt_title = '/'.join(info.get('transNames'))\n\n        return {\n            'id': song_id,\n            'title': info['name'],\n            'alt_title': alt_title,\n            'creator': ' / '.join([artist['name'] for artist in info.get('artists', [])]),\n            'timestamp': self.convert_milliseconds(info.get('album', {}).get('publishTime')),\n            'thumbnail': info.get('album', {}).get('picUrl'),\n            'duration': self.convert_milliseconds(info.get('duration', 0)),\n            'description': lyrics,\n            'formats': formats,\n        }",
        "begin_line": 152,
        "end_line": 185,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE._real_extract#202",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        info = self.query_api(\n            'album/%s?id=%s' % (album_id, album_id),\n            album_id, 'Downloading album data')['album']\n\n        name = info['name']\n        desc = info.get('description')\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['songs']\n        ]\n        return self.playlist_result(entries, album_id, name, desc)",
        "begin_line": 202,
        "end_line": 216,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE._real_extract#243",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        singer_id = self._match_id(url)\n\n        info = self.query_api(\n            'artist/%s?id=%s' % (singer_id, singer_id),\n            singer_id, 'Downloading singer data')\n\n        name = info['artist']['name']\n        if info['artist']['trans']:\n            name = '%s - %s' % (name, info['artist']['trans'])\n        if info['artist']['alias']:\n            name = '%s - %s' % (name, ';'.join(info['artist']['alias']))\n\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['hotSongs']\n        ]\n        return self.playlist_result(entries, singer_id, name)",
        "begin_line": 243,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE._real_extract#289",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        info = self.query_api(\n            'playlist/detail?id=%s&lv=-1&tv=-1' % list_id,\n            list_id, 'Downloading playlist data')['result']\n\n        name = info['name']\n        desc = info.get('description')\n\n        if info.get('specialType') == 10:  # is a chart/toplist\n            datestamp = datetime.fromtimestamp(\n                self.convert_milliseconds(info['updateTime'])).strftime('%Y-%m-%d')\n            name = '%s %s' % (name, datestamp)\n\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song['id'],\n                            'NetEaseMusic', song['id'])\n            for song in info['tracks']\n        ]\n        return self.playlist_result(entries, list_id, name, desc)",
        "begin_line": 289,
        "end_line": 309,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE._real_extract#329",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicMvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mv_id = self._match_id(url)\n\n        info = self.query_api(\n            'mv/detail?id=%s&type=mp4' % mv_id,\n            mv_id, 'Downloading mv info')['data']\n\n        formats = [\n            {'url': mv_url, 'ext': 'mp4', 'format_id': '%sp' % brs, 'height': int(brs)}\n            for brs, mv_url in info['brs'].items()\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': mv_id,\n            'title': info['name'],\n            'description': info.get('desc') or info.get('briefDesc'),\n            'creator': info['artistName'],\n            'upload_date': info['publishTime'].replace('-', ''),\n            'formats': formats,\n            'thumbnail': info.get('cover'),\n            'duration': self.convert_milliseconds(info.get('duration', 0)),\n        }",
        "begin_line": 329,
        "end_line": 351,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE._real_extract#398",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicProgramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        program_id = self._match_id(url)\n\n        info = self.query_api(\n            'dj/program/detail?id=%s' % program_id,\n            program_id, 'Downloading program info')['program']\n\n        name = info['name']\n        description = info['description']\n\n        if not info['songs'] or self._downloader.params.get('noplaylist'):\n            if info['songs']:\n                self.to_screen(\n                    'Downloading just the main audio %s because of --no-playlist'\n                    % info['mainSong']['id'])\n\n            formats = self.extract_formats(info['mainSong'])\n            self._sort_formats(formats)\n\n            return {\n                'id': program_id,\n                'title': name,\n                'description': description,\n                'creator': info['dj']['brand'],\n                'timestamp': self.convert_milliseconds(info['createTime']),\n                'thumbnail': info['coverUrl'],\n                'duration': self.convert_milliseconds(info.get('duration', 0)),\n                'formats': formats,\n            }\n\n        self.to_screen(\n            'Downloading playlist %s - add --no-playlist to just download the main audio %s'\n            % (program_id, info['mainSong']['id']))\n\n        song_ids = [info['mainSong']['id']]\n        song_ids.extend([song['id'] for song in info['songs']])\n        entries = [\n            self.url_result('http://music.163.com/#/song?id=%s' % song_id,\n                            'NetEaseMusic', song_id)\n            for song_id in song_ids\n        ]\n        return self.playlist_result(entries, program_id, name, description)",
        "begin_line": 398,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE._real_extract#458",
        "src_path": "youtube_dl/extractor/neteasemusic.py",
        "class_name": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE",
        "signature": "youtube_dl.extractor.neteasemusic.NetEaseMusicDjRadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        dj_id = self._match_id(url)\n\n        name = None\n        desc = None\n        entries = []\n        for offset in compat_itertools_count(start=0, step=self._PAGE_SIZE):\n            info = self.query_api(\n                'dj/program/byradio?asc=false&limit=%d&radioId=%s&offset=%d'\n                % (self._PAGE_SIZE, dj_id, offset),\n                dj_id, 'Downloading dj programs - %d' % offset)\n\n            entries.extend([\n                self.url_result(\n                    'http://music.163.com/#/program?id=%s' % program['id'],\n                    'NetEaseMusicProgram', program['id'])\n                for program in info['programs']\n            ])\n\n            if name is None:\n                radio = info['programs'][0]['radio']\n                name = radio['name']\n                desc = radio['desc']\n\n            if not info['more']:\n                break\n\n        return self.playlist_result(entries, dj_id, name, desc)",
        "begin_line": 458,
        "end_line": 485,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.netzkino.NetzkinoIE._real_extract#37",
        "src_path": "youtube_dl/extractor/netzkino.py",
        "class_name": "youtube_dl.extractor.netzkino.NetzkinoIE",
        "signature": "youtube_dl.extractor.netzkino.NetzkinoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        category_id = mobj.group('category')\n        video_id = mobj.group('id')\n\n        api_url = 'http://api.netzkino.de.simplecache.net/capi-2.0a/categories/%s.json?d=www' % category_id\n        api_info = self._download_json(api_url, video_id)\n        info = next(\n            p for p in api_info['posts'] if p['slug'] == video_id)\n        custom_fields = info['custom_fields']\n\n        production_js = self._download_webpage(\n            'http://www.netzkino.de/beta/dist/production.min.js', video_id,\n            note='Downloading player code')\n        avo_js = self._search_regex(\n            r'var urlTemplate=(\\{.*?\"\\})',\n            production_js, 'URL templates')\n        templates = self._parse_json(\n            avo_js, video_id, transform_source=js_to_json)\n\n        suffix = {\n            'hds': '.mp4/manifest.f4m',\n            'hls': '.mp4/master.m3u8',\n            'pmd': '.mp4',\n        }\n        film_fn = custom_fields['Streaming'][0]\n        formats = [{\n            'format_id': key,\n            'ext': 'mp4',\n            'url': tpl.replace('{}', film_fn) + suffix[key],\n        } for key, tpl in templates.items()]\n        self._sort_formats(formats)\n\n        comments = [{\n            'timestamp': parse_iso8601(c.get('date'), delimiter=' '),\n            'id': c['id'],\n            'author': c['name'],\n            'html': c['content'],\n            'parent': 'root' if c.get('parent', 0) == 0 else c['parent'],\n        } for c in info.get('comments', [])]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'comments': comments,\n            'title': info['title'],\n            'age_limit': int_or_none(custom_fields.get('FSK')[0]),\n            'timestamp': parse_iso8601(info.get('date'), delimiter=' '),\n            'description': clean_html(info.get('content')),\n            'thumbnail': info.get('thumbnail'),\n            'playlist_title': api_info.get('title'),\n            'playlist_id': category_id,\n        }",
        "begin_line": 37,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract#56",
        "src_path": "youtube_dl/extractor/newgrounds.py",
        "class_name": "youtube_dl.extractor.newgrounds.NewgroundsIE",
        "signature": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, media_id)\n\n        title = self._html_search_regex(\n            r'<title>([^>]+)</title>', webpage, 'title')\n\n        media_url = self._parse_json(self._search_regex(\n            r'\"url\"\\s*:\\s*(\"[^\"]+\"),', webpage, ''), media_id)\n\n        formats = [{\n            'url': media_url,\n            'format_id': 'source',\n            'quality': 1,\n        }]\n\n        max_resolution = int_or_none(self._search_regex(\n            r'max_resolution[\"\\']\\s*:\\s*(\\d+)', webpage, 'max resolution',\n            default=None))\n        if max_resolution:\n            url_base = media_url.rpartition('.')[0]\n            for resolution in (360, 720, 1080):\n                if resolution > max_resolution:\n                    break\n                formats.append({\n                    'url': '%s.%dp.mp4' % (url_base, resolution),\n                    'format_id': '%dp' % resolution,\n                    'height': resolution,\n                })\n\n        self._check_formats(formats, media_id)\n        self._sort_formats(formats)\n\n        uploader = self._search_regex(\n            r'(?:Author|Writer)\\s*<a[^>]+>([^<]+)', webpage, 'uploader',\n            fatal=False)\n\n        timestamp = unified_timestamp(self._search_regex(\n            r'<dt>Uploaded</dt>\\s*<dd>([^<]+)', webpage, 'timestamp',\n            default=None))\n        duration = parse_duration(self._search_regex(\n            r'<dd>Song\\s*</dd><dd>.+?</dd><dd>([^<]+)', webpage, 'duration',\n            default=None))\n\n        filesize_approx = parse_filesize(self._html_search_regex(\n            r'<dd>Song\\s*</dd><dd>(.+?)</dd>', webpage, 'filesize',\n            default=None))\n        if len(formats) == 1:\n            formats[0]['filesize_approx'] = filesize_approx\n\n        if '<dd>Song' in webpage:\n            formats[0]['vcodec'] = 'none'\n\n        return {\n            'id': media_id,\n            'title': title,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.newgrounds.NewgroundsPlaylistIE._real_extract#141",
        "src_path": "youtube_dl/extractor/newgrounds.py",
        "class_name": "youtube_dl.extractor.newgrounds.NewgroundsPlaylistIE",
        "signature": "youtube_dl.extractor.newgrounds.NewgroundsPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        title = self._search_regex(\n            r'<title>([^>]+)</title>', webpage, 'title', default=None)\n\n        # cut left menu\n        webpage = self._search_regex(\n            r'(?s)<div[^>]+\\bclass=[\"\\']column wide(.+)',\n            webpage, 'wide column', default=webpage)\n\n        entries = []\n        for a, path, media_id in re.findall(\n                r'(<a[^>]+\\bhref=[\"\\']/?((?:portal/view|audio/listen)/(\\d+))[^>]+>)',\n                webpage):\n            a_class = extract_attributes(a).get('class')\n            if a_class not in ('item-portalsubmission', 'item-audiosubmission'):\n                continue\n            entries.append(\n                self.url_result(\n                    'https://www.newgrounds.com/%s' % path,\n                    ie=NewgroundsIE.ie_key(), video_id=media_id))\n\n        return self.playlist_result(entries, playlist_id, title)",
        "begin_line": 141,
        "end_line": 166,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.newstube.NewstubeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/newstube.py",
        "class_name": "youtube_dl.extractor.newstube.NewstubeIE",
        "signature": "youtube_dl.extractor.newstube.NewstubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_guid = self._html_search_regex(\n            r'<meta property=\"og:video:url\" content=\"https?://(?:www\\.)?newstube\\.ru/freshplayer\\.swf\\?guid=(?P<guid>[\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})',\n            page, 'video GUID')\n\n        player = self._download_xml(\n            'http://p.newstube.ru/v2/player.asmx/GetAutoPlayInfo6?state=&url=%s&sessionId=&id=%s&placement=profile&location=n2' % (url, video_guid),\n            video_guid, 'Downloading player XML')\n\n        def ns(s):\n            return s.replace('/', '/%(ns)s') % {'ns': '{http://app1.newstube.ru/N2SiteWS/player.asmx}'}\n\n        error_message = player.find(ns('./ErrorMessage'))\n        if error_message is not None:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, error_message.text), expected=True)\n\n        session_id = player.find(ns('./SessionId')).text\n        media_info = player.find(ns('./Medias/MediaInfo'))\n        title = media_info.find(ns('./Name')).text\n        description = self._og_search_description(page)\n        thumbnail = media_info.find(ns('./KeyFrame')).text\n        duration = int(media_info.find(ns('./Duration')).text) / 1000.0\n\n        formats = []\n\n        for stream_info in media_info.findall(ns('./Streams/StreamInfo')):\n            media_location = stream_info.find(ns('./MediaLocation'))\n            if media_location is None:\n                continue\n\n            server = media_location.find(ns('./Server')).text\n            app = media_location.find(ns('./App')).text\n            media_id = stream_info.find(ns('./Id')).text\n            name = stream_info.find(ns('./Name')).text\n            width = int(stream_info.find(ns('./Width')).text)\n            height = int(stream_info.find(ns('./Height')).text)\n\n            formats.append({\n                'url': 'rtmp://%s/%s' % (server, app),\n                'app': app,\n                'play_path': '01/%s' % video_guid.upper(),\n                'rtmp_conn': ['S:%s' % session_id, 'S:%s' % media_id, 'S:n2'],\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': 'rtmp' + ('-%s' % name if name else ''),\n                'width': width,\n                'height': height,\n            })\n\n        sources_data = self._download_json(\n            'http://www.newstube.ru/player2/getsources?guid=%s' % video_guid,\n            video_guid, fatal=False)\n        if sources_data:\n            for source in sources_data.get('Sources', []):\n                source_url = source.get('Src')\n                if not source_url:\n                    continue\n                height = int_or_none(source.get('Height'))\n                f = {\n                    'format_id': 'http' + ('-%dp' % height if height else ''),\n                    'url': source_url,\n                    'width': int_or_none(source.get('Width')),\n                    'height': height,\n                }\n                source_type = source.get('Type')\n                if source_type:\n                    mobj = re.search(r'codecs=\"([^,]+),\\s*([^\"]+)\"', source_type)\n                    if mobj:\n                        vcodec, acodec = mobj.groups()\n                        f.update({\n                            'vcodec': vcodec,\n                            'acodec': acodec,\n                        })\n                formats.append(f)\n\n        self._check_formats(formats, video_guid)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_guid,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._real_extract#35",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        page = self._download_webpage(url, news_id)\n        return self._extract_from_nextmedia_page(news_id, url, page)",
        "begin_line": 35,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._extract_from_nextmedia_page#40",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._extract_from_nextmedia_page(self, news_id, url, page)",
        "snippet": "    def _extract_from_nextmedia_page(self, news_id, url, page):\n        redirection_url = self._search_regex(\n            r'window\\.location\\.href\\s*=\\s*([\\'\"])(?P<url>(?!\\1).+)\\1',\n            page, 'redirection URL', default=None, group='url')\n        if redirection_url:\n            return self.url_result(compat_urlparse.urljoin(url, redirection_url))\n\n        title = self._fetch_title(page)\n        video_url = self._search_regex(self._URL_PATTERN, page, 'video url')\n\n        attrs = {\n            'id': news_id,\n            'title': title,\n            'url': video_url,  # ext can be inferred from url\n            'thumbnail': self._fetch_thumbnail(page),\n            'description': self._fetch_description(page),\n        }\n\n        timestamp = self._fetch_timestamp(page)\n        if timestamp:\n            attrs['timestamp'] = timestamp\n        else:\n            attrs['upload_date'] = self._fetch_upload_date(url)\n\n        return attrs",
        "begin_line": 40,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_title#66",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_title(self, page)",
        "snippet": "    def _fetch_title(self, page):\n        return self._og_search_title(page)",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_thumbnail#69",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_thumbnail(self, page)",
        "snippet": "    def _fetch_thumbnail(self, page):\n        return self._og_search_thumbnail(page)",
        "begin_line": 69,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_timestamp#72",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_timestamp(self, page)",
        "snippet": "    def _fetch_timestamp(self, page):\n        dateCreated = self._search_regex('\"dateCreated\":\"([^\"]+)\"', page, 'created time')\n        return parse_iso8601(dateCreated)",
        "begin_line": 72,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_upload_date#76",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_upload_date(self, url)",
        "snippet": "    def _fetch_upload_date(self, url):\n        return self._search_regex(self._VALID_URL, url, 'upload date', group='date')",
        "begin_line": 76,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_description#79",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaIE._fetch_description(self, page)",
        "snippet": "    def _fetch_description(self, page):\n        return self._og_search_property('description', page)",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE._real_extract#100",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE",
        "signature": "youtube_dl.extractor.nextmedia.NextMediaActionNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        actionnews_page = self._download_webpage(url, news_id)\n        article_url = self._og_search_url(actionnews_page)\n        article_page = self._download_webpage(article_url, news_id)\n        return self._extract_from_nextmedia_page(news_id, url, article_page)",
        "begin_line": 100,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_title#182",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_title(self, page)",
        "snippet": "    def _fetch_title(self, page):\n        return (self._html_search_regex(r'<h1 id=\"h1\">([^<>]+)</h1>', page, 'news title', default=None) or\n                self._html_search_meta('description', page, 'news title'))",
        "begin_line": 182,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_thumbnail#186",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_thumbnail(self, page)",
        "snippet": "    def _fetch_thumbnail(self, page):\n        return self._html_search_regex(r\"setInitialImage\\(\\'([^']+)'\\)\", page, 'video thumbnail', fatal=False)",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_timestamp#189",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_timestamp(self, page)",
        "snippet": "    def _fetch_timestamp(self, page):\n        return None",
        "begin_line": 189,
        "end_line": 190,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_description#192",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.AppleDailyIE",
        "signature": "youtube_dl.extractor.nextmedia.AppleDailyIE._fetch_description(self, page)",
        "snippet": "    def _fetch_description(self, page):\n        return self._html_search_meta('description', page, 'news description')",
        "begin_line": 192,
        "end_line": 193,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nextmedia.NextTVIE._real_extract#213",
        "src_path": "youtube_dl/extractor/nextmedia.py",
        "class_name": "youtube_dl.extractor.nextmedia.NextTVIE",
        "signature": "youtube_dl.extractor.nextmedia.NextTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1[^>]*>([^<]+)</h1>', webpage, 'title')\n\n        data = self._hidden_inputs(webpage)\n\n        video_url = data['ntt-vod-src-detailview']\n\n        date_str = get_element_by_class('date', webpage)\n        timestamp = unified_timestamp(date_str + '+0800') if date_str else None\n\n        view_count = int_or_none(remove_start(\n            clean_html(get_element_by_class('click', webpage)), '\u9ede\u95b1\uff1a'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': data.get('ntt-vod-img-src'),\n            'timestamp': timestamp,\n            'view_count': view_count,\n        }",
        "begin_line": 213,
        "end_line": 238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxIE._extract_urls#68",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxIE",
        "signature": "youtube_dl.extractor.nexx.NexxIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        # Reference:\n        # 1. https://nx-s.akamaized.net/files/201510/44.pdf\n\n        entries = []\n\n        # JavaScript Integration\n        mobj = re.search(\n            r'<script\\b[^>]+\\bsrc=[\"\\']https?://require\\.nexx(?:\\.cloud|cdn\\.com)/(?P<id>\\d+)',\n            webpage)\n        if mobj:\n            domain_id = mobj.group('id')\n            for video_id in re.findall(\n                    r'(?is)onPLAYReady.+?_play\\.init\\s*\\(.+?\\s*,\\s*[\"\\']?(\\d+)',\n                    webpage):\n                entries.append(\n                    'https://api.nexx.cloud/v3/%s/videos/byid/%s'\n                    % (domain_id, video_id))\n\n        # TODO: support more embed formats\n\n        return entries",
        "begin_line": 68,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxIE._extract_url#92",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxIE",
        "signature": "youtube_dl.extractor.nexx.NexxIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        return NexxIE._extract_urls(webpage)[0]",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxIE._handle_error#95",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxIE",
        "signature": "youtube_dl.extractor.nexx.NexxIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        status = int_or_none(try_get(\n            response, lambda x: x['metadata']['status']) or 200)\n        if 200 <= status < 300:\n            return\n        raise ExtractorError(\n            '%s said: %s' % (self.IE_NAME, response['metadata']['errorhint']),\n            expected=True)",
        "begin_line": 95,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxIE._call_api#104",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxIE",
        "signature": "youtube_dl.extractor.nexx.NexxIE._call_api(self, domain_id, path, video_id, data=None, headers={})",
        "snippet": "    def _call_api(self, domain_id, path, video_id, data=None, headers={}):\n        headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=UTF-8'\n        result = self._download_json(\n            'https://api.nexx.cloud/v3/%s/%s' % (domain_id, path), video_id,\n            'Downloading %s JSON' % path, data=urlencode_postdata(data),\n            headers=headers)\n        self._handle_error(result)\n        return result['result']",
        "begin_line": 104,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxIE._real_extract#113",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxIE",
        "signature": "youtube_dl.extractor.nexx.NexxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        domain_id, video_id = mobj.group('domain_id', 'id')\n\n        # Reverse engineered from JS code (see getDeviceID function)\n        device_id = '%d:%d:%d%d' % (\n            random.randint(1, 4), int(time.time()),\n            random.randint(1e4, 99999), random.randint(1, 9))\n\n        result = self._call_api(domain_id, 'session/init', video_id, data={\n            'nxp_devh': device_id,\n            'nxp_userh': '',\n            'precid': '0',\n            'playlicense': '0',\n            'screenx': '1920',\n            'screeny': '1080',\n            'playerversion': '6.0.00',\n            'gateway': 'html5',\n            'adGateway': '',\n            'explicitlanguage': 'en-US',\n            'addTextTemplates': '1',\n            'addDomainData': '1',\n            'addAdModel': '1',\n        }, headers={\n            'X-Request-Enable-Auth-Fallback': '1',\n        })\n\n        cid = result['general']['cid']\n\n        # As described in [1] X-Request-Token generation algorithm is\n        # as follows:\n        #   md5( operation + domain_id + domain_secret )\n        # where domain_secret is a static value that will be given by nexx.tv\n        # as per [1]. Here is how this \"secret\" is generated (reversed\n        # from _play.api.init function, search for clienttoken). So it's\n        # actually not static and not that much of a secret.\n        # 1. https://nexxtvstorage.blob.core.windows.net/files/201610/27.pdf\n        secret = result['device']['clienttoken'][int(device_id[0]):]\n        secret = secret[0:len(secret) - int(device_id[-1])]\n\n        op = 'byid'\n\n        # Reversed from JS code for _play.api.call function (search for\n        # X-Request-Token)\n        request_token = hashlib.md5(\n            ''.join((op, domain_id, secret)).encode('utf-8')).hexdigest()\n\n        video = self._call_api(\n            domain_id, 'videos/%s/%s' % (op, video_id), video_id, data={\n                'additionalfields': 'language,channel,actors,studio,licenseby,slug,subtitle,teaser,description',\n                'addInteractionOptions': '1',\n                'addStatusDetails': '1',\n                'addStreamDetails': '1',\n                'addCaptions': '1',\n                'addScenes': '1',\n                'addHotSpots': '1',\n                'addBumpers': '1',\n                'captionFormat': 'data',\n            }, headers={\n                'X-Request-CID': cid,\n                'X-Request-Token': request_token,\n            })\n\n        general = video['general']\n        title = general['title']\n\n        stream_data = video['streamdata']\n        language = general.get('language_raw') or ''\n\n        # TODO: reverse more cdns and formats\n\n        cdn = stream_data['cdnType']\n        assert cdn == 'azure'\n\n        azure_locator = stream_data['azureLocator']\n\n        AZURE_URL = 'http://nx-p%02d.akamaized.net/'\n\n        for secure in ('s', ''):\n            cdn_shield = stream_data.get('cdnShieldHTTP%s' % secure.upper())\n            if cdn_shield:\n                azure_base = 'http%s://%s' % (secure, cdn_shield)\n                break\n        else:\n            azure_base = AZURE_URL % int(stream_data['azureAccount'].replace('nexxplayplus', ''))\n\n        is_ml = ',' in language\n        azure_m3u8_url = '%s%s/%s_src%s.ism/Manifest(format=m3u8-aapl)' % (\n            azure_base, azure_locator, video_id, ('_manifest' if is_ml else ''))\n\n        protection_token = try_get(\n            video, lambda x: x['protectiondata']['token'], compat_str)\n        if protection_token:\n            azure_m3u8_url += '?hdnts=%s' % protection_token\n\n        formats = self._extract_m3u8_formats(\n            azure_m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native',\n            m3u8_id='%s-hls' % cdn)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'alt_title': general.get('subtitle'),\n            'description': general.get('description'),\n            'release_year': int_or_none(general.get('year')),\n            'creator': general.get('studio') or general.get('studio_adref'),\n            'thumbnail': try_get(\n                video, lambda x: x['imagedata']['thumb'], compat_str),\n            'duration': parse_duration(general.get('runtime')),\n            'timestamp': int_or_none(general.get('uploaded')),\n            'episode_number': int_or_none(try_get(\n                video, lambda x: x['episodedata']['episode'])),\n            'season_number': int_or_none(try_get(\n                video, lambda x: x['episodedata']['season'])),\n            'formats': formats,\n        }",
        "begin_line": 113,
        "end_line": 229,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxEmbedIE._extract_urls#257",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxEmbedIE",
        "signature": "youtube_dl.extractor.nexx.NexxEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        # Reference:\n        # 1. https://nx-s.akamaized.net/files/201510/44.pdf\n\n        # iFrame Embed Integration\n        return [mobj.group('url') for mobj in re.finditer(\n            r'<iframe[^>]+\\bsrc=([\"\\'])(?P<url>(?:https?:)?//embed\\.nexx(?:\\.cloud|cdn\\.com)/\\d+/(?:(?!\\1).)+)\\1',\n            webpage)]",
        "begin_line": 257,
        "end_line": 264,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nexx.NexxEmbedIE._real_extract#266",
        "src_path": "youtube_dl/extractor/nexx.py",
        "class_name": "youtube_dl.extractor.nexx.NexxEmbedIE",
        "signature": "youtube_dl.extractor.nexx.NexxEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        embed_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, embed_id)\n\n        return self.url_result(NexxIE._extract_url(webpage), ie=NexxIE.ie_key())",
        "begin_line": 266,
        "end_line": 271,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nfb.NFBIE._real_extract#36",
        "src_path": "youtube_dl/extractor/nfb.py",
        "class_name": "youtube_dl.extractor.nfb.NFBIE",
        "signature": "youtube_dl.extractor.nfb.NFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_xml(\n            'https://www.nfb.ca/film/%s/player_config' % video_id,\n            video_id, 'Downloading player config XML',\n            data=urlencode_postdata({'getConfig': 'true'}),\n            headers={\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'X-NFB-Referer': 'http://www.nfb.ca/medias/flash/NFBVideoPlayer.swf'\n            })\n\n        title, description, thumbnail, duration, uploader, author = [None] * 6\n        thumbnails, formats = [[]] * 2\n        subtitles = {}\n\n        for media in config.findall('./player/stream/media'):\n            if media.get('type') == 'posterImage':\n                quality_key = qualities(('low', 'high'))\n                thumbnails = []\n                for asset in media.findall('assets/asset'):\n                    asset_url = xpath_text(asset, 'default/url', default=None)\n                    if not asset_url:\n                        continue\n                    quality = asset.get('quality')\n                    thumbnails.append({\n                        'url': asset_url,\n                        'id': quality,\n                        'preference': quality_key(quality),\n                    })\n            elif media.get('type') == 'video':\n                title = xpath_text(media, 'title', fatal=True)\n                for asset in media.findall('assets/asset'):\n                    quality = asset.get('quality')\n                    height = int_or_none(self._search_regex(\n                        r'^(\\d+)[pP]$', quality or '', 'height', default=None))\n                    for node in asset:\n                        streamer = xpath_text(node, 'streamerURI', default=None)\n                        if not streamer:\n                            continue\n                        play_path = xpath_text(node, 'url', default=None)\n                        if not play_path:\n                            continue\n                        formats.append({\n                            'url': streamer,\n                            'app': streamer.split('/', 3)[3],\n                            'play_path': play_path,\n                            'rtmp_live': False,\n                            'ext': 'flv',\n                            'format_id': '%s-%s' % (node.tag, quality) if quality else node.tag,\n                            'height': height,\n                        })\n                self._sort_formats(formats)\n                description = clean_html(xpath_text(media, 'description'))\n                uploader = xpath_text(media, 'author')\n                duration = int_or_none(media.get('duration'))\n                for subtitle in media.findall('./subtitles/subtitle'):\n                    subtitle_url = xpath_text(subtitle, 'url', default=None)\n                    if not subtitle_url:\n                        continue\n                    lang = xpath_text(subtitle, 'lang', default='en')\n                    subtitles.setdefault(lang, []).append({\n                        'url': subtitle_url,\n                        'ext': (subtitle.get('format') or determine_ext(subtitle_url)).lower(),\n                    })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'creator': uploader,\n            'uploader': uploader,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 36,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE.prepend_host#133",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE.prepend_host(host, url)",
        "snippet": "    def prepend_host(host, url):\n        if not url.startswith('http'):\n            if not url.startswith('/'):\n                url = '/%s' % url\n            url = 'http://{0:}{1:}'.format(host, url)\n        return url",
        "begin_line": 133,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE.format_from_stream#141",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE.format_from_stream(stream, protocol, host, path_prefix='', preference=0, note=None)",
        "snippet": "    def format_from_stream(stream, protocol, host, path_prefix='',\n                           preference=0, note=None):\n        url = '{protocol:}://{host:}/{prefix:}{path:}'.format(\n            protocol=protocol,\n            host=host,\n            prefix=path_prefix,\n            path=stream.get('path'),\n        )\n        return {\n            'url': url,\n            'vbr': int_or_none(stream.get('rate', 0), 1000),\n            'preference': preference,\n            'format_note': note,\n        }",
        "begin_line": 141,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nfl.NFLIE._real_extract#156",
        "src_path": "youtube_dl/extractor/nfl.py",
        "class_name": "youtube_dl.extractor.nfl.NFLIE",
        "signature": "youtube_dl.extractor.nfl.NFLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, host = mobj.group('id'), mobj.group('host')\n\n        webpage = self._download_webpage(url, video_id)\n\n        config_url = NFLIE.prepend_host(host, self._search_regex(\n            r'(?:(?:config|configURL)\\s*:\\s*|<nflcs:avplayer[^>]+data-config\\s*=\\s*)([\"\\'])(?P<config>.+?)\\1',\n            webpage, 'config URL', default='static/content/static/config/video/config.json',\n            group='config'))\n        # For articles, the id in the url is not the video id\n        video_id = self._search_regex(\n            r'(?:<nflcs:avplayer[^>]+data-content[Ii]d\\s*=\\s*|content[Ii]d\\s*:\\s*)([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'video id', default=video_id, group='id')\n        config = self._download_json(config_url, video_id, 'Downloading player config')\n        url_template = NFLIE.prepend_host(\n            host, '{contentURLTemplate:}'.format(**config))\n        video_data = self._download_json(\n            url_template.format(id=video_id), video_id)\n\n        formats = []\n        cdn_data = video_data.get('cdnData', {})\n        streams = cdn_data.get('bitrateInfo', [])\n        if cdn_data.get('format') == 'EXTERNAL_HTTP_STREAM':\n            parts = compat_urllib_parse_urlparse(cdn_data.get('uri'))\n            protocol, host = parts.scheme, parts.netloc\n            for stream in streams:\n                formats.append(\n                    NFLIE.format_from_stream(stream, protocol, host))\n        else:\n            cdns = config.get('cdns')\n            if not cdns:\n                raise ExtractorError('Failed to get CDN data', expected=True)\n\n            for name, cdn in cdns.items():\n                # LimeLight streams don't seem to work\n                if cdn.get('name') == 'LIMELIGHT':\n                    continue\n\n                protocol = cdn.get('protocol')\n                host = remove_end(cdn.get('host', ''), '/')\n                if not (protocol and host):\n                    continue\n\n                prefix = cdn.get('pathprefix', '')\n                if prefix and not prefix.endswith('/'):\n                    prefix = '%s/' % prefix\n\n                preference = 0\n                if protocol == 'rtmp':\n                    preference = -2\n                elif 'prog' in name.lower():\n                    preference = 1\n\n                for stream in streams:\n                    formats.append(\n                        NFLIE.format_from_stream(stream, protocol, host,\n                                                 prefix, preference, name))\n\n        self._sort_formats(formats)\n\n        thumbnail = None\n        for q in ('xl', 'l', 'm', 's', 'xs'):\n            thumbnail = video_data.get('imagePaths', {}).get(q)\n            if thumbnail:\n                break\n\n        return {\n            'id': video_id,\n            'title': video_data.get('headline'),\n            'formats': formats,\n            'description': video_data.get('caption'),\n            'duration': video_data.get('duration'),\n            'thumbnail': thumbnail,\n            'timestamp': int_or_none(video_data.get('posted'), 1000),\n        }",
        "begin_line": 156,
        "end_line": 231,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhk.NhkVodIE._real_extract#25",
        "src_path": "youtube_dl/extractor/nhk.py",
        "class_name": "youtube_dl.extractor.nhk.NhkVodIE",
        "signature": "youtube_dl.extractor.nhk.NhkVodIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(self._API_URL, video_id)\n\n        try:\n            episode = next(\n                e for e in data['data']['episodes']\n                if e.get('url') and video_id in e['url'])\n        except StopIteration:\n            raise ExtractorError('Unable to find episode')\n\n        embed_code = episode['vod_id']\n\n        title = episode.get('sub_title_clean') or episode['sub_title']\n        description = episode.get('description_clean') or episode.get('description')\n        series = episode.get('title_clean') or episode.get('title')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'Ooyala',\n            'url': 'ooyala:%s' % embed_code,\n            'title': '%s - %s' % (series, title) if series and title else title,\n            'description': description,\n            'series': series,\n            'episode': title,\n        }",
        "begin_line": 25,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._fix_json#25",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._fix_json(json_string)",
        "snippet": "    def _fix_json(json_string):\n        return json_string.replace('\\\\\\'', '\\'')",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._real_extract_video#28",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._real_extract_video(self, video_id)",
        "snippet": "    def _real_extract_video(self, video_id):\n        vid_parts = video_id.split(',')\n        if len(vid_parts) == 3:\n            video_id = '%s0%s%s-X-h' % (vid_parts[0][:4], vid_parts[1], vid_parts[2].rjust(4, '0'))\n        json_url = 'http://video.nhl.com/videocenter/servlets/playlist?ids=%s&format=json' % video_id\n        data = self._download_json(\n            json_url, video_id, transform_source=self._fix_json)\n        return self._extract_video(data[0])",
        "begin_line": 28,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video#37",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video(self, info)",
        "snippet": "    def _extract_video(self, info):\n        video_id = info['id']\n        self.report_extraction(video_id)\n\n        initial_video_url = info['publishPoint']\n        if info['formats'] == '1':\n            parsed_url = compat_urllib_parse_urlparse(initial_video_url)\n            filename, ext = os.path.splitext(parsed_url.path)\n            path = '%s_sd%s' % (filename, ext)\n            data = compat_urllib_parse_urlencode({\n                'type': 'fvod',\n                'path': compat_urlparse.urlunparse(parsed_url[:2] + (path,) + parsed_url[3:])\n            })\n            path_url = 'http://video.nhl.com/videocenter/servlets/encryptvideopath?' + data\n            path_doc = self._download_xml(\n                path_url, video_id, 'Downloading final video url')\n            video_url = path_doc.find('path').text\n        else:\n            video_url = initial_video_url\n\n        join = compat_urlparse.urljoin\n        ret = {\n            'id': video_id,\n            'title': info['name'],\n            'url': video_url,\n            'description': info['description'],\n            'duration': int(info['duration']),\n            'thumbnail': join(join(video_url, '/u/'), info['bigImage']),\n            'upload_date': unified_strdate(info['releaseDate'].split('.')[0]),\n        }\n        if video_url.startswith('rtmp:'):\n            mobj = re.match(r'(?P<tc_url>rtmp://[^/]+/(?P<app>[a-z0-9/]+))/(?P<play_path>mp4:.*)', video_url)\n            ret.update({\n                'tc_url': mobj.group('tc_url'),\n                'play_path': mobj.group('play_path'),\n                'app': mobj.group('app'),\n                'no_resume': True,\n            })\n        return ret",
        "begin_line": 37,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract#149",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._real_extract_video(video_id)",
        "begin_line": 149,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLNewsIE._real_extract#184",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLNewsIE",
        "signature": "youtube_dl.extractor.nhl.NHLNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        news_id = self._match_id(url)\n        webpage = self._download_webpage(url, news_id)\n        video_id = self._search_regex(\n            [r'pVid(\\d+)', r\"nlid\\s*:\\s*'(\\d+)'\",\n             r'<iframe[^>]+src=[\"\\']https?://video.*?\\.nhl\\.com/videocenter/embed\\?.*\\bplaylist=(\\d+)'],\n            webpage, 'video id')\n        return self._real_extract_video(video_id)",
        "begin_line": 184,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterCategoryIE._real_extract#207",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterCategoryIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterCategoryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        team = mobj.group('team')\n        webpage = self._download_webpage(url, team)\n        cat_id = self._search_regex(\n            [r'var defaultCatId = \"(.+?)\";',\n             r'{statusIndex:0,index:0,.*?id:(.*?),'],\n            webpage, 'category id')\n        playlist_title = self._html_search_regex(\n            r'tab0\"[^>]*?>(.*?)</td>',\n            webpage, 'playlist title', flags=re.DOTALL).lower().capitalize()\n\n        data = compat_urllib_parse_urlencode({\n            'cid': cat_id,\n            # This is the default value\n            'count': 12,\n            'ptrs': 3,\n            'format': 'json',\n        })\n        path = '/videocenter/servlets/browse?' + data\n        request_url = compat_urlparse.urljoin(url, path)\n        response = self._download_webpage(request_url, playlist_title)\n        response = self._fix_json(response)\n        if not response.strip():\n            self._downloader.report_warning('Got an empty response, trying '\n                                            'adding the \"newvideos\" parameter')\n            response = self._download_webpage(request_url + '&newvideos=true',\n                                              playlist_title)\n            response = self._fix_json(response)\n        videos = json.loads(response)\n\n        return {\n            '_type': 'playlist',\n            'title': playlist_title,\n            'id': cat_id,\n            'entries': [self._extract_video(v) for v in videos],\n        }",
        "begin_line": 207,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLIE._real_extract#297",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLIE",
        "signature": "youtube_dl.extractor.nhl.NHLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        tmp_id, site = mobj.group('id'), mobj.group('site')\n        video_data = self._download_json(\n            'https://nhl.bamcontent.com/%s/id/v1/%s/details/web-v1.json'\n            % (self._SITES_MAP[site], tmp_id), tmp_id)\n        if video_data.get('type') == 'article':\n            video_data = video_data['media']\n\n        video_id = compat_str(video_data['id'])\n        title = video_data['title']\n\n        formats = []\n        for playback in video_data.get('playbacks', []):\n            playback_url = playback.get('url')\n            if not playback_url:\n                continue\n            ext = determine_ext(playback_url)\n            if ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    playback_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=playback.get('name', 'hls'), fatal=False)\n                self._check_formats(m3u8_formats, video_id)\n                formats.extend(m3u8_formats)\n            else:\n                height = int_or_none(playback.get('height'))\n                formats.append({\n                    'format_id': playback.get('name', 'http' + ('-%dp' % height if height else '')),\n                    'url': playback_url,\n                    'width': int_or_none(playback.get('width')),\n                    'height': height,\n                })\n        self._sort_formats(formats, ('preference', 'width', 'height', 'tbr', 'format_id'))\n\n        thumbnails = []\n        for thumbnail_id, thumbnail_data in video_data.get('image', {}).get('cuts', {}).items():\n            thumbnail_url = thumbnail_data.get('src')\n            if not thumbnail_url:\n                continue\n            thumbnails.append({\n                'id': thumbnail_id,\n                'url': thumbnail_url,\n                'width': int_or_none(thumbnail_data.get('width')),\n                'height': int_or_none(thumbnail_data.get('height')),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'timestamp': parse_iso8601(video_data.get('date')),\n            'duration': parse_duration(video_data.get('duration')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 297,
        "end_line": 351,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickIE._get_feed_query#66",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickIE",
        "signature": "youtube_dl.extractor.nick.NickIE._get_feed_query(self, uri)",
        "snippet": "    def _get_feed_query(self, uri):\n        return {\n            'feed': 'nick_arc_player_prime',\n            'mgid': uri,\n        }",
        "begin_line": 66,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickIE._extract_mgid#72",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickIE",
        "signature": "youtube_dl.extractor.nick.NickIE._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        return self._search_regex(r'data-contenturi=\"([^\"]+)', webpage, 'mgid')",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickDeIE._extract_mrss_url#96",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickDeIE",
        "signature": "youtube_dl.extractor.nick.NickDeIE._extract_mrss_url(self, webpage, host)",
        "snippet": "    def _extract_mrss_url(self, webpage, host):\n        return update_url_query(self._search_regex(\n            r'data-mrss=([\"\\'])(?P<url>http.+?)\\1', webpage, 'mrss url', group='url'),\n            {'siteKey': host})",
        "begin_line": 96,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickDeIE._real_extract#101",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickDeIE",
        "signature": "youtube_dl.extractor.nick.NickDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        webpage = self._download_webpage(url, video_id)\n\n        mrss_url = self._extract_mrss_url(webpage, host)\n\n        return self._get_videos_info_from_url(mrss_url, video_id)",
        "begin_line": 101,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickNightIE._extract_mrss_url#127",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickNightIE",
        "signature": "youtube_dl.extractor.nick.NickNightIE._extract_mrss_url(self, webpage, *args)",
        "snippet": "    def _extract_mrss_url(self, webpage, *args):\n        return self._search_regex(\n            r'mrss\\s*:\\s*([\"\\'])(?P<url>http.+?)\\1', webpage,\n            'mrss url', group='url')",
        "begin_line": 127,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nick.NickRuIE._real_extract#144",
        "src_path": "youtube_dl/extractor/nick.py",
        "class_name": "youtube_dl.extractor.nick.NickRuIE",
        "signature": "youtube_dl.extractor.nick.NickRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        mgid = self._extract_mgid(webpage)\n        return self.url_result('http://media.mtvnservices.com/embed/%s' % mgid)",
        "begin_line": 144,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize#143",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 143,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._login#146",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if not username:\n            return True\n\n        # Log in\n        login_ok = True\n        login_form_strs = {\n            'mail_tel': username,\n            'password': password,\n        }\n        urlh = self._request_webpage(\n            'https://account.nicovideo.jp/api/v1/login', None,\n            note='Logging in', errnote='Unable to log in',\n            data=urlencode_postdata(login_form_strs))\n        if urlh is False:\n            login_ok = False\n        else:\n            parts = compat_urlparse.urlparse(urlh.geturl())\n            if compat_parse_qs(parts.query).get('message', [None])[0] == 'cant_login':\n                login_ok = False\n        if not login_ok:\n            self._downloader.report_warning('unable to log in: bad username or password')\n        return login_ok",
        "begin_line": 146,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._extract_format_for_quality#172",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._extract_format_for_quality(self, api_data, video_id, audio_quality, video_quality)",
        "snippet": "    def _extract_format_for_quality(self, api_data, video_id, audio_quality, video_quality):\n        def yesno(boolean):\n            return 'yes' if boolean else 'no'\n\n        session_api_data = api_data['video']['dmcInfo']['session_api']\n        session_api_endpoint = session_api_data['urls'][0]\n\n        format_id = '-'.join(map(lambda s: remove_start(s['id'], 'archive_'), [video_quality, audio_quality]))\n\n        session_response = self._download_json(\n            session_api_endpoint['url'], video_id,\n            query={'_format': 'json'},\n            headers={'Content-Type': 'application/json'},\n            note='Downloading JSON metadata for %s' % format_id,\n            data=json.dumps({\n                'session': {\n                    'client_info': {\n                        'player_id': session_api_data['player_id'],\n                    },\n                    'content_auth': {\n                        'auth_type': session_api_data['auth_types'][session_api_data['protocols'][0]],\n                        'content_key_timeout': session_api_data['content_key_timeout'],\n                        'service_id': 'nicovideo',\n                        'service_user_id': session_api_data['service_user_id']\n                    },\n                    'content_id': session_api_data['content_id'],\n                    'content_src_id_sets': [{\n                        'content_src_ids': [{\n                            'src_id_to_mux': {\n                                'audio_src_ids': [audio_quality['id']],\n                                'video_src_ids': [video_quality['id']],\n                            }\n                        }]\n                    }],\n                    'content_type': 'movie',\n                    'content_uri': '',\n                    'keep_method': {\n                        'heartbeat': {\n                            'lifetime': session_api_data['heartbeat_lifetime']\n                        }\n                    },\n                    'priority': session_api_data['priority'],\n                    'protocol': {\n                        'name': 'http',\n                        'parameters': {\n                            'http_parameters': {\n                                'parameters': {\n                                    'http_output_download_parameters': {\n                                        'use_ssl': yesno(session_api_endpoint['is_ssl']),\n                                        'use_well_known_port': yesno(session_api_endpoint['is_well_known_port']),\n                                    }\n                                }\n                            }\n                        }\n                    },\n                    'recipe_id': session_api_data['recipe_id'],\n                    'session_operation_auth': {\n                        'session_operation_auth_by_signature': {\n                            'signature': session_api_data['signature'],\n                            'token': session_api_data['token'],\n                        }\n                    },\n                    'timing_constraint': 'unlimited'\n                }\n            }))\n\n        resolution = video_quality.get('resolution', {})\n\n        return {\n            'url': session_response['data']['session']['content_uri'],\n            'format_id': format_id,\n            'ext': 'mp4',  # Session API are used in HTML5, which always serves mp4\n            'abr': float_or_none(audio_quality.get('bitrate'), 1000),\n            'vbr': float_or_none(video_quality.get('bitrate'), 1000),\n            'height': resolution.get('height'),\n            'width': resolution.get('width'),\n        }",
        "begin_line": 172,
        "end_line": 248,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_extract#250",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Get video webpage. We are not actually interested in it for normal\n        # cases, but need the cookies in order to be able to download the\n        # info webpage\n        webpage, handle = self._download_webpage_handle(\n            'http://www.nicovideo.jp/watch/' + video_id, video_id)\n        if video_id.startswith('so'):\n            video_id = self._match_id(handle.geturl())\n\n        api_data = self._parse_json(self._html_search_regex(\n            'data-api-data=\"([^\"]+)\"', webpage,\n            'API data', default='{}'), video_id)\n\n        def _format_id_from_url(video_url):\n            return 'economy' if video_real_url.endswith('low') else 'normal'\n\n        try:\n            video_real_url = api_data['video']['smileInfo']['url']\n        except KeyError:  # Flash videos\n            # Get flv info\n            flv_info_webpage = self._download_webpage(\n                'http://flapi.nicovideo.jp/api/getflv/' + video_id + '?as3=1',\n                video_id, 'Downloading flv info')\n\n            flv_info = compat_urlparse.parse_qs(flv_info_webpage)\n            if 'url' not in flv_info:\n                if 'deleted' in flv_info:\n                    raise ExtractorError('The video has been deleted.',\n                                         expected=True)\n                elif 'closed' in flv_info:\n                    raise ExtractorError('Niconico videos now require logging in',\n                                         expected=True)\n                elif 'error' in flv_info:\n                    raise ExtractorError('%s reports error: %s' % (\n                        self.IE_NAME, flv_info['error'][0]), expected=True)\n                else:\n                    raise ExtractorError('Unable to find video URL')\n\n            video_info_xml = self._download_xml(\n                'http://ext.nicovideo.jp/api/getthumbinfo/' + video_id,\n                video_id, note='Downloading video info page')\n\n            def get_video_info(items):\n                if not isinstance(items, list):\n                    items = [items]\n                for item in items:\n                    ret = xpath_text(video_info_xml, './/' + item)\n                    if ret:\n                        return ret\n\n            video_real_url = flv_info['url'][0]\n\n            extension = get_video_info('movie_type')\n            if not extension:\n                extension = determine_ext(video_real_url)\n\n            formats = [{\n                'url': video_real_url,\n                'ext': extension,\n                'format_id': _format_id_from_url(video_real_url),\n            }]\n        else:\n            formats = []\n\n            dmc_info = api_data['video'].get('dmcInfo')\n            if dmc_info:  # \"New\" HTML5 videos\n                quality_info = dmc_info['quality']\n                for audio_quality in quality_info['audios']:\n                    for video_quality in quality_info['videos']:\n                        if not audio_quality['available'] or not video_quality['available']:\n                            continue\n                        formats.append(self._extract_format_for_quality(\n                            api_data, video_id, audio_quality, video_quality))\n\n                self._sort_formats(formats)\n            else:  # \"Old\" HTML5 videos\n                formats = [{\n                    'url': video_real_url,\n                    'ext': 'mp4',\n                    'format_id': _format_id_from_url(video_real_url),\n                }]\n\n            def get_video_info(items):\n                return dict_get(api_data['video'], items)\n\n        # Start extracting information\n        title = get_video_info('title')\n        if not title:\n            title = self._og_search_title(webpage, default=None)\n        if not title:\n            title = self._html_search_regex(\n                r'<span[^>]+class=\"videoHeaderTitle\"[^>]*>([^<]+)</span>',\n                webpage, 'video title')\n\n        watch_api_data_string = self._html_search_regex(\n            r'<div[^>]+id=\"watchAPIDataContainer\"[^>]+>([^<]+)</div>',\n            webpage, 'watch api data', default=None)\n        watch_api_data = self._parse_json(watch_api_data_string, video_id) if watch_api_data_string else {}\n        video_detail = watch_api_data.get('videoDetail', {})\n\n        thumbnail = (\n            get_video_info(['thumbnail_url', 'thumbnailURL']) or\n            self._html_search_meta('image', webpage, 'thumbnail', default=None) or\n            video_detail.get('thumbnail'))\n\n        description = get_video_info('description')\n\n        timestamp = (parse_iso8601(get_video_info('first_retrieve')) or\n                     unified_timestamp(get_video_info('postedDateTime')))\n        if not timestamp:\n            match = self._html_search_meta('datePublished', webpage, 'date published', default=None)\n            if match:\n                timestamp = parse_iso8601(match.replace('+', ':00+'))\n        if not timestamp and video_detail.get('postedAt'):\n            timestamp = parse_iso8601(\n                video_detail['postedAt'].replace('/', '-'),\n                delimiter=' ', timezone=datetime.timedelta(hours=9))\n\n        view_count = int_or_none(get_video_info(['view_counter', 'viewCount']))\n        if not view_count:\n            match = self._html_search_regex(\n                r'>Views: <strong[^>]*>([^<]+)</strong>',\n                webpage, 'view count', default=None)\n            if match:\n                view_count = int_or_none(match.replace(',', ''))\n        view_count = view_count or video_detail.get('viewCount')\n\n        comment_count = (int_or_none(get_video_info('comment_num')) or\n                         video_detail.get('commentCount') or\n                         try_get(api_data, lambda x: x['thread']['commentCount']))\n        if not comment_count:\n            match = self._html_search_regex(\n                r'>Comments: <strong[^>]*>([^<]+)</strong>',\n                webpage, 'comment count', default=None)\n            if match:\n                comment_count = int_or_none(match.replace(',', ''))\n\n        duration = (parse_duration(\n            get_video_info('length') or\n            self._html_search_meta(\n                'video:duration', webpage, 'video duration', default=None)) or\n            video_detail.get('length') or\n            get_video_info('duration'))\n\n        webpage_url = get_video_info('watch_url') or url\n\n        owner = api_data.get('owner', {})\n        uploader_id = get_video_info(['ch_id', 'user_id']) or owner.get('id')\n        uploader = get_video_info(['ch_name', 'user_nickname']) or owner.get('nickname')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'duration': duration,\n            'webpage_url': webpage_url,\n        }",
        "begin_line": 250,
        "end_line": 415,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoPlaylistIE._real_extract#430",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoPlaylistIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n        webpage = self._download_webpage(url, list_id)\n\n        entries_json = self._search_regex(r'Mylist\\.preload\\(\\d+, (\\[.*\\])\\);',\n                                          webpage, 'entries')\n        entries = json.loads(entries_json)\n        entries = [{\n            '_type': 'url',\n            'ie_key': NiconicoIE.ie_key(),\n            'url': ('http://www.nicovideo.jp/watch/%s' %\n                    entry['item_data']['video_id']),\n        } for entry in entries]\n\n        return {\n            '_type': 'playlist',\n            'title': self._search_regex(r'\\s+name: \"(.*?)\"', webpage, 'title'),\n            'id': list_id,\n            'entries': entries,\n        }",
        "begin_line": 430,
        "end_line": 449,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ninecninemedia.NineCNineMediaStackIE._real_extract#25",
        "src_path": "youtube_dl/extractor/ninecninemedia.py",
        "class_name": "youtube_dl.extractor.ninecninemedia.NineCNineMediaStackIE",
        "signature": "youtube_dl.extractor.ninecninemedia.NineCNineMediaStackIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        destination_code, content_id, package_id, stack_id = re.match(self._VALID_URL, url).groups()\n        stack_base_url_template = self._API_BASE_TEMPLATE + 'contentpackages/%s/stacks/%s/manifest.'\n        stack_base_url = stack_base_url_template % (destination_code, content_id, package_id, stack_id)\n\n        formats = []\n        formats.extend(self._extract_m3u8_formats(\n            stack_base_url + 'm3u8', stack_id, 'mp4',\n            'm3u8_native', m3u8_id='hls', fatal=False))\n        formats.extend(self._extract_f4m_formats(\n            stack_base_url + 'f4m', stack_id,\n            f4m_id='hds', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': stack_id,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ninecninemedia.NineCNineMediaIE._real_extract#49",
        "src_path": "youtube_dl/extractor/ninecninemedia.py",
        "class_name": "youtube_dl.extractor.ninecninemedia.NineCNineMediaIE",
        "signature": "youtube_dl.extractor.ninecninemedia.NineCNineMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        destination_code, content_id = re.match(self._VALID_URL, url).groups()\n        api_base_url = self._API_BASE_TEMPLATE % (destination_code, content_id)\n        content = self._download_json(api_base_url, content_id, query={\n            '$include': '[Media,Season,ContentPackages]',\n        })\n        title = content['Name']\n        if len(content['ContentPackages']) > 1:\n            raise ExtractorError('multiple content packages')\n        content_package = content['ContentPackages'][0]\n        package_id = content_package['Id']\n        content_package_url = api_base_url + 'contentpackages/%s/' % package_id\n        content_package = self._download_json(content_package_url, content_id)\n\n        if content_package.get('Constraints', {}).get('Security', {}).get('Type') == 'adobe-drm':\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        stacks = self._download_json(content_package_url + 'stacks/', package_id)['Items']\n        multistacks = len(stacks) > 1\n\n        thumbnails = []\n        for image in content.get('Images', []):\n            image_url = image.get('Url')\n            if not image_url:\n                continue\n            thumbnails.append({\n                'url': image_url,\n                'width': int_or_none(image.get('Width')),\n                'height': int_or_none(image.get('Height')),\n            })\n\n        tags, categories = [], []\n        for source_name, container in (('Tags', tags), ('Genres', categories)):\n            for e in content.get(source_name, []):\n                e_name = e.get('Name')\n                if not e_name:\n                    continue\n                container.append(e_name)\n\n        description = content.get('Desc') or content.get('ShortDesc')\n        season = content.get('Season', {})\n        base_info = {\n            'description': description,\n            'timestamp': parse_iso8601(content.get('BroadcastDateTime')),\n            'episode_number': int_or_none(content.get('Episode')),\n            'season': season.get('Name'),\n            'season_number': season.get('Number'),\n            'season_id': season.get('Id'),\n            'series': content.get('Media', {}).get('Name'),\n            'tags': tags,\n            'categories': categories,\n        }\n\n        entries = []\n        for stack in stacks:\n            stack_id = compat_str(stack['Id'])\n            entry = {\n                '_type': 'url_transparent',\n                'url': '9c9media:stack:%s:%s:%s:%s' % (destination_code, content_id, package_id, stack_id),\n                'id': stack_id,\n                'title': '%s_part%s' % (title, stack['Name']) if multistacks else title,\n                'duration': float_or_none(stack.get('Duration')),\n                'ie_key': 'NineCNineMediaStack',\n            }\n            entry.update(base_info)\n            entries.append(entry)\n\n        return {\n            '_type': 'multi_video',\n            'id': content_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 49,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ninegag.NineGagIE._real_extract#69",
        "src_path": "youtube_dl/extractor/ninegag.py",
        "class_name": "youtube_dl.extractor.ninegag.NineGagIE",
        "signature": "youtube_dl.extractor.ninegag.NineGagIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        post_view = self._parse_json(\n            self._search_regex(\n                r'var\\s+postView\\s*=\\s*new\\s+app\\.PostView\\({\\s*post:\\s*({.+?})\\s*,\\s*posts:\\s*prefetchedCurrentPost',\n                webpage, 'post view'),\n            display_id)\n\n        ie_key = None\n        source_url = post_view.get('sourceUrl')\n        if not source_url:\n            external_video_id = post_view['videoExternalId']\n            external_video_provider = post_view['videoExternalProvider']\n            source_url = self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['url'] % external_video_id\n            ie_key = self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['ie_key']\n        title = post_view['title']\n        description = post_view.get('description')\n        view_count = str_to_int(post_view.get('externalView'))\n        thumbnail = post_view.get('thumbnail_700w') or post_view.get('ogImageUrl') or post_view.get('thumbnail_300w')\n\n        return {\n            '_type': 'url_transparent',\n            'url': source_url,\n            'ie_key': ie_key,\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 69,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ninenow.NineNowIE._real_extract#41",
        "src_path": "youtube_dl/extractor/ninenow.py",
        "class_name": "youtube_dl.extractor.ninenow.NineNowIE",
        "signature": "youtube_dl.extractor.ninenow.NineNowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        page_data = self._parse_json(self._search_regex(\n            r'window\\.__data\\s*=\\s*({.*?});', webpage,\n            'page data'), display_id)\n\n        for kind in ('episode', 'clip'):\n            current_key = page_data.get(kind, {}).get(\n                'current%sKey' % kind.capitalize())\n            if not current_key:\n                continue\n            cache = page_data.get(kind, {}).get('%sCache' % kind, {})\n            if not cache:\n                continue\n            common_data = (cache.get(current_key) or list(cache.values())[0])[kind]\n            break\n        else:\n            raise ExtractorError('Unable to find video data')\n\n        video_data = common_data['video']\n\n        if video_data.get('drm'):\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        brightcove_id = video_data.get('brightcoveId') or 'ref:' + video_data['referenceId']\n        video_id = compat_str(video_data.get('id') or brightcove_id)\n        title = common_data['name']\n\n        thumbnails = [{\n            'id': thumbnail_id,\n            'url': thumbnail_url,\n            'width': int_or_none(thumbnail_id[1:])\n        } for thumbnail_id, thumbnail_url in common_data.get('image', {}).get('sizes', {}).items()]\n\n        return {\n            '_type': 'url_transparent',\n            'url': self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,\n            'id': video_id,\n            'title': title,\n            'description': common_data.get('description'),\n            'duration': float_or_none(video_data.get('duration'), 1000),\n            'thumbnails': thumbnails,\n            'ie_key': 'BrightcoveNew',\n        }",
        "begin_line": 41,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nintendo.NintendoIE._real_extract#34",
        "src_path": "youtube_dl/extractor/nintendo.py",
        "class_name": "youtube_dl.extractor.nintendo.NintendoIE",
        "signature": "youtube_dl.extractor.nintendo.NintendoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, page_id)\n\n        entries = [\n            OoyalaIE._build_url_result(m.group('code'))\n            for m in re.finditer(\n                r'class=([\"\\'])embed-video\\1[^>]+data-video-code=([\"\\'])(?P<code>(?:(?!\\2).)+)\\2',\n                webpage)]\n\n        return self.playlist_result(\n            entries, page_id, unescapeHTML(self._og_search_title(webpage, fatal=False)))",
        "begin_line": 34,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.njpwworld.NJPWWorldIE._real_initialize#34",
        "src_path": "youtube_dl/extractor/njpwworld.py",
        "class_name": "youtube_dl.extractor.njpwworld.NJPWWorldIE",
        "signature": "youtube_dl.extractor.njpwworld.NJPWWorldIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.njpwworld.NJPWWorldIE._login#37",
        "src_path": "youtube_dl/extractor/njpwworld.py",
        "class_name": "youtube_dl.extractor.njpwworld.NJPWWorldIE",
        "signature": "youtube_dl.extractor.njpwworld.NJPWWorldIE._login(self)",
        "snippet": "    def _login(self):\n        username, password = self._get_login_info()\n        # No authentication to be performed\n        if not username:\n            return True\n\n        webpage, urlh = self._download_webpage_handle(\n            'https://njpwworld.com/auth/login', None,\n            note='Logging in', errnote='Unable to login',\n            data=urlencode_postdata({'login_id': username, 'pw': password}))\n        # /auth/login will return 302 for successful logins\n        if urlh.geturl() == 'https://njpwworld.com/auth/login':\n            self.report_warning('unable to login')\n            return False\n\n        return True",
        "begin_line": 37,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.njpwworld.NJPWWorldIE._real_extract#54",
        "src_path": "youtube_dl/extractor/njpwworld.py",
        "class_name": "youtube_dl.extractor.njpwworld.NJPWWorldIE",
        "signature": "youtube_dl.extractor.njpwworld.NJPWWorldIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for mobj in re.finditer(r'<a[^>]+\\bhref=([\"\\'])/player.+?[^>]*>', webpage):\n            player = extract_attributes(mobj.group(0))\n            player_path = player.get('href')\n            if not player_path:\n                continue\n            kind = self._search_regex(\n                r'(low|high)$', player.get('class') or '', 'kind',\n                default='low')\n            player_url = compat_urlparse.urljoin(url, player_path)\n            player_page = self._download_webpage(\n                player_url, video_id, note='Downloading player page')\n            entries = self._parse_html5_media_entries(\n                player_url, player_page, video_id, m3u8_id='hls-%s' % kind,\n                m3u8_entry_protocol='m3u8_native')\n            kind_formats = entries[0]['formats']\n            for f in kind_formats:\n                f['quality'] = 2 if kind == 'high' else 1\n            formats.extend(kind_formats)\n\n        self._sort_formats(formats)\n\n        post_content = get_element_by_class('post-content', webpage)\n        tags = re.findall(\n            r'<li[^>]+class=\"tag-[^\"]+\"><a[^>]*>([^<]+)</a></li>', post_content\n        ) if post_content else None\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'tags': tags,\n        }",
        "begin_line": 54,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nobelprize.NobelPrizeIE._real_extract#28",
        "src_path": "youtube_dl/extractor/nobelprize.py",
        "class_name": "youtube_dl.extractor.nobelprize.NobelPrizeIE",
        "signature": "youtube_dl.extractor.nobelprize.NobelPrizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        media = self._parse_json(self._search_regex(\n            r'(?s)var\\s*config\\s*=\\s*({.+?});', webpage,\n            'config'), video_id, js_to_json)['media']\n        title = media['title']\n\n        formats = []\n        for source in media.get('source', []):\n            source_src = source.get('src')\n            if not source_src:\n                continue\n            ext = mimetype2ext(source.get('type')) or determine_ext(source_src)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    source_src, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    update_url_query(source_src, {'hdcore': '3.7.0'}),\n                    video_id, f4m_id='hds', fatal=False))\n            else:\n                formats.append({\n                    'url': source_src,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': get_element_by_attribute('itemprop', 'description', webpage),\n            'duration': int_or_none(media.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_initialize#64",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 64,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._login#67",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login = self._download_json(\n            self._LOGIN_URL, None, 'Logging in as %s' % username,\n            data=urlencode_postdata({\n                'a': 'login',\n                'cookie': '1',\n                'username': username,\n                'password': password,\n            }),\n            headers={\n                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n            })\n\n        if 'erreur' in login:\n            raise ExtractorError('Unable to login: %s' % clean_html(login['erreur']), expected=True)",
        "begin_line": 67,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._ts#88",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._ts()",
        "snippet": "    def _ts():\n        return int(time.time() * 1000)",
        "begin_line": 88,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._call_api#91",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._call_api(self, path, video_id, note, sub_lang=None)",
        "snippet": "    def _call_api(self, path, video_id, note, sub_lang=None):\n        ts = compat_str(self._ts() + self._ts_offset)\n        tk = hashlib.md5((hashlib.md5(ts.encode('ascii')).hexdigest() + '#8S?uCraTedap6a').encode('ascii')).hexdigest()\n        url = self._API_URL_TEMPLATE % (path, ts, tk)\n        if sub_lang:\n            url += self._SUB_LANG_TEMPLATE % sub_lang\n\n        request = sanitized_Request(url)\n        request.add_header('Referer', self._referer)\n\n        resp = self._download_json(request, video_id, note)\n\n        if isinstance(resp, dict) and resp.get('error'):\n            self._raise_error(resp['error'], resp['description'])\n\n        return resp",
        "begin_line": 91,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._raise_error#108",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._raise_error(self, error, description)",
        "snippet": "    def _raise_error(self, error, description):\n        raise ExtractorError(\n            '%s returned error: %s - %s' % (self.IE_NAME, error, description),\n            expected=True)",
        "begin_line": 108,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_extract#113",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Timestamp adjustment offset between server time and local time\n        # must be calculated in order to use timestamps closest to server's\n        # in all API requests (see https://github.com/rg3/youtube-dl/issues/7864)\n        webpage = self._download_webpage(url, video_id)\n\n        player_url = self._search_regex(\n            r'([\"\\'])(?P<player>https?://noco\\.tv/(?:[^/]+/)+NocoPlayer.+?\\.swf.*?)\\1',\n            webpage, 'noco player', group='player',\n            default='http://noco.tv/cdata/js/player/NocoPlayer-v1.2.40.swf')\n\n        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(player_url).query)\n        ts = int_or_none(qs.get('ts', [None])[0])\n        self._ts_offset = ts - self._ts() if ts else 0\n        self._referer = player_url\n\n        medias = self._call_api(\n            'shows/%s/medias' % video_id,\n            video_id, 'Downloading video JSON')\n\n        show = self._call_api(\n            'shows/by_id/%s' % video_id,\n            video_id, 'Downloading show JSON')[0]\n\n        options = self._call_api(\n            'users/init', video_id,\n            'Downloading user options JSON')['options']\n        audio_lang_pref = options.get('audio_language') or options.get('language', 'fr')\n\n        if audio_lang_pref == 'original':\n            audio_lang_pref = show['original_lang']\n        if len(medias) == 1:\n            audio_lang_pref = list(medias.keys())[0]\n        elif audio_lang_pref not in medias:\n            audio_lang_pref = 'fr'\n\n        qualities = self._call_api(\n            'qualities',\n            video_id, 'Downloading qualities JSON')\n\n        formats = []\n\n        for audio_lang, audio_lang_dict in medias.items():\n            preference = 1 if audio_lang == audio_lang_pref else 0\n            for sub_lang, lang_dict in audio_lang_dict['video_list'].items():\n                for format_id, fmt in lang_dict['quality_list'].items():\n                    format_id_extended = 'audio-%s_sub-%s_%s' % (audio_lang, sub_lang, format_id)\n\n                    video = self._call_api(\n                        'shows/%s/video/%s/%s' % (video_id, format_id.lower(), audio_lang),\n                        video_id, 'Downloading %s video JSON' % format_id_extended,\n                        sub_lang if sub_lang != 'none' else None)\n\n                    file_url = video['file']\n                    if not file_url:\n                        continue\n\n                    if file_url in ['forbidden', 'not found']:\n                        popmessage = video['popmessage']\n                        self._raise_error(popmessage['title'], popmessage['message'])\n\n                    formats.append({\n                        'url': file_url,\n                        'format_id': format_id_extended,\n                        'width': int_or_none(fmt.get('res_width')),\n                        'height': int_or_none(fmt.get('res_lines')),\n                        'abr': int_or_none(fmt.get('audiobitrate'), 1000),\n                        'vbr': int_or_none(fmt.get('videobitrate'), 1000),\n                        'filesize': int_or_none(fmt.get('filesize')),\n                        'format_note': qualities[format_id].get('quality_name'),\n                        'quality': qualities[format_id].get('priority'),\n                        'preference': preference,\n                    })\n\n        self._sort_formats(formats)\n\n        timestamp = parse_iso8601(show.get('online_date_start_utc'), ' ')\n\n        if timestamp is not None and timestamp < 0:\n            timestamp = None\n\n        uploader = show.get('partner_name')\n        uploader_id = show.get('partner_key')\n        duration = float_or_none(show.get('duration_ms'), 1000)\n\n        thumbnails = []\n        for thumbnail_key, thumbnail_url in show.items():\n            m = re.search(r'^screenshot_(?P<width>\\d+)x(?P<height>\\d+)$', thumbnail_key)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n\n        episode = show.get('show_TT') or show.get('show_OT')\n        family = show.get('family_TT') or show.get('family_OT')\n        episode_number = show.get('episode_number')\n\n        title = ''\n        if family:\n            title += family\n        if episode_number:\n            title += ' #' + compat_str(episode_number)\n        if episode:\n            title += ' - ' + compat_str(episode)\n\n        description = show.get('show_resume') or show.get('family_resume')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 113,
        "end_line": 235,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nonktube.NonkTubeIE._real_extract#25",
        "src_path": "youtube_dl/extractor/nonktube.py",
        "class_name": "youtube_dl.extractor.nonktube.NonkTubeIE",
        "signature": "youtube_dl.extractor.nonktube.NonkTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._extract_nuevo(\n            'https://www.nonktube.com/media/nuevo/econfig.php?key=%s'\n            % video_id, video_id)\n\n        info['age_limit'] = 18\n        return info",
        "begin_line": 25,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noovo.NoovoIE._real_extract#58",
        "src_path": "youtube_dl/extractor/noovo.py",
        "class_name": "youtube_dl.extractor.noovo.NoovoIE",
        "signature": "youtube_dl.extractor.noovo.NoovoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'http://api.noovo.ca/api/v1/pages/single-episode/%s' % video_id,\n            video_id)['data']\n\n        content = try_get(data, lambda x: x['contents'][0])\n\n        brightcove_id = data.get('brightcoveId') or content['brightcoveId']\n\n        series = try_get(\n            data, (\n                lambda x: x['show']['title'],\n                lambda x: x['season']['show']['title']),\n            compat_str)\n\n        episode = None\n        og = data.get('og')\n        if isinstance(og, dict) and og.get('type') == 'video.episode':\n            episode = og.get('title')\n\n        video = content or data\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': BrightcoveNewIE.ie_key(),\n            'url': smuggle_url(\n                self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,\n                {'geo_countries': ['CA']}),\n            'id': brightcove_id,\n            'title': video.get('title'),\n            'creator': video.get('source'),\n            'view_count': int_or_none(video.get('viewsCount')),\n            'series': series,\n            'season_number': int_or_none(try_get(\n                data, lambda x: x['season']['seasonNumber'])),\n            'episode': episode,\n            'episode_number': int_or_none(data.get('episodeNumber')),\n        }",
        "begin_line": 58,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract#31",
        "src_path": "youtube_dl/extractor/normalboots.py",
        "class_name": "youtube_dl.extractor.normalboots.NormalbootsIE",
        "signature": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_uploader = self._html_search_regex(\n            r'Posted\\sby\\s<a\\shref=\"[A-Za-z0-9/]*\">(?P<uploader>[A-Za-z]*)\\s</a>',\n            webpage, 'uploader', fatal=False)\n        video_upload_date = unified_strdate(self._html_search_regex(\n            r'<span style=\"text-transform:uppercase; font-size:inherit;\">[A-Za-z]+, (?P<date>.*)</span>',\n            webpage, 'date', fatal=False))\n\n        jwplatform_url = JWPlatformIE._extract_url(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': jwplatform_url,\n            'ie_key': JWPlatformIE.ie_key(),\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n        }",
        "begin_line": 31,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract#34",
        "src_path": "youtube_dl/extractor/nosvideo.py",
        "class_name": "youtube_dl.extractor.nosvideo.NosVideoIE",
        "signature": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        fields = {\n            'id': video_id,\n            'op': 'download1',\n            'method_free': 'Continue to Video',\n        }\n        req = sanitized_Request(url, urlencode_postdata(fields))\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading download page')\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        xml_id = self._search_regex(r'php\\|([^\\|]+)\\|', webpage, 'XML ID')\n        playlist_url = self._PLAYLIST_URL.format(xml_id=xml_id)\n        playlist = self._download_xml(playlist_url, video_id)\n\n        track = playlist.find(_x('.//xspf:track'))\n        if track is None:\n            raise ExtractorError(\n                'XML playlist is missing the \\'track\\' element',\n                expected=True)\n        title = xpath_text(track, _x('./xspf:title'), 'title')\n        url = xpath_text(track, _x('./xspf:file'), 'URL', fatal=True)\n        thumbnail = xpath_text(track, _x('./xspf:image'), 'thumbnail')\n        if title is not None:\n            title = title.strip()\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nova.NovaIE._real_extract#99",
        "src_path": "youtube_dl/extractor/nova.py",
        "class_name": "youtube_dl.extractor.nova.NovaIE",
        "signature": "youtube_dl.extractor.nova.NovaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        site = mobj.group('site')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            [r\"(?:media|video_id)\\s*:\\s*'(\\d+)'\",\n             r'media=(\\d+)',\n             r'id=\"article_video_(\\d+)\"',\n             r'id=\"player_(\\d+)\"'],\n            webpage, 'video id')\n\n        config_url = self._search_regex(\n            r'src=\"(http://tn\\.nova\\.cz/bin/player/videojs/config\\.php\\?[^\"]+)\"',\n            webpage, 'config url', default=None)\n\n        if not config_url:\n            DEFAULT_SITE_ID = '23000'\n            SITES = {\n                'tvnoviny': DEFAULT_SITE_ID,\n                'novaplus': DEFAULT_SITE_ID,\n                'vymena': DEFAULT_SITE_ID,\n                'krasna': DEFAULT_SITE_ID,\n                'fanda': '30',\n                'tn': '30',\n                'doma': '30',\n            }\n\n            site_id = self._search_regex(\n                r'site=(\\d+)', webpage, 'site id', default=None) or SITES.get(site, DEFAULT_SITE_ID)\n\n            config_url = ('http://tn.nova.cz/bin/player/videojs/config.php?site=%s&media=%s&jsVar=vjsconfig'\n                          % (site_id, video_id))\n\n        config = self._download_json(\n            config_url, display_id,\n            'Downloading config JSON',\n            transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])\n\n        mediafile = config['mediafile']\n        video_url = mediafile['src']\n\n        m = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>[^/]+?))/&*(?P<playpath>.+)$', video_url)\n        if m:\n            formats = [{\n                'url': m.group('url'),\n                'app': m.group('app'),\n                'play_path': m.group('playpath'),\n                'player_path': 'http://tvnoviny.nova.cz/static/shared/app/videojs/video-js.swf',\n                'ext': 'flv',\n            }]\n        else:\n            formats = [{\n                'url': video_url,\n            }]\n        self._sort_formats(formats)\n\n        title = mediafile.get('meta', {}).get('title') or self._og_search_title(webpage)\n        description = clean_html(self._og_search_description(webpage, default=None))\n        thumbnail = config.get('poster')\n\n        if site == 'novaplus':\n            upload_date = unified_strdate(self._search_regex(\n                r'(\\d{1,2}-\\d{1,2}-\\d{4})$', display_id, 'upload date', default=None))\n        elif site == 'fanda':\n            upload_date = unified_strdate(self._search_regex(\n                r'<span class=\"date_time\">(\\d{1,2}\\.\\d{1,2}\\.\\d{4})', webpage, 'upload date', default=None))\n        else:\n            upload_date = None\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 99,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.novamov.NovaMovIE._check_existence#39",
        "src_path": "youtube_dl/extractor/novamov.py",
        "class_name": "youtube_dl.extractor.novamov.NovaMovIE",
        "signature": "youtube_dl.extractor.novamov.NovaMovIE._check_existence(self, webpage, video_id)",
        "snippet": "    def _check_existence(self, webpage, video_id):\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)",
        "begin_line": 39,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.novamov.NovaMovIE._real_extract#43",
        "src_path": "youtube_dl/extractor/novamov.py",
        "class_name": "youtube_dl.extractor.novamov.NovaMovIE",
        "signature": "youtube_dl.extractor.novamov.NovaMovIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        url = self._URL_TEMPLATE % (self._HOST, video_id)\n\n        webpage = self._download_webpage(\n            url, video_id, 'Downloading video page')\n\n        self._check_existence(webpage, video_id)\n\n        def extract_filekey(default=NO_DEFAULT):\n            filekey = self._search_regex(\n                self._FILEKEY_REGEX, webpage, 'filekey', default=default)\n            if filekey is not default and (filekey[0] != '\"' or filekey[-1] != '\"'):\n                return self._search_regex(\n                    r'var\\s+%s\\s*=\\s*\"([^\"]+)\"' % re.escape(filekey), webpage, 'filekey', default=default)\n            else:\n                return filekey\n\n        filekey = extract_filekey(default=None)\n\n        if not filekey:\n            fields = self._hidden_inputs(webpage)\n            post_url = self._search_regex(\n                r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', webpage,\n                'post url', default=url, group='url')\n            if not post_url.startswith('http'):\n                post_url = compat_urlparse.urljoin(url, post_url)\n            request = sanitized_Request(\n                post_url, urlencode_postdata(fields))\n            request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            request.add_header('Referer', post_url)\n            webpage = self._download_webpage(\n                request, video_id, 'Downloading continue to the video page')\n            self._check_existence(webpage, video_id)\n\n        filekey = extract_filekey()\n\n        title = self._html_search_regex(self._TITLE_REGEX, webpage, 'title')\n        description = self._html_search_regex(self._DESCRIPTION_REGEX, webpage, 'description', default='', fatal=False)\n\n        api_response = self._download_webpage(\n            'http://%s/api/player.api.php?key=%s&file=%s' % (self._HOST, filekey, video_id), video_id,\n            'Downloading video api response')\n\n        response = compat_urlparse.parse_qs(api_response)\n\n        if 'error_msg' in response:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, response['error_msg'][0]), expected=True)\n\n        video_url = response['url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description\n        }",
        "begin_line": 43,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessBaseIE._extract_url_result#17",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessBaseIE",
        "signature": "youtube_dl.extractor.nowness.NownessBaseIE._extract_url_result(self, post)",
        "snippet": "    def _extract_url_result(self, post):\n        if post['type'] == 'video':\n            for media in post['media']:\n                if media['type'] == 'video':\n                    video_id = media['content']\n                    source = media['source']\n                    if source == 'brightcove':\n                        player_code = self._download_webpage(\n                            'http://www.nowness.com/iframe?id=%s' % video_id, video_id,\n                            note='Downloading player JavaScript',\n                            errnote='Unable to download player JavaScript')\n                        bc_url = BrightcoveLegacyIE._extract_brightcove_url(player_code)\n                        if bc_url:\n                            return self.url_result(bc_url, BrightcoveLegacyIE.ie_key())\n                        bc_url = BrightcoveNewIE._extract_url(self, player_code)\n                        if bc_url:\n                            return self.url_result(bc_url, BrightcoveNewIE.ie_key())\n                        raise ExtractorError('Could not find player definition')\n                    elif source == 'vimeo':\n                        return self.url_result('http://vimeo.com/%s' % video_id, 'Vimeo')\n                    elif source == 'youtube':\n                        return self.url_result(video_id, 'Youtube')\n                    elif source == 'cinematique':\n                        # youtube-dl currently doesn't support cinematique\n                        # return self.url_result('http://cinematique.com/embed/%s' % video_id, 'Cinematique')\n                        pass",
        "begin_line": 17,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessBaseIE._api_request#44",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessBaseIE",
        "signature": "youtube_dl.extractor.nowness.NownessBaseIE._api_request(self, url, request_path)",
        "snippet": "    def _api_request(self, url, request_path):\n        display_id = self._match_id(url)\n        request = sanitized_Request(\n            'http://api.nowness.com/api/' + request_path % display_id,\n            headers={\n                'X-Nowness-Language': 'zh-cn' if 'cn.nowness.com' in url else 'en-us',\n            })\n        return display_id, self._download_json(request, display_id)",
        "begin_line": 44,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessIE._real_extract#102",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessIE",
        "signature": "youtube_dl.extractor.nowness.NownessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        _, post = self._api_request(url, 'post/getBySlug/%s')\n        return self._extract_url_result(post)",
        "begin_line": 102,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessPlaylistIE._real_extract#118",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessPlaylistIE",
        "signature": "youtube_dl.extractor.nowness.NownessPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id, playlist = self._api_request(url, 'post?PlaylistId=%s')\n        entries = [self._extract_url_result(item) for item in playlist['items']]\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 118,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessSeriesIE._real_extract#137",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessSeriesIE",
        "signature": "youtube_dl.extractor.nowness.NownessSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id, series = self._api_request(url, 'series/getBySlug/%s')\n        entries = [self._extract_url_result(post) for post in series['posts']]\n        series_title = None\n        series_description = None\n        translations = series.get('translations', [])\n        if translations:\n            series_title = translations[0].get('title') or translations[0]['seoTitle']\n            series_description = translations[0].get('seoDescription')\n        return self.playlist_result(\n            entries, compat_str(series['id']), series_title, series_description)",
        "begin_line": 137,
        "end_line": 147,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowtv.NowTVBaseIE._extract_video#24",
        "src_path": "youtube_dl/extractor/nowtv.py",
        "class_name": "youtube_dl.extractor.nowtv.NowTVBaseIE",
        "signature": "youtube_dl.extractor.nowtv.NowTVBaseIE._extract_video(self, info, display_id=None)",
        "snippet": "    def _extract_video(self, info, display_id=None):\n        video_id = compat_str(info['id'])\n\n        files = info['files']\n        if not files:\n            if info.get('geoblocked', False):\n                raise ExtractorError(\n                    'Video %s is not available from your location due to geo restriction' % video_id,\n                    expected=True)\n            if not info.get('free', True):\n                raise ExtractorError(\n                    'Video %s is not available for free' % video_id, expected=True)\n\n        formats = []\n        for item in files['items']:\n            if determine_ext(item['path']) != 'f4v':\n                continue\n            app, play_path = remove_start(item['path'], '/').split('/', 1)\n            formats.append({\n                'url': 'rtmpe://fms.rtl.de',\n                'app': app,\n                'play_path': 'mp4:%s' % play_path,\n                'ext': 'flv',\n                'page_url': 'http://rtlnow.rtl.de',\n                'player_url': 'http://cdn.static-fra.de/now/vodplayer.swf',\n                'tbr': int_or_none(item.get('bitrate')),\n            })\n        self._sort_formats(formats)\n\n        title = info['title']\n        description = info.get('articleLong') or info.get('articleShort')\n        timestamp = parse_iso8601(info.get('broadcastStartDate'), ' ')\n        duration = parse_duration(info.get('duration'))\n\n        f = info.get('format', {})\n        thumbnail = f.get('defaultImage169Format') or f.get('defaultImage169Logo')\n\n        return {\n            'id': video_id,\n            'display_id': display_id or info.get('seoUrl'),\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 24,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowtv.NowTVIE._real_extract#199",
        "src_path": "youtube_dl/extractor/nowtv.py",
        "class_name": "youtube_dl.extractor.nowtv.NowTVIE",
        "signature": "youtube_dl.extractor.nowtv.NowTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = '%s/%s' % (mobj.group('show_id'), mobj.group('id'))\n\n        info = self._download_json(\n            'https://api.nowtv.de/v3/movies/%s?fields=%s'\n            % (display_id, ','.join(self._VIDEO_FIELDS)), display_id)\n\n        return self._extract_video(info, display_id)",
        "begin_line": 199,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nowtv.NowTVListIE._real_extract#232",
        "src_path": "youtube_dl/extractor/nowtv.py",
        "class_name": "youtube_dl.extractor.nowtv.NowTVListIE",
        "signature": "youtube_dl.extractor.nowtv.NowTVListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_id = mobj.group('show_id')\n        season_id = mobj.group('id')\n\n        fields = []\n        fields.extend(self._SHOW_FIELDS)\n        fields.extend('formatTabs.%s' % field for field in self._SEASON_FIELDS)\n        fields.extend(\n            'formatTabs.formatTabPages.container.movies.%s' % field\n            for field in self._VIDEO_FIELDS)\n\n        list_info = self._download_json(\n            'https://api.nowtv.de/v3/formats/seo?fields=%s&name=%s.php'\n            % (','.join(fields), show_id),\n            season_id)\n\n        season = next(\n            season for season in list_info['formatTabs']['items']\n            if season.get('seoheadline') == season_id)\n\n        title = '%s - %s' % (list_info['title'], season['headline'])\n\n        entries = []\n        for container in season['formatTabPages']['items']:\n            for info in ((container.get('container') or {}).get('movies') or {}).get('items') or []:\n                entries.append(self._extract_video(info))\n\n        return self.playlist_result(\n            entries, compat_str(season.get('id') or season_id), title)",
        "begin_line": 232,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.noz.NozIE._real_extract#31",
        "src_path": "youtube_dl/extractor/noz.py",
        "class_name": "youtube_dl.extractor.noz.NozIE",
        "signature": "youtube_dl.extractor.noz.NozIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        description = self._og_search_description(webpage)\n\n        edge_url = self._html_search_regex(\n            r'<script\\s+(?:type=\"text/javascript\"\\s+)?src=\"(.*?/videojs_.*?)\"',\n            webpage, 'edge URL')\n        edge_content = self._download_webpage(edge_url, 'meta configuration')\n\n        config_url_encoded = self._search_regex(\n            r'so\\.addVariable\\(\"config_url\",\"[^,]*,(.*?)\"',\n            edge_content, 'config URL'\n        )\n        config_url = compat_urllib_parse_unquote(config_url_encoded)\n\n        doc = self._download_xml(config_url, 'video configuration')\n        title = xpath_text(doc, './/title')\n        thumbnail = xpath_text(doc, './/article/thumbnail/url')\n        duration = int_or_none(xpath_text(\n            doc, './/article/movie/file/duration'))\n        formats = []\n        for qnode in doc.findall(compat_xpath('.//article/movie/file/qualities/qual')):\n            http_url_ele = find_xpath_attr(\n                qnode, './html_urls/video_url', 'format', 'video/mp4')\n            http_url = http_url_ele.text if http_url_ele is not None else None\n            if http_url:\n                formats.append({\n                    'url': http_url,\n                    'format_name': xpath_text(qnode, './name'),\n                    'format_id': '%s-%s' % ('http', xpath_text(qnode, './id')),\n                    'height': int_or_none(xpath_text(qnode, './height')),\n                    'width': int_or_none(xpath_text(qnode, './width')),\n                    'tbr': int_or_none(xpath_text(qnode, './bitrate'), scale=1000),\n                })\n            else:\n                f4m_url = xpath_text(qnode, 'url_hd2')\n                if f4m_url:\n                    formats.extend(self._extract_f4m_formats(\n                        update_url_query(f4m_url, {'hdcore': '3.4.0'}),\n                        video_id, f4m_id='hds', fatal=False))\n                m3u8_url_ele = find_xpath_attr(\n                    qnode, './html_urls/video_url',\n                    'format', 'application/vnd.apple.mpegurl')\n                m3u8_url = m3u8_url_ele.text if m3u8_url_ele is not None else None\n                if m3u8_url:\n                    formats.extend(self._extract_m3u8_formats(\n                        m3u8_url, video_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'duration': duration,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 31,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPOBaseIE._get_token#23",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOBaseIE",
        "signature": "youtube_dl.extractor.npo.NPOBaseIE._get_token(self, video_id)",
        "snippet": "    def _get_token(self, video_id):\n        return self._download_json(\n            'http://ida.omroep.nl/app.php/auth', video_id,\n            note='Downloading token')['token']",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._real_extract#161",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self._get_info(video_id)",
        "begin_line": 161,
        "end_line": 163,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._get_info#165",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._get_info(self, video_id)",
        "snippet": "    def _get_info(self, video_id):\n        metadata = self._download_json(\n            'http://e.omroep.nl/metadata/%s' % video_id,\n            video_id,\n            # We have to remove the javascript callback\n            transform_source=strip_jsonp,\n        )\n\n        # For some videos actual video id (prid) is different (e.g. for\n        # http://www.omroepwnl.nl/video/fragment/vandaag-de-dag-verkiezingen__POMS_WNL_853698\n        # video id is POMS_WNL_853698 but prid is POW_00996502)\n        video_id = metadata.get('prid') or video_id\n\n        # titel is too generic in some cases so utilize aflevering_titel as well\n        # when available (e.g. http://tegenlicht.vpro.nl/afleveringen/2014-2015/access-to-africa.html)\n        title = metadata['titel']\n        sub_title = metadata.get('aflevering_titel')\n        if sub_title and sub_title != title:\n            title += ': %s' % sub_title\n\n        token = self._get_token(video_id)\n\n        formats = []\n        urls = set()\n\n        quality = qualities(['adaptive', 'wmv_sb', 'h264_sb', 'wmv_bb', 'h264_bb', 'wvc1_std', 'h264_std'])\n        items = self._download_json(\n            'http://ida.omroep.nl/app.php/%s' % video_id, video_id,\n            'Downloading formats JSON', query={\n                'adaptive': 'yes',\n                'token': token,\n            })['items'][0]\n        for num, item in enumerate(items):\n            item_url = item.get('url')\n            if not item_url or item_url in urls:\n                continue\n            urls.add(item_url)\n            format_id = self._search_regex(\n                r'video/ida/([^/]+)', item_url, 'format id',\n                default=None)\n\n            def add_format_url(format_url):\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                })\n\n            # Example: http://www.npo.nl/de-nieuwe-mens-deel-1/21-07-2010/WO_VPRO_043706\n            if item.get('contentType') in ('url', 'audio'):\n                add_format_url(item_url)\n                continue\n\n            try:\n                stream_info = self._download_json(\n                    item_url + '&type=json', video_id,\n                    'Downloading %s stream JSON'\n                    % item.get('label') or item.get('format') or format_id or num)\n            except ExtractorError as ee:\n                if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404:\n                    error = (self._parse_json(\n                        ee.cause.read().decode(), video_id,\n                        fatal=False) or {}).get('errorstring')\n                    if error:\n                        raise ExtractorError(error, expected=True)\n                raise\n            # Stream URL instead of JSON, example: npo:LI_NL1_4188102\n            if isinstance(stream_info, compat_str):\n                if not stream_info.startswith('http'):\n                    continue\n                video_url = stream_info\n            # JSON\n            else:\n                video_url = stream_info.get('url')\n            if not video_url or video_url in urls:\n                continue\n            urls.add(item_url)\n            if determine_ext(video_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, ext='mp4',\n                    entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n            else:\n                add_format_url(video_url)\n\n        is_live = metadata.get('medium') == 'live'\n\n        if not is_live:\n            for num, stream in enumerate(metadata.get('streams', [])):\n                stream_url = stream.get('url')\n                if not stream_url or stream_url in urls:\n                    continue\n                urls.add(stream_url)\n                # smooth streaming is not supported\n                stream_type = stream.get('type', '').lower()\n                if stream_type in ['ss', 'ms']:\n                    continue\n                if stream_type == 'hds':\n                    f4m_formats = self._extract_f4m_formats(\n                        stream_url, video_id, fatal=False)\n                    # f4m downloader downloads only piece of live stream\n                    for f4m_format in f4m_formats:\n                        f4m_format['preference'] = -1\n                    formats.extend(f4m_formats)\n                elif stream_type == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        stream_url, video_id, ext='mp4', fatal=False))\n                # Example: http://www.npo.nl/de-nieuwe-mens-deel-1/21-07-2010/WO_VPRO_043706\n                elif '.asf' in stream_url:\n                    asx = self._download_xml(\n                        stream_url, video_id,\n                        'Downloading stream %d ASX playlist' % num,\n                        transform_source=fix_xml_ampersands, fatal=False)\n                    if not asx:\n                        continue\n                    ref = asx.find('./ENTRY/Ref')\n                    if ref is None:\n                        continue\n                    video_url = ref.get('href')\n                    if not video_url or video_url in urls:\n                        continue\n                    urls.add(video_url)\n                    formats.append({\n                        'url': video_url,\n                        'ext': stream.get('formaat', 'asf'),\n                        'quality': stream.get('kwaliteit'),\n                        'preference': -10,\n                    })\n                else:\n                    formats.append({\n                        'url': stream_url,\n                        'quality': stream.get('kwaliteit'),\n                    })\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        if metadata.get('tt888') == 'ja':\n            subtitles['nl'] = [{\n                'ext': 'vtt',\n                'url': 'http://tt888.omroep.nl/tt888/%s' % video_id,\n            }]\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': metadata.get('info'),\n            'thumbnail': metadata.get('images', [{'url': None}])[-1]['url'],\n            'upload_date': unified_strdate(metadata.get('gidsdatum')),\n            'duration': parse_duration(metadata.get('tijdsduur')),\n            'formats': formats,\n            'subtitles': subtitles,\n            'is_live': is_live,\n        }",
        "begin_line": 165,
        "end_line": 317,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPOLiveIE._real_extract#341",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOLiveIE",
        "signature": "youtube_dl.extractor.npo.NPOLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url) or 'npo-1'\n\n        webpage = self._download_webpage(url, display_id)\n\n        live_id = self._search_regex(\n            [r'media-id=\"([^\"]+)\"', r'data-prid=\"([^\"]+)\"'], webpage, 'live id')\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'npo:%s' % live_id,\n            'ie_key': NPOIE.ie_key(),\n            'id': live_id,\n            'display_id': display_id,\n        }",
        "begin_line": 341,
        "end_line": 355,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioIE._html_get_attribute_regex#376",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioIE",
        "signature": "youtube_dl.extractor.npo.NPORadioIE._html_get_attribute_regex(attribute)",
        "snippet": "    def _html_get_attribute_regex(attribute):\n        return r'{0}\\s*=\\s*\\'([^\\']+)\\''.format(attribute)",
        "begin_line": 376,
        "end_line": 377,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioIE._real_extract#379",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioIE",
        "signature": "youtube_dl.extractor.npo.NPORadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            self._html_get_attribute_regex('data-channel'), webpage, 'title')\n\n        stream = self._parse_json(\n            self._html_search_regex(self._html_get_attribute_regex('data-streams'), webpage, 'data-streams'),\n            video_id)\n\n        codec = stream.get('codec')\n\n        return {\n            'id': video_id,\n            'url': stream['url'],\n            'title': self._live_title(title),\n            'acodec': codec,\n            'ext': codec,\n            'is_live': True,\n        }",
        "begin_line": 379,
        "end_line": 400,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract#417",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPORadioFragmentIE",
        "signature": "youtube_dl.extractor.npo.NPORadioFragmentIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, audio_id)\n\n        title = self._html_search_regex(\n            r'href=\"/radio/[^/]+/fragment/%s\" title=\"([^\"]+)\"' % audio_id,\n            webpage, 'title')\n\n        audio_url = self._search_regex(\n            r\"data-streams='([^']+)'\", webpage, 'audio url')\n\n        return {\n            'id': audio_id,\n            'url': audio_url,\n            'title': title,\n        }",
        "begin_line": 417,
        "end_line": 433,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPODataMidEmbedIE._real_extract#437",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPODataMidEmbedIE",
        "signature": "youtube_dl.extractor.npo.NPODataMidEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_id = self._search_regex(\n            r'data-mid=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1', webpage, 'video_id', group='id')\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'NPO',\n            'url': 'npo:%s' % video_id,\n            'display_id': display_id\n        }",
        "begin_line": 437,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npo.NPOPlaylistBaseIE._real_extract#491",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOPlaylistBaseIE",
        "signature": "youtube_dl.extractor.npo.NPOPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('npo:%s' % video_id if not video_id.startswith('http') else video_id)\n            for video_id in orderedSet(re.findall(self._PLAYLIST_ENTRY_RE, webpage))\n        ]\n\n        playlist_title = self._html_search_regex(\n            self._PLAYLIST_TITLE_RE, webpage, 'playlist title',\n            default=None) or self._og_search_title(webpage)\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 491,
        "end_line": 505,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.npr.NprIE._real_extract#37",
        "src_path": "youtube_dl/extractor/npr.py",
        "class_name": "youtube_dl.extractor.npr.NprIE",
        "signature": "youtube_dl.extractor.npr.NprIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        config = self._download_json(\n            'http://api.npr.org/query?%s' % compat_urllib_parse_urlencode({\n                'id': playlist_id,\n                'fields': 'titles,audio,show',\n                'format': 'json',\n                'apiKey': 'MDAzMzQ2MjAyMDEyMzk4MTU1MDg3ZmM3MQ010',\n            }), playlist_id)\n\n        story = config['list']['story'][0]\n\n        KNOWN_FORMATS = ('threegp', 'mp4', 'mp3')\n        quality = qualities(KNOWN_FORMATS)\n\n        entries = []\n        for audio in story.get('audio', []):\n            title = audio.get('title', {}).get('$text')\n            duration = int_or_none(audio.get('duration', {}).get('$text'))\n            formats = []\n            for format_id, formats_entry in audio.get('format', {}).items():\n                if not formats_entry:\n                    continue\n                if isinstance(formats_entry, list):\n                    formats_entry = formats_entry[0]\n                format_url = formats_entry.get('$text')\n                if not format_url:\n                    continue\n                if format_id in KNOWN_FORMATS:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                        'ext': formats_entry.get('type'),\n                        'quality': quality(format_id),\n                    })\n            self._sort_formats(formats)\n            entries.append({\n                'id': audio['id'],\n                'title': title,\n                'duration': duration,\n                'formats': formats,\n            })\n\n        playlist_title = story.get('title', {}).get('$text')\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 37,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKBaseIE._real_extract#19",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKBaseIE",
        "signature": "youtube_dl.extractor.nrk.NRKBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'http://%s/mediaelement/%s' % (self._API_HOST, video_id),\n            video_id, 'Downloading mediaelement JSON')\n\n        title = data.get('fullTitle') or data.get('mainTitle') or data['title']\n        video_id = data.get('id') or video_id\n\n        entries = []\n\n        conviva = data.get('convivaStatistics') or {}\n        live = (data.get('mediaElementType') == 'Live' or\n                data.get('isLive') is True or conviva.get('isLive'))\n\n        def make_title(t):\n            return self._live_title(t) if live else t\n\n        media_assets = data.get('mediaAssets')\n        if media_assets and isinstance(media_assets, list):\n            def video_id_and_title(idx):\n                return ((video_id, title) if len(media_assets) == 1\n                        else ('%s-%d' % (video_id, idx), '%s (Part %d)' % (title, idx)))\n            for num, asset in enumerate(media_assets, 1):\n                asset_url = asset.get('url')\n                if not asset_url:\n                    continue\n                formats = self._extract_akamai_formats(asset_url, video_id)\n                if not formats:\n                    continue\n                self._sort_formats(formats)\n\n                # Some f4m streams may not work with hdcore in fragments' URLs\n                for f in formats:\n                    extra_param = f.get('extra_param_to_segment_url')\n                    if extra_param and 'hdcore' in extra_param:\n                        del f['extra_param_to_segment_url']\n\n                entry_id, entry_title = video_id_and_title(num)\n                duration = parse_duration(asset.get('duration'))\n                subtitles = {}\n                for subtitle in ('webVtt', 'timedText'):\n                    subtitle_url = asset.get('%sSubtitlesUrl' % subtitle)\n                    if subtitle_url:\n                        subtitles.setdefault('no', []).append({\n                            'url': compat_urllib_parse_unquote(subtitle_url)\n                        })\n                entries.append({\n                    'id': asset.get('carrierId') or entry_id,\n                    'title': make_title(entry_title),\n                    'duration': duration,\n                    'subtitles': subtitles,\n                    'formats': formats,\n                })\n\n        if not entries:\n            media_url = data.get('mediaUrl')\n            if media_url:\n                formats = self._extract_akamai_formats(media_url, video_id)\n                self._sort_formats(formats)\n                duration = parse_duration(data.get('duration'))\n                entries = [{\n                    'id': video_id,\n                    'title': make_title(title),\n                    'duration': duration,\n                    'formats': formats,\n                }]\n\n        if not entries:\n            MESSAGES = {\n                'ProgramRightsAreNotReady': 'Du kan dessverre ikke se eller h\u00f8re programmet',\n                'ProgramRightsHasExpired': 'Programmet har g\u00e5tt ut',\n                'ProgramIsGeoBlocked': 'NRK har ikke rettigheter til \u00e5 vise dette programmet utenfor Norge',\n            }\n            message_type = data.get('messageType', '')\n            # Can be ProgramIsGeoBlocked or ChannelIsGeoBlocked*\n            if 'IsGeoBlocked' in message_type:\n                self.raise_geo_restricted(\n                    msg=MESSAGES.get('ProgramIsGeoBlocked'),\n                    countries=self._GEO_COUNTRIES)\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, MESSAGES.get(\n                    message_type, message_type)),\n                expected=True)\n\n        series = conviva.get('seriesName') or data.get('seriesTitle')\n        episode = conviva.get('episodeName') or data.get('episodeNumberOrDate')\n\n        season_number = None\n        episode_number = None\n        if data.get('mediaElementType') == 'Episode':\n            _season_episode = data.get('scoresStatistics', {}).get('springStreamStream') or \\\n                data.get('relativeOriginUrl', '')\n            EPISODENUM_RE = [\n                r'/s(?P<season>\\d{,2})e(?P<episode>\\d{,2})\\.',\n                r'/sesong-(?P<season>\\d{,2})/episode-(?P<episode>\\d{,2})',\n            ]\n            season_number = int_or_none(self._search_regex(\n                EPISODENUM_RE, _season_episode, 'season number',\n                default=None, group='season'))\n            episode_number = int_or_none(self._search_regex(\n                EPISODENUM_RE, _season_episode, 'episode number',\n                default=None, group='episode'))\n\n        thumbnails = None\n        images = data.get('images')\n        if images and isinstance(images, dict):\n            web_images = images.get('webImages')\n            if isinstance(web_images, list):\n                thumbnails = [{\n                    'url': image['imageUrl'],\n                    'width': int_or_none(image.get('width')),\n                    'height': int_or_none(image.get('height')),\n                } for image in web_images if image.get('imageUrl')]\n\n        description = data.get('description')\n        category = data.get('mediaAnalytics', {}).get('category')\n\n        common_info = {\n            'description': description,\n            'series': series,\n            'episode': episode,\n            'season_number': season_number,\n            'episode_number': episode_number,\n            'categories': [category] if category else None,\n            'age_limit': parse_age_limit(data.get('legalAge')),\n            'thumbnails': thumbnails,\n        }\n\n        vcodec = 'none' if data.get('mediaType') == 'Audio' else None\n\n        for entry in entries:\n            entry.update(common_info)\n            for f in entry['formats']:\n                f['vcodec'] = vcodec\n\n        points = data.get('shortIndexPoints')\n        if isinstance(points, list):\n            chapters = []\n            for next_num, point in enumerate(points, start=1):\n                if not isinstance(point, dict):\n                    continue\n                start_time = parse_duration(point.get('startPoint'))\n                if start_time is None:\n                    continue\n                end_time = parse_duration(\n                    data.get('duration')\n                    if next_num == len(points)\n                    else points[next_num].get('startPoint'))\n                if end_time is None:\n                    continue\n                chapters.append({\n                    'start_time': start_time,\n                    'end_time': end_time,\n                    'title': point.get('title'),\n                })\n            if chapters and len(entries) == 1:\n                entries[0]['chapters'] = chapters\n\n        return self.playlist_result(entries, video_id, title, description)",
        "begin_line": 19,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE._extract_description#367",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE",
        "signature": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE._extract_description(self, webpage)",
        "snippet": "    def _extract_description(self, webpage):\n        pass",
        "begin_line": 367,
        "end_line": 368,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE._real_extract#370",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE",
        "signature": "youtube_dl.extractor.nrk.NRKPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('nrk:%s' % video_id, NRKIE.ie_key())\n            for video_id in re.findall(self._ITEM_RE, webpage)\n        ]\n\n        playlist_title = self. _extract_title(webpage)\n        playlist_description = self._extract_description(webpage)\n\n        return self.playlist_result(\n            entries, playlist_id, playlist_title, playlist_description)",
        "begin_line": 370,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKPlaylistIE._extract_title#408",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKPlaylistIE",
        "signature": "youtube_dl.extractor.nrk.NRKPlaylistIE._extract_title(self, webpage)",
        "snippet": "    def _extract_title(self, webpage):\n        return self._og_search_title(webpage, fatal=False)",
        "begin_line": 408,
        "end_line": 409,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKPlaylistIE._extract_description#411",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKPlaylistIE",
        "signature": "youtube_dl.extractor.nrk.NRKPlaylistIE._extract_description(self, webpage)",
        "snippet": "    def _extract_description(self, webpage):\n        return self._og_search_description(webpage)",
        "begin_line": 411,
        "end_line": 412,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVEpisodesIE._extract_title#427",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVEpisodesIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVEpisodesIE._extract_title(self, webpage)",
        "snippet": "    def _extract_title(self, webpage):\n        return self._html_search_regex(\n            r'<h1>([^<]+)</h1>', webpage, 'title', fatal=False)",
        "begin_line": 427,
        "end_line": 429,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVSeriesIE.suitable#463",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVSeriesIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVSeriesIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if NRKTVIE.suitable(url) else super(NRKTVSeriesIE, cls).suitable(url)",
        "begin_line": 463,
        "end_line": 464,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVSeriesIE._real_extract#466",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVSeriesIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        series_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, series_id)\n\n        entries = [\n            self.url_result(\n                'https://tv.nrk.no/program/Episodes/{series}/{season}'.format(\n                    series=series_id, season=season_id))\n            for season_id in re.findall(self._ITEM_RE, webpage)\n        ]\n\n        title = self._html_search_meta(\n            'seriestitle', webpage,\n            'title', default=None) or self._og_search_title(\n            webpage, fatal=False)\n\n        description = self._html_search_meta(\n            'series_description', webpage,\n            'description', default=None) or self._og_search_description(webpage)\n\n        return self.playlist_result(entries, series_id, title, description)",
        "begin_line": 466,
        "end_line": 487,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKSkoleIE._real_extract#509",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKSkoleIE",
        "signature": "youtube_dl.extractor.nrk.NRKSkoleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://mimir.nrk.no/plugin/1.0/static?mediaId=%s' % video_id,\n            video_id)\n\n        nrk_id = self._parse_json(\n            self._search_regex(\n                r'<script[^>]+type=[\"\\']application/json[\"\\'][^>]*>({.+?})</script>',\n                webpage, 'application json'),\n            video_id)['activeMedia']['psId']\n\n        return self.url_result('nrk:%s' % nrk_id)",
        "begin_line": 509,
        "end_line": 522,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ntvde.NTVDeIE._real_extract#35",
        "src_path": "youtube_dl/extractor/ntvde.py",
        "class_name": "youtube_dl.extractor.ntvde.NTVDeIE",
        "signature": "youtube_dl.extractor.ntvde.NTVDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        info = self._parse_json(self._search_regex(\n            r'(?s)ntv\\.pageInfo\\.article\\s*=\\s*(\\{.*?\\});', webpage, 'info'),\n            video_id, transform_source=js_to_json)\n        timestamp = int_or_none(info.get('publishedDateAsUnixTimeStamp'))\n        vdata = self._parse_json(self._search_regex(\n            r'(?s)\\$\\(\\s*\"\\#player\"\\s*\\)\\s*\\.data\\(\\s*\"player\",\\s*(\\{.*?\\})\\);',\n            webpage, 'player data'), video_id,\n            transform_source=lambda s: js_to_json(re.sub(r'advertising:\\s*{[^}]+},', '', s)))\n        duration = parse_duration(vdata.get('duration'))\n\n        formats = []\n        if vdata.get('video'):\n            formats.append({\n                'format_id': 'flash',\n                'url': 'rtmp://fms.n-tv.de/%s' % vdata['video'],\n            })\n        if vdata.get('videoMp4'):\n            formats.append({\n                'format_id': 'mobile',\n                'url': compat_urlparse.urljoin('http://video.n-tv.de', vdata['videoMp4']),\n                'tbr': 400,  # estimation\n            })\n        if vdata.get('videoM3u8'):\n            m3u8_url = compat_urlparse.urljoin('http://video.n-tv.de', vdata['videoM3u8'])\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, ext='mp4', entry_protocol='m3u8_native',\n                preference=0, m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['headline'],\n            'description': info.get('intro'),\n            'alt_title': info.get('kicker'),\n            'timestamp': timestamp,\n            'thumbnail': vdata.get('html5VideoPoster'),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 35,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ntvru.NTVRuIE._real_extract#79",
        "src_path": "youtube_dl/extractor/ntvru.py",
        "class_name": "youtube_dl.extractor.ntvru.NTVRuIE",
        "signature": "youtube_dl.extractor.ntvru.NTVRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._og_search_property(\n            ('video', 'video:iframe'), webpage, default=None)\n        if video_url:\n            video_id = self._search_regex(\n                r'https?://(?:www\\.)?ntv\\.ru/video/(?:embed/)?(\\d+)',\n                video_url, 'video id', default=None)\n\n        if not video_id:\n            video_id = self._html_search_regex(\n                self._VIDEO_ID_REGEXES, webpage, 'video id')\n\n        player = self._download_xml(\n            'http://www.ntv.ru/vi%s/' % video_id,\n            video_id, 'Downloading video XML')\n\n        title = clean_html(xpath_text(player, './data/title', 'title', fatal=True))\n        description = clean_html(xpath_text(player, './data/description', 'description'))\n\n        video = player.find('./data/video')\n        video_id = xpath_text(video, './id', 'video id')\n        thumbnail = xpath_text(video, './splash', 'thumbnail')\n        duration = int_or_none(xpath_text(video, './totaltime', 'duration'))\n        view_count = int_or_none(xpath_text(video, './views', 'view count'))\n\n        token = self._download_webpage(\n            'http://stat.ntv.ru/services/access/token',\n            video_id, 'Downloading access token')\n\n        formats = []\n        for format_id in ['', 'hi', 'webm']:\n            file_ = video.find('./%sfile' % format_id)\n            if file_ is None:\n                continue\n            size = video.find('./%ssize' % format_id)\n            formats.append({\n                'url': 'http://media2.ntv.ru/vod/%s&tok=%s' % (file_.text, token),\n                'filesize': int_or_none(size.text if size is not None else None),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 79,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nuevo.NuevoBaseIE._extract_nuevo#13",
        "src_path": "youtube_dl/extractor/nuevo.py",
        "class_name": "youtube_dl.extractor.nuevo.NuevoBaseIE",
        "signature": "youtube_dl.extractor.nuevo.NuevoBaseIE._extract_nuevo(self, config_url, video_id, headers={})",
        "snippet": "    def _extract_nuevo(self, config_url, video_id, headers={}):\n        config = self._download_xml(\n            config_url, video_id, transform_source=lambda s: s.strip(),\n            headers=headers)\n\n        title = xpath_text(config, './title', 'title', fatal=True).strip()\n        video_id = xpath_text(config, './mediaid', default=video_id)\n        thumbnail = xpath_text(config, ['./image', './thumb'])\n        duration = float_or_none(xpath_text(config, './duration'))\n\n        formats = []\n        for element_name, format_id in (('file', 'sd'), ('filehd', 'hd')):\n            video_url = xpath_text(config, element_name)\n            if video_url:\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                })\n        self._check_formats(formats, video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 13,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nuvid.NuvidIE._real_extract#25",
        "src_path": "youtube_dl/extractor/nuvid.py",
        "class_name": "youtube_dl.extractor.nuvid.NuvidIE",
        "signature": "youtube_dl.extractor.nuvid.NuvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        page_url = 'http://m.nuvid.com/video/%s' % video_id\n        webpage = self._download_webpage(\n            page_url, video_id, 'Downloading video page')\n        # When dwnld_speed exists and has a value larger than the MP4 file's\n        # bitrate, Nuvid returns the MP4 URL\n        # It's unit is 100bytes/millisecond, see mobile-nuvid-min.js for the algorithm\n        self._set_cookie('nuvid.com', 'dwnld_speed', '10.0')\n        mp4_webpage = self._download_webpage(\n            page_url, video_id, 'Downloading video page for MP4 format')\n\n        html5_video_re = r'(?s)<(?:video|audio)[^<]*(?:>.*?<source[^>]*)?\\s+src=[\"\\'](.*?)[\"\\']',\n        video_url = self._html_search_regex(html5_video_re, webpage, video_id)\n        mp4_video_url = self._html_search_regex(html5_video_re, mp4_webpage, video_id)\n        formats = [{\n            'url': video_url,\n        }]\n        if mp4_video_url != video_url:\n            formats.append({\n                'url': mp4_video_url,\n            })\n\n        title = self._html_search_regex(\n            [r'<span title=\"([^\"]+)\">',\n             r'<div class=\"thumb-holder video\">\\s*<h5[^>]*>([^<]+)</h5>',\n             r'<span[^>]+class=\"title_thumb\">([^<]+)</span>'], webpage, 'title').strip()\n        thumbnails = [\n            {\n                'url': thumb_url,\n            } for thumb_url in re.findall(r'<img src=\"([^\"]+)\" alt=\"\" />', webpage)\n        ]\n        thumbnail = thumbnails[0]['url'] if thumbnails else None\n        duration = parse_duration(self._html_search_regex(\n            [r'<i class=\"fa fa-clock-o\"></i>\\s*(\\d{2}:\\d{2})',\n             r'<span[^>]+class=\"view_time\">([^<]+)</span>'], webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id#23",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesBaseIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesBaseIE._extract_video_from_id(self, video_id)",
        "snippet": "    def _extract_video_from_id(self, video_id):\n        # Authorization generation algorithm is reverse engineered from `signer` in\n        # http://graphics8.nytimes.com/video/vhs/vhs-2.x.min.js\n        path = '/svc/video/api/v3/video/' + video_id\n        hm = hmac.new(self._SECRET, (path + ':vhs').encode(), hashlib.sha512).hexdigest()\n        video_data = self._download_json('http://www.nytimes.com' + path, video_id, 'Downloading video JSON', headers={\n            'Authorization': 'NYTV ' + base64.b64encode(hm.encode()).decode(),\n            'X-NYTV': 'vhs',\n        }, fatal=False)\n        if not video_data:\n            video_data = self._download_json(\n                'http://www.nytimes.com/svc/video/api/v2/video/' + video_id,\n                video_id, 'Downloading video JSON')\n\n        title = video_data['headline']\n\n        def get_file_size(file_size):\n            if isinstance(file_size, int):\n                return file_size\n            elif isinstance(file_size, dict):\n                return int(file_size.get('value', 0))\n            else:\n                return None\n\n        urls = []\n        formats = []\n        for video in video_data.get('renditions', []):\n            video_url = video.get('url')\n            format_id = video.get('type')\n            if not video_url or format_id == 'thumbs' or video_url in urls:\n                continue\n            urls.append(video_url)\n            ext = mimetype2ext(video.get('mimetype')) or determine_ext(video_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=format_id or 'hls', fatal=False))\n            elif ext == 'mpd':\n                continue\n            #     formats.extend(self._extract_mpd_formats(\n            #         video_url, video_id, format_id or 'dash', fatal=False))\n            else:\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'vcodec': video.get('videoencoding') or video.get('video_codec'),\n                    'width': int_or_none(video.get('width')),\n                    'height': int_or_none(video.get('height')),\n                    'filesize': get_file_size(video.get('file_size') or video.get('fileSize')),\n                    'tbr': int_or_none(video.get('bitrate'), 1000),\n                    'ext': ext,\n                })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for image in video_data.get('images', []):\n            image_url = image.get('url')\n            if not image_url:\n                continue\n            thumbnails.append({\n                'url': 'http://www.nytimes.com/' + image_url,\n                'width': int_or_none(image.get('width')),\n                'height': int_or_none(image.get('height')),\n            })\n\n        publication_date = video_data.get('publication_date')\n        timestamp = parse_iso8601(publication_date[:-8]) if publication_date else None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('summary'),\n            'timestamp': timestamp,\n            'uploader': video_data.get('byline'),\n            'duration': float_or_none(video_data.get('duration'), 1000),\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 23,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract#124",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        return self._extract_video_from_id(video_id)",
        "begin_line": 124,
        "end_line": 127,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesArticleIE._extract_podcast_from_json#175",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesArticleIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesArticleIE._extract_podcast_from_json(self, json, page_id, webpage)",
        "snippet": "    def _extract_podcast_from_json(self, json, page_id, webpage):\n        podcast_audio = self._parse_json(\n            json, page_id, transform_source=js_to_json)\n\n        audio_data = podcast_audio['data']\n        track = audio_data['track']\n\n        episode_title = track['title']\n        video_url = track['source']\n\n        description = track.get('description') or self._html_search_meta(\n            ['og:description', 'twitter:description'], webpage)\n\n        podcast_title = audio_data.get('podcast', {}).get('title')\n        title = ('%s: %s' % (podcast_title, episode_title)\n                 if podcast_title else episode_title)\n\n        episode = audio_data.get('podcast', {}).get('episode') or ''\n        episode_number = int_or_none(self._search_regex(\n            r'[Ee]pisode\\s+(\\d+)', episode, 'episode number', default=None))\n\n        return {\n            'id': remove_start(podcast_audio.get('target'), 'FT') or page_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'creator': track.get('credit'),\n            'series': podcast_title,\n            'episode': episode_title,\n            'episode_number': episode_number,\n            'duration': int_or_none(track.get('duration')),\n        }",
        "begin_line": 175,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesArticleIE._real_extract#208",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesArticleIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, page_id)\n\n        video_id = self._search_regex(\n            r'data-videoid=[\"\\'](\\d+)', webpage, 'video id',\n            default=None, fatal=False)\n        if video_id is not None:\n            return self._extract_video_from_id(video_id)\n\n        podcast_data = self._search_regex(\n            (r'NYTD\\.FlexTypes\\.push\\s*\\(\\s*({.+?})\\s*\\)\\s*;\\s*</script',\n             r'NYTD\\.FlexTypes\\.push\\s*\\(\\s*({.+})\\s*\\)\\s*;'),\n            webpage, 'podcast data')\n        return self._extract_podcast_from_json(podcast_data, page_id, webpage)",
        "begin_line": 208,
        "end_line": 223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.nzz.NZZIE._real_extract#22",
        "src_path": "youtube_dl/extractor/nzz.py",
        "class_name": "youtube_dl.extractor.nzz.NZZIE",
        "signature": "youtube_dl.extractor.nzz.NZZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n\n        entries = []\n        for player_element in re.findall(r'(<[^>]+class=\"kalturaPlayer\"[^>]*>)', webpage):\n            player_params = extract_attributes(player_element)\n            if player_params.get('data-type') not in ('kaltura_singleArticle',):\n                self.report_warning('Unsupported player type')\n                continue\n            entry_id = player_params['data-id']\n            entries.append(self.url_result(\n                'kaltura:1750922:' + entry_id, 'Kaltura', entry_id))\n\n        return self.playlist_result(entries, page_id)",
        "begin_line": 22,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.odatv.OdaTVIE._real_extract#32",
        "src_path": "youtube_dl/extractor/odatv.py",
        "class_name": "youtube_dl.extractor.odatv.OdaTVIE",
        "signature": "youtube_dl.extractor.odatv.OdaTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        no_video = 'NO VIDEO!' in webpage\n\n        video_url = self._search_regex(\n            r'mp4\\s*:\\s*([\"\\'])(?P<url>http.+?)\\1', webpage, 'video url',\n            default=None if no_video else NO_DEFAULT, group='url')\n\n        if no_video:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': remove_start(self._og_search_title(webpage), 'Video: '),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 32,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE._real_extract#103",
        "src_path": "youtube_dl/extractor/odnoklassniki.py",
        "class_name": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE",
        "signature": "youtube_dl.extractor.odnoklassniki.OdnoklassnikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        start_time = int_or_none(compat_parse_qs(\n            compat_urllib_parse_urlparse(url).query).get('fromTime', [None])[0])\n\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://ok.ru/video/%s' % video_id, video_id)\n\n        error = self._search_regex(\n            r'[^>]+class=\"vp_video_stub_txt\"[^>]*>([^<]+)<',\n            webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(error, expected=True)\n\n        player = self._parse_json(\n            unescapeHTML(self._search_regex(\n                r'data-options=(?P<quote>[\"\\'])(?P<player>{.+?%s.+?})(?P=quote)' % video_id,\n                webpage, 'player', group='player')),\n            video_id)\n\n        flashvars = player['flashvars']\n\n        metadata = flashvars.get('metadata')\n        if metadata:\n            metadata = self._parse_json(metadata, video_id)\n        else:\n            metadata = self._download_json(\n                compat_urllib_parse_unquote(flashvars['metadataUrl']),\n                video_id, 'Downloading metadata JSON')\n\n        movie = metadata['movie']\n\n        # Some embedded videos may not contain title in movie dict (e.g.\n        # http://ok.ru/video/62036049272859-0) thus we allow missing title\n        # here and it's going to be extracted later by an extractor that\n        # will process the actual embed.\n        provider = metadata.get('provider')\n        title = movie['title'] if provider == 'UPLOADED_ODKL' else movie.get('title')\n\n        thumbnail = movie.get('poster')\n        duration = int_or_none(movie.get('duration'))\n\n        author = metadata.get('author', {})\n        uploader_id = author.get('id')\n        uploader = author.get('name')\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'ya:ovs:upload_date', webpage, 'upload date', default=None))\n\n        age_limit = None\n        adult = self._html_search_meta(\n            'ya:ovs:adult', webpage, 'age limit', default=None)\n        if adult:\n            age_limit = 18 if adult == 'true' else 0\n\n        like_count = int_or_none(metadata.get('likeCount'))\n\n        info = {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'like_count': like_count,\n            'age_limit': age_limit,\n            'start_time': start_time,\n        }\n\n        if provider == 'USER_YOUTUBE':\n            info.update({\n                '_type': 'url_transparent',\n                'url': movie['contentId'],\n            })\n            return info\n\n        quality = qualities(('4', '0', '1', '2', '3', '5'))\n\n        formats = [{\n            'url': f['url'],\n            'ext': 'mp4',\n            'format_id': f['name'],\n        } for f in metadata['videos']]\n\n        m3u8_url = metadata.get('hlsManifestUrl')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        dash_manifest = metadata.get('metadataEmbedded')\n        if dash_manifest:\n            formats.extend(self._parse_mpd_formats(\n                compat_etree_fromstring(dash_manifest), 'mpd'))\n\n        for fmt in formats:\n            fmt_type = self._search_regex(\n                r'\\btype[/=](\\d)', fmt['url'],\n                'format type', default=None)\n            if fmt_type:\n                fmt['quality'] = quality(fmt_type)\n\n        self._sort_formats(formats)\n\n        info['formats'] = formats\n        return info",
        "begin_line": 103,
        "end_line": 210,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/oktoberfesttv.py",
        "class_name": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE",
        "signature": "youtube_dl.extractor.oktoberfesttv.OktoberfestTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._live_title(self._html_search_regex(\n            r'<h1><strong>.*?</strong>(.*?)</h1>', webpage, 'title'))\n\n        clip = self._search_regex(\n            r\"clip:\\s*\\{\\s*url:\\s*'([^']+)'\", webpage, 'clip')\n        ncurl = self._search_regex(\n            r\"netConnectionUrl:\\s*'([^']+)'\", webpage, 'rtmp base')\n        video_url = ncurl + clip\n        thumbnail = self._search_regex(\n            r\"canvas:\\s*\\{\\s*backgroundImage:\\s*'url\\(([^)]+)\\)'\", webpage,\n            'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'is_live': True,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.once.OnceIE._extract_once_formats#14",
        "src_path": "youtube_dl/extractor/once.py",
        "class_name": "youtube_dl.extractor.once.OnceIE",
        "signature": "youtube_dl.extractor.once.OnceIE._extract_once_formats(self, url)",
        "snippet": "    def _extract_once_formats(self, url):\n        domain_id, application_id, media_item_id = re.match(\n            OnceIE._VALID_URL, url).groups()\n        formats = self._extract_m3u8_formats(\n            self.ADAPTIVE_URL_TEMPLATE % (\n                domain_id, application_id, media_item_id),\n            media_item_id, 'mp4', m3u8_id='hls', fatal=False)\n        progressive_formats = []\n        for adaptive_format in formats:\n            # Prevent advertisement from embedding into m3u8 playlist (see\n            # https://github.com/rg3/youtube-dl/issues/8893#issuecomment-199912684)\n            adaptive_format['url'] = re.sub(\n                r'\\badsegmentlength=\\d+', r'adsegmentlength=0', adaptive_format['url'])\n            rendition_id = self._search_regex(\n                r'/now/media/playlist/[^/]+/[^/]+/([^/]+)',\n                adaptive_format['url'], 'redition id', default=None)\n            if rendition_id:\n                progressive_format = adaptive_format.copy()\n                progressive_format.update({\n                    'url': self.PROGRESSIVE_URL_TEMPLATE % (\n                        domain_id, application_id, rendition_id, media_item_id),\n                    'format_id': adaptive_format['format_id'].replace(\n                        'hls', 'http'),\n                    'protocol': 'http',\n                })\n                progressive_formats.append(progressive_format)\n        self._check_formats(progressive_formats, media_item_id)\n        formats.extend(progressive_formats)\n        return formats",
        "begin_line": 14,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ondemandkorea.OnDemandKoreaIE._real_extract#27",
        "src_path": "youtube_dl/extractor/ondemandkorea.py",
        "class_name": "youtube_dl.extractor.ondemandkorea.OnDemandKoreaIE",
        "signature": "youtube_dl.extractor.ondemandkorea.OnDemandKoreaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id, fatal=False)\n\n        if not webpage:\n            # Page sometimes returns captcha page with HTTP 403\n            raise ExtractorError(\n                'Unable to access page. You may have been blocked.',\n                expected=True)\n\n        if 'msg_block_01.png' in webpage:\n            self.raise_geo_restricted(\n                msg='This content is not available in your region',\n                countries=self._GEO_COUNTRIES)\n\n        if 'This video is only available to ODK PLUS members.' in webpage:\n            raise ExtractorError(\n                'This video is only available to ODK PLUS members.',\n                expected=True)\n\n        title = self._og_search_title(webpage)\n\n        jw_config = self._parse_json(\n            self._search_regex(\n                r'(?s)jwplayer\\(([\\'\"])(?:(?!\\1).)+\\1\\)\\.setup\\s*\\((?P<options>.+?)\\);',\n                webpage, 'jw config', group='options'),\n            video_id, transform_source=js_to_json)\n        info = self._parse_jwplayer_data(\n            jw_config, video_id, require_title=False, m3u8_id='hls',\n            base_url=url)\n\n        info.update({\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        })\n        return info",
        "begin_line": 27,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetBaseIE._search_mvp_id#23",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetBaseIE",
        "signature": "youtube_dl.extractor.onet.OnetBaseIE._search_mvp_id(self, webpage)",
        "snippet": "    def _search_mvp_id(self, webpage):\n        return self._search_regex(\n            r'id=([\"\\'])mvp:(?P<id>.+?)\\1', webpage, 'mvp id', group='id')",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetBaseIE._extract_from_id#27",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetBaseIE",
        "signature": "youtube_dl.extractor.onet.OnetBaseIE._extract_from_id(self, video_id, webpage=None)",
        "snippet": "    def _extract_from_id(self, video_id, webpage=None):\n        response = self._download_json(\n            'http://qi.ckm.onetapi.pl/', video_id,\n            query={\n                'body[id]': video_id,\n                'body[jsonrpc]': '2.0',\n                'body[method]': 'get_asset_detail',\n                'body[params][ID_Publikacji]': video_id,\n                'body[params][Service]': 'www.onet.pl',\n                'content-type': 'application/jsonp',\n                'x-onet-app': 'player.front.onetapi.pl',\n            })\n\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, error['message']), expected=True)\n\n        video = response['result'].get('0')\n\n        formats = []\n        for _, formats_dict in video['formats'].items():\n            if not isinstance(formats_dict, dict):\n                continue\n            for format_id, format_list in formats_dict.items():\n                if not isinstance(format_list, list):\n                    continue\n                for f in format_list:\n                    video_url = f.get('url')\n                    if not video_url:\n                        continue\n                    ext = determine_ext(video_url)\n                    if format_id == 'ism':\n                        formats.extend(self._extract_ism_formats(\n                            video_url, video_id, 'mss', fatal=False))\n                    elif ext == 'mpd':\n                        formats.extend(self._extract_mpd_formats(\n                            video_url, video_id, mpd_id='dash', fatal=False))\n                    else:\n                        formats.append({\n                            'url': video_url,\n                            'format_id': format_id,\n                            'height': int_or_none(f.get('vertical_resolution')),\n                            'width': int_or_none(f.get('horizontal_resolution')),\n                            'abr': float_or_none(f.get('audio_bitrate')),\n                            'vbr': float_or_none(f.get('video_bitrate')),\n                        })\n        self._sort_formats(formats)\n\n        meta = video.get('meta', {})\n\n        title = (self._og_search_title(\n            webpage, default=None) if webpage else None) or meta['title']\n        description = (self._og_search_description(\n            webpage, default=None) if webpage else None) or meta.get('description')\n        duration = meta.get('length') or meta.get('lenght')\n        timestamp = parse_iso8601(meta.get('addDate'), ' ')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetMVPIE._real_extract#103",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetMVPIE",
        "signature": "youtube_dl.extractor.onet.OnetMVPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_from_id(self._match_id(url))",
        "begin_line": 103,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetIE._real_extract#125",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetIE",
        "signature": "youtube_dl.extractor.onet.OnetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id, video_id = mobj.group('display_id', 'id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        mvp_id = self._search_mvp_id(webpage)\n\n        info_dict = self._extract_from_id(mvp_id, webpage)\n        info_dict.update({\n            'id': video_id,\n            'display_id': display_id,\n        })\n\n        return info_dict",
        "begin_line": 125,
        "end_line": 139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetChannelIE._real_extract#156",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetChannelIE",
        "signature": "youtube_dl.extractor.onet.OnetChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, channel_id)\n\n        current_clip_info = self._parse_json(self._search_regex(\n            r'var\\s+currentClip\\s*=\\s*({[^}]+})', webpage, 'video info'), channel_id,\n            transform_source=lambda s: js_to_json(re.sub(r'\\'\\s*\\+\\s*\\'', '', s)))\n        video_id = remove_start(current_clip_info['ckmId'], 'mvp:')\n        video_name = url_basename(current_clip_info['url'])\n\n        if self._downloader.params.get('noplaylist'):\n            self.to_screen(\n                'Downloading just video %s because of --no-playlist' % video_name)\n            return self._extract_from_id(video_id, webpage)\n\n        self.to_screen(\n            'Downloading channel %s - add --no-playlist to just download video %s' % (\n                channel_id, video_name))\n        matches = re.findall(\n            r'<a[^>]+href=[\\'\"](https?://(?:www\\.)?onet\\.tv/[a-z]/[a-z]+/[0-9a-z-]+/[0-9a-z]+)',\n            webpage)\n        entries = [\n            self.url_result(video_link, OnetIE.ie_key())\n            for video_link in matches]\n\n        channel_title = strip_or_none(get_element_by_class('o_channelName', webpage))\n        channel_description = strip_or_none(get_element_by_class('o_channelDesc', webpage))\n        return self.playlist_result(entries, channel_id, channel_title, channel_description)",
        "begin_line": 156,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetPlIE._search_mvp_id#229",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetPlIE",
        "signature": "youtube_dl.extractor.onet.OnetPlIE._search_mvp_id(self, webpage, default=NO_DEFAULT)",
        "snippet": "    def _search_mvp_id(self, webpage, default=NO_DEFAULT):\n        return self._search_regex(\n            r'data-(?:params-)?mvp=[\"\\'](\\d+\\.\\d+)', webpage, 'mvp id',\n            default=default)",
        "begin_line": 229,
        "end_line": 232,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onet.OnetPlIE._real_extract#234",
        "src_path": "youtube_dl/extractor/onet.py",
        "class_name": "youtube_dl.extractor.onet.OnetPlIE",
        "signature": "youtube_dl.extractor.onet.OnetPlIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        mvp_id = self._search_mvp_id(webpage, default=None)\n\n        if not mvp_id:\n            pulsembed_url = self._search_regex(\n                r'data-src=([\"\\'])(?P<url>(?:https?:)?//pulsembed\\.eu/.+?)\\1',\n                webpage, 'pulsembed url', group='url')\n            webpage = self._download_webpage(\n                pulsembed_url, video_id, 'Downloading pulsembed webpage')\n            mvp_id = self._search_mvp_id(webpage)\n\n        return self.url_result(\n            'onetmvp:%s' % mvp_id, OnetMVPIE.ie_key(), video_id=mvp_id)",
        "begin_line": 234,
        "end_line": 250,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onionstudios.OnionStudiosIE._extract_url#35",
        "src_path": "youtube_dl/extractor/onionstudios.py",
        "class_name": "youtube_dl.extractor.onionstudios.OnionStudiosIE",
        "signature": "youtube_dl.extractor.onionstudios.OnionStudiosIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?onionstudios\\.com/embed.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 35,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.onionstudios.OnionStudiosIE._real_extract#41",
        "src_path": "youtube_dl/extractor/onionstudios.py",
        "class_name": "youtube_dl.extractor.onionstudios.OnionStudiosIE",
        "signature": "youtube_dl.extractor.onionstudios.OnionStudiosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_data = self._download_json(\n            'http://www.onionstudios.com/video/%s.json' % video_id, video_id)\n\n        title = video_data['title']\n\n        formats = []\n        for source in video_data.get('sources', []):\n            source_url = source.get('url')\n            if not source_url:\n                continue\n            ext = mimetype2ext(source.get('content_type')) or determine_ext(source_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    source_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n            else:\n                tbr = int_or_none(source.get('bitrate'))\n                formats.append({\n                    'format_id': ext + ('-%d' % tbr if tbr else ''),\n                    'url': source_url,\n                    'width': int_or_none(source.get('width')),\n                    'tbr': tbr,\n                    'ext': ext,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': video_data.get('poster_url'),\n            'uploader': video_data.get('channel_name'),\n            'uploader_id': video_data.get('channel_slug'),\n            'duration': float_or_none(video_data.get('duration', 1000)),\n            'tags': video_data.get('tags'),\n            'formats': formats,\n        }",
        "begin_line": 41,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract#23",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaBaseIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaBaseIE._extract(self, content_tree_url, video_id, domain='example.org', supportedformats=None, embed_token=None)",
        "snippet": "    def _extract(self, content_tree_url, video_id, domain='example.org', supportedformats=None, embed_token=None):\n        content_tree = self._download_json(content_tree_url, video_id)['content_tree']\n        metadata = content_tree[list(content_tree)[0]]\n        embed_code = metadata['embed_code']\n        pcode = metadata.get('asset_pcode') or embed_code\n        title = metadata['title']\n\n        auth_data = self._download_json(\n            self._AUTHORIZATION_URL_TEMPLATE % (pcode, embed_code) +\n            compat_urllib_parse_urlencode({\n                'domain': domain,\n                'supportedFormats': supportedformats or 'mp4,rtmp,m3u8,hds,dash,smooth',\n                'embedToken': embed_token,\n            }), video_id)\n\n        cur_auth_data = auth_data['authorization_data'][embed_code]\n\n        urls = []\n        formats = []\n        if cur_auth_data['authorized']:\n            for stream in cur_auth_data['streams']:\n                url_data = try_get(stream, lambda x: x['url']['data'], compat_str)\n                if not url_data:\n                    continue\n                s_url = base64.b64decode(url_data.encode('ascii')).decode('utf-8')\n                if not s_url or s_url in urls:\n                    continue\n                urls.append(s_url)\n                ext = determine_ext(s_url, None)\n                delivery_type = stream.get('delivery_type')\n                if delivery_type == 'hls' or ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        re.sub(r'/ip(?:ad|hone)/', '/all/', s_url), embed_code, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n                elif delivery_type == 'hds' or ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        s_url + '?hdcore=3.7.0', embed_code, f4m_id='hds', fatal=False))\n                elif delivery_type == 'dash' or ext == 'mpd':\n                    formats.extend(self._extract_mpd_formats(\n                        s_url, embed_code, mpd_id='dash', fatal=False))\n                elif delivery_type == 'smooth':\n                    self._extract_ism_formats(\n                        s_url, embed_code, ism_id='mss', fatal=False)\n                elif ext == 'smil':\n                    formats.extend(self._extract_smil_formats(\n                        s_url, embed_code, fatal=False))\n                else:\n                    formats.append({\n                        'url': s_url,\n                        'ext': ext or delivery_type,\n                        'vcodec': stream.get('video_codec'),\n                        'format_id': delivery_type,\n                        'width': int_or_none(stream.get('width')),\n                        'height': int_or_none(stream.get('height')),\n                        'abr': int_or_none(stream.get('audio_bitrate')),\n                        'vbr': int_or_none(stream.get('video_bitrate')),\n                        'fps': float_or_none(stream.get('framerate')),\n                    })\n        else:\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, cur_auth_data['message']), expected=True)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for lang, sub in metadata.get('closed_captions_vtt', {}).get('captions', {}).items():\n            sub_url = sub.get('url')\n            if not sub_url:\n                continue\n            subtitles[lang] = [{\n                'url': sub_url,\n            }]\n\n        return {\n            'id': embed_code,\n            'title': title,\n            'description': metadata.get('description'),\n            'thumbnail': metadata.get('thumbnail_image') or metadata.get('promo_image'),\n            'duration': float_or_none(metadata.get('duration'), 1000),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._url_for_embed_code#152",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._url_for_embed_code(embed_code)",
        "snippet": "    def _url_for_embed_code(embed_code):\n        return 'http://player.ooyala.com/player.js?embedCode=%s' % embed_code",
        "begin_line": 152,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._build_url_result#156",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._build_url_result(cls, embed_code)",
        "snippet": "    def _build_url_result(cls, embed_code):\n        return cls.url_result(cls._url_for_embed_code(embed_code),\n                              ie=cls.ie_key())",
        "begin_line": 156,
        "end_line": 158,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract#160",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        embed_code = self._match_id(url)\n        domain = smuggled_data.get('domain')\n        supportedformats = smuggled_data.get('supportedformats')\n        embed_token = smuggled_data.get('embed_token')\n        content_tree_url = self._CONTENT_TREE_BASE + 'embed_code/%s/%s' % (embed_code, embed_code)\n        return self._extract(content_tree_url, embed_code, domain, supportedformats, embed_token)",
        "begin_line": 160,
        "end_line": 167,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaExternalIE._real_extract#201",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaExternalIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaExternalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        partner_id, video_id, pcode = re.match(self._VALID_URL, url).groups()\n        content_tree_url = self._CONTENT_TREE_BASE + 'external_id/%s/%s:%s' % (pcode, partner_id, video_id)\n        return self._extract(content_tree_url, video_id)",
        "begin_line": 201,
        "end_line": 204,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.openload.OpenloadIE._extract_urls#62",
        "src_path": "youtube_dl/extractor/openload.py",
        "class_name": "youtube_dl.extractor.openload.OpenloadIE",
        "signature": "youtube_dl.extractor.openload.OpenloadIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=[\"\\']((?:https?://)?(?:openload\\.(?:co|io)|oload\\.tv)/embed/[a-zA-Z0-9-_]+)',\n            webpage)",
        "begin_line": 62,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.openload.OpenloadIE._real_extract#67",
        "src_path": "youtube_dl/extractor/openload.py",
        "class_name": "youtube_dl.extractor.openload.OpenloadIE",
        "signature": "youtube_dl.extractor.openload.OpenloadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage('https://openload.co/embed/%s/' % video_id, video_id)\n\n        if 'File not found' in webpage or 'deleted by the owner' in webpage:\n            raise ExtractorError('File not found', expected=True)\n\n        ol_id = self._search_regex(\n            '<span[^>]+id=\"[^\"]+\"[^>]*>([0-9A-Za-z]+)</span>',\n            webpage, 'openload ID')\n\n        decoded = ''\n        a = ol_id[0:24]\n        b = []\n        for i in range(0, len(a), 8):\n            b.append(int(a[i:i + 8] or '0', 16))\n        ol_id = ol_id[24:]\n        j = 0\n        k = 0\n        while j < len(ol_id):\n            c = 128\n            d = 0\n            e = 0\n            f = 0\n            _more = True\n            while _more:\n                if j + 1 >= len(ol_id):\n                    c = 143\n                f = int(ol_id[j:j + 2] or '0', 16)\n                j += 2\n                d += (f & 127) << e\n                e += 7\n                _more = f >= c\n            g = d ^ b[k % 3]\n            for i in range(4):\n                char_dec = (g >> 8 * i) & (c + 127)\n                char = compat_chr(char_dec)\n                if char != '#':\n                    decoded += char\n            k += 1\n\n        video_url = 'https://openload.co/stream/%s?mime=true'\n        video_url = video_url % decoded\n\n        title = self._og_search_title(webpage, default=None) or self._search_regex(\n            r'<span[^>]+class=[\"\\']title[\"\\'][^>]*>([^<]+)', webpage,\n            'title', default=None) or self._html_search_meta(\n            'description', webpage, 'title', fatal=True)\n\n        entries = self._parse_html5_media_entries(url, webpage, video_id)\n        subtitles = entries[0]['subtitles'] if entries else None\n\n        info_dict = {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'url': video_url,\n            # Seems all videos have extensions in their titles\n            'ext': determine_ext(title, 'mp4'),\n            'subtitles': subtitles,\n        }\n        return info_dict",
        "begin_line": 67,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ora.OraTVIE._real_extract#30",
        "src_path": "youtube_dl/extractor/ora.py",
        "class_name": "youtube_dl.extractor.ora.OraTVIE",
        "signature": "youtube_dl.extractor.ora.OraTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        video_data = self._search_regex(\n            r'\"(?:video|current)\"\\s*:\\s*({[^}]+?})', webpage, 'current video')\n        m3u8_url = self._search_regex(\n            r'hls_stream\"?\\s*:\\s*\"([^\"]+)', video_data, 'm3u8 url', None)\n        if m3u8_url:\n            formats = self._extract_m3u8_formats(\n                m3u8_url, display_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False)\n            # similar to GameSpotIE\n            m3u8_path = compat_urlparse.urlparse(m3u8_url).path\n            QUALITIES_RE = r'((,[a-z]+\\d+)+,?)'\n            available_qualities = self._search_regex(\n                QUALITIES_RE, m3u8_path, 'qualities').strip(',').split(',')\n            http_path = m3u8_path[1:].split('/', 1)[1]\n            http_template = re.sub(QUALITIES_RE, r'%s', http_path)\n            http_template = http_template.replace('.csmil/master.m3u8', '')\n            http_template = compat_urlparse.urljoin(\n                'http://videocdn-pmd.ora.tv/', http_template)\n            preference = qualities(\n                ['mobile400', 'basic400', 'basic600', 'sd900', 'sd1200', 'sd1500', 'hd720', 'hd1080'])\n            for q in available_qualities:\n                formats.append({\n                    'url': http_template % q,\n                    'format_id': q,\n                    'preference': preference(q),\n                })\n            self._sort_formats(formats)\n        else:\n            return self.url_result(self._search_regex(\n                r'\"youtube_id\"\\s*:\\s*\"([^\"]+)', webpage, 'youtube id'), 'Youtube')\n\n        return {\n            'id': self._search_regex(\n                r'\"id\"\\s*:\\s*(\\d+)', video_data, 'video id', default=display_id),\n            'display_id': display_id,\n            'title': unescapeHTML(self._og_search_title(webpage)),\n            'description': get_element_by_attribute(\n                'class', 'video_txt_decription', webpage),\n            'thumbnail': self._proto_relative_url(self._search_regex(\n                r'\"thumb\"\\s*:\\s*\"([^\"]+)', video_data, 'thumbnail', None)),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract#60",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFTVthekIE",
        "signature": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n\n        data_jsb = self._parse_json(\n            self._search_regex(\n                r'<div[^>]+class=([\"\\']).*?VideoPlaylist.*?\\1[^>]+data-jsb=([\"\\'])(?P<json>.+?)\\2',\n                webpage, 'playlist', group='json'),\n            playlist_id, transform_source=unescapeHTML)['playlist']['videos']\n\n        def quality_to_int(s):\n            m = re.search('([0-9]+)', s)\n            if m is None:\n                return -1\n            return int(m.group(1))\n\n        entries = []\n        for sd in data_jsb:\n            video_id, title = sd.get('id'), sd.get('title')\n            if not video_id or not title:\n                continue\n            video_id = compat_str(video_id)\n            formats = [{\n                'preference': -10 if fd['delivery'] == 'hls' else None,\n                'format_id': '%s-%s-%s' % (\n                    fd['delivery'], fd['quality'], fd['quality_string']),\n                'url': fd['src'],\n                'protocol': fd['protocol'],\n                'quality': quality_to_int(fd['quality']),\n            } for fd in sd['sources']]\n\n            # Check for geoblocking.\n            # There is a property is_geoprotection, but that's always false\n            geo_str = sd.get('geoprotection_string')\n            if geo_str:\n                try:\n                    http_url = next(\n                        f['url']\n                        for f in formats\n                        if re.match(r'^https?://.*\\.mp4$', f['url']))\n                except StopIteration:\n                    pass\n                else:\n                    req = HEADRequest(http_url)\n                    self._request_webpage(\n                        req, video_id,\n                        note='Testing for geoblocking',\n                        errnote=((\n                            'This video seems to be blocked outside of %s. '\n                            'You may want to try the streaming-* formats.')\n                            % geo_str),\n                        fatal=False)\n\n            self._check_formats(formats, video_id)\n            self._sort_formats(formats)\n\n            subtitles = {}\n            for sub in sd.get('subtitles', []):\n                sub_src = sub.get('src')\n                if not sub_src:\n                    continue\n                subtitles.setdefault(sub.get('lang', 'de-AT'), []).append({\n                    'url': sub_src,\n                })\n\n            upload_date = unified_strdate(sd.get('created_date'))\n            entries.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': title,\n                'formats': formats,\n                'subtitles': subtitles,\n                'description': sd.get('description'),\n                'duration': int_or_none(sd.get('duration_in_seconds')),\n                'upload_date': upload_date,\n                'thumbnail': sd.get('image_full_url'),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': playlist_id,\n        }",
        "begin_line": 60,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.orf.ORFRadioIE._real_extract#146",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFRadioIE",
        "signature": "youtube_dl.extractor.orf.ORFRadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        station = mobj.group('station')\n        show_date = mobj.group('date')\n        show_id = mobj.group('show')\n\n        if station == 'fm4':\n            show_id = '4%s' % show_id\n\n        data = self._download_json(\n            'http://audioapi.orf.at/%s/api/json/current/broadcast/%s/%s' % (station, show_id, show_date),\n            show_id\n        )\n\n        def extract_entry_dict(info, title, subtitle):\n            return {\n                'id': info['loopStreamId'].replace('.mp3', ''),\n                'url': 'http://loopstream01.apa.at/?channel=%s&id=%s' % (station, info['loopStreamId']),\n                'title': title,\n                'description': subtitle,\n                'duration': (info['end'] - info['start']) / 1000,\n                'timestamp': info['start'] / 1000,\n                'ext': 'mp3'\n            }\n\n        entries = [extract_entry_dict(t, data['title'], data['subtitle']) for t in data['streams']]\n\n        return {\n            '_type': 'playlist',\n            'id': show_id,\n            'title': data['title'],\n            'description': data['subtitle'],\n            'entries': entries\n        }",
        "begin_line": 146,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.orf.ORFIPTVIE._real_extract#242",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFIPTVIE",
        "signature": "youtube_dl.extractor.orf.ORFIPTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        story_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://iptv.orf.at/stories/%s' % story_id, story_id)\n\n        video_id = self._search_regex(\n            r'data-video(?:id)?=\"(\\d+)\"', webpage, 'video id')\n\n        data = self._download_json(\n            'http://bits.orf.at/filehandler/static-api/json/current/data.json?file=%s' % video_id,\n            video_id)[0]\n\n        duration = float_or_none(data['duration'], 1000)\n\n        video = data['sources']['default']\n        load_balancer_url = video['loadBalancerUrl']\n        abr = int_or_none(video.get('audioBitrate'))\n        vbr = int_or_none(video.get('bitrate'))\n        fps = int_or_none(video.get('videoFps'))\n        width = int_or_none(video.get('videoWidth'))\n        height = int_or_none(video.get('videoHeight'))\n        thumbnail = video.get('preview')\n\n        rendition = self._download_json(\n            load_balancer_url, video_id, transform_source=strip_jsonp)\n\n        f = {\n            'abr': abr,\n            'vbr': vbr,\n            'fps': fps,\n            'width': width,\n            'height': height,\n        }\n\n        formats = []\n        for format_id, format_url in rendition['redirect'].items():\n            if format_id == 'rtmp':\n                ff = f.copy()\n                ff.update({\n                    'url': format_url,\n                    'format_id': format_id,\n                })\n                formats.append(ff)\n            elif determine_ext(format_url) == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    format_url, video_id, f4m_id=format_id))\n            elif determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', m3u8_id=format_id))\n            else:\n                continue\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - iptv.ORF.at')\n        description = self._og_search_description(webpage)\n        upload_date = unified_strdate(self._html_search_meta(\n            'dc.date', webpage, 'upload date'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 242,
        "end_line": 309,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubIE._real_initialize#44",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        try:\n            self._TOKEN = self._download_json(\n                self._MAPT_REST + '/users/tokens', None,\n                'Downloading Authorization Token', data=json.dumps({\n                    'email': username,\n                    'password': password,\n                }).encode())['data']['access']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code in (400, 401, 404):\n                message = self._parse_json(e.cause.read().decode(), None)['message']\n                raise ExtractorError(message, expected=True)\n            raise",
        "begin_line": 44,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubIE._handle_error#61",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if response.get('status') != 'success':\n            raise ExtractorError(\n                '% said: %s' % (self.IE_NAME, response['message']),\n                expected=True)",
        "begin_line": 61,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubIE._download_json#67",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubIE._download_json(self, *args, **kwargs)",
        "snippet": "    def _download_json(self, *args, **kwargs):\n        response = super(PacktPubIE, self)._download_json(*args, **kwargs)\n        self._handle_error(response)\n        return response",
        "begin_line": 67,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubIE._real_extract#72",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_id, chapter_id, video_id = mobj.group(\n            'course_id', 'chapter_id', 'id')\n\n        headers = {}\n        if self._TOKEN:\n            headers['Authorization'] = 'Bearer ' + self._TOKEN\n        video = self._download_json(\n            '%s/users/me/products/%s/chapters/%s/sections/%s'\n            % (self._MAPT_REST, course_id, chapter_id, video_id), video_id,\n            'Downloading JSON video', headers=headers)['data']\n\n        content = video.get('content')\n        if not content:\n            self.raise_login_required('This video is locked')\n\n        video_url = content['file']\n\n        metadata = self._download_json(\n            '%s/products/%s/chapters/%s/sections/%s/metadata'\n            % (self._MAPT_REST, course_id, chapter_id, video_id),\n            video_id)['data']\n\n        title = metadata['pageTitle']\n        course_title = metadata.get('title')\n        if course_title:\n            title = remove_end(title, ' - %s' % course_title)\n        timestamp = unified_timestamp(metadata.get('publicationDate'))\n        thumbnail = urljoin(self._PACKT_BASE, metadata.get('filepath'))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n        }",
        "begin_line": 72,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubCourseIE.suitable#124",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubCourseIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if PacktPubIE.suitable(url) else super(\n            PacktPubCourseIE, cls).suitable(url)",
        "begin_line": 124,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.packtpub.PacktPubCourseIE._real_extract#128",
        "src_path": "youtube_dl/extractor/packtpub.py",
        "class_name": "youtube_dl.extractor.packtpub.PacktPubCourseIE",
        "signature": "youtube_dl.extractor.packtpub.PacktPubCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        url, course_id = mobj.group('url', 'id')\n\n        course = self._download_json(\n            '%s/products/%s/metadata' % (self._MAPT_REST, course_id),\n            course_id)['data']\n\n        entries = []\n        for chapter_num, chapter in enumerate(course['tableOfContents'], 1):\n            if chapter.get('type') != 'chapter':\n                continue\n            children = chapter.get('children')\n            if not isinstance(children, list):\n                continue\n            chapter_info = {\n                'chapter': chapter.get('title'),\n                'chapter_number': chapter_num,\n                'chapter_id': chapter.get('id'),\n            }\n            for section in children:\n                if section.get('type') != 'section':\n                    continue\n                section_url = section.get('seoUrl')\n                if not isinstance(section_url, compat_str):\n                    continue\n                entry = {\n                    '_type': 'url_transparent',\n                    'url': urljoin(url + '/', section_url),\n                    'title': strip_or_none(section.get('title')),\n                    'description': clean_html(section.get('summary')),\n                    'ie_key': PacktPubIE.ie_key(),\n                }\n                entry.update(chapter_info)\n                entries.append(entry)\n\n        return self.playlist_result(entries, course_id, course.get('title'))",
        "begin_line": 128,
        "end_line": 164,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pandatv.PandaTVIE._real_extract#32",
        "src_path": "youtube_dl/extractor/pandatv.py",
        "class_name": "youtube_dl.extractor.pandatv.PandaTVIE",
        "signature": "youtube_dl.extractor.pandatv.PandaTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_json(\n            'https://www.panda.tv/api_room?roomid=%s' % video_id, video_id)\n\n        error_code = config.get('errno', 0)\n        if error_code is not 0:\n            raise ExtractorError(\n                '%s returned error %s: %s'\n                % (self.IE_NAME, error_code, config['errmsg']),\n                expected=True)\n\n        data = config['data']\n        video_info = data['videoinfo']\n\n        # 2 = live, 3 = offline\n        if video_info.get('status') != '2':\n            raise ExtractorError(\n                'Live stream is offline', expected=True)\n\n        title = data['roominfo']['name']\n        uploader = data.get('hostinfo', {}).get('name')\n        room_key = video_info['room_key']\n        stream_addr = video_info.get(\n            'stream_addr', {'OD': '1', 'HD': '1', 'SD': '1'})\n\n        # Reverse engineered from web player swf\n        # (http://s6.pdim.gs/static/07153e425f581151.swf at the moment of\n        # writing).\n        plflag0, plflag1 = video_info['plflag'].split('_')\n        plflag0 = int(plflag0) - 1\n        if plflag1 == '21':\n            plflag0 = 10\n            plflag1 = '4'\n        live_panda = 'live_panda' if plflag0 < 1 else ''\n\n        quality_key = qualities(['OD', 'HD', 'SD'])\n        suffix = ['_small', '_mid', '']\n        formats = []\n        for k, v in stream_addr.items():\n            if v != '1':\n                continue\n            quality = quality_key(k)\n            if quality <= 0:\n                continue\n            for pref, (ext, pl) in enumerate((('m3u8', '-hls'), ('flv', ''))):\n                formats.append({\n                    'url': 'https://pl%s%s.live.panda.tv/live_panda/%s%s%s.%s'\n                    % (pl, plflag1, room_key, live_panda, suffix[quality], ext),\n                    'format_id': '%s-%s' % (k, ext),\n                    'quality': quality,\n                    'source_preference': pref,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title),\n            'uploader': uploader,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 32,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pandoratv.PandoraTVIE._real_extract#58",
        "src_path": "youtube_dl/extractor/pandoratv.py",
        "class_name": "youtube_dl.extractor.pandoratv.PandoraTVIE",
        "signature": "youtube_dl.extractor.pandoratv.PandoraTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        video_id = qs.get('prgid', [None])[0]\n        user_id = qs.get('ch_userid', [None])[0]\n        if any(not f for f in (video_id, user_id,)):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        data = self._download_json(\n            'http://m.pandora.tv/?c=view&m=viewJsonApi&ch_userid=%s&prgid=%s'\n            % (user_id, video_id), video_id)\n\n        info = data['data']['rows']['vod_play_info']['result']\n\n        formats = []\n        for format_id, format_url in info.items():\n            if not format_url:\n                continue\n            height = self._search_regex(\n                r'^v(\\d+)[Uu]rl$', format_id, 'height', default=None)\n            if not height:\n                continue\n\n            play_url = self._download_json(\n                'http://m.pandora.tv/?c=api&m=play_url', video_id,\n                data=urlencode_postdata({\n                    'prgid': video_id,\n                    'runtime': info.get('runtime'),\n                    'vod_url': format_url,\n                }),\n                headers={\n                    'Origin': url,\n                    'Content-Type': 'application/x-www-form-urlencoded',\n                })\n            format_url = play_url.get('url')\n            if not format_url:\n                continue\n\n            formats.append({\n                'format_id': '%sp' % height,\n                'url': format_url,\n                'height': int(height),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['subject'],\n            'description': info.get('body'),\n            'thumbnail': info.get('thumbnail') or info.get('poster'),\n            'duration': float_or_none(info.get('runtime'), 1000) or parse_duration(info.get('time')),\n            'upload_date': info['fid'].split('/')[-1][:8] if isinstance(info.get('fid'), compat_str) else None,\n            'uploader': info.get('nickname'),\n            'uploader_id': info.get('upload_userid'),\n            'view_count': str_to_int(info.get('hit')),\n            'like_count': str_to_int(info.get('likecnt')),\n            'formats': formats,\n        }",
        "begin_line": 58,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract#26",
        "src_path": "youtube_dl/extractor/parliamentliveuk.py",
        "class_name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE",
        "signature": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://vodplayer.parliamentlive.tv/?mid=' + video_id, video_id)\n        widget_config = self._parse_json(self._search_regex(\n            r'kWidgetConfig\\s*=\\s*({.+});',\n            webpage, 'kaltura widget config'), video_id)\n        kaltura_url = 'kaltura:%s:%s' % (widget_config['wid'][1:], widget_config['entry_id'])\n        event_title = self._download_json(\n            'http://parliamentlive.tv/Event/GetShareVideo/' + video_id, video_id)['event']['title']\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': event_title,\n            'description': '',\n            'url': kaltura_url,\n            'ie_key': 'Kaltura',\n        }",
        "begin_line": 26,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.patreon.PatreonIE._real_extract#79",
        "src_path": "youtube_dl/extractor/patreon.py",
        "class_name": "youtube_dl.extractor.patreon.PatreonIE",
        "signature": "youtube_dl.extractor.patreon.PatreonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage).strip()\n\n        attach_fn = self._html_search_regex(\n            r'<div class=\"attach\"><a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage, 'attachment URL', default=None)\n        embed = self._html_search_regex(\n            r'<div[^>]+id=\"watchCreation\"[^>]*>\\s*<iframe[^>]+src=\"([^\"]+)\"',\n            webpage, 'embedded URL', default=None)\n\n        if attach_fn is not None:\n            video_url = 'http://www.patreon.com' + attach_fn\n            thumbnail = self._og_search_thumbnail(webpage)\n            uploader = self._html_search_regex(\n                r'<strong>(.*?)</strong> is creating', webpage, 'uploader')\n        elif embed is not None:\n            return self.url_result(embed)\n        else:\n            playlist = self._parse_json(self._search_regex(\n                r'(?s)new\\s+jPlayerPlaylist\\(\\s*\\{\\s*[^}]*},\\s*(\\[.*?,?\\s*\\])',\n                webpage, 'playlist JSON'),\n                video_id, transform_source=js_to_json)\n            data = playlist[0]\n            video_url = self._proto_relative_url(data['mp3'])\n            thumbnail = self._proto_relative_url(data.get('cover'))\n            uploader = data.get('artist')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 79,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._real_initialize#379",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        cookie = (self._download_json(\n            'http://localization.services.pbs.org/localize/auto/cookie/',\n            None, headers=self.geo_verification_headers(), fatal=False) or {}).get('cookie')\n        if cookie:\n            station = self._search_regex(r'#?s=\\[\"([^\"]+)\"', cookie, 'station')\n            if station:\n                self._set_cookie('.pbs.org', 'pbsol.station', station)",
        "begin_line": 379,
        "end_line": 386,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._extract_webpage#388",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._extract_webpage(self, url)",
        "snippet": "    def _extract_webpage(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        description = None\n\n        presumptive_id = mobj.group('presumptive_id')\n        display_id = presumptive_id\n        if presumptive_id:\n            webpage = self._download_webpage(url, display_id)\n\n            description = strip_or_none(self._og_search_description(\n                webpage, default=None) or self._html_search_meta(\n                'description', webpage, default=None))\n            upload_date = unified_strdate(self._search_regex(\n                r'<input type=\"hidden\" id=\"air_date_[0-9]+\" value=\"([^\"]+)\"',\n                webpage, 'upload date', default=None))\n\n            # tabbed frontline videos\n            MULTI_PART_REGEXES = (\n                r'<div[^>]+class=\"videotab[^\"]*\"[^>]+vid=\"(\\d+)\"',\n                r'<a[^>]+href=[\"\\']#(?:video-|part)\\d+[\"\\'][^>]+data-cove[Ii]d=[\"\\'](\\d+)',\n            )\n            for p in MULTI_PART_REGEXES:\n                tabbed_videos = orderedSet(re.findall(p, webpage))\n                if tabbed_videos:\n                    return tabbed_videos, presumptive_id, upload_date, description\n\n            MEDIA_ID_REGEXES = [\n                r\"div\\s*:\\s*'videoembed'\\s*,\\s*mediaid\\s*:\\s*'(\\d+)'\",  # frontline video embed\n                r'class=\"coveplayerid\">([^<]+)<',                       # coveplayer\n                r'<section[^>]+data-coveid=\"(\\d+)\"',                    # coveplayer from http://www.pbs.org/wgbh/frontline/film/real-csi/\n                r'<input type=\"hidden\" id=\"pbs_video_id_[0-9]+\" value=\"([0-9]+)\"/>',  # jwplayer\n            ]\n\n            media_id = self._search_regex(\n                MEDIA_ID_REGEXES, webpage, 'media ID', fatal=False, default=None)\n            if media_id:\n                return media_id, presumptive_id, upload_date, description\n\n            # Fronline video embedded via flp\n            video_id = self._search_regex(\n                r'videoid\\s*:\\s*\"([\\d+a-z]{7,})\"', webpage, 'videoid', default=None)\n            if video_id:\n                # pkg_id calculation is reverse engineered from\n                # http://www.pbs.org/wgbh/pages/frontline/js/flp2012.js\n                prg_id = self._search_regex(\n                    r'videoid\\s*:\\s*\"([\\d+a-z]{7,})\"', webpage, 'videoid')[7:]\n                if 'q' in prg_id:\n                    prg_id = prg_id.split('q')[1]\n                prg_id = int(prg_id, 16)\n                getdir = self._download_json(\n                    'http://www.pbs.org/wgbh/pages/frontline/.json/getdir/getdir%d.json' % prg_id,\n                    presumptive_id, 'Downloading getdir JSON',\n                    transform_source=strip_jsonp)\n                return getdir['mid'], presumptive_id, upload_date, description\n\n            for iframe in re.findall(r'(?s)<iframe(.+?)></iframe>', webpage):\n                url = self._search_regex(\n                    r'src=([\"\\'])(?P<url>.+?partnerplayer.+?)\\1', iframe,\n                    'player URL', default=None, group='url')\n                if url:\n                    break\n\n            if not url:\n                url = self._og_search_url(webpage)\n\n            mobj = re.match(self._VALID_URL, url)\n\n        player_id = mobj.group('player_id')\n        if not display_id:\n            display_id = player_id\n        if player_id:\n            player_page = self._download_webpage(\n                url, display_id, note='Downloading player page',\n                errnote='Could not download player page')\n            video_id = self._search_regex(\n                r'<div\\s+id=\"video_([0-9]+)\"', player_page, 'video ID')\n        else:\n            video_id = mobj.group('id')\n            display_id = video_id\n\n        return video_id, display_id, None, description",
        "begin_line": 388,
        "end_line": 469,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._real_extract#471",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id, upload_date, description = self._extract_webpage(url)\n\n        if isinstance(video_id, list):\n            entries = [self.url_result(\n                'http://video.pbs.org/video/%s' % vid_id, 'PBS', vid_id)\n                for vid_id in video_id]\n            return self.playlist_result(entries, display_id)\n\n        info = None\n        redirects = []\n        redirect_urls = set()\n\n        def extract_redirect_urls(info):\n            for encoding_name in ('recommended_encoding', 'alternate_encoding'):\n                redirect = info.get(encoding_name)\n                if not redirect:\n                    continue\n                redirect_url = redirect.get('url')\n                if redirect_url and redirect_url not in redirect_urls:\n                    redirects.append(redirect)\n                    redirect_urls.add(redirect_url)\n\n        chapters = []\n        # Player pages may also serve different qualities\n        for page in ('widget/partnerplayer', 'portalplayer'):\n            player = self._download_webpage(\n                'http://player.pbs.org/%s/%s' % (page, video_id),\n                display_id, 'Downloading %s page' % page, fatal=False)\n            if player:\n                video_info = self._parse_json(\n                    self._search_regex(\n                        r'(?s)PBS\\.videoData\\s*=\\s*({.+?});\\n',\n                        player, '%s video data' % page, default='{}'),\n                    display_id, transform_source=js_to_json, fatal=False)\n                if video_info:\n                    extract_redirect_urls(video_info)\n                    if not info:\n                        info = video_info\n                if not chapters:\n                    for chapter_data in re.findall(r'(?s)chapters\\.push\\(({.*?})\\)', player):\n                        chapter = self._parse_json(chapter_data, video_id, js_to_json, fatal=False)\n                        if not chapter:\n                            continue\n                        start_time = float_or_none(chapter.get('start_time'), 1000)\n                        duration = float_or_none(chapter.get('duration'), 1000)\n                        if start_time is None or duration is None:\n                            continue\n                        chapters.append({\n                            'start_time': start_time,\n                            'end_time': start_time + duration,\n                            'title': chapter.get('title'),\n                        })\n\n        formats = []\n        http_url = None\n        for num, redirect in enumerate(redirects):\n            redirect_id = redirect.get('eeid')\n\n            redirect_info = self._download_json(\n                '%s?format=json' % redirect['url'], display_id,\n                'Downloading %s video url info' % (redirect_id or num),\n                headers=self.geo_verification_headers())\n\n            if redirect_info['status'] == 'error':\n                message = self._ERRORS.get(\n                    redirect_info['http_code'], redirect_info['message'])\n                if redirect_info['http_code'] == 403:\n                    self.raise_geo_restricted(\n                        msg=message, countries=self._GEO_COUNTRIES)\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, message), expected=True)\n\n            format_url = redirect_info.get('url')\n            if not format_url:\n                continue\n\n            if determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, display_id, 'mp4', m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': redirect_id,\n                })\n                if re.search(r'^https?://.*(?:\\d+k|baseline)', format_url):\n                    http_url = format_url\n        self._remove_duplicate_formats(formats)\n        m3u8_formats = list(filter(\n            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none',\n            formats))\n        if http_url:\n            for m3u8_format in m3u8_formats:\n                bitrate = self._search_regex(r'(\\d+)k', m3u8_format['url'], 'bitrate', default=None)\n                # Lower qualities (150k and 192k) are not available as HTTP formats (see [1]),\n                # we won't try extracting them.\n                # Since summer 2016 higher quality formats (4500k and 6500k) are also available\n                # albeit they are not documented in [2].\n                # 1. https://github.com/rg3/youtube-dl/commit/cbc032c8b70a038a69259378c92b4ba97b42d491#commitcomment-17313656\n                # 2. https://projects.pbs.org/confluence/display/coveapi/COVE+Video+Specifications\n                if not bitrate or int(bitrate) < 400:\n                    continue\n                f_url = re.sub(r'\\d+k|baseline', bitrate + 'k', http_url)\n                # This may produce invalid links sometimes (e.g.\n                # http://www.pbs.org/wgbh/frontline/film/suicide-plan)\n                if not self._is_valid_url(f_url, display_id, 'http-%sk video' % bitrate):\n                    continue\n                f = m3u8_format.copy()\n                f.update({\n                    'url': f_url,\n                    'format_id': m3u8_format['format_id'].replace('hls', 'http'),\n                    'protocol': 'http',\n                })\n                formats.append(f)\n        self._sort_formats(formats)\n\n        rating_str = info.get('rating')\n        if rating_str is not None:\n            rating_str = rating_str.rpartition('-')[2]\n        age_limit = US_RATINGS.get(rating_str)\n\n        subtitles = {}\n        closed_captions_url = info.get('closed_captions_url')\n        if closed_captions_url:\n            subtitles['en'] = [{\n                'ext': 'ttml',\n                'url': closed_captions_url,\n            }]\n            mobj = re.search(r'/(\\d+)_Encoded\\.dfxp', closed_captions_url)\n            if mobj:\n                ttml_caption_suffix, ttml_caption_id = mobj.group(0, 1)\n                ttml_caption_id = int(ttml_caption_id)\n                subtitles['en'].extend([{\n                    'url': closed_captions_url.replace(\n                        ttml_caption_suffix, '/%d_Encoded.srt' % (ttml_caption_id + 1)),\n                    'ext': 'srt',\n                }, {\n                    'url': closed_captions_url.replace(\n                        ttml_caption_suffix, '/%d_Encoded.vtt' % (ttml_caption_id + 2)),\n                    'ext': 'vtt',\n                }])\n\n        # info['title'] is often incomplete (e.g. 'Full Episode', 'Episode 5', etc)\n        # Try turning it to 'program - title' naming scheme if possible\n        alt_title = info.get('program', {}).get('title')\n        if alt_title:\n            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + r'[\\s\\-:]+', '', info['title'])\n\n        description = info.get('description') or info.get(\n            'program', {}).get('description') or description\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': info['title'],\n            'description': description,\n            'thumbnail': info.get('image_url'),\n            'duration': int_or_none(info.get('duration')),\n            'age_limit': age_limit,\n            'upload_date': upload_date,\n            'formats': formats,\n            'subtitles': subtitles,\n            'chapters': chapters,\n        }",
        "begin_line": 471,
        "end_line": 634,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pearvideo.PearVideoIE._real_extract#27",
        "src_path": "youtube_dl/extractor/pearvideo.py",
        "class_name": "youtube_dl.extractor.pearvideo.PearVideoIE",
        "signature": "youtube_dl.extractor.pearvideo.PearVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        quality = qualities(\n            ('ldflv', 'ld', 'sdflv', 'sd', 'hdflv', 'hd', 'src'))\n\n        formats = [{\n            'url': mobj.group('url'),\n            'format_id': mobj.group('id'),\n            'quality': quality(mobj.group('id')),\n        } for mobj in re.finditer(\n            r'(?P<id>[a-zA-Z]+)Url\\s*=\\s*([\"\\'])(?P<url>(?:https?:)?//.+?)\\2',\n            webpage)]\n        self._sort_formats(formats)\n\n        title = self._search_regex(\n            (r'<h1[^>]+\\bclass=([\"\\'])video-tt\\1[^>]*>(?P<value>[^<]+)',\n             r'<[^>]+\\bdata-title=([\"\\'])(?P<value>(?:(?!\\1).)+)\\1'),\n            webpage, 'title', group='value')\n        description = self._search_regex(\n            (r'<div[^>]+\\bclass=([\"\\'])summary\\1[^>]*>(?P<value>[^<]+)',\n             r'<[^>]+\\bdata-summary=([\"\\'])(?P<value>(?:(?!\\1).)+)\\1'),\n            webpage, 'description', default=None,\n            group='value') or self._html_search_meta('Description', webpage)\n        timestamp = unified_timestamp(self._search_regex(\n            r'<div[^>]+\\bclass=[\"\\']date[\"\\'][^>]*>([^<]+)',\n            webpage, 'timestamp', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.people.PeopleIE._real_extract#29",
        "src_path": "youtube_dl/extractor/people.py",
        "class_name": "youtube_dl.extractor.people.PeopleIE",
        "signature": "youtube_dl.extractor.people.PeopleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(\n            'http://players.brightcove.net/416418724/default_default/index.html?videoId=ref:%s'\n            % self._match_id(url), 'BrightcoveNew')",
        "begin_line": 29,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeBaseIE._call_api#14",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeBaseIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeBaseIE._call_api(self, method, query, item_id)",
        "snippet": "    def _call_api(self, method, query, item_id):\n        return self._download_json(\n            'https://api.periscope.tv/api/v2/%s' % method,\n            item_id, query=query)",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeIE._extract_url#50",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=([\\'\"])(?P<url>(?:https?:)?//(?:www\\.)?(?:periscope|pscp)\\.tv/(?:(?!\\1).)+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 50,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeIE._real_extract#56",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        token = self._match_id(url)\n\n        broadcast_data = self._call_api(\n            'getBroadcastPublic', {'broadcast_id': token}, token)\n        broadcast = broadcast_data['broadcast']\n        status = broadcast['status']\n\n        user = broadcast_data.get('user', {})\n\n        uploader = broadcast.get('user_display_name') or user.get('display_name')\n        uploader_id = (broadcast.get('username') or user.get('username') or\n                       broadcast.get('user_id') or user.get('id'))\n\n        title = '%s - %s' % (uploader, status) if uploader else status\n        state = broadcast.get('state').lower()\n        if state == 'running':\n            title = self._live_title(title)\n        timestamp = parse_iso8601(broadcast.get('created_at'))\n\n        thumbnails = [{\n            'url': broadcast[image],\n        } for image in ('image_url', 'image_url_small') if broadcast.get(image)]\n\n        stream = self._call_api(\n            'getAccessPublic', {'broadcast_id': token}, token)\n\n        video_urls = set()\n        formats = []\n        for format_id in ('replay', 'rtmp', 'hls', 'https_hls', 'lhls', 'lhlsweb'):\n            video_url = stream.get(format_id + '_url')\n            if not video_url or video_url in video_urls:\n                continue\n            video_urls.add(video_url)\n            if format_id != 'rtmp':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, token, 'mp4',\n                    entry_protocol='m3u8_native'\n                    if state in ('ended', 'timed_out') else 'm3u8',\n                    m3u8_id=format_id, fatal=False))\n                continue\n            formats.append({\n                'url': video_url,\n                'ext': 'flv' if format_id == 'rtmp' else 'mp4',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': broadcast.get('id') or token,\n            'title': title,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.periscope.PeriscopeUserIE._real_extract#131",
        "src_path": "youtube_dl/extractor/periscope.py",
        "class_name": "youtube_dl.extractor.periscope.PeriscopeUserIE",
        "signature": "youtube_dl.extractor.periscope.PeriscopeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_name = self._match_id(url)\n\n        webpage = self._download_webpage(url, user_name)\n\n        data_store = self._parse_json(\n            unescapeHTML(self._search_regex(\n                r'data-store=([\"\\'])(?P<data>.+?)\\1',\n                webpage, 'data store', default='{}', group='data')),\n            user_name)\n\n        user = list(data_store['UserCache']['users'].values())[0]['user']\n        user_id = user['id']\n        session_id = data_store['SessionToken']['public']['broadcastHistory']['token']['session_id']\n\n        broadcasts = self._call_api(\n            'getUserBroadcastsPublic',\n            {'user_id': user_id, 'session_id': session_id},\n            user_name)['broadcasts']\n\n        broadcast_ids = [\n            broadcast['id'] for broadcast in broadcasts if broadcast.get('id')]\n\n        title = user.get('display_name') or user.get('username') or user_name\n        description = user.get('description')\n\n        entries = [\n            self.url_result(\n                'https://www.periscope.tv/%s/%s' % (user_name, broadcast_id))\n            for broadcast_id in broadcast_ids]\n\n        return self.playlist_result(entries, user_id, title, description)",
        "begin_line": 131,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE._real_extract#38",
        "src_path": "youtube_dl/extractor/philharmoniedeparis.py",
        "class_name": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE",
        "signature": "youtube_dl.extractor.philharmoniedeparis.PhilharmonieDeParisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        concert = self._download_xml(\n            'http://live.philharmoniedeparis.fr/misc/Playlist.ashx?id=%s' % video_id,\n            video_id).find('./concert')\n\n        formats = []\n        info_dict = {\n            'id': video_id,\n            'title': xpath_text(concert, './titre', 'title', fatal=True),\n            'formats': formats,\n        }\n\n        fichiers = concert.find('./fichiers')\n        stream = fichiers.attrib['serveurstream']\n        for fichier in fichiers.findall('./fichier'):\n            info_dict['duration'] = float_or_none(fichier.get('timecodefin'))\n            for quality, (format_id, suffix) in enumerate([('lq', ''), ('hq', '_hd')]):\n                format_url = fichier.get('url%s' % suffix)\n                if not format_url:\n                    continue\n                formats.append({\n                    'url': stream,\n                    'play_path': format_url,\n                    'ext': 'flv',\n                    'format_id': format_id,\n                    'width': int_or_none(concert.get('largeur%s' % suffix)),\n                    'height': int_or_none(concert.get('hauteur%s' % suffix)),\n                    'quality': quality,\n                })\n        self._sort_formats(formats)\n\n        date, hour = concert.get('date'), concert.get('heure')\n        if date and hour:\n            info_dict['timestamp'] = parse_iso8601(\n                '%s-%s-%sT%s:00' % (date[0:4], date[4:6], date[6:8], hour))\n        elif date:\n            info_dict['upload_date'] = date\n\n        return info_dict",
        "begin_line": 38,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.phoenix.PhoenixIE._real_extract#36",
        "src_path": "youtube_dl/extractor/phoenix.py",
        "class_name": "youtube_dl.extractor.phoenix.PhoenixIE",
        "signature": "youtube_dl.extractor.phoenix.PhoenixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        internal_id = self._search_regex(\n            r'<div class=\"phx_vod\" id=\"phx_vod_([0-9]+)\"',\n            webpage, 'internal video ID')\n\n        api_url = 'http://www.phoenix.de/php/mediaplayer/data/beitrags_details.php?ak=web&id=%s' % internal_id\n        return self.extract_from_xml_url(video_id, api_url)",
        "begin_line": 36,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract#25",
        "src_path": "youtube_dl/extractor/photobucket.py",
        "class_name": "youtube_dl.extractor.photobucket.PhotobucketIE",
        "signature": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_extension = mobj.group('ext')\n\n        webpage = self._download_webpage(url, video_id)\n\n        # Extract URL, uploader, and title from webpage\n        self.report_extraction(video_id)\n        info_json = self._search_regex(r'Pb\\.Data\\.Shared\\.put\\(Pb\\.Data\\.Shared\\.MEDIA, (.*?)\\);',\n                                       webpage, 'info json')\n        info = json.loads(info_json)\n        url = compat_urllib_parse_unquote(self._html_search_regex(r'file=(.+\\.mp4)', info['linkcodes']['html'], 'url'))\n        return {\n            'id': video_id,\n            'url': url,\n            'uploader': info['username'],\n            'timestamp': info['creationDate'],\n            'title': info['title'],\n            'ext': video_extension,\n            'thumbnail': info['thumbUrl'],\n        }",
        "begin_line": 25,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.piksel.PikselIE._extract_url#48",
        "src_path": "youtube_dl/extractor/piksel.py",
        "class_name": "youtube_dl.extractor.piksel.PikselIE",
        "signature": "youtube_dl.extractor.piksel.PikselIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=[\"\\'](?P<url>(?:https?:)?//player\\.piksel\\.com/v/[a-z0-9]+)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 48,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.piksel.PikselIE._real_extract#55",
        "src_path": "youtube_dl/extractor/piksel.py",
        "class_name": "youtube_dl.extractor.piksel.PikselIE",
        "signature": "youtube_dl.extractor.piksel.PikselIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        app_token = self._search_regex([\n            r'clientAPI\\s*:\\s*\"([^\"]+)\"',\n            r'data-de-api-key\\s*=\\s*\"([^\"]+)\"'\n        ], webpage, 'app token')\n        response = self._download_json(\n            'http://player.piksel.com/ws/ws_program/api/%s/mode/json/apiv/5' % app_token,\n            video_id, query={\n                'v': video_id\n            })['response']\n        failure = response.get('failure')\n        if failure:\n            raise ExtractorError(response['failure']['reason'], expected=True)\n        video_data = response['WsProgramResponse']['program']['asset']\n        title = video_data['title']\n\n        formats = []\n\n        m3u8_url = dict_get(video_data, [\n            'm3u8iPadURL',\n            'ipadM3u8Url',\n            'm3u8AndroidURL',\n            'm3u8iPhoneURL',\n            'iphoneM3u8Url'])\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                m3u8_url, video_id, 'mp4', 'm3u8_native',\n                m3u8_id='hls', fatal=False))\n\n        asset_type = dict_get(video_data, ['assetType', 'asset_type'])\n        for asset_file in video_data.get('assetFiles', []):\n            # TODO: extract rtmp formats\n            http_url = asset_file.get('http_url')\n            if not http_url:\n                continue\n            tbr = None\n            vbr = int_or_none(asset_file.get('videoBitrate'), 1024)\n            abr = int_or_none(asset_file.get('audioBitrate'), 1024)\n            if asset_type == 'video':\n                tbr = vbr + abr\n            elif asset_type == 'audio':\n                tbr = abr\n\n            format_id = ['http']\n            if tbr:\n                format_id.append(compat_str(tbr))\n\n            formats.append({\n                'format_id': '-'.join(format_id),\n                'url': unescapeHTML(http_url),\n                'vbr': vbr,\n                'abr': abr,\n                'width': int_or_none(asset_file.get('videoWidth')),\n                'height': int_or_none(asset_file.get('videoHeight')),\n                'filesize': int_or_none(asset_file.get('filesize')),\n                'tbr': tbr,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnailUrl'),\n            'timestamp': parse_iso8601(video_data.get('dateadd')),\n            'formats': formats,\n        }",
        "begin_line": 55,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pinkbike.PinkbikeIE._real_extract#39",
        "src_path": "youtube_dl/extractor/pinkbike.py",
        "class_name": "youtube_dl.extractor.pinkbike.PinkbikeIE",
        "signature": "youtube_dl.extractor.pinkbike.PinkbikeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.pinkbike.com/video/%s' % video_id, video_id)\n\n        formats = []\n        for _, format_id, src in re.findall(\n                r'data-quality=((?:\\\\)?[\"\\'])(.+?)\\1[^>]+src=\\1(.+?)\\1', webpage):\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None))\n            formats.append({\n                'url': src,\n                'format_id': format_id,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' Video - Pinkbike')\n        description = self._html_search_regex(\n            r'(?s)id=\"media-description\"[^>]*>(.+?)<',\n            webpage, 'description', default=None) or remove_start(\n            self._og_search_description(webpage), title + '. ')\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(self._html_search_meta(\n            'video:duration', webpage, 'duration'))\n\n        uploader = self._search_regex(\n            r'<a[^>]+\\brel=[\"\\']author[^>]+>([^<]+)', webpage,\n            'uploader', fatal=False)\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"fullTime\"[^>]+title=\"([^\"]+)\"',\n            webpage, 'upload date', fatal=False))\n\n        location = self._html_search_regex(\n            r'(?s)<dt>Location</dt>\\s*<dd>(.+?)<',\n            webpage, 'location', fatal=False)\n\n        def extract_count(webpage, label):\n            return str_to_int(self._search_regex(\n                r'<span[^>]+class=\"stat-num\"[^>]*>([\\d,.]+)</span>\\s*<span[^>]+class=\"stat-label\"[^>]*>%s' % label,\n                webpage, label, fatal=False))\n\n        view_count = extract_count(webpage, 'Views')\n        comment_count = extract_count(webpage, 'Comments')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'location': location,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats\n        }",
        "begin_line": 39,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pladform.PladformIE._extract_url#50",
        "src_path": "youtube_dl/extractor/pladform.py",
        "class_name": "youtube_dl.extractor.pladform.PladformIE",
        "signature": "youtube_dl.extractor.pladform.PladformIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//out\\.pladform\\.ru/player\\?.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 50,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pladform.PladformIE._real_extract#56",
        "src_path": "youtube_dl/extractor/pladform.py",
        "class_name": "youtube_dl.extractor.pladform.PladformIE",
        "signature": "youtube_dl.extractor.pladform.PladformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_xml(\n            'http://out.pladform.ru/getVideo?pl=1&videoid=%s' % video_id,\n            video_id)\n\n        if video.tag == 'error':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, video.text),\n                expected=True)\n\n        quality = qualities(('ld', 'sd', 'hd'))\n\n        formats = [{\n            'url': src.text,\n            'format_id': src.get('quality'),\n            'quality': quality(src.get('quality')),\n        } for src in video.findall('./src')]\n        self._sort_formats(formats)\n\n        webpage = self._download_webpage(\n            'http://video.pladform.ru/catalog/video/videoid/%s' % video_id,\n            video_id)\n\n        title = self._og_search_title(webpage, fatal=False) or xpath_text(\n            video, './/title', 'title', fatal=True)\n        description = self._search_regex(\n            r'</h3>\\s*<p>([^<]+)</p>', webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage) or xpath_text(\n            video, './/cover', 'cover')\n\n        duration = int_or_none(xpath_text(video, './/time', 'duration'))\n        age_limit = int_or_none(xpath_text(video, './/age18', 'age limit'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.playfm.PlayFMIE._real_extract#37",
        "src_path": "youtube_dl/extractor/playfm.py",
        "class_name": "youtube_dl.extractor.playfm.PlayFMIE",
        "signature": "youtube_dl.extractor.playfm.PlayFMIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        slug = mobj.group('slug')\n\n        recordings = self._download_json(\n            'http://v2api.play.fm/recordings/slug/%s' % slug, video_id)\n\n        error = recordings.get('error')\n        if isinstance(error, dict):\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error.get('message')),\n                expected=True)\n\n        audio_url = recordings['audio']\n        video_id = compat_str(recordings.get('id') or video_id)\n        title = recordings['title']\n        description = recordings.get('description')\n        duration = int_or_none(recordings.get('recordingDuration'))\n        timestamp = parse_iso8601(recordings.get('created_at'))\n        uploader = recordings.get('page', {}).get('title')\n        uploader_id = compat_str(recordings.get('page', {}).get('id'))\n        view_count = int_or_none(recordings.get('playCount'))\n        comment_count = int_or_none(recordings.get('commentCount'))\n        categories = [tag['name'] for tag in recordings.get('tags', []) if tag.get('name')]\n\n        return {\n            'id': video_id,\n            'url': audio_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n        }",
        "begin_line": 37,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.plays.PlaysTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/plays.py",
        "class_name": "youtube_dl.extractor.plays.PlaysTVIE",
        "signature": "youtube_dl.extractor.plays.PlaysTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'https://plays.tv/video/%s' % video_id, video_id)\n\n        info = self._search_json_ld(webpage, video_id,)\n\n        mpd_url, sources = re.search(\n            r'(?s)<video[^>]+data-mpd=\"([^\"]+)\"[^>]*>(.+?)</video>',\n            webpage).groups()\n        formats = self._extract_mpd_formats(\n            self._proto_relative_url(mpd_url), video_id, mpd_id='DASH')\n        for format_id, height, format_url in re.findall(r'<source\\s+res=\"((\\d+)h?)\"\\s+src=\"([^\"]+)\"', sources):\n            formats.append({\n                'url': self._proto_relative_url(format_url),\n                'format_id': 'http-' + format_id,\n                'height': int_or_none(height),\n            })\n        self._sort_formats(formats)\n\n        info.update({\n            'id': video_id,\n            'description': self._og_search_description(webpage),\n            'thumbnail': info.get('thumbnail') or self._og_search_thumbnail(webpage),\n            'formats': formats,\n        })\n\n        return info",
        "begin_line": 26,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.playtvak.PlaytvakIE._real_extract#92",
        "src_path": "youtube_dl/extractor/playtvak.py",
        "class_name": "youtube_dl.extractor.playtvak.PlaytvakIE",
        "signature": "youtube_dl.extractor.playtvak.PlaytvakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        info_url = self._html_search_regex(\n            r'Misc\\.videoFLV\\(\\s*{\\s*data\\s*:\\s*\"([^\"]+)\"', webpage, 'info url')\n\n        parsed_url = compat_urlparse.urlparse(info_url)\n\n        qs = compat_urlparse.parse_qs(parsed_url.query)\n        qs.update({\n            'reklama': ['0'],\n            'type': ['js'],\n        })\n\n        info_url = compat_urlparse.urlunparse(\n            parsed_url._replace(query=compat_urllib_parse_urlencode(qs, True)))\n\n        json_info = self._download_json(\n            info_url, video_id,\n            transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])\n\n        item = None\n        for i in json_info['items']:\n            if i.get('type') == 'video' or i.get('type') == 'stream':\n                item = i\n                break\n        if not item:\n            raise ExtractorError('No suitable stream found')\n\n        quality = qualities(('low', 'middle', 'high'))\n\n        formats = []\n        for fmt in item['video']:\n            video_url = fmt.get('file')\n            if not video_url:\n                continue\n\n            format_ = fmt['format']\n            format_id = '%s_%s' % (format_, fmt['quality'])\n            preference = None\n\n            if format_ in ('mp4', 'webm'):\n                ext = format_\n            elif format_ == 'rtmp':\n                ext = 'flv'\n            elif format_ == 'apple':\n                ext = 'mp4'\n                # Some streams have mp3 audio which does not play\n                # well with ffmpeg filter aac_adtstoasc\n                preference = -1\n            elif format_ == 'adobe':  # f4m manifest fails with 404 in 80% of requests\n                continue\n            else:  # Other formats not supported yet\n                continue\n\n            formats.append({\n                'url': video_url,\n                'ext': ext,\n                'format_id': format_id,\n                'quality': quality(fmt.get('quality')),\n                'preference': preference,\n            })\n        self._sort_formats(formats)\n\n        title = item['title']\n        is_live = item['type'] == 'stream'\n        if is_live:\n            title = self._live_title(title)\n        description = self._og_search_description(webpage, default=None) or self._html_search_meta(\n            'description', webpage, 'description')\n        timestamp = None\n        duration = None\n        if not is_live:\n            duration = int_or_none(item.get('length'))\n            timestamp = item.get('published')\n            if timestamp:\n                timestamp = parse_iso8601(timestamp[:-5])\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': item.get('image'),\n            'duration': duration,\n            'timestamp': timestamp,\n            'is_live': is_live,\n            'formats': formats,\n        }",
        "begin_line": 92,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.playvid.PlayvidIE._real_extract#41",
        "src_path": "youtube_dl/extractor/playvid.py",
        "class_name": "youtube_dl.extractor.playvid.PlayvidIE",
        "signature": "youtube_dl.extractor.playvid.PlayvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        m_error = re.search(\n            r'<div class=\"block-error\">\\s*<div class=\"heading\">\\s*<div>(?P<msg>.+?)</div>\\s*</div>', webpage)\n        if m_error:\n            raise ExtractorError(clean_html(m_error.group('msg')), expected=True)\n\n        video_title = None\n        duration = None\n        video_thumbnail = None\n        formats = []\n\n        # most of the information is stored in the flashvars\n        flashvars = self._html_search_regex(\n            r'flashvars=\"(.+?)\"', webpage, 'flashvars')\n\n        infos = compat_urllib_parse_unquote(flashvars).split(r'&')\n        for info in infos:\n            videovars_match = re.match(r'^video_vars\\[(.+?)\\]=(.+?)$', info)\n            if videovars_match:\n                key = videovars_match.group(1)\n                val = videovars_match.group(2)\n\n                if key == 'title':\n                    video_title = compat_urllib_parse_unquote_plus(val)\n                if key == 'duration':\n                    try:\n                        duration = int(val)\n                    except ValueError:\n                        pass\n                if key == 'big_thumb':\n                    video_thumbnail = val\n\n                videourl_match = re.match(\n                    r'^video_urls\\]\\[(?P<resolution>[0-9]+)p', key)\n                if videourl_match:\n                    height = int(videourl_match.group('resolution'))\n                    formats.append({\n                        'height': height,\n                        'url': val,\n                    })\n        self._sort_formats(formats)\n\n        # Extract title - should be in the flashvars; if not, look elsewhere\n        if video_title is None:\n            video_title = self._html_search_regex(\n                r'<title>(.*?)</title', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'duration': duration,\n            'description': None,\n            'age_limit': 18\n        }",
        "begin_line": 41,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.playwire.PlaywireIE._real_extract#48",
        "src_path": "youtube_dl/extractor/playwire.py",
        "class_name": "youtube_dl.extractor.playwire.PlaywireIE",
        "signature": "youtube_dl.extractor.playwire.PlaywireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        publisher_id, video_id = mobj.group('publisher_id'), mobj.group('id')\n\n        player = self._download_json(\n            'http://config.playwire.com/%s/videos/v2/%s/zeus.json' % (publisher_id, video_id),\n            video_id)\n\n        title = player['settings']['title']\n        duration = float_or_none(player.get('duration'), 1000)\n\n        content = player['content']\n        thumbnail = content.get('poster')\n        src = content['media']['f4m']\n\n        formats = self._extract_f4m_formats(src, video_id, m3u8_id='hls')\n        for a_format in formats:\n            if not dict_get(a_format, ['tbr', 'width', 'height']):\n                a_format['quality'] = 1 if '-hd.' in a_format['url'] else 0\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 48,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightBaseIE._download_course#30",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightBaseIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightBaseIE._download_course(self, course_id, url, display_id)",
        "snippet": "    def _download_course(self, course_id, url, display_id):\n        try:\n            return self._download_course_rpc(course_id, url, display_id)\n        except ExtractorError:\n            # Old API fallback\n            return self._download_json(\n                'https://app.pluralsight.com/player/user/api/v1/player/payload',\n                display_id, data=urlencode_postdata({'courseId': course_id}),\n                headers={'Referer': url})",
        "begin_line": 30,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightBaseIE._download_course_rpc#40",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightBaseIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightBaseIE._download_course_rpc(self, course_id, url, display_id)",
        "snippet": "    def _download_course_rpc(self, course_id, url, display_id):\n        response = self._download_json(\n            '%s/player/functions/rpc' % self._API_BASE, display_id,\n            'Downloading course JSON',\n            data=json.dumps({\n                'fn': 'bootstrapPlayer',\n                'payload': {\n                    'courseId': course_id,\n                },\n            }).encode('utf-8'),\n            headers={\n                'Content-Type': 'application/json;charset=utf-8',\n                'Referer': url,\n            })\n\n        course = try_get(response, lambda x: x['payload']['course'], dict)\n        if course:\n            return course\n\n        raise ExtractorError(\n            '%s said: %s' % (self.IE_NAME, response['error']['message']),\n            expected=True)",
        "begin_line": 40,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._real_initialize#93",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 93,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._login#96",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'Username': username,\n            'Password': password,\n        })\n\n        post_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', login_page,\n            'post url', default=self._LOGIN_URL, group='url')\n\n        if not post_url.startswith('http'):\n            post_url = compat_urlparse.urljoin(self._LOGIN_URL, post_url)\n\n        response = self._download_webpage(\n            post_url, None, 'Logging in as %s' % username,\n            data=urlencode_postdata(login_form),\n            headers={'Content-Type': 'application/x-www-form-urlencoded'})\n\n        error = self._search_regex(\n            r'<span[^>]+class=\"field-validation-error\"[^>]*>([^<]+)</span>',\n            response, 'error message', default=None)\n        if error:\n            raise ExtractorError('Unable to login: %s' % error, expected=True)\n\n        if all(p not in response for p in ('__INITIAL_STATE__', '\"currentUser\"')):\n            BLOCKED = 'Your account has been blocked due to suspicious activity'\n            if BLOCKED in response:\n                raise ExtractorError(\n                    'Unable to login: %s' % BLOCKED, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 96,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._get_subtitles#136",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._get_subtitles(self, author, clip_id, lang, name, duration, video_id)",
        "snippet": "    def _get_subtitles(self, author, clip_id, lang, name, duration, video_id):\n        captions_post = {\n            'a': author,\n            'cn': clip_id,\n            'lc': lang,\n            'm': name,\n        }\n        captions = self._download_json(\n            '%s/player/retrieve-captions' % self._API_BASE, video_id,\n            'Downloading captions JSON', 'Unable to download captions JSON',\n            fatal=False, data=json.dumps(captions_post).encode('utf-8'),\n            headers={'Content-Type': 'application/json;charset=utf-8'})\n        if captions:\n            return {\n                lang: [{\n                    'ext': 'json',\n                    'data': json.dumps(captions),\n                }, {\n                    'ext': 'srt',\n                    'data': self._convert_subtitles(duration, captions),\n                }]\n            }",
        "begin_line": 136,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._convert_subtitles#160",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._convert_subtitles(duration, subs)",
        "snippet": "    def _convert_subtitles(duration, subs):\n        srt = ''\n        TIME_OFFSET_KEYS = ('displayTimeOffset', 'DisplayTimeOffset')\n        TEXT_KEYS = ('text', 'Text')\n        for num, current in enumerate(subs):\n            current = subs[num]\n            start, text = (\n                float_or_none(dict_get(current, TIME_OFFSET_KEYS)),\n                dict_get(current, TEXT_KEYS))\n            if start is None or text is None:\n                continue\n            end = duration if num == len(subs) - 1 else float_or_none(\n                dict_get(subs[num + 1], TIME_OFFSET_KEYS))\n            if end is None:\n                continue\n            srt += os.linesep.join(\n                (\n                    '%d' % num,\n                    '%s --> %s' % (\n                        srt_subtitles_timecode(start),\n                        srt_subtitles_timecode(end)),\n                    text,\n                    os.linesep,\n                ))\n        return srt",
        "begin_line": 160,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightIE._real_extract#186",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n\n        author = qs.get('author', [None])[0]\n        name = qs.get('name', [None])[0]\n        clip_id = qs.get('clip', [None])[0]\n        course_name = qs.get('course', [None])[0]\n\n        if any(not f for f in (author, name, clip_id, course_name,)):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        display_id = '%s-%s' % (name, clip_id)\n\n        course = self._download_course(course_name, url, display_id)\n\n        collection = course['modules']\n\n        clip = None\n\n        for module_ in collection:\n            if name in (module_.get('moduleName'), module_.get('name')):\n                for clip_ in module_.get('clips', []):\n                    clip_index = clip_.get('clipIndex')\n                    if clip_index is None:\n                        clip_index = clip_.get('index')\n                    if clip_index is None:\n                        continue\n                    if compat_str(clip_index) == clip_id:\n                        clip = clip_\n                        break\n\n        if not clip:\n            raise ExtractorError('Unable to resolve clip')\n\n        title = clip['title']\n\n        QUALITIES = {\n            'low': {'width': 640, 'height': 480},\n            'medium': {'width': 848, 'height': 640},\n            'high': {'width': 1024, 'height': 768},\n            'high-widescreen': {'width': 1280, 'height': 720},\n        }\n\n        QUALITIES_PREFERENCE = ('low', 'medium', 'high', 'high-widescreen',)\n        quality_key = qualities(QUALITIES_PREFERENCE)\n\n        AllowedQuality = collections.namedtuple('AllowedQuality', ['ext', 'qualities'])\n\n        ALLOWED_QUALITIES = (\n            AllowedQuality('webm', ['high', ]),\n            AllowedQuality('mp4', ['low', 'medium', 'high', ]),\n        )\n\n        # Some courses also offer widescreen resolution for high quality (see\n        # https://github.com/rg3/youtube-dl/issues/7766)\n        widescreen = course.get('supportsWideScreenVideoFormats') is True\n        best_quality = 'high-widescreen' if widescreen else 'high'\n        if widescreen:\n            for allowed_quality in ALLOWED_QUALITIES:\n                allowed_quality.qualities.append(best_quality)\n\n        # In order to minimize the number of calls to ViewClip API and reduce\n        # the probability of being throttled or banned by Pluralsight we will request\n        # only single format until formats listing was explicitly requested.\n        if self._downloader.params.get('listformats', False):\n            allowed_qualities = ALLOWED_QUALITIES\n        else:\n            def guess_allowed_qualities():\n                req_format = self._downloader.params.get('format') or 'best'\n                req_format_split = req_format.split('-', 1)\n                if len(req_format_split) > 1:\n                    req_ext, req_quality = req_format_split\n                    req_quality = '-'.join(req_quality.split('-')[:2])\n                    for allowed_quality in ALLOWED_QUALITIES:\n                        if req_ext == allowed_quality.ext and req_quality in allowed_quality.qualities:\n                            return (AllowedQuality(req_ext, (req_quality, )), )\n                req_ext = 'webm' if self._downloader.params.get('prefer_free_formats') else 'mp4'\n                return (AllowedQuality(req_ext, (best_quality, )), )\n            allowed_qualities = guess_allowed_qualities()\n\n        formats = []\n        for ext, qualities_ in allowed_qualities:\n            for quality in qualities_:\n                f = QUALITIES[quality].copy()\n                clip_post = {\n                    'author': author,\n                    'includeCaptions': False,\n                    'clipIndex': int(clip_id),\n                    'courseName': course_name,\n                    'locale': 'en',\n                    'moduleName': name,\n                    'mediaType': ext,\n                    'quality': '%dx%d' % (f['width'], f['height']),\n                }\n                format_id = '%s-%s' % (ext, quality)\n                viewclip = self._download_json(\n                    '%s/video/clips/viewclip' % self._API_BASE, display_id,\n                    'Downloading %s viewclip JSON' % format_id, fatal=False,\n                    data=json.dumps(clip_post).encode('utf-8'),\n                    headers={'Content-Type': 'application/json;charset=utf-8'})\n\n                # Pluralsight tracks multiple sequential calls to ViewClip API and start\n                # to return 429 HTTP errors after some time (see\n                # https://github.com/rg3/youtube-dl/pull/6989). Moreover it may even lead\n                # to account ban (see https://github.com/rg3/youtube-dl/issues/6842).\n                # To somewhat reduce the probability of these consequences\n                # we will sleep random amount of time before each call to ViewClip.\n                self._sleep(\n                    random.randint(2, 5), display_id,\n                    '%(video_id)s: Waiting for %(timeout)s seconds to avoid throttling')\n\n                if not viewclip:\n                    continue\n\n                clip_urls = viewclip.get('urls')\n                if not isinstance(clip_urls, list):\n                    continue\n\n                for clip_url_data in clip_urls:\n                    clip_url = clip_url_data.get('url')\n                    if not clip_url:\n                        continue\n                    cdn = clip_url_data.get('cdn')\n                    clip_f = f.copy()\n                    clip_f.update({\n                        'url': clip_url,\n                        'ext': ext,\n                        'format_id': '%s-%s' % (format_id, cdn) if cdn else format_id,\n                        'quality': quality_key(quality),\n                        'source_preference': int_or_none(clip_url_data.get('rank')),\n                    })\n                    formats.append(clip_f)\n\n        self._sort_formats(formats)\n\n        duration = int_or_none(\n            clip.get('duration')) or parse_duration(clip.get('formattedDuration'))\n\n        # TODO: other languages?\n        subtitles = self.extract_subtitles(\n            author, clip_id, 'en', name, duration, display_id)\n\n        return {\n            'id': clip.get('clipName') or clip['name'],\n            'title': title,\n            'duration': duration,\n            'creator': author,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 186,
        "end_line": 335,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pluralsight.PluralsightCourseIE._real_extract#360",
        "src_path": "youtube_dl/extractor/pluralsight.py",
        "class_name": "youtube_dl.extractor.pluralsight.PluralsightCourseIE",
        "signature": "youtube_dl.extractor.pluralsight.PluralsightCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_id = self._match_id(url)\n\n        # TODO: PSM cookie\n\n        course = self._download_course(course_id, url, course_id)\n\n        title = course['title']\n        course_name = course['name']\n        course_data = course['modules']\n        description = course.get('description') or course.get('shortDescription')\n\n        entries = []\n        for num, module in enumerate(course_data, 1):\n            author = module.get('author')\n            module_name = module.get('name')\n            if not author or not module_name:\n                continue\n            for clip in module.get('clips', []):\n                clip_index = int_or_none(clip.get('index'))\n                if clip_index is None:\n                    continue\n                clip_url = update_url_query(\n                    '%s/player' % self._API_BASE, query={\n                        'mode': 'live',\n                        'course': course_name,\n                        'author': author,\n                        'name': module_name,\n                        'clip': clip_index,\n                    })\n                entries.append({\n                    '_type': 'url_transparent',\n                    'url': clip_url,\n                    'ie_key': PluralsightIE.ie_key(),\n                    'chapter': module.get('title'),\n                    'chapter_number': num,\n                    'chapter_id': module.get('moduleRef'),\n                })\n\n        return self.playlist_result(entries, course_id, title, description)",
        "begin_line": 360,
        "end_line": 399,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract#48",
        "src_path": "youtube_dl/extractor/podomatic.py",
        "class_name": "youtube_dl.extractor.podomatic.PodomaticIE",
        "signature": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel = mobj.group('channel') or mobj.group('channel_2')\n\n        json_url = (('%s://%s.podomatic.com/entry/embed_params/%s' +\n                     '?permalink=true&rtmp=0') %\n                    (mobj.group('proto'), channel, video_id))\n        data_json = self._download_webpage(\n            json_url, video_id, 'Downloading video info')\n        data = json.loads(data_json)\n\n        video_url = data['downloadLink']\n        if not video_url:\n            video_url = '%s/%s' % (data['streamer'].replace('rtmp', 'http'), data['mediaLocation'])\n        uploader = data['podcast']\n        title = data['title']\n        thumbnail = data['imageLocation']\n        duration = int_or_none(data.get('length'), 1000)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': channel,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 48,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pokemon.PokemonIE._real_extract#38",
        "src_path": "youtube_dl/extractor/pokemon.py",
        "class_name": "youtube_dl.extractor.pokemon.PokemonIE",
        "signature": "youtube_dl.extractor.pokemon.PokemonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id = re.match(self._VALID_URL, url).groups()\n        webpage = self._download_webpage(url, video_id or display_id)\n        video_data = extract_attributes(self._search_regex(\n            r'(<[^>]+data-video-id=\"%s\"[^>]*>)' % (video_id if video_id else '[a-z0-9]{32}'),\n            webpage, 'video data element'))\n        video_id = video_data['data-video-id']\n        title = video_data['data-video-title']\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': 'limelight:media:%s' % video_id,\n            'title': title,\n            'description': video_data.get('data-video-summary'),\n            'thumbnail': video_data.get('data-video-poster'),\n            'series': 'Pok\u00e9mon',\n            'season_number': int_or_none(video_data.get('data-video-season')),\n            'episode': title,\n            'episode_number': int_or_none(video_data.get('data-video-episode')),\n            'ie_key': 'LimelightMedia',\n        }",
        "begin_line": 38,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.polskieradio.PolskieRadioIE._real_extract#62",
        "src_path": "youtube_dl/extractor/polskieradio.py",
        "class_name": "youtube_dl.extractor.polskieradio.PolskieRadioIE",
        "signature": "youtube_dl.extractor.polskieradio.PolskieRadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        content = self._search_regex(\n            r'(?s)<div[^>]+class=\"\\s*this-article\\s*\"[^>]*>(.+?)<div[^>]+class=\"tags\"[^>]*>',\n            webpage, 'content')\n\n        timestamp = unified_timestamp(self._html_search_regex(\n            r'(?s)<span[^>]+id=\"datetime2\"[^>]*>(.+?)</span>',\n            webpage, 'timestamp', fatal=False))\n\n        thumbnail_url = self._og_search_thumbnail(webpage)\n\n        entries = []\n\n        media_urls = set()\n\n        for data_media in re.findall(r'<[^>]+data-media=({[^>]+})', content):\n            media = self._parse_json(data_media, playlist_id, fatal=False)\n            if not media.get('file') or not media.get('desc'):\n                continue\n            media_url = self._proto_relative_url(media['file'], 'http:')\n            if media_url in media_urls:\n                continue\n            media_urls.add(media_url)\n            entries.append({\n                'id': compat_str(media['id']),\n                'url': media_url,\n                'title': compat_urllib_parse_unquote(media['desc']),\n                'duration': int_or_none(media.get('length')),\n                'vcodec': 'none' if media.get('provider') == 'audio' else None,\n                'timestamp': timestamp,\n                'thumbnail': thumbnail_url\n            })\n\n        title = self._og_search_title(webpage).strip()\n        description = strip_or_none(self._og_search_description(webpage))\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 62,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE.suitable#147",
        "src_path": "youtube_dl/extractor/polskieradio.py",
        "class_name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE",
        "signature": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if PolskieRadioIE.suitable(url) else super(PolskieRadioCategoryIE, cls).suitable(url)",
        "begin_line": 147,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE._entries#150",
        "src_path": "youtube_dl/extractor/polskieradio.py",
        "class_name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE",
        "signature": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE._entries(self, url, page, category_id)",
        "snippet": "    def _entries(self, url, page, category_id):\n        content = page\n        for page_num in itertools.count(2):\n            for a_entry, entry_id in re.findall(\n                    r'(?s)<article[^>]+>.*?(<a[^>]+href=[\"\\']/\\d+/\\d+/Artykul/(\\d+)[^>]+>).*?</article>',\n                    content):\n                entry = extract_attributes(a_entry)\n                href = entry.get('href')\n                if not href:\n                    continue\n                yield self.url_result(\n                    compat_urlparse.urljoin(url, href), PolskieRadioIE.ie_key(),\n                    entry_id, entry.get('title'))\n            mobj = re.search(\n                r'<div[^>]+class=[\"\\']next[\"\\'][^>]*>\\s*<a[^>]+href=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n                content)\n            if not mobj:\n                break\n            next_url = compat_urlparse.urljoin(url, mobj.group('url'))\n            content = self._download_webpage(\n                next_url, category_id, 'Downloading page %s' % page_num)",
        "begin_line": 150,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE._real_extract#172",
        "src_path": "youtube_dl/extractor/polskieradio.py",
        "class_name": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE",
        "signature": "youtube_dl.extractor.polskieradio.PolskieRadioCategoryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        category_id = self._match_id(url)\n        webpage = self._download_webpage(url, category_id)\n        title = self._html_search_regex(\n            r'<title>([^<]+) - [^<]+ - [^<]+</title>',\n            webpage, 'title', fatal=False)\n        return self.playlist_result(\n            self._entries(url, webpage, category_id),\n            category_id, title)",
        "begin_line": 172,
        "end_line": 180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.porn91.Porn91IE._real_extract#28",
        "src_path": "youtube_dl/extractor/porn91.py",
        "class_name": "youtube_dl.extractor.porn91.Porn91IE",
        "signature": "youtube_dl.extractor.porn91.Porn91IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        self._set_cookie('91porn.com', 'language', 'cn_CN')\n\n        webpage = self._download_webpage(\n            'http://91porn.com/view_video.php?viewkey=%s' % video_id, video_id)\n\n        if '\u4f5c\u4e3a\u6e38\u5ba2\uff0c\u4f60\u6bcf\u5929\u53ea\u53ef\u89c2\u770b10\u4e2a\u89c6\u9891' in webpage:\n            raise ExtractorError('91 Porn says: Daily limit 10 videos exceeded', expected=True)\n\n        title = self._search_regex(\n            r'<div id=\"viewvideo-title\">([^<]+)</div>', webpage, 'title')\n        title = title.replace('\\n', '')\n\n        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]\n\n        duration = parse_duration(self._search_regex(\n            r'\u65f6\u957f:\\s*</span>\\s*(\\d+:\\d+)', webpage, 'duration', fatal=False))\n\n        comment_count = int_or_none(self._search_regex(\n            r'\u7559\u8a00:\\s*</span>\\s*(\\d+)', webpage, 'comment count', fatal=False))\n\n        info_dict.update({\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'comment_count': comment_count,\n            'age_limit': self._rta_search(webpage),\n        })\n\n        return info_dict",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.porncom.PornComIE._real_extract#37",
        "src_path": "youtube_dl/extractor/porncom.py",
        "class_name": "youtube_dl.extractor.porncom.PornComIE",
        "signature": "youtube_dl.extractor.porncom.PornComIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        config = self._parse_json(\n            self._search_regex(\n                r'=\\s*({.+?})\\s*,\\s*[\\da-zA-Z_]+\\s*=',\n                webpage, 'config', default='{}'),\n            display_id, transform_source=js_to_json, fatal=False)\n\n        if config:\n            title = config['title']\n            formats = [{\n                'url': stream['url'],\n                'format_id': stream.get('id'),\n                'height': int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]', stream.get('id') or '', 'height', default=None))\n            } for stream in config['streams'] if stream.get('url')]\n            thumbnail = (compat_urlparse.urljoin(\n                config['thumbCDN'], config['poster'])\n                if config.get('thumbCDN') and config.get('poster') else None)\n            duration = int_or_none(config.get('length'))\n        else:\n            title = self._search_regex(\n                (r'<title>([^<]+)</title>', r'<h1[^>]*>([^<]+)</h1>'),\n                webpage, 'title')\n            formats = [{\n                'url': compat_urlparse.urljoin(url, format_url),\n                'format_id': '%sp' % height,\n                'height': int(height),\n                'filesize_approx': parse_filesize(filesize),\n            } for format_url, height, filesize in re.findall(\n                r'<a[^>]+href=\"(/download/[^\"]+)\">MPEG4 (\\d+)p<span[^>]*>(\\d+\\s+[a-zA-Z]+)<',\n                webpage)]\n            thumbnail = None\n            duration = None\n\n        self._sort_formats(formats)\n\n        view_count = str_to_int(self._search_regex(\n            r'class=[\"\\']views[\"\\'][^>]*><p>([\\d,.]+)', webpage,\n            'view count', fatal=False))\n\n        def extract_list(kind):\n            s = self._search_regex(\n                r'(?s)<p[^>]*>%s:(.+?)</p>' % kind.capitalize(),\n                webpage, kind, fatal=False)\n            return re.findall(r'<a[^>]+>([^<]+)</a>', s or '')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n            'categories': extract_list('categories'),\n            'tags': extract_list('tags'),\n        }",
        "begin_line": 37,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornflip.PornFlipIE._real_extract#39",
        "src_path": "youtube_dl/extractor/pornflip.py",
        "class_name": "youtube_dl.extractor.pornflip.PornFlipIE",
        "signature": "youtube_dl.extractor.pornflip.PornFlipIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://www.pornflip.com/v/%s' % video_id, video_id)\n\n        flashvars = compat_parse_qs(self._search_regex(\n            r'<embed[^>]+flashvars=([\"\\'])(?P<flashvars>(?:(?!\\1).)+)\\1',\n            webpage, 'flashvars', group='flashvars'))\n\n        title = flashvars['video_vars[title]'][0]\n\n        def flashvar(kind):\n            return try_get(\n                flashvars, lambda x: x['video_vars[%s]' % kind][0], compat_str)\n\n        formats = []\n        for key, value in flashvars.items():\n            if not (value and isinstance(value, list)):\n                continue\n            format_url = value[0]\n            if key == 'video_vars[hds_manifest]':\n                formats.extend(self._extract_mpd_formats(\n                    format_url, video_id, mpd_id='dash', fatal=False))\n                continue\n            height = self._search_regex(\n                r'video_vars\\[video_urls\\]\\[(\\d+)', key, 'height', default=None)\n            if not height:\n                continue\n            formats.append({\n                'url': format_url,\n                'format_id': 'http-%s' % height,\n                'height': int_or_none(height),\n            })\n        self._sort_formats(formats)\n\n        uploader = self._html_search_regex(\n            (r'<span[^>]+class=\"name\"[^>]*>\\s*<a[^>]+>\\s*<strong>(?P<uploader>[^<]+)',\n             r'<meta[^>]+content=([\"\\'])[^>]*\\buploaded by (?P<uploader>.+?)\\1'),\n            webpage, 'uploader', fatal=False, group='uploader')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'thumbnail': flashvar('big_thumb'),\n            'duration': int_or_none(flashvar('duration')),\n            'timestamp': unified_timestamp(self._html_search_meta(\n                'uploadDate', webpage, 'timestamp')),\n            'uploader_id': flashvar('author_id'),\n            'uploader': uploader,\n            'view_count': int_or_none(flashvar('views')),\n            'age_limit': 18,\n        }",
        "begin_line": 39,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhd.PornHdIE._real_extract#45",
        "src_path": "youtube_dl/extractor/pornhd.py",
        "class_name": "youtube_dl.extractor.pornhd.PornHdIE",
        "signature": "youtube_dl.extractor.pornhd.PornHdIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id or video_id)\n\n        title = self._html_search_regex(\n            [r'<span[^>]+class=[\"\\']video-name[\"\\'][^>]*>([^<]+)',\n             r'<title>(.+?) - .*?[Pp]ornHD.*?</title>'], webpage, 'title')\n\n        sources = self._parse_json(js_to_json(self._search_regex(\n            r\"(?s)sources'?\\s*:\\s*(\\{.+?\\})\\s*\\}[;,)]\",\n            webpage, 'sources', default='{}')), video_id)\n\n        if not sources:\n            message = self._html_search_regex(\n                r'(?s)<(div|p)[^>]+class=\"no-video\"[^>]*>(?P<value>.+?)</\\1',\n                webpage, 'error message', group='value')\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, message), expected=True)\n\n        formats = []\n        for format_id, video_url in sources.items():\n            if not video_url:\n                continue\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]', format_id, 'height', default=None))\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(\n            r'<(div|p)[^>]+class=\"description\"[^>]*>(?P<value>[^<]+)</\\1',\n            webpage, 'description', fatal=False, group='value')\n        view_count = int_or_none(self._html_search_regex(\n            r'(\\d+) views\\s*<', webpage, 'view count', fatal=False))\n        thumbnail = self._search_regex(\n            r\"'poster'\\s*:\\s*'([^']+)'\", webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 45,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._extract_urls#106",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+?src=[\"\\'](?P<url>(?:https?:)?//(?:www\\.)?pornhub\\.com/embed/[\\da-z]+)',\n            webpage)",
        "begin_line": 106,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._extract_count#111",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._extract_count(self, pattern, webpage, name)",
        "snippet": "    def _extract_count(self, pattern, webpage, name):\n        return str_to_int(self._search_regex(\n            pattern, webpage, '%s count' % name, fatal=False))",
        "begin_line": 111,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._real_extract#115",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        def dl_webpage(platform):\n            return self._download_webpage(\n                'http://www.pornhub.com/view_video.php?viewkey=%s' % video_id,\n                video_id, headers={\n                    'Cookie': 'age_verified=1; platform=%s' % platform,\n                })\n\n        webpage = dl_webpage('pc')\n\n        error_msg = self._html_search_regex(\n            r'(?s)<div[^>]+class=([\"\\'])(?:(?!\\1).)*\\b(?:removed|userMessageSection)\\b(?:(?!\\1).)*\\1[^>]*>(?P<error>.+?)</div>',\n            webpage, 'error message', default=None, group='error')\n        if error_msg:\n            error_msg = re.sub(r'\\s+', ' ', error_msg)\n            raise ExtractorError(\n                'PornHub said: %s' % error_msg,\n                expected=True, video_id=video_id)\n\n        tv_webpage = dl_webpage('tv')\n\n        assignments = self._search_regex(\n            r'(var.+?mediastring.+?)</script>', tv_webpage,\n            'encoded url').split(';')\n\n        js_vars = {}\n\n        def parse_js_value(inp):\n            inp = re.sub(r'/\\*(?:(?!\\*/).)*?\\*/', '', inp)\n            if '+' in inp:\n                inps = inp.split('+')\n                return functools.reduce(\n                    operator.concat, map(parse_js_value, inps))\n            inp = inp.strip()\n            if inp in js_vars:\n                return js_vars[inp]\n            return remove_quotes(inp)\n\n        for assn in assignments:\n            assn = assn.strip()\n            if not assn:\n                continue\n            assn = re.sub(r'var\\s+', '', assn)\n            vname, value = assn.split('=', 1)\n            js_vars[vname] = parse_js_value(value)\n\n        video_url = js_vars['mediastring']\n\n        title = self._search_regex(\n            r'<h1>([^>]+)</h1>', tv_webpage, 'title', default=None)\n\n        # video_title from flashvars contains whitespace instead of non-ASCII (see\n        # http://www.pornhub.com/view_video.php?viewkey=1331683002), not relying\n        # on that anymore.\n        title = title or self._html_search_meta(\n            'twitter:title', webpage, default=None) or self._search_regex(\n            (r'<h1[^>]+class=[\"\\']title[\"\\'][^>]*>(?P<title>[^<]+)',\n             r'<div[^>]+data-video-title=([\"\\'])(?P<title>.+?)\\1',\n             r'shareTitle\\s*=\\s*([\"\\'])(?P<title>.+?)\\1'),\n            webpage, 'title', group='title')\n\n        flashvars = self._parse_json(\n            self._search_regex(\n                r'var\\s+flashvars_\\d+\\s*=\\s*({.+?});', webpage, 'flashvars', default='{}'),\n            video_id)\n        if flashvars:\n            thumbnail = flashvars.get('image_url')\n            duration = int_or_none(flashvars.get('video_duration'))\n        else:\n            title, thumbnail, duration = [None] * 3\n\n        video_uploader = self._html_search_regex(\n            r'(?s)From:&nbsp;.+?<(?:a href=\"/users/|a href=\"/channels/|span class=\"username)[^>]+>(.+?)<',\n            webpage, 'uploader', fatal=False)\n\n        view_count = self._extract_count(\n            r'<span class=\"count\">([\\d,\\.]+)</span> views', webpage, 'view')\n        like_count = self._extract_count(\n            r'<span class=\"votesUp\">([\\d,\\.]+)</span>', webpage, 'like')\n        dislike_count = self._extract_count(\n            r'<span class=\"votesDown\">([\\d,\\.]+)</span>', webpage, 'dislike')\n        comment_count = self._extract_count(\n            r'All Comments\\s*<span>\\(([\\d,.]+)\\)', webpage, 'comment')\n\n        page_params = self._parse_json(self._search_regex(\n            r'page_params\\.zoneDetails\\[([\\'\"])[^\\'\"]+\\1\\]\\s*=\\s*(?P<data>{[^}]+})',\n            webpage, 'page parameters', group='data', default='{}'),\n            video_id, transform_source=js_to_json, fatal=False)\n        tags = categories = None\n        if page_params:\n            tags = page_params.get('tags', '').split(',')\n            categories = page_params.get('categories', '').split(',')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': video_uploader,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            # 'formats': formats,\n            'age_limit': 18,\n            'tags': tags,\n            'categories': categories,\n        }",
        "begin_line": 115,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE._extract_entries#229",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE._extract_entries(self, webpage)",
        "snippet": "    def _extract_entries(self, webpage):\n        # Only process container div with main playlist content skipping\n        # drop-down menu that uses similar pattern for videos (see\n        # https://github.com/rg3/youtube-dl/issues/11594).\n        container = self._search_regex(\n            r'(?s)(<div[^>]+class=[\"\\']container.+)', webpage,\n            'container', default=webpage)\n\n        return [\n            self.url_result(\n                'http://www.pornhub.com/%s' % video_url,\n                PornHubIE.ie_key(), video_title=title)\n            for video_url, title in orderedSet(re.findall(\n                r'href=\"/?(view_video\\.php\\?.*\\bviewkey=[\\da-z]+[^\"]*)\"[^>]*\\s+title=\"([^\"]+)\"',\n                container))\n        ]",
        "begin_line": 229,
        "end_line": 244,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE._real_extract#246",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = self._extract_entries(webpage)\n\n        playlist = self._parse_json(\n            self._search_regex(\n                r'(?:playlistObject|PLAYLIST_VIEW)\\s*=\\s*({.+?});', webpage,\n                'playlist', default='{}'),\n            playlist_id, fatal=False)\n        title = playlist.get('title') or self._search_regex(\n            r'>Videos\\s+in\\s+(.+?)\\s+[Pp]laylist<', webpage, 'title', fatal=False)\n\n        return self.playlist_result(\n            entries, playlist_id, title, playlist.get('description'))",
        "begin_line": 246,
        "end_line": 262,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubUserVideosIE._real_extract#290",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubUserVideosIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubUserVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n\n        entries = []\n        for page_num in itertools.count(1):\n            try:\n                webpage = self._download_webpage(\n                    url, user_id, 'Downloading page %d' % page_num,\n                    query={'page': page_num})\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code == 404:\n                    break\n                raise\n            page_entries = self._extract_entries(webpage)\n            if not page_entries:\n                break\n            entries.extend(page_entries)\n\n        return self.playlist_result(entries, user_id)",
        "begin_line": 290,
        "end_line": 308,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract#28",
        "src_path": "youtube_dl/extractor/pornotube.py",
        "class_name": "youtube_dl.extractor.pornotube.PornotubeIE",
        "signature": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        token = self._download_json(\n            'https://api.aebn.net/auth/v2/origins/authenticate',\n            video_id, note='Downloading token',\n            data=json.dumps({'credentials': 'Clip Application'}).encode('utf-8'),\n            headers={\n                'Content-Type': 'application/json',\n                'Origin': 'http://www.pornotube.com',\n            })['tokenKey']\n\n        video_url = self._download_json(\n            'https://api.aebn.net/delivery/v1/clips/%s/MP4' % video_id,\n            video_id, note='Downloading delivery information',\n            headers={'Authorization': token})['mediaUrl']\n\n        FIELDS = (\n            'title', 'description', 'startSecond', 'endSecond', 'publishDate',\n            'studios{name}', 'categories{name}', 'movieId', 'primaryImageNumber'\n        )\n\n        info = self._download_json(\n            'https://api.aebn.net/content/v2/clips/%s?fields=%s'\n            % (video_id, ','.join(FIELDS)), video_id,\n            note='Downloading metadata',\n            headers={'Authorization': token})\n\n        if isinstance(info, list):\n            info = info[0]\n\n        title = info['title']\n\n        timestamp = int_or_none(info.get('publishDate'), scale=1000)\n        uploader = info.get('studios', [{}])[0].get('name')\n        movie_id = info.get('movieId')\n        primary_image_number = info.get('primaryImageNumber')\n        thumbnail = None\n        if movie_id and primary_image_number:\n            thumbnail = 'http://pic.aebn.net/dis/t/%s/%s_%08d.jpg' % (\n                movie_id, movie_id, primary_image_number)\n        start = int_or_none(info.get('startSecond'))\n        end = int_or_none(info.get('endSecond'))\n        duration = end - start if start and end else None\n        categories = [c['name'] for c in info.get('categories', []) if c.get('name')]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': info.get('description'),\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE._real_extract#41",
        "src_path": "youtube_dl/extractor/pornovoisines.py",
        "class_name": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE",
        "signature": "youtube_dl.extractor.pornovoisines.PornoVoisinesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        settings_url = self._download_json(\n            'http://www.pornovoisines.com/api/video/%s/getsettingsurl/' % video_id,\n            video_id, note='Getting settings URL')['video_settings_url']\n        settings = self._download_json(settings_url, video_id)['data']\n\n        formats = []\n        for kind, data in settings['variants'].items():\n            if kind == 'HLS':\n                formats.extend(self._extract_m3u8_formats(\n                    data, video_id, ext='mp4', entry_protocol='m3u8_native', m3u8_id='hls'))\n            elif kind == 'MP4':\n                for item in data:\n                    formats.append({\n                        'url': item['url'],\n                        'height': item.get('height'),\n                        'bitrate': item.get('bitrate'),\n                    })\n        self._sort_formats(formats)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n\n        # The webpage has a bug - there's no space between \"thumb\" and src=\n        thumbnail = self._html_search_regex(\n            r'<img[^>]+class=([\\'\"])thumb\\1[^>]*src=([\\'\"])(?P<url>[^\"]+)\\2',\n            webpage, 'thumbnail', fatal=False, group='url')\n\n        upload_date = unified_strdate(self._search_regex(\n            r'Le\\s*<b>([\\d/]+)', webpage, 'upload date', fatal=False))\n        duration = settings.get('main', {}).get('duration')\n        view_count = int_or_none(self._search_regex(\n            r'(\\d+) vues', webpage, 'view count', fatal=False))\n        average_rating = self._search_regex(\n            r'Note\\s*:\\s*(\\d+(?:,\\d+)?)', webpage, 'average rating', fatal=False)\n        if average_rating:\n            average_rating = float_or_none(average_rating.replace(',', '.'))\n\n        categories = self._html_search_regex(\n            r'(?s)Cat\u00e9gories\\s*:\\s*<b>(.+?)</b>', webpage, 'categories', fatal=False)\n        if categories:\n            categories = [category.strip() for category in categories.split(',')]\n\n        subtitles = {'fr': [{\n            'url': subtitle,\n        } for subtitle in settings.get('main', {}).get('vtt_tracks', {}).values()]}\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'average_rating': average_rating,\n            'categories': categories,\n            'age_limit': 18,\n            'subtitles': subtitles,\n        }",
        "begin_line": 41,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract#28",
        "src_path": "youtube_dl/extractor/pornoxo.py",
        "class_name": "youtube_dl.extractor.pornoxo.PornoXOIE",
        "signature": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, display_id = mobj.groups()\n\n        webpage = self._download_webpage(url, video_id)\n        video_data = self._extract_jwplayer_data(webpage, video_id, require_title=False)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*PornoXO', webpage, 'title')\n\n        view_count = str_to_int(self._html_search_regex(\n            r'[vV]iews:\\s*([0-9,]+)', webpage, 'view count', fatal=False))\n\n        categories_str = self._html_search_regex(\n            r'<meta name=\"description\" content=\".*featuring\\s*([^\"]+)\"',\n            webpage, 'categories', fatal=False)\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        video_data.update({\n            'id': video_id,\n            'title': title,\n            'display_id': display_id,\n            'description': self._html_search_meta('description', webpage),\n            'categories': categories,\n            'view_count': view_count,\n            'age_limit': 18,\n        })\n\n        return video_data",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.presstv.PressTVIE._real_extract#27",
        "src_path": "youtube_dl/extractor/presstv.py",
        "class_name": "youtube_dl.extractor.presstv.PressTVIE",
        "signature": "youtube_dl.extractor.presstv.PressTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        # extract video URL from webpage\n        video_url = self._hidden_inputs(webpage)['inpPlayback']\n\n        # build list of available formats\n        # specified in http://www.presstv.ir/Scripts/playback.js\n        base_url = 'http://192.99.219.222:82/presstv'\n        _formats = [\n            (180, '_low200.mp4'),\n            (360, '_low400.mp4'),\n            (720, '_low800.mp4'),\n            (1080, '.mp4')\n        ]\n\n        formats = [{\n            'url': base_url + video_url[:-4] + extension,\n            'format_id': '%dp' % height,\n            'height': height,\n        } for height, extension in _formats]\n\n        # extract video metadata\n        title = remove_start(\n            self._html_search_meta('title', webpage, fatal=True), 'PressTV-')\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        upload_date = '%04d%02d%02d' % (\n            int(mobj.group('y')),\n            int(mobj.group('m')),\n            int(mobj.group('d')),\n        )\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'description': description\n        }",
        "begin_line": 27,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.primesharetv.PrimeShareTVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/primesharetv.py",
        "class_name": "youtube_dl.extractor.primesharetv.PrimeShareTVIE",
        "signature": "youtube_dl.extractor.primesharetv.PrimeShareTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>File not exist<' in webpage:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        fields = self._hidden_inputs(webpage)\n\n        headers = {\n            'Referer': url,\n            'Content-Type': 'application/x-www-form-urlencoded',\n        }\n\n        wait_time = int(self._search_regex(\n            r'var\\s+cWaitTime\\s*=\\s*(\\d+)',\n            webpage, 'wait time', default=7)) + 1\n        self._sleep(wait_time, video_id)\n\n        req = sanitized_Request(\n            url, urlencode_postdata(fields), headers)\n        video_page = self._download_webpage(\n            req, video_id, 'Downloading video page')\n\n        video_url = self._search_regex(\n            r\"url\\s*:\\s*'([^']+\\.primeshare\\.tv(?::443)?/file/[^']+)'\",\n            video_page, 'video url')\n\n        title = self._html_search_regex(\n            r'<h1>Watch\\s*(?:&nbsp;)?\\s*\\((.+?)(?:\\s*\\[\\.\\.\\.\\])?\\)\\s*(?:&nbsp;)?\\s*<strong>',\n            video_page, 'title')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': 'mp4',\n        }",
        "begin_line": 24,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract#27",
        "src_path": "youtube_dl/extractor/promptfile.py",
        "class_name": "youtube_dl.extractor.promptfile.PromptFileIE",
        "signature": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(r'<div.+id=\"not_found_msg\".+>(?!We are).+</div>[^-]', webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        chash = self._search_regex(\n            r'val\\(\"([^\"]*)\"\\s*\\+\\s*\\$\\(\"#chash\"\\)', webpage, 'chash')\n        fields = self._hidden_inputs(webpage)\n        keys = list(fields.keys())\n        chash_key = keys[0] if len(keys) == 1 else next(\n            key for key in keys if key.startswith('cha'))\n        fields[chash_key] = chash + fields[chash_key]\n\n        webpage = self._download_webpage(\n            url, video_id, 'Downloading video page',\n            data=urlencode_postdata(fields),\n            headers={'Content-type': 'application/x-www-form-urlencoded'})\n\n        video_url = self._search_regex(\n            (r'<a[^>]+href=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1[^>]*>\\s*Download File',\n             r'<a[^>]+href=([\"\\'])(?P<url>https?://(?:www\\.)?promptfile\\.com/file/(?:(?!\\1).)+)\\1'),\n            webpage, 'video url', group='url')\n        title = self._html_search_regex(\n            r'<span.+title=\"([^\"]+)\">', webpage, 'title')\n        thumbnail = self._html_search_regex(\n            r'<div id=\"player_overlay\">.*button>.*?<img src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False, flags=re.DOTALL)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'ext': determine_ext(title),\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1BaseIE._extract_video_info#19",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1BaseIE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1BaseIE._extract_video_info(self, url, clip_id)",
        "snippet": "    def _extract_video_info(self, url, clip_id):\n        client_location = url\n\n        video = self._download_json(\n            'http://vas.sim-technik.de/vas/live/v2/videos',\n            clip_id, 'Downloading videos JSON', query={\n                'access_token': self._TOKEN,\n                'client_location': client_location,\n                'client_name': self._CLIENT_NAME,\n                'ids': clip_id,\n            })[0]\n\n        if video.get('is_protected') is True:\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        duration = float_or_none(video.get('duration'))\n        source_ids = [compat_str(source['id']) for source in video['sources']]\n\n        client_id = self._SALT[:2] + sha1(''.join([clip_id, self._SALT, self._TOKEN, client_location, self._SALT, self._CLIENT_NAME]).encode('utf-8')).hexdigest()\n\n        sources = self._download_json(\n            'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources' % clip_id,\n            clip_id, 'Downloading sources JSON', query={\n                'access_token': self._TOKEN,\n                'client_id': client_id,\n                'client_location': client_location,\n                'client_name': self._CLIENT_NAME,\n            })\n        server_id = sources['server_id']\n\n        def fix_bitrate(bitrate):\n            bitrate = int_or_none(bitrate)\n            if not bitrate:\n                return None\n            return (bitrate // 1000) if bitrate % 1000 == 0 else bitrate\n\n        formats = []\n        for source_id in source_ids:\n            client_id = self._SALT[:2] + sha1(''.join([self._SALT, clip_id, self._TOKEN, server_id, client_location, source_id, self._SALT, self._CLIENT_NAME]).encode('utf-8')).hexdigest()\n            urls = self._download_json(\n                'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url' % clip_id,\n                clip_id, 'Downloading urls JSON', fatal=False, query={\n                    'access_token': self._TOKEN,\n                    'client_id': client_id,\n                    'client_location': client_location,\n                    'client_name': self._CLIENT_NAME,\n                    'server_id': server_id,\n                    'source_ids': source_id,\n                })\n            if not urls:\n                continue\n            if urls.get('status_code') != 0:\n                raise ExtractorError('This video is unavailable', expected=True)\n            urls_sources = urls['sources']\n            if isinstance(urls_sources, dict):\n                urls_sources = urls_sources.values()\n            for source in urls_sources:\n                source_url = source.get('url')\n                if not source_url:\n                    continue\n                protocol = source.get('protocol')\n                mimetype = source.get('mimetype')\n                if mimetype == 'application/f4m+xml' or 'f4mgenerator' in source_url or determine_ext(source_url) == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        source_url, clip_id, f4m_id='hds', fatal=False))\n                elif mimetype == 'application/x-mpegURL':\n                    formats.extend(self._extract_m3u8_formats(\n                        source_url, clip_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n                elif mimetype == 'application/dash+xml':\n                    formats.extend(self._extract_mpd_formats(\n                        source_url, clip_id, mpd_id='dash', fatal=False))\n                else:\n                    tbr = fix_bitrate(source['bitrate'])\n                    if protocol in ('rtmp', 'rtmpe'):\n                        mobj = re.search(r'^(?P<url>rtmpe?://[^/]+)/(?P<path>.+)$', source_url)\n                        if not mobj:\n                            continue\n                        path = mobj.group('path')\n                        mp4colon_index = path.rfind('mp4:')\n                        app = path[:mp4colon_index]\n                        play_path = path[mp4colon_index:]\n                        formats.append({\n                            'url': '%s/%s' % (mobj.group('url'), app),\n                            'app': app,\n                            'play_path': play_path,\n                            'player_url': 'http://livepassdl.conviva.com/hf/ver/2.79.0.17083/LivePassModuleMain.swf',\n                            'page_url': 'http://www.prosieben.de',\n                            'tbr': tbr,\n                            'ext': 'flv',\n                            'format_id': 'rtmp%s' % ('-%d' % tbr if tbr else ''),\n                        })\n                    else:\n                        formats.append({\n                            'url': source_url,\n                            'tbr': tbr,\n                            'format_id': 'http%s' % ('-%d' % tbr if tbr else ''),\n                        })\n        self._sort_formats(formats)\n\n        return {\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 19,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_clip#385",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_clip(self, url, webpage)",
        "snippet": "    def _extract_clip(self, url, webpage):\n        clip_id = self._html_search_regex(\n            self._CLIPID_REGEXES, webpage, 'clip id')\n        title = self._html_search_regex(\n            self._TITLE_REGEXES, webpage, 'title',\n            default=None) or self._og_search_title(webpage)\n        info = self._extract_video_info(url, clip_id)\n        description = self._html_search_regex(\n            self._DESCRIPTION_REGEXES, webpage, 'description', default=None)\n        if description is None:\n            description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._html_search_regex(\n            self._UPLOAD_DATE_REGEXES, webpage, 'upload date', default=None))\n\n        info.update({\n            'id': clip_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        })\n        return info",
        "begin_line": 385,
        "end_line": 407,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_playlist#409",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._extract_playlist(self, url, webpage)",
        "snippet": "    def _extract_playlist(self, url, webpage):\n        playlist_id = self._html_search_regex(\n            self._PLAYLIST_ID_REGEXES, webpage, 'playlist id')\n        playlist = self._parse_json(\n            self._search_regex(\n                r'var\\s+contentResources\\s*=\\s*(\\[.+?\\]);\\s*</script',\n                webpage, 'playlist'),\n            playlist_id)\n        entries = []\n        for item in playlist:\n            clip_id = item.get('id') or item.get('upc')\n            if not clip_id:\n                continue\n            info = self._extract_video_info(url, clip_id)\n            info.update({\n                'id': clip_id,\n                'title': item.get('title') or item.get('teaser', {}).get('headline'),\n                'description': item.get('teaser', {}).get('description'),\n                'thumbnail': item.get('poster'),\n                'duration': float_or_none(item.get('duration')),\n                'series': item.get('tvShowTitle'),\n                'uploader': item.get('broadcastPublisher'),\n            })\n            entries.append(info)\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 409,
        "end_line": 433,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract#435",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        page_type = self._search_regex(\n            self._PAGE_TYPE_REGEXES, webpage,\n            'page type', default='clip').lower()\n        if page_type == 'clip':\n            return self._extract_clip(url, webpage)\n        elif page_type == 'playlist':\n            return self._extract_playlist(url, webpage)\n        else:\n            raise ExtractorError(\n                'Unsupported page type %s' % page_type, expected=True)",
        "begin_line": 435,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.puls4.Puls4IE._real_extract#36",
        "src_path": "youtube_dl/extractor/puls4.py",
        "class_name": "youtube_dl.extractor.puls4.Puls4IE",
        "signature": "youtube_dl.extractor.puls4.Puls4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path = self._match_id(url)\n        content_path = self._download_json(\n            'http://www.puls4.com/api/json-fe/page/' + path, path)['content'][0]['url']\n        media = self._download_json(\n            'http://www.puls4.com' + content_path,\n            content_path)['mediaCurrent']\n        player_content = media['playerContent']\n        info = self._extract_video_info(url, player_content['id'])\n        info.update({\n            'id': compat_str(media['objectId']),\n            'title': player_content['title'],\n            'description': media.get('description'),\n            'thumbnail': media.get('previewLink'),\n            'upload_date': unified_strdate(media.get('date')),\n            'duration': parse_duration(player_content.get('duration')),\n            'episode': player_content.get('episodePartName'),\n            'show': media.get('channel'),\n            'season_id': player_content.get('seasonId'),\n            'uploader': player_content.get('sourceCompany'),\n        })\n        return info",
        "begin_line": 36,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract#29",
        "src_path": "youtube_dl/extractor/pyvideo.py",
        "class_name": "youtube_dl.extractor.pyvideo.PyvideoIE",
        "signature": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        category = mobj.group('category')\n        video_id = mobj.group('id')\n\n        entries = []\n\n        data = self._download_json(\n            'https://raw.githubusercontent.com/pyvideo/data/master/%s/videos/%s.json'\n            % (category, video_id), video_id, fatal=False)\n\n        if data:\n            for video in data['videos']:\n                video_url = video.get('url')\n                if video_url:\n                    if video.get('type') == 'youtube':\n                        entries.append(self.url_result(video_url, 'Youtube'))\n                    else:\n                        entries.append({\n                            'id': compat_str(data.get('id') or video_id),\n                            'url': video_url,\n                            'title': data['title'],\n                            'description': data.get('description') or data.get('summary'),\n                            'thumbnail': data.get('thumbnail_url'),\n                            'duration': int_or_none(data.get('duration')),\n                        })\n        else:\n            webpage = self._download_webpage(url, video_id)\n            title = self._og_search_title(webpage)\n            media_urls = self._search_regex(\n                r'(?s)Media URL:(.+?)</li>', webpage, 'media urls')\n            for m in re.finditer(\n                    r'<a[^>]+href=([\"\\'])(?P<url>http.+?)\\1', media_urls):\n                media_url = m.group('url')\n                if re.match(r'https?://www\\.youtube\\.com/watch\\?v=.*', media_url):\n                    entries.append(self.url_result(media_url, 'Youtube'))\n                else:\n                    entries.append({\n                        'id': video_id,\n                        'url': media_url,\n                        'title': title,\n                    })\n\n        return self.playlist_result(entries, video_id)",
        "begin_line": 29,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicIE.m_r_get_ruin#72",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicIE.m_r_get_ruin()",
        "snippet": "    def m_r_get_ruin():\n        curMs = int(time.time() * 1000) % 1000\n        return int(round(random.random() * 2147483647) * curMs % 1E10)",
        "begin_line": 72,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicIE._real_extract#76",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        detail_info_page = self._download_webpage(\n            'http://s.plcloud.music.qq.com/fcgi-bin/fcg_yqq_song_detail_info.fcg?songmid=%s&play=0' % mid,\n            mid, note='Download song detail info',\n            errnote='Unable to get song detail info', encoding='gbk')\n\n        song_name = self._html_search_regex(\n            r\"songname:\\s*'([^']+)'\", detail_info_page, 'song name')\n\n        publish_time = self._html_search_regex(\n            r'\u53d1\u884c\u65f6\u95f4\uff1a(\\d{4}-\\d{2}-\\d{2})', detail_info_page,\n            'publish time', default=None)\n        if publish_time:\n            publish_time = publish_time.replace('-', '')\n\n        singer = self._html_search_regex(\n            r\"singer:\\s*'([^']+)\", detail_info_page, 'singer', default=None)\n\n        lrc_content = self._html_search_regex(\n            r'<div class=\"content\" id=\"lrc_content\"[^<>]*>([^<>]+)</div>',\n            detail_info_page, 'LRC lyrics', default=None)\n        if lrc_content:\n            lrc_content = lrc_content.replace('\\\\n', '\\n')\n\n        thumbnail_url = None\n        albummid = self._search_regex(\n            [r'albummid:\\'([0-9a-zA-Z]+)\\'', r'\"albummid\":\"([0-9a-zA-Z]+)\"'],\n            detail_info_page, 'album mid', default=None)\n        if albummid:\n            thumbnail_url = 'http://i.gtimg.cn/music/photo/mid_album_500/%s/%s/%s.jpg' \\\n                            % (albummid[-2:-1], albummid[-1], albummid)\n\n        guid = self.m_r_get_ruin()\n\n        vkey = self._download_json(\n            'http://base.music.qq.com/fcgi-bin/fcg_musicexpress.fcg?json=3&guid=%s' % guid,\n            mid, note='Retrieve vkey', errnote='Unable to get vkey',\n            transform_source=strip_jsonp)['key']\n\n        formats = []\n        for format_id, details in self._FORMATS.items():\n            formats.append({\n                'url': 'http://cc.stream.qqmusic.qq.com/%s%s.%s?vkey=%s&guid=%s&fromtag=0'\n                       % (details['prefix'], mid, details['ext'], vkey, guid),\n                'format': format_id,\n                'format_id': format_id,\n                'preference': details['preference'],\n                'abr': details.get('abr'),\n            })\n        self._check_formats(formats, mid)\n        self._sort_formats(formats)\n\n        actual_lrc_lyrics = ''.join(\n            line + '\\n' for line in re.findall(\n                r'(?m)^(\\[[0-9]{2}:[0-9]{2}(?:\\.[0-9]{2,})?\\][^\\n]*|\\[[^\\]]*\\])', lrc_content))\n\n        info_dict = {\n            'id': mid,\n            'formats': formats,\n            'title': song_name,\n            'release_date': publish_time,\n            'creator': singer,\n            'description': lrc_content,\n            'thumbnail': thumbnail_url\n        }\n        if actual_lrc_lyrics:\n            info_dict['subtitles'] = {\n                'origin': [{\n                    'ext': 'lrc',\n                    'data': actual_lrc_lyrics,\n                }]\n            }\n        return info_dict",
        "begin_line": 76,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.qq_static_url#155",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE",
        "signature": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.qq_static_url(category, mid)",
        "snippet": "    def qq_static_url(category, mid):\n        return 'http://y.qq.com/y/static/%s/%s/%s/%s.html' % (category, mid[-2], mid[-1], mid)",
        "begin_line": 155,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_singer_all_songs#158",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE",
        "signature": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_singer_all_songs(self, singmid, num)",
        "snippet": "    def get_singer_all_songs(self, singmid, num):\n        return self._download_webpage(\n            r'https://c.y.qq.com/v8/fcg-bin/fcg_v8_singer_track_cp.fcg', singmid,\n            query={\n                'format': 'json',\n                'inCharset': 'utf8',\n                'outCharset': 'utf-8',\n                'platform': 'yqq',\n                'needNewCode': 0,\n                'singermid': singmid,\n                'order': 'listen',\n                'begin': 0,\n                'num': num,\n                'songstatus': 1,\n            })",
        "begin_line": 158,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_entries_from_page#174",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE",
        "signature": "youtube_dl.extractor.qqmusic.QQPlaylistBaseIE.get_entries_from_page(self, singmid)",
        "snippet": "    def get_entries_from_page(self, singmid):\n        entries = []\n\n        default_num = 1\n        json_text = self.get_singer_all_songs(singmid, default_num)\n        json_obj_all_songs = self._parse_json(json_text, singmid)\n\n        if json_obj_all_songs['code'] == 0:\n            total = json_obj_all_songs['data']['total']\n            json_text = self.get_singer_all_songs(singmid, total)\n            json_obj_all_songs = self._parse_json(json_text, singmid)\n\n        for item in json_obj_all_songs['data']['list']:\n            if item['musicData'].get('songmid') is not None:\n                songmid = item['musicData']['songmid']\n                entries.append(self.url_result(\n                    r'https://y.qq.com/n/yqq/song/%s.html' % songmid, 'QQMusic', songmid))\n\n        return entries",
        "begin_line": 174,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicSingerIE._real_extract#209",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicSingerIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicSingerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        entries = self.get_entries_from_page(mid)\n        singer_page = self._download_webpage(url, mid, 'Download singer page')\n        singer_name = self._html_search_regex(\n            r\"singername\\s*:\\s*'(.*?)'\", singer_page, 'singer name', default=None)\n        singer_desc = None\n\n        if mid:\n            singer_desc_page = self._download_xml(\n                'http://s.plcloud.music.qq.com/fcgi-bin/fcg_get_singer_desc.fcg', mid,\n                'Donwload singer description XML',\n                query={'utf8': 1, 'outCharset': 'utf-8', 'format': 'xml', 'singermid': mid},\n                headers={'Referer': 'https://y.qq.com/n/yqq/singer/'})\n\n            singer_desc = singer_desc_page.find('./data/info/desc').text\n\n        return self.playlist_result(entries, mid, singer_name, singer_desc)",
        "begin_line": 209,
        "end_line": 227,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE._real_extract#253",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mid = self._match_id(url)\n\n        album = self._download_json(\n            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_album_info_cp.fcg?albummid=%s&format=json' % mid,\n            mid, 'Download album page')['data']\n\n        entries = [\n            self.url_result(\n                'https://y.qq.com/n/yqq/song/' + song['songmid'] + '.html', 'QQMusic', song['songmid']\n            ) for song in album['list']\n        ]\n        album_name = album.get('name')\n        album_detail = album.get('desc')\n        if album_detail is not None:\n            album_detail = album_detail.strip()\n\n        return self.playlist_result(entries, mid, album_name, album_detail)",
        "begin_line": 253,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicToplistIE._real_extract#304",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicToplistIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicToplistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        toplist_json = self._download_json(\n            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_toplist_cp.fcg', list_id,\n            note='Download toplist page',\n            query={'type': 'toplist', 'topid': list_id, 'format': 'json'})\n\n        entries = [self.url_result(\n            'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + '.html', 'QQMusic',\n            song['data']['songmid'])\n            for song in toplist_json['songlist']]\n\n        topinfo = toplist_json.get('topinfo', {})\n        list_name = topinfo.get('ListName')\n        list_description = topinfo.get('info')\n        return self.playlist_result(entries, list_id, list_name, list_description)",
        "begin_line": 304,
        "end_line": 320,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE._real_extract#347",
        "src_path": "youtube_dl/extractor/qqmusic.py",
        "class_name": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE",
        "signature": "youtube_dl.extractor.qqmusic.QQMusicPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        list_id = self._match_id(url)\n\n        list_json = self._download_json(\n            'http://i.y.qq.com/qzone-music/fcg-bin/fcg_ucc_getcdinfo_byids_cp.fcg',\n            list_id, 'Download list page',\n            query={'type': 1, 'json': 1, 'utf8': 1, 'onlysong': 0, 'disstid': list_id},\n            transform_source=strip_jsonp)\n        if not len(list_json.get('cdlist', [])):\n            if list_json.get('code'):\n                raise ExtractorError(\n                    'QQ Music said: error %d in fetching playlist info' % list_json['code'],\n                    expected=True)\n            raise ExtractorError('Unable to get playlist info')\n\n        cdlist = list_json['cdlist'][0]\n        entries = [self.url_result(\n            'https://y.qq.com/n/yqq/song/' + song['songmid'] + '.html', 'QQMusic', song['songmid'])\n            for song in cdlist['songlist']]\n\n        list_name = cdlist.get('dissname')\n        list_description = clean_html(unescapeHTML(cdlist.get('desc')))\n        return self.playlist_result(entries, list_id, list_name, list_description)",
        "begin_line": 347,
        "end_line": 369,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.r7.R7IE._real_extract#42",
        "src_path": "youtube_dl/extractor/r7.py",
        "class_name": "youtube_dl.extractor.r7.R7IE",
        "signature": "youtube_dl.extractor.r7.R7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://player-api.r7.com/video/i/%s' % video_id, video_id)\n\n        title = video['title']\n\n        formats = []\n        media_url_hls = video.get('media_url_hls')\n        if media_url_hls:\n            formats.extend(self._extract_m3u8_formats(\n                media_url_hls, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls', fatal=False))\n        media_url = video.get('media_url')\n        if media_url:\n            f = {\n                'url': media_url,\n                'format_id': 'http',\n            }\n            # m3u8 format always matches the http format, let's copy metadata from\n            # one to another\n            m3u8_formats = list(filter(\n                lambda f: f.get('vcodec') != 'none', formats))\n            if len(m3u8_formats) == 1:\n                f_copy = m3u8_formats[0].copy()\n                f_copy.update(f)\n                f_copy['protocol'] = 'http'\n                f = f_copy\n            formats.append(f)\n        self._sort_formats(formats)\n\n        description = video.get('description')\n        thumbnail = video.get('thumb')\n        duration = int_or_none(video.get('media_duration'))\n        like_count = int_or_none(video.get('likes'))\n        view_count = int_or_none(video.get('views'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'like_count': like_count,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 42,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.r7.R7ArticleIE.suitable#100",
        "src_path": "youtube_dl/extractor/r7.py",
        "class_name": "youtube_dl.extractor.r7.R7ArticleIE",
        "signature": "youtube_dl.extractor.r7.R7ArticleIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if R7IE.suitable(url) else super(R7ArticleIE, cls).suitable(url)",
        "begin_line": 100,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.r7.R7ArticleIE._real_extract#103",
        "src_path": "youtube_dl/extractor/r7.py",
        "class_name": "youtube_dl.extractor.r7.R7ArticleIE",
        "signature": "youtube_dl.extractor.r7.R7ArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'<div[^>]+(?:id=[\"\\']player-|class=[\"\\']embed[\"\\'][^>]+id=[\"\\'])([\\da-f]{24})',\n            webpage, 'video id')\n\n        return self.url_result('http://player.r7.com/video/i/%s' % video_id, R7IE.ie_key())",
        "begin_line": 103,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiobremen.RadioBremenIE._real_extract#28",
        "src_path": "youtube_dl/extractor/radiobremen.py",
        "class_name": "youtube_dl.extractor.radiobremen.RadioBremenIE",
        "signature": "youtube_dl.extractor.radiobremen.RadioBremenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        meta_url = 'http://www.radiobremen.de/apps/php/mediathek/metadaten.php?id=%s' % video_id\n        meta_doc = self._download_webpage(\n            meta_url, video_id, 'Downloading metadata')\n        title = self._html_search_regex(\n            r'<h1.*>(?P<title>.+)</h1>', meta_doc, 'title')\n        description = self._html_search_regex(\n            r'<p>(?P<description>.*)</p>', meta_doc, 'description', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'L&auml;nge:</td>\\s+<td>(?P<duration>[0-9]+:[0-9]+)</td>',\n            meta_doc, 'duration', fatal=False))\n\n        page_doc = self._download_webpage(\n            url, video_id, 'Downloading video information')\n        mobj = re.search(\n            r\"ardformatplayerclassic\\(\\'playerbereich\\',\\'(?P<width>[0-9]+)\\',\\'.*\\',\\'(?P<video_id>[0-9]+)\\',\\'(?P<secret>[0-9]+)\\',\\'(?P<thumbnail>.+)\\',\\'\\'\\)\",\n            page_doc)\n        video_url = (\n            \"http://dl-ondemand.radiobremen.de/mediabase/%s/%s_%s_%s.mp4\" %\n            (video_id, video_id, mobj.group(\"secret\"), mobj.group('width')))\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'width': int(mobj.group('width')),\n        }]\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n            'thumbnail': mobj.group('thumbnail'),\n        }",
        "begin_line": 28,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiocanada.RadioCanadaIE._real_extract#38",
        "src_path": "youtube_dl/extractor/radiocanada.py",
        "class_name": "youtube_dl.extractor.radiocanada.RadioCanadaIE",
        "signature": "youtube_dl.extractor.radiocanada.RadioCanadaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n        app_code, video_id = re.match(self._VALID_URL, url).groups()\n\n        metadata = self._download_xml(\n            'http://api.radio-canada.ca/metaMedia/v1/index.ashx',\n            video_id, note='Downloading metadata XML', query={\n                'appCode': app_code,\n                'idMedia': video_id,\n            })\n\n        def get_meta(name):\n            el = find_xpath_attr(metadata, './/Meta', 'name', name)\n            return el.text if el is not None else None\n\n        if get_meta('protectionType'):\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        device_types = ['ipad']\n        if not smuggled_data:\n            device_types.append('flash')\n            device_types.append('android')\n\n        formats = []\n        # TODO: extract f4m formats\n        # f4m formats can be extracted using flashhd device_type but they produce unplayable file\n        for device_type in device_types:\n            validation_url = 'http://api.radio-canada.ca/validationMedia/v1/Validation.ashx'\n            query = {\n                'appCode': app_code,\n                'idMedia': video_id,\n                'connectionType': 'broadband',\n                'multibitrate': 'true',\n                'deviceType': device_type,\n            }\n            if smuggled_data:\n                validation_url = 'https://services.radio-canada.ca/media/validation/v2/'\n                query.update(smuggled_data)\n            else:\n                query.update({\n                    # paysJ391wsHjbOJwvCs26toz and bypasslock are used to bypass geo-restriction\n                    'paysJ391wsHjbOJwvCs26toz': 'CA',\n                    'bypasslock': 'NZt5K62gRqfc',\n                })\n            v_data = self._download_xml(validation_url, video_id, note='Downloading %s XML' % device_type, query=query, fatal=False)\n            v_url = xpath_text(v_data, 'url')\n            if not v_url:\n                continue\n            if v_url == 'null':\n                raise ExtractorError('%s said: %s' % (\n                    self.IE_NAME, xpath_text(v_data, 'message')), expected=True)\n            ext = determine_ext(v_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    v_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    v_url, video_id, f4m_id='hds', fatal=False))\n            else:\n                ext = determine_ext(v_url)\n                bitrates = xpath_element(v_data, 'bitrates')\n                for url_e in bitrates.findall('url'):\n                    tbr = int_or_none(url_e.get('bitrate'))\n                    if not tbr:\n                        continue\n                    f_url = re.sub(r'\\d+\\.%s' % ext, '%d.%s' % (tbr, ext), v_url)\n                    protocol = determine_protocol({'url': f_url})\n                    f = {\n                        'format_id': '%s-%d' % (protocol, tbr),\n                        'url': f_url,\n                        'ext': 'flv' if protocol == 'rtmp' else ext,\n                        'protocol': protocol,\n                        'width': int_or_none(url_e.get('width')),\n                        'height': int_or_none(url_e.get('height')),\n                        'tbr': tbr,\n                    }\n                    mobj = re.match(r'(?P<url>rtmp://[^/]+/[^/]+)/(?P<playpath>[^?]+)(?P<auth>\\?.+)', f_url)\n                    if mobj:\n                        f.update({\n                            'url': mobj.group('url') + mobj.group('auth'),\n                            'play_path': mobj.group('playpath'),\n                        })\n                    formats.append(f)\n                    if protocol == 'rtsp':\n                        base_url = self._search_regex(\n                            r'rtsp://([^?]+)', f_url, 'base url', default=None)\n                        if base_url:\n                            base_url = 'http://' + base_url\n                            formats.extend(self._extract_m3u8_formats(\n                                base_url + '/playlist.m3u8', video_id, 'mp4',\n                                'm3u8_native', m3u8_id='hls', fatal=False))\n                            formats.extend(self._extract_f4m_formats(\n                                base_url + '/manifest.f4m', video_id,\n                                f4m_id='hds', fatal=False))\n        self._sort_formats(formats)\n\n        subtitles = {}\n        closed_caption_url = get_meta('closedCaption') or get_meta('closedCaptionHTML5')\n        if closed_caption_url:\n            subtitles['fr'] = [{\n                'url': closed_caption_url,\n                'ext': determine_ext(closed_caption_url, 'vtt'),\n            }]\n\n        return {\n            'id': video_id,\n            'title': get_meta('Title'),\n            'description': get_meta('Description') or get_meta('ShortDescription'),\n            'thumbnail': get_meta('imageHR') or get_meta('imageMR') or get_meta('imageBR'),\n            'duration': int_or_none(get_meta('length')),\n            'series': get_meta('Emission'),\n            'season_number': int_or_none('SrcSaison'),\n            'episode_number': int_or_none('SrcEpisode'),\n            'upload_date': unified_strdate(get_meta('Date')),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiocanada.RadioCanadaAudioVideoIE._real_extract#175",
        "src_path": "youtube_dl/extractor/radiocanada.py",
        "class_name": "youtube_dl.extractor.radiocanada.RadioCanadaAudioVideoIE",
        "signature": "youtube_dl.extractor.radiocanada.RadioCanadaAudioVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result('radiocanada:medianet:%s' % self._match_id(url))",
        "begin_line": 175,
        "end_line": 176,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiode.RadioDeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/radiode.py",
        "class_name": "youtube_dl.extractor.radiode.RadioDeIE",
        "signature": "youtube_dl.extractor.radiode.RadioDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        radio_id = self._match_id(url)\n        webpage = self._download_webpage(url, radio_id)\n        jscode = self._search_regex(\n            r\"'components/station/stationService':\\s*\\{\\s*'?station'?:\\s*(\\{.*?\\s*\\}),\\n\",\n            webpage, 'broadcast')\n\n        broadcast = self._parse_json(jscode, radio_id)\n        title = self._live_title(broadcast['name'])\n        description = broadcast.get('description') or broadcast.get('shortDescription')\n        thumbnail = broadcast.get('picture4Url') or broadcast.get('picture4TransUrl') or broadcast.get('logo100x100')\n\n        formats = [{\n            'url': stream['streamUrl'],\n            'ext': stream['streamContentFormat'].lower(),\n            'acodec': stream['streamContentFormat'],\n            'abr': stream['bitRate'],\n            'asr': stream['sampleRate']\n        } for stream in broadcast['streamUrls']]\n        self._sort_formats(formats)\n\n        return {\n            'id': radio_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 24,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract#25",
        "src_path": "youtube_dl/extractor/radiofrance.py",
        "class_name": "youtube_dl.extractor.radiofrance.RadioFranceIE",
        "signature": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"bloc_page_wrapper\"><div class=\"text\">(.*?)</div>',\n            webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<div class=\"credit\">&nbsp;&nbsp;&copy;&nbsp;(.*?)</div>',\n            webpage, 'uploader', fatal=False)\n\n        formats_str = self._html_search_regex(\n            r'class=\"jp-jplayer[^\"]*\" data-source=\"([^\"]+)\">',\n            webpage, 'audio URLs')\n        formats = [\n            {\n                'format_id': fm[0],\n                'url': fm[1],\n                'vcodec': 'none',\n                'preference': i,\n            }\n            for i, fm in\n            enumerate(re.findall(r\"([a-z0-9]+)\\s*:\\s*'([^']+)'\", formats_str))\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n        }",
        "begin_line": 25,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.radiojavan.RadioJavanIE._real_extract#29",
        "src_path": "youtube_dl/extractor/radiojavan.py",
        "class_name": "youtube_dl.extractor.radiojavan.RadioJavanIE",
        "signature": "youtube_dl.extractor.radiojavan.RadioJavanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = [{\n            'url': 'https://media.rdjavan.com/media/music_video/%s' % video_path,\n            'format_id': '%sp' % height,\n            'height': int(height),\n        } for height, video_path in re.findall(r\"RJ\\.video(\\d+)p\\s*=\\s*'/?([^']+)'\", webpage)]\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        upload_date = unified_strdate(self._search_regex(\n            r'class=\"date_added\">Date added: ([^<]+)<',\n            webpage, 'upload date', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'class=\"views\">Plays: ([\\d,]+)',\n            webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._search_regex(\n            r'class=\"rating\">([\\d,]+) likes',\n            webpage, 'like count', fatal=False))\n        dislike_count = str_to_int(self._search_regex(\n            r'class=\"rating\">([\\d,]+) dislikes',\n            webpage, 'dislike count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiBaseIE._extract_relinker_info#33",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiBaseIE",
        "signature": "youtube_dl.extractor.rai.RaiBaseIE._extract_relinker_info(self, relinker_url, video_id)",
        "snippet": "    def _extract_relinker_info(self, relinker_url, video_id):\n        formats = []\n        geoprotection = None\n        is_live = None\n        duration = None\n\n        for platform in ('mon', 'flash', 'native'):\n            relinker = self._download_xml(\n                relinker_url, video_id,\n                note='Downloading XML metadata for platform %s' % platform,\n                transform_source=fix_xml_ampersands,\n                query={'output': 45, 'pl': platform},\n                headers=self.geo_verification_headers())\n\n            if not geoprotection:\n                geoprotection = xpath_text(\n                    relinker, './geoprotection', default=None) == 'Y'\n\n            if not is_live:\n                is_live = xpath_text(\n                    relinker, './is_live', default=None) == 'Y'\n            if not duration:\n                duration = parse_duration(xpath_text(\n                    relinker, './duration', default=None))\n\n            url_elem = find_xpath_attr(relinker, './url', 'type', 'content')\n            if url_elem is None:\n                continue\n\n            media_url = url_elem.text\n\n            # This does not imply geo restriction (e.g.\n            # http://www.raisport.rai.it/dl/raiSport/media/rassegna-stampa-04a9f4bd-b563-40cf-82a6-aad3529cb4a9.html)\n            if media_url == 'http://download.rai.it/video_no_available.mp4':\n                continue\n\n            ext = determine_ext(media_url)\n            if (ext == 'm3u8' and platform != 'mon') or (ext == 'f4m' and platform != 'flash'):\n                continue\n\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    media_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                manifest_url = update_url_query(\n                    media_url.replace('manifest#live_hds.f4m', 'manifest.f4m'),\n                    {'hdcore': '3.7.0', 'plugin': 'aasp-3.7.0.39.44'})\n                formats.extend(self._extract_f4m_formats(\n                    manifest_url, video_id, f4m_id='hds', fatal=False))\n            else:\n                bitrate = int_or_none(xpath_text(relinker, 'bitrate'))\n                formats.append({\n                    'url': media_url,\n                    'tbr': bitrate if bitrate > 0 else None,\n                    'format_id': 'http-%d' % bitrate if bitrate > 0 else 'http',\n                })\n\n        if not formats and geoprotection is True:\n            self.raise_geo_restricted(countries=self._GEO_COUNTRIES)\n\n        return dict((k, v) for k, v in {\n            'is_live': is_live,\n            'duration': duration,\n            'formats': formats,\n        }.items() if v is not None)",
        "begin_line": 33,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiBaseIE._extract_subtitles#101",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiBaseIE",
        "signature": "youtube_dl.extractor.rai.RaiBaseIE._extract_subtitles(url, subtitle_url)",
        "snippet": "    def _extract_subtitles(url, subtitle_url):\n        subtitles = {}\n        if subtitle_url and isinstance(subtitle_url, compat_str):\n            subtitle_url = urljoin(url, subtitle_url)\n            STL_EXT = '.stl'\n            SRT_EXT = '.srt'\n            subtitles['it'] = [{\n                'ext': 'stl',\n                'url': subtitle_url,\n            }]\n            if subtitle_url.endswith(STL_EXT):\n                srt_url = subtitle_url[:-len(STL_EXT)] + SRT_EXT\n                subtitles['it'].append({\n                    'ext': 'srt',\n                    'url': srt_url,\n                })\n        return subtitles",
        "begin_line": 101,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiPlayIE._real_extract#165",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiPlayIE",
        "signature": "youtube_dl.extractor.rai.RaiPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        url, video_id = mobj.group('url', 'id')\n\n        media = self._download_json(\n            '%s?json' % url, video_id, 'Downloading video JSON')\n\n        title = media['name']\n\n        video = media['video']\n\n        relinker_info = self._extract_relinker_info(video['contentUrl'], video_id)\n        self._sort_formats(relinker_info['formats'])\n\n        thumbnails = []\n        if 'images' in media:\n            for _, value in media.get('images').items():\n                if value:\n                    thumbnails.append({\n                        'url': value.replace('[RESOLUTION]', '600x400')\n                    })\n\n        timestamp = unified_timestamp(try_get(\n            media, lambda x: x['availabilities'][0]['start'], compat_str))\n\n        subtitles = self._extract_subtitles(url, video.get('subtitles'))\n\n        info = {\n            'id': video_id,\n            'title': self._live_title(title) if relinker_info.get(\n                'is_live') else title,\n            'alt_title': media.get('subtitle'),\n            'description': media.get('description'),\n            'uploader': strip_or_none(media.get('channel')),\n            'creator': strip_or_none(media.get('editor')),\n            'duration': parse_duration(video.get('duration')),\n            'timestamp': timestamp,\n            'thumbnails': thumbnails,\n            'series': try_get(\n                media, lambda x: x['isPartOf']['name'], compat_str),\n            'season_number': int_or_none(try_get(\n                media, lambda x: x['isPartOf']['numeroStagioni'])),\n            'season': media.get('stagione') or None,\n            'subtitles': subtitles,\n        }\n\n        info.update(relinker_info)\n        return info",
        "begin_line": 165,
        "end_line": 212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiPlayLiveIE._real_extract#234",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiPlayLiveIE",
        "signature": "youtube_dl.extractor.rai.RaiPlayLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'data-uniquename=[\"\\']ContentItem-(%s)' % RaiBaseIE._UUID_RE,\n            webpage, 'content id')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': RaiPlayIE.ie_key(),\n            'url': 'http://www.raiplay.it/dirette/ContentItem-%s.html' % video_id,\n            'id': video_id,\n            'display_id': display_id,\n        }",
        "begin_line": 234,
        "end_line": 249,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._extract_from_content_id#338",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._extract_from_content_id(self, content_id, url)",
        "snippet": "    def _extract_from_content_id(self, content_id, url):\n        media = self._download_json(\n            'http://www.rai.tv/dl/RaiTV/programmi/media/ContentItem-%s.html?json' % content_id,\n            content_id, 'Downloading video JSON')\n\n        title = media['name'].strip()\n\n        media_type = media['type']\n        if 'Audio' in media_type:\n            relinker_info = {\n                'formats': {\n                    'format_id': media.get('formatoAudio'),\n                    'url': media['audioUrl'],\n                    'ext': media.get('formatoAudio'),\n                }\n            }\n        elif 'Video' in media_type:\n            relinker_info = self._extract_relinker_info(media['mediaUri'], content_id)\n        else:\n            raise ExtractorError('not a media file')\n\n        self._sort_formats(relinker_info['formats'])\n\n        thumbnails = []\n        for image_type in ('image', 'image_medium', 'image_300'):\n            thumbnail_url = media.get(image_type)\n            if thumbnail_url:\n                thumbnails.append({\n                    'url': compat_urlparse.urljoin(url, thumbnail_url),\n                })\n\n        subtitles = self._extract_subtitles(url, media.get('subtitlesUrl'))\n\n        info = {\n            'id': content_id,\n            'title': title,\n            'description': strip_or_none(media.get('desc')),\n            'thumbnails': thumbnails,\n            'uploader': media.get('author'),\n            'upload_date': unified_strdate(media.get('date')),\n            'duration': parse_duration(media.get('length')),\n            'subtitles': subtitles,\n        }\n\n        info.update(relinker_info)\n\n        return info",
        "begin_line": 338,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._real_extract#386",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        content_item_id = None\n\n        content_item_url = self._html_search_meta(\n            ('og:url', 'og:video', 'og:video:secure_url', 'twitter:url',\n             'twitter:player', 'jsonlink'), webpage, default=None)\n        if content_item_url:\n            content_item_id = self._search_regex(\n                r'ContentItem-(%s)' % self._UUID_RE, content_item_url,\n                'content item id', default=None)\n\n        if not content_item_id:\n            content_item_id = self._search_regex(\n                r'''(?x)\n                    (?:\n                        (?:initEdizione|drawMediaRaiTV)\\(|\n                        <(?:[^>]+\\bdata-id|var\\s+uniquename)=\n                    )\n                    ([\"\\'])\n                    (?:(?!\\1).)*\\bContentItem-(?P<id>%s)\n                ''' % self._UUID_RE,\n                webpage, 'content item id', default=None, group='id')\n\n        content_item_ids = set()\n        if content_item_id:\n            content_item_ids.add(content_item_id)\n        if video_id not in content_item_ids:\n            content_item_ids.add(video_id)\n\n        for content_item_id in content_item_ids:\n            try:\n                return self._extract_from_content_id(content_item_id, url)\n            except GeoRestrictedError:\n                raise\n            except ExtractorError:\n                pass\n\n        relinker_url = self._search_regex(\n            r'''(?x)\n                (?:\n                    var\\s+videoURL|\n                    mediaInfo\\.mediaUri\n                )\\s*=\\s*\n                ([\\'\"])\n                (?P<url>\n                    (?:https?:)?\n                    //mediapolis(?:vod)?\\.rai\\.it/relinker/relinkerServlet\\.htm\\?\n                    (?:(?!\\1).)*\\bcont=(?:(?!\\1).)+)\\1\n            ''',\n            webpage, 'relinker URL', group='url')\n\n        relinker_info = self._extract_relinker_info(\n            urljoin(url, relinker_url), video_id)\n        self._sort_formats(relinker_info['formats'])\n\n        title = self._search_regex(\n            r'var\\s+videoTitolo\\s*=\\s*([\\'\"])(?P<title>[^\\'\"]+)\\1',\n            webpage, 'title', group='title',\n            default=None) or self._og_search_title(webpage)\n\n        info = {\n            'id': video_id,\n            'title': title,\n        }\n\n        info.update(relinker_info)\n\n        return info",
        "begin_line": 386,
        "end_line": 457,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract#32",
        "src_path": "youtube_dl/extractor/rbmaradio.py",
        "class_name": "youtube_dl.extractor.rbmaradio.RBMARadioIE",
        "signature": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_id = mobj.group('show_id')\n        episode_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, episode_id)\n\n        episode = self._parse_json(\n            self._search_regex(\n                r'__INITIAL_STATE__\\s*=\\s*({.+?})\\s*</script>',\n                webpage, 'json data'),\n            episode_id)['episodes'][show_id][episode_id]\n\n        title = episode['title']\n\n        show_title = episode.get('showTitle')\n        if show_title:\n            title = '%s - %s' % (show_title, title)\n\n        formats = [{\n            'url': update_url_query(episode['audioURL'], query={'cbr': abr}),\n            'format_id': compat_str(abr),\n            'abr': abr,\n            'vcodec': 'none',\n        } for abr in (96, 128, 256)]\n\n        description = clean_html(episode.get('longTeaser'))\n        thumbnail = self._proto_relative_url(episode.get('imageURL', {}).get('landscape'))\n        duration = int_or_none(episode.get('duration'))\n        timestamp = unified_timestamp(episode.get('publishedAt'))\n\n        return {\n            'id': episode_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rds.RDSIE._real_extract#35",
        "src_path": "youtube_dl/extractor/rds.py",
        "class_name": "youtube_dl.extractor.rds.RDSIE",
        "signature": "youtube_dl.extractor.rds.RDSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        item = self._parse_json(self._search_regex(r'(?s)itemToPush\\s*=\\s*({.+?});', webpage, 'item'), display_id, js_to_json)\n        video_id = compat_str(item['id'])\n        title = item.get('title') or self._og_search_title(webpage) or self._html_search_meta(\n            'title', webpage, 'title', fatal=True)\n        description = self._og_search_description(webpage) or self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = item.get('urlImageBig') or self._og_search_thumbnail(webpage) or self._search_regex(\n            [r'<link[^>]+itemprop=\"thumbnailUrl\"[^>]+href=\"([^\"]+)\"',\n             r'<span[^>]+itemprop=\"thumbnailUrl\"[^>]+content=\"([^\"]+)\"'],\n            webpage, 'thumbnail', fatal=False)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<span[^>]+itemprop=\"uploadDate\"[^>]+content=\"([^\"]+)\"',\n            webpage, 'upload date', fatal=False))\n        duration = parse_duration(self._search_regex(\n            r'<span[^>]+itemprop=\"duration\"[^>]+content=\"([^\"]+)\"',\n            webpage, 'duration', fatal=False))\n        age_limit = self._family_friendly_search(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'display_id': display_id,\n            'url': '9c9media:rds_web:%s' % video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'age_limit': age_limit,\n            'ie_key': 'NineCNineMedia',\n        }",
        "begin_line": 35,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.redbulltv.RedBullTVIE._real_extract#66",
        "src_path": "youtube_dl/extractor/redbulltv.py",
        "class_name": "youtube_dl.extractor.redbulltv.RedBullTVIE",
        "signature": "youtube_dl.extractor.redbulltv.RedBullTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        session = self._download_json(\n            'https://api-v2.redbull.tv/session', video_id,\n            note='Downloading access token', query={\n                'build': '4.370.0',\n                'category': 'personal_computer',\n                'os_version': '1.0',\n                'os_family': 'http',\n            })\n        if session.get('code') == 'error':\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, session['message']))\n        auth = '%s %s' % (session.get('token_type', 'Bearer'), session['access_token'])\n\n        try:\n            info = self._download_json(\n                'https://api-v2.redbull.tv/content/%s' % video_id,\n                video_id, note='Downloading video information',\n                headers={'Authorization': auth}\n            )\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 404:\n                error_message = self._parse_json(\n                    e.cause.read().decode(), video_id)['message']\n                raise ExtractorError('%s said: %s' % (\n                    self.IE_NAME, error_message), expected=True)\n            raise\n\n        video = info['video_product']\n\n        title = info['title'].strip()\n\n        formats = self._extract_m3u8_formats(\n            video['url'], video_id, 'mp4', entry_protocol='m3u8_native',\n            m3u8_id='hls')\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for _, captions in (try_get(\n                video, lambda x: x['attachments']['captions'],\n                dict) or {}).items():\n            if not captions or not isinstance(captions, list):\n                continue\n            for caption in captions:\n                caption_url = caption.get('url')\n                if not caption_url:\n                    continue\n                ext = caption.get('format')\n                if ext == 'xml':\n                    ext = 'ttml'\n                subtitles.setdefault(caption.get('lang') or 'en', []).append({\n                    'url': caption_url,\n                    'ext': ext,\n                })\n\n        subheading = info.get('subheading')\n        if subheading:\n            title += ' - %s' % subheading\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': info.get('long_description') or info.get(\n                'short_description'),\n            'duration': float_or_none(video.get('duration'), scale=1000),\n            # 'timestamp': unified_timestamp(info.get('published')),\n            'series': info.get('show_title'),\n            'season_number': int_or_none(info.get('season_number')),\n            'episode_number': int_or_none(info.get('episode_number')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 66,
        "end_line": 139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.reddit.RedditIE._real_extract#27",
        "src_path": "youtube_dl/extractor/reddit.py",
        "class_name": "youtube_dl.extractor.reddit.RedditIE",
        "signature": "youtube_dl.extractor.reddit.RedditIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        formats = self._extract_m3u8_formats(\n            'https://v.redd.it/%s/HLSPlaylist.m3u8' % video_id, video_id,\n            'mp4', entry_protocol='m3u8_native', m3u8_id='hls', fatal=False)\n\n        formats.extend(self._extract_mpd_formats(\n            'https://v.redd.it/%s/DASHPlaylist.mpd' % video_id, video_id,\n            mpd_id='dash', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': video_id,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.reddit.RedditRIE._real_extract#83",
        "src_path": "youtube_dl/extractor/reddit.py",
        "class_name": "youtube_dl.extractor.reddit.RedditRIE",
        "signature": "youtube_dl.extractor.reddit.RedditRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            url + '.json', video_id)[0]['data']['children'][0]['data']\n\n        video_url = data['url']\n\n        # Avoid recursing into the same reddit URL\n        if 'reddit.com/' in video_url and '/%s/' % video_id in video_url:\n            raise ExtractorError('No media found', expected=True)\n\n        over_18 = data.get('over_18')\n        if over_18 is True:\n            age_limit = 18\n        elif over_18 is False:\n            age_limit = 0\n        else:\n            age_limit = None\n\n        return {\n            '_type': 'url_transparent',\n            'url': video_url,\n            'title': data.get('title'),\n            'thumbnail': data.get('thumbnail'),\n            'timestamp': float_or_none(data.get('created_utc')),\n            'uploader': data.get('author'),\n            'like_count': int_or_none(data.get('ups')),\n            'dislike_count': int_or_none(data.get('downs')),\n            'comment_count': int_or_none(data.get('num_comments')),\n            'age_limit': age_limit,\n        }",
        "begin_line": 83,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.redtube.RedTubeIE._extract_urls#34",
        "src_path": "youtube_dl/extractor/redtube.py",
        "class_name": "youtube_dl.extractor.redtube.RedTubeIE",
        "signature": "youtube_dl.extractor.redtube.RedTubeIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+?src=[\"\\'](?P<url>(?:https?:)?//embed\\.redtube\\.com/\\?.*?\\bid=\\d+)',\n            webpage)",
        "begin_line": 34,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.redtube.RedTubeIE._real_extract#39",
        "src_path": "youtube_dl/extractor/redtube.py",
        "class_name": "youtube_dl.extractor.redtube.RedTubeIE",
        "signature": "youtube_dl.extractor.redtube.RedTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://www.redtube.com/%s' % video_id, video_id)\n\n        if any(s in webpage for s in ['video-deleted-info', '>This video has been removed']):\n            raise ExtractorError('Video %s has been removed' % video_id, expected=True)\n\n        title = self._html_search_regex(\n            (r'<h1 class=\"videoTitle[^\"]*\">(?P<title>.+?)</h1>',\n             r'videoTitle\\s*:\\s*([\"\\'])(?P<title>)\\1'),\n            webpage, 'title', group='title')\n\n        formats = []\n        sources = self._parse_json(\n            self._search_regex(\n                r'sources\\s*:\\s*({.+?})', webpage, 'source', default='{}'),\n            video_id, fatal=False)\n        if sources and isinstance(sources, dict):\n            for format_id, format_url in sources.items():\n                if format_url:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                        'height': int_or_none(format_id),\n                    })\n        else:\n            video_url = self._html_search_regex(\n                r'<source src=\"(.+?)\" type=\"video/mp4\">', webpage, 'video URL')\n            formats.append({'url': video_url})\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'<span[^>]+class=\"added-time\"[^>]*>ADDED ([^<]+)<',\n            webpage, 'upload date', fatal=False))\n        duration = int_or_none(self._search_regex(\n            r'videoDuration\\s*:\\s*(\\d+)', webpage, 'duration', fatal=False))\n        view_count = str_to_int(self._search_regex(\n            r'<span[^>]*>VIEWS</span></td>\\s*<td>([\\d,.]+)',\n            webpage, 'view count', fatal=False))\n\n        # No self-labeling, but they describe themselves as\n        # \"Home of Videos Porno\"\n        age_limit = 18\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'title': title,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 39,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.regiotv.RegioTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/regiotv.py",
        "class_name": "youtube_dl.extractor.regiotv.RegioTVIE",
        "signature": "youtube_dl.extractor.regiotv.RegioTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        key = self._search_regex(\n            r'key\\s*:\\s*([\"\\'])(?P<key>.+?)\\1', webpage, 'key', group='key')\n        title = self._og_search_title(webpage)\n\n        SOAP_TEMPLATE = '<?xml version=\"1.0\" encoding=\"utf-8\"?><soap:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"><soap:Body><{0} xmlns=\"http://v.telvi.de/\"><key xsi:type=\"xsd:string\">{1}</key></{0}></soap:Body></soap:Envelope>'\n\n        request = sanitized_Request(\n            'http://v.telvi.de/',\n            SOAP_TEMPLATE.format('GetHTML5VideoData', key).encode('utf-8'))\n        video_data = self._download_xml(request, video_id, 'Downloading video XML')\n\n        NS_MAP = {\n            'xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n            'soap': 'http://schemas.xmlsoap.org/soap/envelope/',\n        }\n\n        video_url = xpath_text(\n            video_data, xpath_with_ns('.//video', NS_MAP), 'video url', fatal=True)\n        thumbnail = xpath_text(\n            video_data, xpath_with_ns('.//image', NS_MAP), 'thumbnail')\n        description = self._og_search_description(\n            webpage) or self._html_search_meta('description', webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rentv.RENTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/rentv.py",
        "class_name": "youtube_dl.extractor.rentv.RENTVIE",
        "signature": "youtube_dl.extractor.rentv.RENTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage('http://ren.tv/player/' + video_id, video_id)\n        jw_config = self._parse_json(self._search_regex(\n            r'config\\s*=\\s*({.+});', webpage, 'jw config'), video_id)\n        return self._parse_jwplayer_data(jw_config, video_id, m3u8_id='hls')",
        "begin_line": 26,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rentv.RENTVArticleIE._real_extract#61",
        "src_path": "youtube_dl/extractor/rentv.py",
        "class_name": "youtube_dl.extractor.rentv.RENTVArticleIE",
        "signature": "youtube_dl.extractor.rentv.RENTVArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        drupal_settings = self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n            webpage, 'drupal settings'), display_id)\n\n        entries = []\n        for config_profile in drupal_settings.get('ren_jwplayer', {}).values():\n            media_id = config_profile.get('mediaid')\n            if not media_id:\n                continue\n            media_id = compat_str(media_id)\n            entries.append(self.url_result('rentv:' + media_id, 'RENTV', media_id))\n        return self.playlist_result(entries, display_id)",
        "begin_line": 61,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.restudy.RestudyIE._real_extract#23",
        "src_path": "youtube_dl/extractor/restudy.py",
        "class_name": "youtube_dl.extractor.restudy.RestudyIE",
        "signature": "youtube_dl.extractor.restudy.RestudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage).strip()\n        description = self._og_search_description(webpage).strip()\n\n        formats = self._extract_smil_formats(\n            'https://www.restudy.dk/awsmedia/SmilDirectory/video_%s.xml' % video_id,\n            video_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.reuters.ReutersIE._real_extract#26",
        "src_path": "youtube_dl/extractor/reuters.py",
        "class_name": "youtube_dl.extractor.reuters.ReutersIE",
        "signature": "youtube_dl.extractor.reuters.ReutersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://www.reuters.com/assets/iframe/yovideo?videoId=%s' % video_id, video_id)\n        video_data = js_to_json(self._search_regex(\n            r'(?s)Reuters\\.yovideo\\.drawPlayer\\(({.*?})\\);',\n            webpage, 'video data'))\n\n        def get_json_value(key, fatal=False):\n            return self._search_regex(r'\"%s\"\\s*:\\s*\"([^\"]+)\"' % key, video_data, key, fatal=fatal)\n\n        title = unescapeHTML(get_json_value('title', fatal=True))\n        mmid, fid = re.search(r',/(\\d+)\\?f=(\\d+)', get_json_value('flv', fatal=True)).groups()\n\n        mas_data = self._download_json(\n            'http://mas-e.cds1.yospace.com/mas/%s/%s?trans=json' % (mmid, fid),\n            video_id, transform_source=js_to_json)\n        formats = []\n        for f in mas_data:\n            f_url = f.get('url')\n            if not f_url:\n                continue\n            method = f.get('method')\n            if method == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    f_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n            else:\n                container = f.get('container')\n                ext = '3gp' if method == 'mobile' else container\n                formats.append({\n                    'format_id': ext,\n                    'url': f_url,\n                    'ext': ext,\n                    'container': container if method != 'mobile' else None,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': get_json_value('thumb'),\n            'duration': int_or_none(get_json_value('seconds')),\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract#25",
        "src_path": "youtube_dl/extractor/reverbnation.py",
        "class_name": "youtube_dl.extractor.reverbnation.ReverbNationIE",
        "signature": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        api_res = self._download_json(\n            'https://api.reverbnation.com/song/%s' % song_id,\n            song_id,\n            note='Downloading information of song %s' % song_id\n        )\n\n        THUMBNAILS = ('thumbnail', 'image')\n        quality = qualities(THUMBNAILS)\n        thumbnails = []\n        for thumb_key in THUMBNAILS:\n            if api_res.get(thumb_key):\n                thumbnails.append({\n                    'url': api_res[thumb_key],\n                    'preference': quality(thumb_key)\n                })\n\n        return {\n            'id': song_id,\n            'title': api_res['name'],\n            'url': api_res['url'],\n            'uploader': api_res.get('artist', {}).get('name'),\n            'uploader_id': str_or_none(api_res.get('artist', {}).get('id')),\n            'thumbnails': thumbnails,\n            'ext': 'mp3',\n            'vcodec': 'none',\n        }",
        "begin_line": 25,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.revision3.Revision3EmbedIE._real_extract#33",
        "src_path": "youtube_dl/extractor/revision3.py",
        "class_name": "youtube_dl.extractor.revision3.Revision3EmbedIE",
        "signature": "youtube_dl.extractor.revision3.Revision3EmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('playlist_id')\n        playlist_type = mobj.group('playlist_type') or 'video_id'\n        video_data = self._download_json(\n            'http://revision3.com/api/getPlaylist.json', playlist_id, query={\n                'api_key': self._API_KEY,\n                'codecs': 'h264,vp8,theora',\n                playlist_type: playlist_id,\n            })['items'][0]\n\n        formats = []\n        for vcodec, media in video_data['media'].items():\n            for quality_id, quality in media.items():\n                if quality_id == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        quality['url'], playlist_id, 'mp4',\n                        'm3u8_native', m3u8_id='hls', fatal=False))\n                else:\n                    formats.append({\n                        'url': quality['url'],\n                        'format_id': '%s-%s' % (vcodec, quality_id),\n                        'tbr': int_or_none(quality.get('bitrate')),\n                        'vcodec': vcodec,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': playlist_id,\n            'title': unescapeHTML(video_data['title']),\n            'description': unescapeHTML(video_data.get('summary')),\n            'uploader': video_data.get('show', {}).get('name'),\n            'uploader_id': video_data.get('show', {}).get('slug'),\n            'duration': int_or_none(video_data.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 33,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.revision3.Revision3IE._real_extract#100",
        "src_path": "youtube_dl/extractor/revision3.py",
        "class_name": "youtube_dl.extractor.revision3.Revision3IE",
        "signature": "youtube_dl.extractor.revision3.Revision3IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, display_id = re.match(self._VALID_URL, url).groups()\n        site = domain.split('.')[0]\n        page_info = self._download_json(\n            self._PAGE_DATA_TEMPLATE % (domain, display_id, domain), display_id)\n\n        page_data = page_info['data']\n        page_type = page_data['type']\n        if page_type in ('episode', 'embed'):\n            show_data = page_data['show']['data']\n            page_id = compat_str(page_data['id'])\n            video_id = compat_str(page_data['video']['data']['id'])\n\n            preference = qualities(['mini', 'small', 'medium', 'large'])\n            thumbnails = [{\n                'url': image_url,\n                'id': image_id,\n                'preference': preference(image_id)\n            } for image_id, image_url in page_data.get('images', {}).items()]\n\n            info = {\n                'id': page_id,\n                'display_id': display_id,\n                'title': unescapeHTML(page_data['name']),\n                'description': unescapeHTML(page_data.get('summary')),\n                'timestamp': parse_iso8601(page_data.get('publishTime'), ' '),\n                'author': page_data.get('author'),\n                'uploader': show_data.get('name'),\n                'uploader_id': show_data.get('slug'),\n                'thumbnails': thumbnails,\n                'extractor_key': site,\n            }\n\n            if page_type == 'embed':\n                info.update({\n                    '_type': 'url_transparent',\n                    'url': page_data['video']['data']['embed'],\n                })\n                return info\n\n            info.update({\n                '_type': 'url_transparent',\n                'url': 'revision3:%s' % video_id,\n            })\n            return info\n        else:\n            list_data = page_info[page_type]['data']\n            episodes_data = page_info['episodes']['data']\n            num_episodes = page_info['meta']['totalEpisodes']\n            processed_episodes = 0\n            entries = []\n            page_num = 1\n            while True:\n                entries.extend([{\n                    '_type': 'url',\n                    'url': 'http://%s%s' % (domain, episode['path']),\n                    'id': compat_str(episode['id']),\n                    'ie_key': 'Revision3',\n                    'extractor_key': site,\n                } for episode in episodes_data])\n                processed_episodes += len(episodes_data)\n                if processed_episodes == num_episodes:\n                    break\n                page_num += 1\n                episodes_data = self._download_json(self._PAGE_DATA_TEMPLATE % (\n                    domain, display_id + '/' + compat_str(page_num), domain),\n                    display_id)['episodes']['data']\n\n            return self.playlist_result(\n                entries, compat_str(list_data['id']),\n                list_data.get('name'), list_data.get('summary'))",
        "begin_line": 100,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rice.RICEIE._real_extract#32",
        "src_path": "youtube_dl/extractor/rice.py",
        "class_name": "youtube_dl.extractor.rice.RICEIE",
        "signature": "youtube_dl.extractor.rice.RICEIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        qs = compat_parse_qs(re.match(self._VALID_URL, url).group('query'))\n        if not qs.get('PortalID') or not qs.get('DestinationID') or not qs.get('ContentID'):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        portal_id = qs['PortalID'][0]\n        playlist_id = qs['DestinationID'][0]\n        content_id = qs['ContentID'][0]\n\n        content_data = self._download_xml('https://mediahub.rice.edu/api/portal/GetContentTitle', content_id, query={\n            'portalId': portal_id,\n            'playlistId': playlist_id,\n            'contentId': content_id\n        })\n        metadata = xpath_element(content_data, './/metaData', fatal=True)\n        title = xpath_text(metadata, 'primaryTitle', fatal=True)\n        encodings = xpath_element(content_data, './/encodings', fatal=True)\n        player_data = self._download_xml('https://mediahub.rice.edu/api/player/GetPlayerConfig', content_id, query={\n            'temporaryLinkId': xpath_text(encodings, 'temporaryLinkId', fatal=True),\n            'contentId': content_id,\n        })\n\n        common_fmt = {}\n        dimensions = xpath_text(encodings, 'dimensions')\n        if dimensions:\n            wh = dimensions.split('x')\n            if len(wh) == 2:\n                common_fmt.update({\n                    'width': int_or_none(wh[0]),\n                    'height': int_or_none(wh[1]),\n                })\n\n        formats = []\n        rtsp_path = xpath_text(player_data, self._xpath_ns('RtspPath', self._NS))\n        if rtsp_path:\n            fmt = {\n                'url': rtsp_path,\n                'format_id': 'rtsp',\n            }\n            fmt.update(common_fmt)\n            formats.append(fmt)\n        for source in player_data.findall(self._xpath_ns('.//Source', self._NS)):\n            video_url = xpath_text(source, self._xpath_ns('File', self._NS))\n            if not video_url:\n                continue\n            if '.m3u8' in video_url:\n                formats.extend(self._extract_m3u8_formats(video_url, content_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n            else:\n                fmt = {\n                    'url': video_url,\n                    'format_id': video_url.split(':')[0],\n                }\n                fmt.update(common_fmt)\n                rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', video_url)\n                if rtmp:\n                    fmt.update({\n                        'url': rtmp.group('url'),\n                        'play_path': rtmp.group('playpath'),\n                        'app': rtmp.group('app'),\n                        'ext': 'flv',\n                    })\n                formats.append(fmt)\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for content_asset in content_data.findall('.//contentAssets'):\n            asset_type = xpath_text(content_asset, 'type')\n            if asset_type == 'image':\n                image_url = xpath_text(content_asset, 'httpPath')\n                if not image_url:\n                    continue\n                thumbnails.append({\n                    'id': xpath_text(content_asset, 'ID'),\n                    'url': image_url,\n                })\n\n        return {\n            'id': content_id,\n            'title': title,\n            'description': xpath_text(metadata, 'abstract'),\n            'duration': int_or_none(xpath_text(metadata, 'duration')),\n            'timestamp': parse_iso8601(xpath_text(metadata, 'dateUpdated')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ringtv.RingTVIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ringtv.py",
        "class_name": "youtube_dl.extractor.ringtv.RingTVIE",
        "signature": "youtube_dl.extractor.ringtv.RingTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id').split('-')[0]\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('type') == 'news':\n            video_id = self._search_regex(\n                r'''(?x)<iframe[^>]+src=\"http://cms\\.springboardplatform\\.com/\n                        embed_iframe/[0-9]+/video/([0-9]+)/''',\n                webpage, 'real video ID')\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'addthis:description=\"([^\"]+)\"',\n            webpage, 'description', fatal=False)\n        final_url = 'http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/conversion/%s.mp4' % video_id\n        thumbnail_url = 'http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/snapshots/%s.jpg' % video_id\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rmcdecouverte.RMCDecouverteIE._real_extract#33",
        "src_path": "youtube_dl/extractor/rmcdecouverte.py",
        "class_name": "youtube_dl.extractor.rmcdecouverte.RMCDecouverteIE",
        "signature": "youtube_dl.extractor.rmcdecouverte.RMCDecouverteIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        brightcove_legacy_url = BrightcoveLegacyIE._extract_brightcove_url(webpage)\n        if brightcove_legacy_url:\n            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(\n                brightcove_legacy_url).query)['@videoPlayer'][0]\n        else:\n            brightcove_id = self._search_regex(\n                r'data-video-id=[\"\\'](\\d+)', webpage, 'brightcove id')\n        return self.url_result(\n            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew',\n            brightcove_id)",
        "begin_line": 33,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ro220.Ro220IE._real_extract#21",
        "src_path": "youtube_dl/extractor/ro220.py",
        "class_name": "youtube_dl.extractor.ro220.Ro220IE",
        "signature": "youtube_dl.extractor.ro220.Ro220IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        url = compat_urllib_parse_unquote(self._search_regex(\n            r'(?s)clip\\s*:\\s*{.*?url\\s*:\\s*\\'([^\\']+)\\'', webpage, 'url'))\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': 'mp4',\n        }]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rockstargames.RockstarGamesIE._real_extract#30",
        "src_path": "youtube_dl/extractor/rockstargames.py",
        "class_name": "youtube_dl.extractor.rockstargames.RockstarGamesIE",
        "signature": "youtube_dl.extractor.rockstargames.RockstarGamesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'https://www.rockstargames.com/videoplayer/videos/get-video.json',\n            video_id, query={\n                'id': video_id,\n                'locale': 'en_us',\n            })['video']\n\n        title = video['title']\n\n        formats = []\n        for video in video['files_processed']['video/mp4']:\n            if not video.get('src'):\n                continue\n            resolution = video.get('resolution')\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', resolution or '', 'height', default=None))\n            formats.append({\n                'url': self._proto_relative_url(video['src']),\n                'format_id': resolution,\n                'height': height,\n            })\n\n        if not formats:\n            youtube_id = video.get('youtube_id')\n            if youtube_id:\n                return self.url_result(youtube_id, 'Youtube')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnail': self._proto_relative_url(video.get('screencap')),\n            'timestamp': parse_iso8601(video.get('created')),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._login#52",
        "src_path": "youtube_dl/extractor/roosterteeth.py",
        "class_name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE",
        "signature": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='Unable to download login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'username': username,\n            'password': password,\n        })\n\n        login_request = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Logging in as %s' % username,\n            data=urlencode_postdata(login_form),\n            headers={\n                'Referer': self._LOGIN_URL,\n            })\n\n        if not any(re.search(p, login_request) for p in (\n                r'href=[\"\\']https?://(?:www\\.)?roosterteeth\\.com/logout\"',\n                r'>Sign Out<')):\n            error = self._html_search_regex(\n                r'(?s)<div[^>]+class=([\"\\']).*?\\balert-danger\\b.*?\\1[^>]*>(?:\\s*<button[^>]*>.*?</button>)?(?P<error>.+?)</div>',\n                login_request, 'alert', default=None, group='error')\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 52,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._real_initialize#87",
        "src_path": "youtube_dl/extractor/roosterteeth.py",
        "class_name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE",
        "signature": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._real_extract#90",
        "src_path": "youtube_dl/extractor/roosterteeth.py",
        "class_name": "youtube_dl.extractor.roosterteeth.RoosterTeethIE",
        "signature": "youtube_dl.extractor.roosterteeth.RoosterTeethIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        episode = strip_or_none(unescapeHTML(self._search_regex(\n            (r'videoTitle\\s*=\\s*([\"\\'])(?P<title>(?:(?!\\1).)+)\\1',\n             r'<title>(?P<title>[^<]+)</title>'), webpage, 'title',\n            default=None, group='title')))\n\n        title = strip_or_none(self._og_search_title(\n            webpage, default=None)) or episode\n\n        m3u8_url = self._search_regex(\n            r'file\\s*:\\s*([\"\\'])(?P<url>http.+?\\.m3u8.*?)\\1',\n            webpage, 'm3u8 url', default=None, group='url')\n\n        if not m3u8_url:\n            if re.search(r'<div[^>]+class=[\"\\']non-sponsor', webpage):\n                self.raise_login_required(\n                    '%s is only available for FIRST members' % display_id)\n\n            if re.search(r'<div[^>]+class=[\"\\']golive-gate', webpage):\n                self.raise_login_required('%s is not available yet' % display_id)\n\n            raise ExtractorError('Unable to extract m3u8 URL')\n\n        formats = self._extract_m3u8_formats(\n            m3u8_url, display_id, ext='mp4',\n            entry_protocol='m3u8_native', m3u8_id='hls')\n        self._sort_formats(formats)\n\n        description = strip_or_none(self._og_search_description(webpage))\n        thumbnail = self._proto_relative_url(self._og_search_thumbnail(webpage))\n\n        series = self._search_regex(\n            (r'<h2>More ([^<]+)</h2>', r'<a[^>]+>See All ([^<]+) Videos<'),\n            webpage, 'series', fatal=False)\n\n        comment_count = int_or_none(self._search_regex(\n            r'>Comments \\((\\d+)\\)<', webpage,\n            'comment count', fatal=False))\n\n        video_id = self._search_regex(\n            (r'containerId\\s*=\\s*[\"\\']episode-(\\d+)\\1',\n             r'<div[^<]+id=[\"\\']episode-(\\d+)'), webpage,\n            'video id', default=display_id)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'series': series,\n            'episode': episode,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 90,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rottentomatoes.RottenTomatoesIE._real_extract#21",
        "src_path": "youtube_dl/extractor/rottentomatoes.py",
        "class_name": "youtube_dl.extractor.rottentomatoes.RottenTomatoesIE",
        "signature": "youtube_dl.extractor.rottentomatoes.RottenTomatoesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        iva_id = self._search_regex(r'publishedid=(\\d+)', webpage, 'internet video archive id')\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'http://video.internetvideoarchive.net/player/6/configuration.ashx?domain=www.videodetective.com&customerid=69249&playerid=641&publishedid=' + iva_id,\n            'ie_key': InternetVideoArchiveIE.ie_key(),\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 21,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract#29",
        "src_path": "youtube_dl/extractor/roxwel.py",
        "class_name": "youtube_dl.extractor.roxwel.RoxwelIE",
        "signature": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        filename = mobj.group('filename')\n        info_url = 'http://www.roxwel.com/api/videos/%s' % filename\n        info = self._download_json(info_url, filename)\n\n        rtmp_rates = sorted([int(r.replace('flv_', '')) for r in info['media_rates'] if r.startswith('flv_')])\n        best_rate = rtmp_rates[-1]\n        url_page_url = 'http://roxwel.com/pl_one_time.php?filename=%s&quality=%s' % (filename, best_rate)\n        rtmp_url = self._download_webpage(url_page_url, filename, 'Downloading video url')\n        ext = determine_ext(rtmp_url)\n        if ext == 'f4v':\n            rtmp_url = rtmp_url.replace(filename, 'mp4:%s' % filename)\n\n        return {\n            'id': filename,\n            'title': info['title'],\n            'url': rtmp_url,\n            'ext': 'flv',\n            'description': info['description'],\n            'thumbnail': info.get('player_image_url') or info.get('image_url_large'),\n            'uploader': info['artist'],\n            'uploader_id': info['artistname'],\n            'upload_date': unified_strdate(info['dbdate']),\n        }",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rozhlas.RozhlasIE._real_extract#27",
        "src_path": "youtube_dl/extractor/rozhlas.py",
        "class_name": "youtube_dl.extractor.rozhlas.RozhlasIE",
        "signature": "youtube_dl.extractor.rozhlas.RozhlasIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        audio_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://prehravac.rozhlas.cz/audio/%s' % audio_id, audio_id)\n\n        title = self._html_search_regex(\n            r'<h3>(.+?)</h3>\\s*<p[^>]*>.*?</p>\\s*<div[^>]+id=[\"\\']player-track',\n            webpage, 'title', default=None) or remove_start(\n            self._og_search_title(webpage), 'Radio Wave - ')\n        description = self._html_search_regex(\n            r'<p[^>]+title=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1[^>]*>.*?</p>\\s*<div[^>]+id=[\"\\']player-track',\n            webpage, 'description', fatal=False, group='url')\n        duration = int_or_none(self._search_regex(\n            r'data-duration=[\"\\'](\\d+)', webpage, 'duration', default=None))\n\n        return {\n            'id': audio_id,\n            'url': 'http://media.rozhlas.cz/_audio/%s.mp3' % audio_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'vcodec': 'none',\n        }",
        "begin_line": 27,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtbf.RTBFIE._real_extract#55",
        "src_path": "youtube_dl/extractor/rtbf.py",
        "class_name": "youtube_dl.extractor.rtbf.RTBFIE",
        "signature": "youtube_dl.extractor.rtbf.RTBFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        data = self._download_json(\n            'http://www.rtbf.be/api/media/video?method=getVideoDetail&args[]=%s' % video_id, video_id)\n\n        error = data.get('error')\n        if error:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)\n\n        data = data['data']\n\n        provider = data.get('provider')\n        if provider in self._PROVIDERS:\n            return self.url_result(data['url'], self._PROVIDERS[provider])\n\n        formats = []\n        for key, format_id in self._QUALITIES:\n            format_url = data.get(key + 'Url')\n            if format_url:\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                })\n\n        thumbnails = []\n        for thumbnail_id, thumbnail_url in data.get('thumbnail', {}).items():\n            if thumbnail_id != 'default':\n                thumbnails.append({\n                    'url': self._IMAGE_HOST + thumbnail_url,\n                    'id': thumbnail_id,\n                })\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': data['title'],\n            'description': data.get('description') or data.get('subtitle'),\n            'thumbnails': thumbnails,\n            'duration': data.get('duration') or data.get('realDuration'),\n            'timestamp': int_or_none(data.get('created')),\n            'view_count': int_or_none(data.get('viewCount')),\n            'uploader': data.get('channel'),\n            'tags': data.get('tags'),\n        }",
        "begin_line": 55,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rte.RteBaseIE._real_extract#17",
        "src_path": "youtube_dl/extractor/rte.py",
        "class_name": "youtube_dl.extractor.rte.RteBaseIE",
        "signature": "youtube_dl.extractor.rte.RteBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        item_id = self._match_id(url)\n\n        try:\n            json_string = self._download_json(\n                'http://www.rte.ie/rteavgen/getplaylist/?type=web&format=json&id=' + item_id,\n                item_id)\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404:\n                error_info = self._parse_json(ee.cause.read().decode(), item_id, fatal=False)\n                if error_info:\n                    raise ExtractorError(\n                        '%s said: %s' % (self.IE_NAME, error_info['message']),\n                        expected=True)\n            raise\n\n        # NB the string values in the JSON are stored using XML escaping(!)\n        show = json_string['shows'][0]\n        title = unescapeHTML(show['title'])\n        description = unescapeHTML(show.get('description'))\n        thumbnail = show.get('thumbnail')\n        duration = float_or_none(show.get('duration'), 1000)\n        timestamp = parse_iso8601(show.get('published'))\n\n        mg = show['media:group'][0]\n\n        formats = []\n\n        if mg.get('url'):\n            m = re.match(r'(?P<url>rtmpe?://[^/]+)/(?P<app>.+)/(?P<playpath>mp4:.*)', mg['url'])\n            if m:\n                m = m.groupdict()\n                formats.append({\n                    'url': m['url'] + '/' + m['app'],\n                    'app': m['app'],\n                    'play_path': m['playpath'],\n                    'player_url': url,\n                    'ext': 'flv',\n                    'format_id': 'rtmp',\n                })\n\n        if mg.get('hls_server') and mg.get('hls_url'):\n            formats.extend(self._extract_m3u8_formats(\n                mg['hls_server'] + mg['hls_url'], item_id, 'mp4',\n                entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n\n        if mg.get('hds_server') and mg.get('hds_url'):\n            formats.extend(self._extract_f4m_formats(\n                mg['hds_server'] + mg['hds_url'], item_id,\n                f4m_id='hds', fatal=False))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': item_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 17,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtl2.RTL2IE._real_extract#51",
        "src_path": "youtube_dl/extractor/rtl2.py",
        "class_name": "youtube_dl.extractor.rtl2.RTL2IE",
        "signature": "youtube_dl.extractor.rtl2.RTL2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Some rtl2 urls have no slash at the end, so append it.\n        if not url.endswith('/'):\n            url += '/'\n\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(\n            r'<div[^>]+data-collection=\"(?P<vico_id>\\d+)\"[^>]+data-video=\"(?P<vivi_id>\\d+)\"',\n            webpage)\n        if mobj:\n            vico_id = mobj.group('vico_id')\n            vivi_id = mobj.group('vivi_id')\n        else:\n            vico_id = self._html_search_regex(\n                r'vico_id\\s*:\\s*([0-9]+)', webpage, 'vico_id')\n            vivi_id = self._html_search_regex(\n                r'vivi_id\\s*:\\s*([0-9]+)', webpage, 'vivi_id')\n\n        info = self._download_json(\n            'http://www.rtl2.de/sites/default/modules/rtl2/mediathek/php/get_video_jw.php',\n            video_id, query={\n                'vico_id': vico_id,\n                'vivi_id': vivi_id,\n            })\n        video_info = info['video']\n        title = video_info['titel']\n\n        formats = []\n\n        rtmp_url = video_info.get('streamurl')\n        if rtmp_url:\n            rtmp_url = rtmp_url.replace('\\\\', '')\n            stream_url = 'mp4:' + self._html_search_regex(r'/ondemand/(.+)', rtmp_url, 'stream URL')\n            rtmp_conn = ['S:connect', 'O:1', 'NS:pageUrl:' + url, 'NB:fpad:0', 'NN:videoFunction:1', 'O:0']\n\n            formats.append({\n                'format_id': 'rtmp',\n                'url': rtmp_url,\n                'play_path': stream_url,\n                'player_url': 'http://www.rtl2.de/flashplayer/vipo_player.swf',\n                'page_url': url,\n                'flash_version': 'LNX 11,2,202,429',\n                'rtmp_conn': rtmp_conn,\n                'no_resume': True,\n                'preference': 1,\n            })\n\n        m3u8_url = video_info.get('streamurl_hls')\n        if m3u8_url:\n            formats.extend(self._extract_akamai_formats(m3u8_url, video_id))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': video_info.get('image'),\n            'description': video_info.get('beschreibung'),\n            'duration': int_or_none(video_info.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 51,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtl2.RTL2YouIE._real_extract#139",
        "src_path": "youtube_dl/extractor/rtl2.py",
        "class_name": "youtube_dl.extractor.rtl2.RTL2YouIE",
        "signature": "youtube_dl.extractor.rtl2.RTL2YouIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        stream_data = self._download_json(\n            self._BACKWERK_BASE_URL + 'stream/video/' + video_id, video_id)\n\n        data, iv = base64.b64decode(stream_data['streamUrl']).decode().split(':')\n        stream_url = intlist_to_bytes(aes_cbc_decrypt(\n            bytes_to_intlist(base64.b64decode(data)),\n            bytes_to_intlist(self._AES_KEY),\n            bytes_to_intlist(base64.b64decode(iv))\n        ))\n        if b'rtl2_you_video_not_found' in stream_url:\n            raise ExtractorError('video not found', expected=True)\n\n        formats = self._extract_m3u8_formats(\n            stream_url[:-compat_ord(stream_url[-1])].decode(),\n            video_id, 'mp4', 'm3u8_native')\n        self._sort_formats(formats)\n\n        video_data = self._download_json(\n            self._BACKWERK_BASE_URL + 'video/' + video_id, video_id)\n\n        series = video_data.get('formatTitle')\n        title = episode = video_data.get('title') or series\n        if series and series != title:\n            title = '%s - %s' % (series, title)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': strip_or_none(video_data.get('description')),\n            'thumbnail': video_data.get('image'),\n            'duration': int_or_none(stream_data.get('duration') or video_data.get('duration'), 1000),\n            'series': series,\n            'episode': episode,\n            'age_limit': int_or_none(video_data.get('minimumAge')),\n        }",
        "begin_line": 139,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtl2.RTL2YouSeriesIE._real_extract#191",
        "src_path": "youtube_dl/extractor/rtl2.py",
        "class_name": "youtube_dl.extractor.rtl2.RTL2YouSeriesIE",
        "signature": "youtube_dl.extractor.rtl2.RTL2YouSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        series_id = self._match_id(url)\n        stream_data = self._download_json(\n            self._BACKWERK_BASE_URL + 'videos',\n            series_id, query={\n                'formatId': series_id,\n                'limit': 1000000000,\n            })\n\n        entries = []\n        for video in stream_data.get('videos', []):\n            video_id = compat_str(video['videoId'])\n            if not video_id:\n                continue\n            entries.append(self.url_result(\n                'http://you.rtl2.de/video/%s/%s' % (series_id, video_id),\n                'RTL2You', video_id))\n        return self.playlist_result(entries, series_id)",
        "begin_line": 191,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtlnl.RtlNlIE._real_extract#78",
        "src_path": "youtube_dl/extractor/rtlnl.py",
        "class_name": "youtube_dl.extractor.rtlnl.RtlNlIE",
        "signature": "youtube_dl.extractor.rtlnl.RtlNlIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        uuid = self._match_id(url)\n        info = self._download_json(\n            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=adaptive/' % uuid,\n            uuid)\n\n        material = info['material'][0]\n        title = info['abstracts'][0]['name']\n        subtitle = material.get('title')\n        if subtitle:\n            title += ' - %s' % subtitle\n        description = material.get('synopsis')\n\n        meta = info.get('meta', {})\n\n        # m3u8 streams are encrypted and may not be handled properly by older ffmpeg/avconv.\n        # To workaround this previously adaptive -> flash trick was used to obtain\n        # unencrypted m3u8 streams (see https://github.com/rg3/youtube-dl/issues/4118)\n        # and bypass georestrictions as well.\n        # Currently, unencrypted m3u8 playlists are (intentionally?) invalid and therefore\n        # unusable albeit can be fixed by simple string replacement (see\n        # https://github.com/rg3/youtube-dl/pull/6337)\n        # Since recent ffmpeg and avconv handle encrypted streams just fine encrypted\n        # streams are used now.\n        videopath = material['videopath']\n        m3u8_url = meta.get('videohost', 'http://manifest.us.rtl.nl') + videopath\n\n        formats = self._extract_m3u8_formats(\n            m3u8_url, uuid, 'mp4', m3u8_id='hls', fatal=False)\n\n        video_urlpart = videopath.split('/adaptive/')[1][:-5]\n        PG_URL_TEMPLATE = 'http://pg.us.rtl.nl/rtlxl/network/%s/progressive/%s.mp4'\n\n        PG_FORMATS = (\n            ('a2t', 512, 288),\n            ('a3t', 704, 400),\n            ('nettv', 1280, 720),\n        )\n\n        def pg_format(format_id, width, height):\n            return {\n                'url': PG_URL_TEMPLATE % (format_id, video_urlpart),\n                'format_id': 'pg-%s' % format_id,\n                'protocol': 'http',\n                'width': width,\n                'height': height,\n            }\n\n        if not formats:\n            formats = [pg_format(*pg_tuple) for pg_tuple in PG_FORMATS]\n        else:\n            pg_formats = []\n            for format_id, width, height in PG_FORMATS:\n                try:\n                    # Find hls format with the same width and height corresponding\n                    # to progressive format and copy metadata from it.\n                    f = next(f for f in formats if f.get('height') == height)\n                    # hls formats may have invalid width\n                    f['width'] = width\n                    f_copy = f.copy()\n                    f_copy.update(pg_format(format_id, width, height))\n                    pg_formats.append(f_copy)\n                except StopIteration:\n                    # Missing hls format does mean that no progressive format with\n                    # such width and height exists either.\n                    pass\n            formats.extend(pg_formats)\n        self._sort_formats(formats)\n\n        thumbnails = []\n\n        for p in ('poster_base_url', '\"thumb_base_url\"'):\n            if not meta.get(p):\n                continue\n\n            thumbnails.append({\n                'url': self._proto_relative_url(meta[p] + uuid),\n                'width': int_or_none(self._search_regex(\n                    r'/sz=([0-9]+)', meta[p], 'thumbnail width', fatal=False)),\n                'height': int_or_none(self._search_regex(\n                    r'/sz=[0-9]+x([0-9]+)',\n                    meta[p], 'thumbnail height', fatal=False))\n            })\n\n        return {\n            'id': uuid,\n            'title': title,\n            'formats': formats,\n            'timestamp': material['original_date'],\n            'description': description,\n            'duration': parse_duration(material.get('duration')),\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 78,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtp.RTPIE._real_extract#30",
        "src_path": "youtube_dl/extractor/rtp.py",
        "class_name": "youtube_dl.extractor.rtp.RTPIE",
        "signature": "youtube_dl.extractor.rtp.RTPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_meta(\n            'twitter:title', webpage, display_name='title', fatal=True)\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        player_config = self._search_regex(\n            r'(?s)RTPPLAY\\.player\\.newPlayer\\(\\s*(\\{.*?\\})\\s*\\)', webpage, 'player config')\n        config = self._parse_json(player_config, video_id)\n\n        path, ext = config.get('file').rsplit('.', 1)\n        formats = [{\n            'format_id': 'rtmp',\n            'ext': ext,\n            'vcodec': config.get('type') == 'audio' and 'none' or None,\n            'preference': -2,\n            'url': 'rtmp://{streamer:s}/{application:s}'.format(**config),\n            'app': config.get('application'),\n            'play_path': '{ext:s}:{path:s}'.format(ext=ext, path=path),\n            'page_url': url,\n            'rtmp_live': config.get('live', False),\n            'player_url': 'http://programas.rtp.pt/play/player.swf?v3',\n            'rtmp_real_time': True,\n        }]\n\n        # Construct regular HTTP download URLs\n        replacements = {\n            'audio': {\n                'format_id': 'mp3',\n                'pattern': r'^nas2\\.share/wavrss/',\n                'repl': 'http://rsspod.rtp.pt/podcasts/',\n                'vcodec': 'none',\n            },\n            'video': {\n                'format_id': 'mp4_h264',\n                'pattern': r'^nas2\\.share/h264/',\n                'repl': 'http://rsspod.rtp.pt/videocasts/',\n                'vcodec': 'h264',\n            },\n        }\n        r = replacements[config['type']]\n        if re.match(r['pattern'], config['file']) is not None:\n            formats.append({\n                'format_id': r['format_id'],\n                'url': re.sub(r['pattern'], r['repl'], config['file']),\n                'vcodec': r['vcodec'],\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rts.RTSIE._real_extract#114",
        "src_path": "youtube_dl/extractor/rts.py",
        "class_name": "youtube_dl.extractor.rts.RTSIE",
        "signature": "youtube_dl.extractor.rts.RTSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        media_id = m.group('rts_id') or m.group('id')\n        display_id = m.group('display_id') or media_id\n\n        def download_json(internal_id):\n            return self._download_json(\n                'http://www.rts.ch/a/%s.html?f=json/article' % internal_id,\n                display_id)\n\n        all_info = download_json(media_id)\n\n        # media_id extracted out of URL is not always a real id\n        if 'video' not in all_info and 'audio' not in all_info:\n            entries = []\n\n            for item in all_info.get('items', []):\n                item_url = item.get('url')\n                if not item_url:\n                    continue\n                entries.append(self.url_result(item_url, 'RTS'))\n\n            if not entries:\n                page, urlh = self._download_webpage_handle(url, display_id)\n                if re.match(self._VALID_URL, urlh.geturl()).group('id') != media_id:\n                    return self.url_result(urlh.geturl(), 'RTS')\n\n                # article with videos on rhs\n                videos = re.findall(\n                    r'<article[^>]+class=\"content-item\"[^>]*>\\s*<a[^>]+data-video-urn=\"urn:([^\"]+)\"',\n                    page)\n                if not videos:\n                    videos = re.findall(\n                        r'(?s)<iframe[^>]+class=\"srg-player\"[^>]+src=\"[^\"]+urn:([^\"]+)\"',\n                        page)\n                if videos:\n                    entries = [self.url_result('srgssr:%s' % video_urn, 'SRGSSR') for video_urn in videos]\n\n            if entries:\n                return self.playlist_result(entries, media_id, all_info.get('title'))\n\n            internal_id = self._html_search_regex(\n                r'<(?:video|audio) data-id=\"([0-9]+)\"', page,\n                'internal video id')\n            all_info = download_json(internal_id)\n\n        media_type = 'video' if 'video' in all_info else 'audio'\n\n        # check for errors\n        self.get_media_data('rts', media_type, media_id)\n\n        info = all_info['video']['JSONinfo'] if 'video' in all_info else all_info['audio']\n\n        title = info['title']\n\n        def extract_bitrate(url):\n            return int_or_none(self._search_regex(\n                r'-([0-9]+)k\\.', url, 'bitrate', default=None))\n\n        formats = []\n        streams = info.get('streams', {})\n        for format_id, format_url in streams.items():\n            if format_id == 'hds_sd' and 'hds' in streams:\n                continue\n            if format_id == 'hls_sd' and 'hls' in streams:\n                continue\n            ext = determine_ext(format_url)\n            if ext in ('m3u8', 'f4m'):\n                format_url = self._get_tokenized_src(format_url, media_id, format_id)\n                if ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        format_url + ('?' if '?' not in format_url else '&') + 'hdcore=3.4.0',\n                        media_id, f4m_id=format_id, fatal=False))\n                else:\n                    formats.extend(self._extract_m3u8_formats(\n                        format_url, media_id, 'mp4', 'm3u8_native', m3u8_id=format_id, fatal=False))\n            else:\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                    'tbr': extract_bitrate(format_url),\n                })\n\n        for media in info.get('media', []):\n            media_url = media.get('url')\n            if not media_url or re.match(r'https?://', media_url):\n                continue\n            rate = media.get('rate')\n            ext = media.get('ext') or determine_ext(media_url, 'mp4')\n            format_id = ext\n            if rate:\n                format_id += '-%dk' % rate\n            formats.append({\n                'format_id': format_id,\n                'url': 'http://download-video.rts.ch/' + media_url,\n                'tbr': rate or extract_bitrate(media_url),\n            })\n\n        self._check_formats(formats, media_id)\n        self._sort_formats(formats)\n\n        duration = info.get('duration') or info.get('cutout') or info.get('cutduration')\n        if isinstance(duration, compat_str):\n            duration = parse_duration(duration)\n\n        return {\n            'id': media_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': title,\n            'description': info.get('intro'),\n            'duration': duration,\n            'view_count': int_or_none(info.get('plays')),\n            'uploader': info.get('programName'),\n            'timestamp': parse_iso8601(info.get('broadcast_date')),\n            'thumbnail': unescapeHTML(info.get('preview_image_url')),\n        }",
        "begin_line": 114,
        "end_line": 230,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve._decrypt_url#22",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve",
        "signature": "youtube_dl.extractor.rtve._decrypt_url(png)",
        "snippet": "def _decrypt_url(png):\n    encrypted_data = base64.b64decode(png.encode('utf-8'))\n    text_index = encrypted_data.find(b'tEXt')\n    text_chunk = encrypted_data[text_index - 4:]\n    length = compat_struct_unpack('!I', text_chunk[:4])[0]\n    # Use bytearray to get integers when iterating in both python 2.x and 3.x\n    data = bytearray(text_chunk[8:8 + length])\n    data = [chr(b) for b in data if b != 0]\n    hash_index = data.index('#')\n    alphabet_data = data[:hash_index]\n    url_data = data[hash_index + 1:]\n\n    alphabet = []\n    e = 0\n    d = 0\n    for l in alphabet_data:\n        if d == 0:\n            alphabet.append(l)\n            d = e = (e + 1) % 4\n        else:\n            d -= 1\n    url = ''\n    f = 0\n    e = 3\n    b = 1\n    for letter in url_data:\n        if f == 0:\n            l = int(letter) * 10\n            f = 1\n        else:\n            if e == 0:\n                l += int(letter)\n                url += alphabet[l]\n                e = (b + 3) % 4\n                f = 0\n                b += 1\n            else:\n                e -= 1\n\n    return url",
        "begin_line": 22,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_initialize#95",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        user_agent_b64 = base64.b64encode(std_headers['User-Agent'].encode('utf-8')).decode('utf-8')\n        manager_info = self._download_json(\n            'http://www.rtve.es/odin/loki/' + user_agent_b64,\n            None, 'Fetching manager info')\n        self._manager = manager_info['manager']",
        "begin_line": 95,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract#102",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info = self._download_json(\n            'http://www.rtve.es/api/videos/%s/config/alacarta_videos.json' % video_id,\n            video_id)['page']['items'][0]\n        if info['state'] == 'DESPU':\n            raise ExtractorError('The video is no longer available', expected=True)\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/%s/videos/%s.png' % (self._manager, video_id)\n        png_request = sanitized_Request(png_url)\n        png_request.add_header('Referer', url)\n        png = self._download_webpage(png_request, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n        if not video_url.endswith('.f4m'):\n            if '?' not in video_url:\n                video_url = video_url.replace('resources/', 'auth/resources/')\n            video_url = video_url.replace('.net.rtve', '.multimedia.cdn.rtve')\n\n        subtitles = None\n        if info.get('sbtFile') is not None:\n            subtitles = self.extract_subtitles(video_id, info['sbtFile'])\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info.get('image'),\n            'page_url': url,\n            'subtitles': subtitles,\n            'duration': float_or_none(info.get('duration'), scale=1000),\n        }",
        "begin_line": 102,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._get_subtitles#134",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._get_subtitles(self, video_id, sub_file)",
        "snippet": "    def _get_subtitles(self, video_id, sub_file):\n        subs = self._download_json(\n            sub_file + '.json', video_id,\n            'Downloading subtitles info')['page']['items']\n        return dict(\n            (s['lang'], [{'ext': 'vtt', 'url': s['src']}])\n            for s in subs)",
        "begin_line": 134,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEInfantilIE._real_extract#160",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEInfantilIE",
        "signature": "youtube_dl.extractor.rtve.RTVEInfantilIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        info = self._download_json(\n            'http://www.rtve.es/api/videos/%s/config/alacarta_videos.json' % video_id,\n            video_id)['page']['items'][0]\n\n        webpage = self._download_webpage(url, video_id)\n        vidplayer_id = self._search_regex(\n            r' id=\"vidplayer([0-9]+)\"', webpage, 'internal video ID')\n\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % vidplayer_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info.get('image'),\n            'duration': float_or_none(info.get('duration'), scale=1000),\n        }",
        "begin_line": 160,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract#201",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVELiveIE",
        "signature": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        start_time = time.gmtime()\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = remove_end(self._og_search_title(webpage), ' en directo en RTVE.es')\n        title = remove_start(title, 'Estoy viendo ')\n        title += ' ' + time.strftime('%Y-%m-%dZ%H%M%S', start_time)\n\n        vidplayer_id = self._search_regex(\n            (r'playerId=player([0-9]+)',\n             r'class=[\"\\'].*?\\blive_mod\\b.*?[\"\\'][^>]+data-assetid=[\"\\'](\\d+)',\n             r'data-id=[\"\\'](\\d+)'),\n            webpage, 'internal video ID')\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/amonet/videos/%s.png' % vidplayer_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        m3u8_url = _decrypt_url(png)\n        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 201,
        "end_line": 227,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVETelevisionIE._real_extract#247",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVETelevisionIE",
        "signature": "youtube_dl.extractor.rtve.RTVETelevisionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n\n        alacarta_url = self._search_regex(\n            r'data-location=\"alacarta_videos\"[^<]+url&quot;:&quot;(http://www\\.rtve\\.es/alacarta.+?)&',\n            webpage, 'alacarta url', default=None)\n        if alacarta_url is None:\n            raise ExtractorError(\n                'The webpage doesn\\'t contain any video', expected=True)\n\n        return self.url_result(alacarta_url, ie=RTVEALaCartaIE.ie_key())",
        "begin_line": 247,
        "end_line": 258,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rtvnh.RTVNHIE._real_extract#21",
        "src_path": "youtube_dl/extractor/rtvnh.py",
        "class_name": "youtube_dl.extractor.rtvnh.RTVNHIE",
        "signature": "youtube_dl.extractor.rtvnh.RTVNHIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        meta = self._parse_json(self._download_webpage(\n            'http://www.rtvnh.nl/video/json?m=' + video_id, video_id), video_id)\n\n        status = meta.get('status')\n        if status != 200:\n            raise ExtractorError(\n                '%s returned error code %d' % (self.IE_NAME, status), expected=True)\n\n        formats = []\n        rtmp_formats = self._extract_smil_formats(\n            'http://www.rtvnh.nl/video/smil?m=' + video_id, video_id)\n        formats.extend(rtmp_formats)\n\n        for rtmp_format in rtmp_formats:\n            rtmp_url = '%s/%s' % (rtmp_format['url'], rtmp_format['play_path'])\n            rtsp_format = rtmp_format.copy()\n            del rtsp_format['play_path']\n            del rtsp_format['ext']\n            rtsp_format.update({\n                'format_id': rtmp_format['format_id'].replace('rtmp', 'rtsp'),\n                'url': rtmp_url.replace('rtmp://', 'rtsp://'),\n                'protocol': 'rtsp',\n            })\n            formats.append(rtsp_format)\n            http_base_url = rtmp_url.replace('rtmp://', 'http://')\n            formats.extend(self._extract_m3u8_formats(\n                http_base_url + '/playlist.m3u8', video_id, 'mp4',\n                'm3u8_native', m3u8_id='hls', fatal=False))\n            formats.extend(self._extract_f4m_formats(\n                http_base_url + '/manifest.f4m',\n                video_id, f4m_id='hds', fatal=False))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': meta['title'].strip(),\n            'thumbnail': meta.get('image'),\n            'formats': formats\n        }",
        "begin_line": 21,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rudo.RudoIE._extract_url#29",
        "src_path": "youtube_dl/extractor/rudo.py",
        "class_name": "youtube_dl.extractor.rudo.RudoIE",
        "signature": "youtube_dl.extractor.rudo.RudoIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=(?P<q1>[\\'\"])(?P<url>(?:https?:)?//rudo\\.video/vod/[0-9a-zA-Z]+)(?P=q1)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 29,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rudo.RudoIE._real_extract#36",
        "src_path": "youtube_dl/extractor/rudo.py",
        "class_name": "youtube_dl.extractor.rudo.RudoIE",
        "signature": "youtube_dl.extractor.rudo.RudoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id, encoding='iso-8859-1')\n\n        jwplayer_data = self._parse_json(self._search_regex(\n            r'(?s)playerInstance\\.setup\\(({.+?})\\)', webpage, 'jwplayer data'), video_id,\n            transform_source=lambda s: js_to_json(re.sub(r'encodeURI\\([^)]+\\)', '\"\"', s)))\n\n        info_dict = self._parse_jwplayer_data(\n            jwplayer_data, video_id, require_title=False, m3u8_id='hls', mpd_id='dash')\n\n        info_dict.update({\n            'title': self._og_search_title(webpage),\n            'upload_date': unified_strdate(get_element_by_class('date', webpage)),\n        })\n\n        return info_dict",
        "begin_line": 36,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ruhd.RUHDIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ruhd.py",
        "class_name": "youtube_dl.extractor.ruhd.RUHDIE",
        "signature": "youtube_dl.extractor.ruhd.RUHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<param name=\"src\" value=\"([^\"]+)\"', webpage, 'video url')\n        title = self._html_search_regex(\n            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - \u0412\u0438\u0434\u0435\u043e \u0412\u044b\u0441\u043e\u043a\u043e\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u21161 \u0432 \u0420\u043e\u0441\u0441\u0438\u0438!</title>',\n            webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"longdesc\">(.+?)<span id=\"showlink\">',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'<param name=\"previewImage\" value=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = 'http://www.ruhd.ru' + thumbnail\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ruleporn.RulePornIE._real_extract#22",
        "src_path": "youtube_dl/extractor/ruleporn.py",
        "class_name": "youtube_dl.extractor.ruleporn.RulePornIE",
        "signature": "youtube_dl.extractor.ruleporn.RulePornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._search_regex(\n            r'lovehomeporn\\.com/embed/(\\d+)', webpage, 'video id')\n\n        title = self._search_regex(\n            r'<h2[^>]+title=([\"\\'])(?P<url>.+?)\\1',\n            webpage, 'title', group='url')\n        description = self._html_search_meta('description', webpage)\n\n        info = self._extract_nuevo(\n            'http://lovehomeporn.com/media/nuevo/econfig.php?key=%s&rp=true' % video_id,\n            video_id)\n        info.update({\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'age_limit': 18\n        })\n        return info",
        "begin_line": 22,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeIE._extract_urls#48",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeIE",
        "signature": "youtube_dl.extractor.rutube.RutubeIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [mobj.group('url') for mobj in re.finditer(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//rutube\\.ru/embed/[\\da-z]{32}.*?)\\1',\n            webpage)]",
        "begin_line": 48,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeIE._real_extract#53",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeIE",
        "signature": "youtube_dl.extractor.rutube.RutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video = self._download_json(\n            'http://rutube.ru/api/video/%s/?format=json' % video_id,\n            video_id, 'Downloading video JSON')\n\n        # Some videos don't have the author field\n        author = video.get('author') or {}\n\n        options = self._download_json(\n            'http://rutube.ru/api/play/options/%s/?format=json' % video_id,\n            video_id, 'Downloading options JSON')\n\n        formats = []\n        for format_id, format_url in options['video_balancer'].items():\n            ext = determine_ext(format_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', m3u8_id=format_id, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    format_url, video_id, f4m_id=format_id, fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video['id'],\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'view_count': video['hits'],\n            'formats': formats,\n            'thumbnail': video['thumbnail_url'],\n            'uploader': author.get('name'),\n            'uploader_id': compat_str(author['id']) if author else None,\n            'upload_date': unified_strdate(video['created_ts']),\n            'age_limit': 18 if video['is_adult'] else 0,\n        }",
        "begin_line": 53,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeEmbedIE._real_extract#121",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeEmbedIE",
        "signature": "youtube_dl.extractor.rutube.RutubeEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        embed_id = self._match_id(url)\n        webpage = self._download_webpage(url, embed_id)\n\n        canonical_url = self._html_search_regex(\n            r'<link\\s+rel=\"canonical\"\\s+href=\"([^\"]+?)\"', webpage,\n            'Canonical URL')\n        return self.url_result(canonical_url, 'Rutube')",
        "begin_line": 121,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos#145",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos(self, channel_id, channel_title=None)",
        "snippet": "    def _extract_videos(self, channel_id, channel_title=None):\n        entries = []\n        for pagenum in itertools.count(1):\n            page = self._download_json(\n                self._PAGE_TEMPLATE % (channel_id, pagenum),\n                channel_id, 'Downloading page %s' % pagenum)\n            results = page['results']\n            if not results:\n                break\n            entries.extend(self.url_result(result['video_url'], 'Rutube') for result in results)\n            if not page['has_next']:\n                break\n        return self.playlist_result(entries, channel_id, channel_title)",
        "begin_line": 145,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract#159",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id)",
        "begin_line": 159,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract#174",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeMovieIE",
        "signature": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        movie_id = self._match_id(url)\n        movie = self._download_json(\n            self._MOVIE_TEMPLATE % movie_id, movie_id,\n            'Downloading movie JSON')\n        movie_name = movie['name']\n        return self._extract_videos(movie_id, movie_name)",
        "begin_line": 174,
        "end_line": 180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._extract_url#113",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:test)?player\\.(?:rutv\\.ru|vgtrk\\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=([\"\\'])og:video\\1[^>]+?content=([\"\\'])(?P<url>https?://(?:test)?player\\.(?:rutv\\.ru|vgtrk\\.com)/flash\\d+v/container\\.swf\\?id=.+?\\2)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 113,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._real_extract#125",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_path = mobj.group('path')\n\n        if re.match(r'flash\\d+v', video_path):\n            video_type = 'video'\n        elif video_path.startswith('iframe'):\n            video_type = mobj.group('type')\n            if video_type == 'swf':\n                video_type = 'video'\n        elif video_path.startswith('index/iframe/cast_id'):\n            video_type = 'live'\n\n        is_live = video_type == 'live'\n\n        json_data = self._download_json(\n            'http://player.rutv.ru/iframe/data%s/id/%s' % ('live' if is_live else 'video', video_id),\n            video_id, 'Downloading JSON')\n\n        if json_data['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, json_data['errors']), expected=True)\n\n        playlist = json_data['data']['playlist']\n        medialist = playlist['medialist']\n        media = medialist[0]\n\n        if media['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, media['errors']), expected=True)\n\n        view_count = playlist.get('count_views')\n        priority_transport = playlist['priority_transport']\n\n        thumbnail = media['picture']\n        width = int_or_none(media['width'])\n        height = int_or_none(media['height'])\n        description = media['anons']\n        title = media['title']\n        duration = int_or_none(media.get('duration'))\n\n        formats = []\n\n        for transport, links in media['sources'].items():\n            for quality, url in links.items():\n                preference = -1 if priority_transport == transport else -2\n                if transport == 'rtmp':\n                    mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>.+)$', url)\n                    if not mobj:\n                        continue\n                    fmt = {\n                        'url': mobj.group('url'),\n                        'play_path': mobj.group('playpath'),\n                        'app': mobj.group('app'),\n                        'page_url': 'http://player.rutv.ru',\n                        'player_url': 'http://player.rutv.ru/flash3v/osmf.swf?i=22',\n                        'rtmp_live': True,\n                        'ext': 'flv',\n                        'vbr': int(quality),\n                        'preference': preference,\n                    }\n                elif transport == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        url, video_id, 'mp4', preference=preference, m3u8_id='hls'))\n                    continue\n                else:\n                    fmt = {\n                        'url': url\n                    }\n                fmt.update({\n                    'width': width,\n                    'height': height,\n                    'format_id': '%s-%s' % (transport, quality),\n                })\n                formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'duration': duration,\n            'formats': formats,\n            'is_live': is_live,\n        }",
        "begin_line": 125,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ruutu.RuutuIE._real_extract#58",
        "src_path": "youtube_dl/extractor/ruutu.py",
        "class_name": "youtube_dl.extractor.ruutu.RuutuIE",
        "signature": "youtube_dl.extractor.ruutu.RuutuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_xml = self._download_xml(\n            'http://gatling.ruutu.fi/media-xml-cache?id=%s' % video_id, video_id)\n\n        formats = []\n        processed_urls = []\n\n        def extract_formats(node):\n            for child in node:\n                if child.tag.endswith('Files'):\n                    extract_formats(child)\n                elif child.tag.endswith('File'):\n                    video_url = child.text\n                    if (not video_url or video_url in processed_urls or\n                            any(p in video_url for p in ('NOT_USED', 'NOT-USED'))):\n                        return\n                    processed_urls.append(video_url)\n                    ext = determine_ext(video_url)\n                    if ext == 'm3u8':\n                        formats.extend(self._extract_m3u8_formats(\n                            video_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n                    elif ext == 'f4m':\n                        formats.extend(self._extract_f4m_formats(\n                            video_url, video_id, f4m_id='hds', fatal=False))\n                    elif ext == 'mpd':\n                        # video-only and audio-only streams are of different\n                        # duration resulting in out of sync issue\n                        continue\n                        formats.extend(self._extract_mpd_formats(\n                            video_url, video_id, mpd_id='dash', fatal=False))\n                    else:\n                        proto = compat_urllib_parse_urlparse(video_url).scheme\n                        if not child.tag.startswith('HTTP') and proto != 'rtmp':\n                            continue\n                        preference = -1 if proto == 'rtmp' else 1\n                        label = child.get('label')\n                        tbr = int_or_none(child.get('bitrate'))\n                        format_id = '%s-%s' % (proto, label if label else tbr) if label or tbr else proto\n                        if not self._is_valid_url(video_url, video_id, format_id):\n                            continue\n                        width, height = [int_or_none(x) for x in child.get('resolution', 'x').split('x')[:2]]\n                        formats.append({\n                            'format_id': format_id,\n                            'url': video_url,\n                            'width': width,\n                            'height': height,\n                            'tbr': tbr,\n                            'preference': preference,\n                        })\n\n        extract_formats(video_xml.find('./Clip'))\n\n        drm = xpath_text(video_xml, './Clip/DRM', default=None)\n        if not formats and drm:\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': xpath_attr(video_xml, './/Behavior/Program', 'program_name', 'title', fatal=True),\n            'description': xpath_attr(video_xml, './/Behavior/Program', 'description', 'description'),\n            'thumbnail': xpath_attr(video_xml, './/Behavior/Startpicture', 'href', 'thumbnail'),\n            'duration': int_or_none(xpath_text(video_xml, './/Runtime', 'duration')),\n            'age_limit': int_or_none(xpath_text(video_xml, './/AgeLimit', 'age limit')),\n            'formats': formats,\n        }",
        "begin_line": 58,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ruv.RuvIE._real_extract#53",
        "src_path": "youtube_dl/extractor/ruv.py",
        "class_name": "youtube_dl.extractor.ruv.RuvIE",
        "signature": "youtube_dl.extractor.ruv.RuvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n\n        FIELD_RE = r'video\\.%s\\s*=\\s*([\"\\'])(?P<url>(?:(?!\\1).)+)\\1'\n\n        media_url = self._html_search_regex(\n            FIELD_RE % 'src', webpage, 'video URL', group='url')\n\n        video_id = self._search_regex(\n            r'<link\\b[^>]+\\bhref=[\"\\']https?://www\\.ruv\\.is/node/(\\d+)',\n            webpage, 'video id', default=display_id)\n\n        ext = determine_ext(media_url)\n\n        if ext == 'm3u8':\n            formats = self._extract_m3u8_formats(\n                media_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls')\n        elif ext == 'mp3':\n            formats = [{\n                'format_id': 'mp3',\n                'url': media_url,\n                'vcodec': 'none',\n            }]\n        else:\n            formats = [{\n                'url': media_url,\n            }]\n\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._og_search_thumbnail(\n            webpage, default=None) or self._search_regex(\n            FIELD_RE % 'poster', webpage, 'thumbnail', fatal=False)\n        timestamp = unified_timestamp(self._html_search_meta(\n            'article:published_time', webpage, 'timestamp', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 53,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.safari.SafariBaseIE._real_initialize#26",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariBaseIE",
        "signature": "youtube_dl.extractor.safari.SafariBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 26,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.safari.SafariBaseIE._login#29",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariBaseIE",
        "signature": "youtube_dl.extractor.safari.SafariBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        headers = std_headers.copy()\n        if 'Referer' not in headers:\n            headers['Referer'] = self._LOGIN_URL\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login form', headers=headers)\n\n        def is_logged(webpage):\n            return any(re.search(p, webpage) for p in (\n                r'href=[\"\\']/accounts/logout/', r'>Sign Out<'))\n\n        if is_logged(login_page):\n            self.LOGGED_IN = True\n            return\n\n        csrf = self._html_search_regex(\n            r\"name='csrfmiddlewaretoken'\\s+value='([^']+)'\",\n            login_page, 'csrf token')\n\n        login_form = {\n            'csrfmiddlewaretoken': csrf,\n            'email': username,\n            'password1': password,\n            'login': 'Sign In',\n            'next': '',\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form), headers=headers)\n        login_page = self._download_webpage(\n            request, None, 'Logging in as %s' % username)\n\n        if not is_logged(login_page):\n            raise ExtractorError(\n                'Login failed; make sure your credentials are correct and try again.',\n                expected=True)\n\n        self.LOGGED_IN = True",
        "begin_line": 29,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.safari.SafariIE._real_extract#99",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariIE",
        "signature": "youtube_dl.extractor.safari.SafariIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = '%s/%s' % (mobj.group('course_id'), mobj.group('part'))\n\n        webpage = self._download_webpage(url, video_id)\n        reference_id = self._search_regex(\n            r'data-reference-id=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'kaltura reference id', group='id')\n        partner_id = self._search_regex(\n            r'data-partner-id=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'kaltura widget id', group='id')\n        ui_id = self._search_regex(\n            r'data-ui-id=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n            webpage, 'kaltura uiconf id', group='id')\n\n        query = {\n            'wid': '_%s' % partner_id,\n            'uiconf_id': ui_id,\n            'flashvars[referenceId]': reference_id,\n        }\n\n        if self.LOGGED_IN:\n            kaltura_session = self._download_json(\n                '%s/player/kaltura_session/?reference_id=%s' % (self._API_BASE, reference_id),\n                video_id, 'Downloading kaltura session JSON',\n                'Unable to download kaltura session JSON', fatal=False)\n            if kaltura_session:\n                session = kaltura_session.get('session')\n                if session:\n                    query['flashvars[ks]'] = session\n\n        return self.url_result(update_url_query(\n            'https://cdnapisec.kaltura.com/html5/html5lib/v2.37.1/mwEmbedFrame.php', query),\n            'Kaltura')",
        "begin_line": 99,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.safari.SafariApiIE._real_extract#147",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariApiIE",
        "signature": "youtube_dl.extractor.safari.SafariApiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        part = self._download_json(\n            url, '%s/%s' % (mobj.group('course_id'), mobj.group('part')),\n            'Downloading part JSON')\n        return self.url_result(part['web_url'], SafariIE.ie_key())",
        "begin_line": 147,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.safari.SafariCourseIE._real_extract#184",
        "src_path": "youtube_dl/extractor/safari.py",
        "class_name": "youtube_dl.extractor.safari.SafariCourseIE",
        "signature": "youtube_dl.extractor.safari.SafariCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_id = self._match_id(url)\n\n        course_json = self._download_json(\n            '%s/book/%s/?override_format=%s' % (self._API_BASE, course_id, self._API_FORMAT),\n            course_id, 'Downloading course JSON')\n\n        if 'chapters' not in course_json:\n            raise ExtractorError(\n                'No chapters found for course %s' % course_id, expected=True)\n\n        entries = [\n            self.url_result(chapter, SafariApiIE.ie_key())\n            for chapter in course_json['chapters']]\n\n        course_title = course_json['title']\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 184,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sandia.SandiaIE._real_extract#30",
        "src_path": "youtube_dl/extractor/sandia.py",
        "class_name": "youtube_dl.extractor.sandia.SandiaIE",
        "signature": "youtube_dl.extractor.sandia.SandiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        presentation_data = self._download_json(\n            'http://digitalops.sandia.gov/Mediasite/PlayerService/PlayerService.svc/json/GetPlayerOptions',\n            video_id, data=json.dumps({\n                'getPlayerOptionsRequest': {\n                    'ResourceId': video_id,\n                    'QueryString': '',\n                }\n            }), headers={\n                'Content-Type': 'application/json; charset=utf-8',\n            })['d']['Presentation']\n\n        title = presentation_data['Title']\n\n        formats = []\n        for stream in presentation_data.get('Streams', []):\n            for fd in stream.get('VideoUrls', []):\n                formats.append({\n                    'format_id': fd['MediaType'],\n                    'format_note': fd['MimeType'].partition('/')[2],\n                    'ext': mimetype2ext(fd['MimeType']),\n                    'url': fd['Location'],\n                    'protocol': 'f4m' if fd['MimeType'] == 'video/x-mp4-fragmented' else None,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': presentation_data.get('Description'),\n            'formats': formats,\n            'timestamp': int_or_none(presentation_data.get('UnixTime'), 1000),\n            'duration': int_or_none(presentation_data.get('Duration'), 1000),\n        }",
        "begin_line": 30,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sapo.SapoIE._real_extract#65",
        "src_path": "youtube_dl/extractor/sapo.py",
        "class_name": "youtube_dl.extractor.sapo.SapoIE",
        "signature": "youtube_dl.extractor.sapo.SapoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        item = self._download_xml(\n            'http://rd3.videos.sapo.pt/%s/rss2' % video_id, video_id).find('./channel/item')\n\n        title = item.find('./title').text\n        description = item.find('./{http://videos.sapo.pt/mrss/}synopse').text\n        thumbnail = item.find('./{http://search.yahoo.com/mrss/}content').get('url')\n        duration = parse_duration(item.find('./{http://videos.sapo.pt/mrss/}time').text)\n        uploader = item.find('./{http://videos.sapo.pt/mrss/}author').text\n        upload_date = unified_strdate(item.find('./pubDate').text)\n        view_count = int(item.find('./{http://videos.sapo.pt/mrss/}views').text)\n        comment_count = int(item.find('./{http://videos.sapo.pt/mrss/}comment_count').text)\n        tags = item.find('./{http://videos.sapo.pt/mrss/}tags').text\n        categories = tags.split() if tags else []\n        age_limit = 18 if item.find('./{http://videos.sapo.pt/mrss/}m18').text == 'true' else 0\n\n        video_url = item.find('./{http://videos.sapo.pt/mrss/}videoFile').text\n        video_size = item.find('./{http://videos.sapo.pt/mrss/}videoSize').text.split('x')\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'sd',\n            'width': int(video_size[0]),\n            'height': int(video_size[1]),\n        }]\n\n        if item.find('./{http://videos.sapo.pt/mrss/}HD').text == 'true':\n            formats.append({\n                'url': re.sub(r'/mov/1$', '/mov/39', video_url),\n                'ext': 'mp4',\n                'format_id': 'hd',\n                'width': 1280,\n                'height': 720,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract#30",
        "src_path": "youtube_dl/extractor/savefrom.py",
        "class_name": "youtube_dl.extractor.savefrom.SaveFromIE",
        "signature": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = os.path.splitext(url.split('/')[-1])[0]\n        return {\n            '_type': 'url',\n            'id': video_id,\n            'url': mobj.group('url'),\n        }",
        "begin_line": 30,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sbs.SBSIE._real_extract#39",
        "src_path": "youtube_dl/extractor/sbs.py",
        "class_name": "youtube_dl.extractor.sbs.SBSIE",
        "signature": "youtube_dl.extractor.sbs.SBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        player_params = self._download_json(\n            'http://www.sbs.com.au/api/video_pdkvars/id/%s?form=json' % video_id, video_id)\n\n        error = player_params.get('error')\n        if error:\n            error_message = 'Sorry, The video you are looking for does not exist.'\n            video_data = error.get('results') or {}\n            error_code = error.get('errorCode')\n            if error_code == 'ComingSoon':\n                error_message = '%s is not yet available.' % video_data.get('title', '')\n            elif error_code in ('Forbidden', 'intranetAccessOnly'):\n                error_message = 'Sorry, This video cannot be accessed via this website'\n            elif error_code == 'Expired':\n                error_message = 'Sorry, %s is no longer available.' % video_data.get('title', '')\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error_message), expected=True)\n\n        urls = player_params['releaseUrls']\n        theplatform_url = (urls.get('progressive') or urls.get('html') or\n                           urls.get('standard') or player_params['relatedItemsURL'])\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'id': video_id,\n            'url': smuggle_url(self._proto_relative_url(theplatform_url), {'force_smil_url': True}),\n        }",
        "begin_line": 39,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.screencast.ScreencastIE._real_extract#61",
        "src_path": "youtube_dl/extractor/screencast.py",
        "class_name": "youtube_dl.extractor.screencast.ScreencastIE",
        "signature": "youtube_dl.extractor.screencast.ScreencastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<embed name=\"Video\".*?src=\"([^\"]+)\"', webpage,\n            'QuickTime embed', default=None)\n\n        if video_url is None:\n            flash_vars_s = self._html_search_regex(\n                r'<param name=\"flashVars\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                default=None)\n            if not flash_vars_s:\n                flash_vars_s = self._html_search_regex(\n                    r'<param name=\"initParams\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                    default=None)\n                if flash_vars_s:\n                    flash_vars_s = flash_vars_s.replace(',', '&')\n            if flash_vars_s:\n                flash_vars = compat_parse_qs(flash_vars_s)\n                video_url_raw = compat_urllib_request.quote(\n                    flash_vars['content'][0])\n                video_url = video_url_raw.replace('http%3A', 'http:')\n\n        if video_url is None:\n            video_meta = self._html_search_meta(\n                'og:video', webpage, default=None)\n            if video_meta:\n                video_url = self._search_regex(\n                    r'src=(.*?)(?:$|&)', video_meta,\n                    'meta tag video URL', default=None)\n\n        if video_url is None:\n            raise ExtractorError('Cannot find video')\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                [r'<b>Title:</b> ([^<]+)</div>',\n                 r'class=\"tabSeperator\">></span><span class=\"tabText\">(.+?)<',\n                 r'<title>([^<]+)</title>'],\n                webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage, default=None)\n        if description is None:\n            description = self._html_search_meta('description', webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 61,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE._real_extract#23",
        "src_path": "youtube_dl/extractor/screencastomatic.py",
        "class_name": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE",
        "signature": "youtube_dl.extractor.screencastomatic.ScreencastOMaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        jwplayer_data = self._parse_json(\n            self._search_regex(\n                r\"(?s)jwplayer\\('mp4Player'\\).setup\\((\\{.*?\\})\\);\", webpage, 'setup code'),\n            video_id, transform_source=js_to_json)\n\n        info_dict = self._parse_jwplayer_data(jwplayer_data, video_id, require_title=False)\n        info_dict.update({\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        })\n        return info_dict",
        "begin_line": 23,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.scrippsnetworks.ScrippsNetworksWatchIE._real_extract#30",
        "src_path": "youtube_dl/extractor/scrippsnetworks.py",
        "class_name": "youtube_dl.extractor.scrippsnetworks.ScrippsNetworksWatchIE",
        "signature": "youtube_dl.extractor.scrippsnetworks.ScrippsNetworksWatchIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        channel = self._parse_json(self._search_regex(\n            r'\"channels\"\\s*:\\s*(\\[.+\\])',\n            webpage, 'channels'), video_id)[0]\n        video_data = next(v for v in channel['videos'] if v.get('nlvid') == video_id)\n        title = video_data['title']\n        release_url = video_data['releaseUrl']\n        if video_data.get('restricted'):\n            requestor_id = self._search_regex(\n                r'requestorId\\s*=\\s*\"([^\"]+)\";', webpage, 'requestor id')\n            resource = self._get_mvpd_resource(\n                requestor_id, title, video_id,\n                video_data.get('ratings', [{}])[0].get('rating'))\n            auth = self._extract_mvpd_auth(\n                url, video_id, requestor_id, resource)\n            release_url = update_url_query(release_url, {'auth': auth})\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'url': smuggle_url(release_url, {'force_smil_url': True}),\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('thumbnailUrl'),\n            'series': video_data.get('showTitle'),\n            'season_number': int_or_none(video_data.get('season')),\n            'episode_number': int_or_none(video_data.get('episodeNumber')),\n            'ie_key': 'ThePlatform',\n        }",
        "begin_line": 30,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.seeker.SeekerIE._real_extract#45",
        "src_path": "youtube_dl/extractor/seeker.py",
        "class_name": "youtube_dl.extractor.seeker.SeekerIE",
        "signature": "youtube_dl.extractor.seeker.SeekerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id, article_id = re.match(self._VALID_URL, url).groups()\n        webpage = self._download_webpage(url, display_id)\n        mobj = re.search(r\"player\\.loadRevision3Item\\('([^']+)'\\s*,\\s*(\\d+)\\);\", webpage)\n        if mobj:\n            playlist_type, playlist_id = mobj.groups()\n            return self.url_result(\n                'revision3:%s:%s' % (playlist_type, playlist_id), 'Revision3Embed', playlist_id)\n        else:\n            entries = [self.url_result('revision3:video_id:%s' % video_id, 'Revision3Embed', video_id) for video_id in re.findall(\n                r'<iframe[^>]+src=[\\'\"](?:https?:)?//api\\.seekernetwork\\.com/player/embed\\?videoId=(\\d+)', webpage)]\n            return self.playlist_result(\n                entries, article_id, self._og_search_title(webpage), self._og_search_description(webpage))",
        "begin_line": 45,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url#90",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._search_iframe_url(webpage)",
        "snippet": "    def _search_iframe_url(webpage):\n        mobj = re.search(\n            r\"<iframe[^>]+src=['\\\"](?P<url>https?://www\\.senate\\.gov/isvp/?\\?[^'\\\"]+)['\\\"]\",\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 90,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._get_info_for_comm#97",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._get_info_for_comm(self, committee)",
        "snippet": "    def _get_info_for_comm(self, committee):\n        for entry in self._COMM_MAP:\n            if entry[0] == committee:\n                return entry[1:]",
        "begin_line": 97,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.senateisvp.SenateISVPIE._real_extract#102",
        "src_path": "youtube_dl/extractor/senateisvp.py",
        "class_name": "youtube_dl.extractor.senateisvp.SenateISVPIE",
        "signature": "youtube_dl.extractor.senateisvp.SenateISVPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        qs = compat_parse_qs(re.match(self._VALID_URL, url).group('qs'))\n        if not qs.get('filename') or not qs.get('type') or not qs.get('comm'):\n            raise ExtractorError('Invalid URL', expected=True)\n\n        video_id = re.sub(r'.mp4$', '', qs['filename'][0])\n\n        webpage = self._download_webpage(url, video_id)\n\n        if smuggled_data.get('force_title'):\n            title = smuggled_data['force_title']\n        else:\n            title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, video_id)\n        poster = qs.get('poster')\n        thumbnail = poster[0] if poster else None\n\n        video_type = qs['type'][0]\n        committee = video_type if video_type == 'arch' else qs['comm'][0]\n        stream_num, domain = self._get_info_for_comm(committee)\n\n        formats = []\n        if video_type == 'arch':\n            filename = video_id if '.' in video_id else video_id + '.mp4'\n            formats = [{\n                # All parameters in the query string are necessary to prevent a 403 error\n                'url': compat_urlparse.urljoin(domain, filename) + '?v=3.1.0&fp=&r=&g=',\n            }]\n        else:\n            hdcore_sign = 'hdcore=3.1.0'\n            url_params = (domain, video_id, stream_num)\n            f4m_url = '%s/z/%s_1@%s/manifest.f4m?' % url_params + hdcore_sign\n            m3u8_url = '%s/i/%s_1@%s/master.m3u8' % url_params\n            for entry in self._extract_f4m_formats(f4m_url, video_id, f4m_id='f4m'):\n                # URLs without the extra param induce an 404 error\n                entry.update({'extra_param_to_segment_url': hdcore_sign})\n                formats.append(entry)\n            for entry in self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4', m3u8_id='m3u8'):\n                mobj = re.search(r'(?P<tag>(?:-p|-b)).m3u8', entry['url'])\n                if mobj:\n                    entry['format_id'] += mobj.group('tag')\n                formats.append(entry)\n\n            self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 102,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sendtonews.SendtoNewsIE._extract_url#49",
        "src_path": "youtube_dl/extractor/sendtonews.py",
        "class_name": "youtube_dl.extractor.sendtonews.SendtoNewsIE",
        "signature": "youtube_dl.extractor.sendtonews.SendtoNewsIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(r'''(?x)<script[^>]+src=([\\'\"])\n            (?:https?:)?//embed\\.sendtonews\\.com/player/responsiveembed\\.php\\?\n                .*\\bSC=(?P<SC>[0-9a-zA-Z-]+).*\n            \\1>''', webpage)\n        if mobj:\n            sc = mobj.group('SC')\n            return cls._URL_TEMPLATE % sc",
        "begin_line": 49,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sendtonews.SendtoNewsIE._real_extract#58",
        "src_path": "youtube_dl/extractor/sendtonews.py",
        "class_name": "youtube_dl.extractor.sendtonews.SendtoNewsIE",
        "signature": "youtube_dl.extractor.sendtonews.SendtoNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        data_url = update_url_query(\n            url.replace('embedplayer.php', 'data_read.php'),\n            {'cmd': 'loadInitial'})\n        playlist_data = self._download_json(data_url, playlist_id)\n\n        entries = []\n        for video in playlist_data['playlistData'][0]:\n            info_dict = self._parse_jwplayer_data(\n                video['jwconfiguration'],\n                require_title=False, m3u8_id='hls', rtmp_params={'no_resume': True})\n\n            for f in info_dict['formats']:\n                if f.get('tbr'):\n                    continue\n                tbr = int_or_none(self._search_regex(\n                    r'/(\\d+)k/', f['url'], 'bitrate', default=None))\n                if not tbr:\n                    continue\n                f.update({\n                    'format_id': '%s-%d' % (determine_protocol(f), tbr),\n                    'tbr': tbr,\n                })\n            self._sort_formats(info_dict['formats'], ('tbr', 'height', 'width', 'format_id'))\n\n            thumbnails = []\n            if video.get('thumbnailUrl'):\n                thumbnails.append({\n                    'id': 'normal',\n                    'url': video['thumbnailUrl'],\n                })\n            if video.get('smThumbnailUrl'):\n                thumbnails.append({\n                    'id': 'small',\n                    'url': video['smThumbnailUrl'],\n                })\n            info_dict.update({\n                'title': video['S_headLine'].strip(),\n                'description': unescapeHTML(video.get('S_fullStory')),\n                'thumbnails': thumbnails,\n                'duration': float_or_none(video.get('SM_length')),\n                'timestamp': parse_iso8601(video.get('S_sysDate'), delimiter=' '),\n            })\n            entries.append(info_dict)\n\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 58,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract#47",
        "src_path": "youtube_dl/extractor/servingsys.py",
        "class_name": "youtube_dl.extractor.servingsys.ServingSysIE",
        "signature": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        pl_id = self._match_id(url)\n        vast_doc = self._download_xml(url, pl_id)\n\n        title = vast_doc.find('.//AdTitle').text\n        media = vast_doc.find('.//MediaFile').text\n        info_url = self._search_regex(r'&adData=([^&]+)&', media, 'info URL')\n\n        doc = self._download_xml(info_url, pl_id, 'Downloading video info')\n        entries = [{\n            '_type': 'video',\n            'id': a.attrib['id'],\n            'title': '%s (%s)' % (title, a.attrib['assetID']),\n            'url': a.attrib['URL'],\n            'duration': int_or_none(a.attrib.get('length')),\n            'tbr': int_or_none(a.attrib.get('bitrate')),\n            'height': int_or_none(a.attrib.get('height')),\n            'width': int_or_none(a.attrib.get('width')),\n        } for a in doc.findall('.//AdditionalAssets/asset')]\n\n        return {\n            '_type': 'playlist',\n            'id': pl_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 47,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sexu.SexuIE._real_extract#22",
        "src_path": "youtube_dl/extractor/sexu.py",
        "class_name": "youtube_dl.extractor.sexu.SexuIE",
        "signature": "youtube_dl.extractor.sexu.SexuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        jwvideo = self._parse_json(\n            self._search_regex(r'\\.setup\\(\\s*({.+?})\\s*\\);', webpage, 'jwvideo'),\n            video_id)\n\n        sources = jwvideo['sources']\n\n        formats = [{\n            'url': source['file'].replace('\\\\', ''),\n            'format_id': source.get('label'),\n            'height': int(self._search_regex(\n                r'^(\\d+)[pP]', source.get('label', ''), 'height',\n                default=None)),\n        } for source in sources if source.get('file')]\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*Sexu\\.Com</title>', webpage, 'title')\n\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        thumbnail = jwvideo.get('image')\n\n        categories_str = self._html_search_meta(\n            'keywords', webpage, 'categories')\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 22,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._real_initialize#46",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        email, password = self._get_login_info()\n        if email is None:\n            return\n\n        try:\n            user_data = self._download_json(\n                'https://shahid.mbc.net/wd/service/users/login',\n                None, 'Logging in', data=json.dumps({\n                    'email': email,\n                    'password': password,\n                    'basic': 'false',\n                }).encode('utf-8'), headers={\n                    'Content-Type': 'application/json; charset=UTF-8',\n                })['user']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                fail_data = self._parse_json(\n                    e.cause.read().decode('utf-8'), None, fatal=False)\n                if fail_data:\n                    faults = fail_data.get('faults', [])\n                    faults_message = ', '.join([clean_html(fault['userMessage']) for fault in faults if fault.get('userMessage')])\n                    if faults_message:\n                        raise ExtractorError(faults_message, expected=True)\n            raise\n\n        self._download_webpage(\n            'https://shahid.mbc.net/populateContext',\n            None, 'Populate Context', data=urlencode_postdata({\n                'firstName': user_data['firstName'],\n                'lastName': user_data['lastName'],\n                'userName': user_data['email'],\n                'csg_user_name': user_data['email'],\n                'subscriberId': user_data['id'],\n                'sessionId': user_data['sessionId'],\n            }))",
        "begin_line": 46,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._get_api_data#83",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._get_api_data(self, response)",
        "snippet": "    def _get_api_data(self, response):\n        data = response.get('data', {})\n\n        error = data.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, '\\n'.join(error.values())),\n                expected=True)\n\n        return data",
        "begin_line": 83,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shahid.ShahidIE._real_extract#94",
        "src_path": "youtube_dl/extractor/shahid.py",
        "class_name": "youtube_dl.extractor.shahid.ShahidIE",
        "signature": "youtube_dl.extractor.shahid.ShahidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_type, video_id = re.match(self._VALID_URL, url).groups()\n\n        player = self._get_api_data(self._download_json(\n            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-%s.type-player.html' % video_id,\n            video_id, 'Downloading player JSON'))\n\n        if player.get('drm'):\n            raise ExtractorError('This video is DRM protected.', expected=True)\n\n        formats = self._extract_m3u8_formats(player['url'], video_id, 'mp4')\n        self._sort_formats(formats)\n\n        video = self._get_api_data(self._download_json(\n            'http://api.shahid.net/api/v1_1/%s/%s' % (page_type, video_id),\n            video_id, 'Downloading video JSON', query={\n                'apiKey': 'sh@hid0nlin3',\n                'hash': 'b2wMCTHpSmyxGqQjJFOycRmLSex+BpTK/ooxy6vHaqs=',\n            }))[page_type]\n\n        title = video['title']\n        categories = [\n            category['name']\n            for category in video.get('genres', []) if 'name' in category]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnail': video.get('thumbnailUrl'),\n            'duration': int_or_none(video.get('duration')),\n            'timestamp': parse_iso8601(video.get('referenceDate')),\n            'categories': categories,\n            'series': video.get('showTitle') or video.get('showName'),\n            'season': video.get('seasonTitle'),\n            'season_number': int_or_none(video.get('seasonNumber')),\n            'season_id': str_or_none(video.get('seasonId')),\n            'episode_number': int_or_none(video.get('number')),\n            'episode_id': video_id,\n            'formats': formats,\n        }",
        "begin_line": 94,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shared.SharedBaseIE._real_extract#14",
        "src_path": "youtube_dl/extractor/shared.py",
        "class_name": "youtube_dl.extractor.shared.SharedBaseIE",
        "signature": "youtube_dl.extractor.shared.SharedBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n\n        if self._FILE_NOT_FOUND in webpage:\n            raise ExtractorError(\n                'Video %s does not exist' % video_id, expected=True)\n\n        video_url = self._extract_video_url(webpage, video_id, url)\n\n        title = base64.b64decode(self._html_search_meta(\n            'full:title', webpage, 'title').encode('utf-8')).decode('utf-8')\n        filesize = int_or_none(self._html_search_meta(\n            'full:size', webpage, 'file size', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'filesize': filesize,\n            'title': title,\n        }",
        "begin_line": 14,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shared.SharedIE._extract_video_url#55",
        "src_path": "youtube_dl/extractor/shared.py",
        "class_name": "youtube_dl.extractor.shared.SharedIE",
        "signature": "youtube_dl.extractor.shared.SharedIE._extract_video_url(self, webpage, video_id, url)",
        "snippet": "    def _extract_video_url(self, webpage, video_id, url):\n        download_form = self._hidden_inputs(webpage)\n\n        video_page = self._download_webpage(\n            url, video_id, 'Downloading video page',\n            data=urlencode_postdata(download_form),\n            headers={\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Referer': url,\n            })\n\n        video_url = self._html_search_regex(\n            r'data-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n            video_page, 'video URL', group='url')\n\n        return video_url",
        "begin_line": 55,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.shared.VivoIE._extract_video_url#89",
        "src_path": "youtube_dl/extractor/shared.py",
        "class_name": "youtube_dl.extractor.shared.VivoIE",
        "signature": "youtube_dl.extractor.shared.VivoIE._extract_video_url(self, webpage, video_id, *args)",
        "snippet": "    def _extract_video_url(self, webpage, video_id, *args):\n        return self._parse_json(\n            self._search_regex(\n                r'InitializeStream\\s*\\(\\s*([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n                webpage, 'stream', group='url'),\n            video_id,\n            transform_source=lambda x: base64.b64decode(\n                x.encode('ascii')).decode('utf-8'))[0]",
        "begin_line": 89,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.showroomlive.ShowRoomLiveIE._real_extract#20",
        "src_path": "youtube_dl/extractor/showroomlive.py",
        "class_name": "youtube_dl.extractor.showroomlive.ShowRoomLiveIE",
        "signature": "youtube_dl.extractor.showroomlive.ShowRoomLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        broadcaster_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, broadcaster_id)\n\n        room_id = self._search_regex(\n            (r'SrGlobal\\.roomId\\s*=\\s*(\\d+)',\n             r'(?:profile|room)\\?room_id\\=(\\d+)'), webpage, 'room_id')\n\n        room = self._download_json(\n            urljoin(url, '/api/room/profile?room_id=%s' % room_id),\n            broadcaster_id)\n\n        is_live = room.get('is_onlive')\n        if is_live is not True:\n            raise ExtractorError('%s is offline' % broadcaster_id, expected=True)\n\n        uploader = room.get('performer_name') or broadcaster_id\n        title = room.get('room_name') or room.get('main_name') or uploader\n\n        streaming_url_list = self._download_json(\n            urljoin(url, '/api/live/streaming_url?room_id=%s' % room_id),\n            broadcaster_id)['streaming_url_list']\n\n        formats = []\n        for stream in streaming_url_list:\n            stream_url = stream.get('url')\n            if not stream_url:\n                continue\n            stream_type = stream.get('type')\n            if stream_type == 'hls':\n                m3u8_formats = self._extract_m3u8_formats(\n                    stream_url, broadcaster_id, ext='mp4', m3u8_id='hls',\n                    live=True)\n                for f in m3u8_formats:\n                    f['quality'] = int_or_none(stream.get('quality', 100))\n                formats.extend(m3u8_formats)\n            elif stream_type == 'rtmp':\n                stream_name = stream.get('stream_name')\n                if not stream_name:\n                    continue\n                formats.append({\n                    'url': stream_url,\n                    'play_path': stream_name,\n                    'page_url': url,\n                    'player_url': 'https://www.showroom-live.com/assets/swf/v3/ShowRoomLive.swf',\n                    'rtmp_live': True,\n                    'ext': 'flv',\n                    'format_id': 'rtmp',\n                    'format_note': stream.get('label'),\n                    'quality': int_or_none(stream.get('quality', 100)),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(room.get('live_id') or broadcaster_id),\n            'title': self._live_title(title),\n            'description': room.get('description'),\n            'timestamp': int_or_none(room.get('current_live_started_at')),\n            'uploader': uploader,\n            'uploader_id': broadcaster_id,\n            'view_count': int_or_none(room.get('view_num')),\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 20,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._real_extract#58",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('video_id')\n        if not video_id:\n            if mobj.group('token') is not None:\n                # The video id is in the redirected url\n                self.to_screen('Getting video id')\n                request = HEADRequest(url)\n                (_, urlh) = self._download_webpage_handle(request, 'NA', False)\n                return self._real_extract(urlh.geturl())\n            else:\n                pseudo_id = mobj.group('pseudo_id')\n                webpage = self._download_webpage(url, pseudo_id)\n                error = get_element_by_attribute('class', 'errtitle', webpage)\n                if error:\n                    raise ExtractorError('%s said: %s' % (\n                        self.IE_NAME, clean_html(error)), expected=True)\n                video_id = self._search_regex(\n                    r\"video_id\\s*:\\s*'(\\d+)'\", webpage, 'video id')\n\n        video_data = self._download_json(\n            'http://s.video.sina.com.cn/video/h5play',\n            video_id, query={'video_id': video_id})\n        if video_data['code'] != 1:\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, video_data['message']), expected=True)\n        else:\n            video_data = video_data['data']\n            title = video_data['title']\n            description = video_data.get('description')\n            if description:\n                description = description.strip()\n\n            preference = qualities(['cif', 'sd', 'hd', 'fhd', 'ffd'])\n            formats = []\n            for quality_id, quality in video_data.get('videos', {}).get('mp4', {}).items():\n                file_api = quality.get('file_api')\n                file_id = quality.get('file_id')\n                if not file_api or not file_id:\n                    continue\n                formats.append({\n                    'format_id': quality_id,\n                    'url': update_url_query(file_api, {'vid': file_id}),\n                    'preference': preference(quality_id),\n                    'ext': 'mp4',\n                })\n            self._sort_formats(formats)\n\n            return {\n                'id': video_id,\n                'title': title,\n                'description': description,\n                'thumbnail': video_data.get('image'),\n                'duration': int_or_none(video_data.get('length')),\n                'timestamp': int_or_none(video_data.get('create_time')),\n                'formats': formats,\n            }",
        "begin_line": 58,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sixplay.SixPlayIE._real_extract#35",
        "src_path": "youtube_dl/extractor/sixplay.py",
        "class_name": "youtube_dl.extractor.sixplay.SixPlayIE",
        "signature": "youtube_dl.extractor.sixplay.SixPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'https://pc.middleware.6play.fr/6play/v2/platforms/m6group_web/services/6play/videos/clip_%s' % video_id,\n            video_id, query={\n                'csa': 5,\n                'with': 'clips',\n            })\n\n        clip_data = data['clips'][0]\n        title = clip_data['title']\n\n        urls = []\n        quality_key = qualities(['lq', 'sd', 'hq', 'hd'])\n        formats = []\n        for asset in clip_data['assets']:\n            asset_url = asset.get('full_physical_path')\n            protocol = asset.get('protocol')\n            if not asset_url or protocol == 'primetime' or asset_url in urls:\n                continue\n            urls.append(asset_url)\n            container = asset.get('video_container')\n            ext = determine_ext(asset_url)\n            if container == 'm3u8' or ext == 'm3u8':\n                if protocol == 'usp':\n                    asset_url = re.sub(r'/([^/]+)\\.ism/[^/]*\\.m3u8', r'/\\1.ism/\\1.m3u8', asset_url)\n                    formats.extend(self._extract_m3u8_formats(\n                        asset_url, video_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n                    formats.extend(self._extract_f4m_formats(\n                        asset_url.replace('.m3u8', '.f4m'),\n                        video_id, f4m_id='hds', fatal=False))\n                    formats.extend(self._extract_mpd_formats(\n                        asset_url.replace('.m3u8', '.mpd'),\n                        video_id, mpd_id='dash', fatal=False))\n                    formats.extend(self._extract_ism_formats(\n                        re.sub(r'/[^/]+\\.m3u8', '/Manifest', asset_url),\n                        video_id, ism_id='mss', fatal=False))\n                else:\n                    formats.extend(self._extract_m3u8_formats(\n                        asset_url, video_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n            elif container == 'mp4' or ext == 'mp4':\n                quality = asset.get('video_quality')\n                formats.append({\n                    'url': asset_url,\n                    'format_id': quality,\n                    'quality': quality_key(quality),\n                    'ext': ext,\n                })\n        self._sort_formats(formats)\n\n        def get(getter):\n            for src in (data, clip_data):\n                v = try_get(src, getter, compat_str)\n                if v:\n                    return v\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': get(lambda x: x['description']),\n            'duration': int_or_none(clip_data.get('duration')),\n            'series': get(lambda x: x['program']['title']),\n            'formats': formats,\n        }",
        "begin_line": 35,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skylinewebcams.SkylineWebcamsIE._real_extract#23",
        "src_path": "youtube_dl/extractor/skylinewebcams.py",
        "class_name": "youtube_dl.extractor.skylinewebcams.SkylineWebcamsIE",
        "signature": "youtube_dl.extractor.skylinewebcams.SkylineWebcamsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        stream_url = self._search_regex(\n            r'url\\s*:\\s*([\"\\'])(?P<url>(?:https?:)?//.+?\\.m3u8.*?)\\1', webpage,\n            'stream url', group='url')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n\n        return {\n            'id': video_id,\n            'url': stream_url,\n            'ext': 'mp4',\n            'title': self._live_title(title),\n            'description': description,\n            'is_live': True,\n        }",
        "begin_line": 23,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._call_api#15",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._call_api(self, path, value)",
        "snippet": "    def _call_api(self, path, value):\n        return self._download_json('http://api.skynewsarabia.com/web/rest/v2/%s/%s.json' % (path, value), value)",
        "begin_line": 15,
        "end_line": 16,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._get_limelight_media_id#18",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._get_limelight_media_id(self, url)",
        "snippet": "    def _get_limelight_media_id(self, url):\n        return self._search_regex(r'/media/[^/]+/([a-z0-9]{32})', url, 'limelight media id')",
        "begin_line": 18,
        "end_line": 19,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._get_image_url#21",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._get_image_url(self, image_path_template, width='1600', height='1200')",
        "snippet": "    def _get_image_url(self, image_path_template, width='1600', height='1200'):\n        return self._IMAGE_BASE_URL + image_path_template.format(width=width, height=height)",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._extract_video_info#24",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaBaseIE._extract_video_info(self, video_data)",
        "snippet": "    def _extract_video_info(self, video_data):\n        video_id = compat_str(video_data['id'])\n        topic = video_data.get('topicTitle')\n        return {\n            '_type': 'url_transparent',\n            'url': 'limelight:media:%s' % self._get_limelight_media_id(video_data['videoUrl'][0]['url']),\n            'id': video_id,\n            'title': video_data['headline'],\n            'description': video_data.get('summary'),\n            'thumbnail': self._get_image_url(video_data['mediaAsset']['imageUrl']),\n            'timestamp': parse_iso8601(video_data.get('date')),\n            'duration': parse_duration(video_data.get('runTime')),\n            'tags': video_data.get('tags', []),\n            'categories': [topic] if topic else [],\n            'webpage_url': 'http://www.skynewsarabia.com/web/video/%s' % video_id,\n            'ie_key': 'LimelightMedia',\n        }",
        "begin_line": 24,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaIE._real_extract#63",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._call_api('video', video_id)\n        return self._extract_video_info(video_data)",
        "begin_line": 63,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaArticleIE._real_extract#97",
        "src_path": "youtube_dl/extractor/skynewsarabia.py",
        "class_name": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaArticleIE",
        "signature": "youtube_dl.extractor.skynewsarabia.SkyNewsArabiaArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        article_id = self._match_id(url)\n        article_data = self._call_api('article', article_id)\n        media_asset = article_data['mediaAsset']\n        if media_asset['type'] == 'VIDEO':\n            topic = article_data.get('topicTitle')\n            return {\n                '_type': 'url_transparent',\n                'url': 'limelight:media:%s' % self._get_limelight_media_id(media_asset['videoUrl'][0]['url']),\n                'id': article_id,\n                'title': article_data['headline'],\n                'description': article_data.get('summary'),\n                'thumbnail': self._get_image_url(media_asset['imageUrl']),\n                'timestamp': parse_iso8601(article_data.get('date')),\n                'tags': article_data.get('tags', []),\n                'categories': [topic] if topic else [],\n                'webpage_url': url,\n                'ie_key': 'LimelightMedia',\n            }\n        entries = [self._extract_video_info(item) for item in article_data.get('inlineItems', []) if item['type'] == 'VIDEO']\n        return self.playlist_result(entries, article_id, article_data['headline'], article_data.get('summary'))",
        "begin_line": 97,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.skysports.SkySportsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/skysports.py",
        "class_name": "youtube_dl.extractor.skysports.SkySportsIE",
        "signature": "youtube_dl.extractor.skysports.SkySportsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': 'ooyala:%s' % self._search_regex(\n                r'data-video-id=\"([^\"]+)\"', webpage, 'ooyala id'),\n            'title': self._og_search_title(webpage),\n            'description': strip_or_none(self._og_search_description(webpage)),\n            'ie_key': 'Ooyala',\n        }",
        "begin_line": 22,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract#29",
        "src_path": "youtube_dl/extractor/slideshare.py",
        "class_name": "youtube_dl.extractor.slideshare.SlideshareIE",
        "signature": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        slideshare_obj = self._search_regex(\n            r'\\$\\.extend\\(.*?slideshare_object,\\s*(\\{.*?\\})\\);',\n            webpage, 'slideshare object')\n        info = json.loads(slideshare_obj)\n        if info['slideshow']['type'] != 'video':\n            raise ExtractorError('Webpage type is \"%s\": only video extraction is supported for Slideshare' % info['slideshow']['type'], expected=True)\n\n        doc = info['doc']\n        bucket = info['jsplayer']['video_bucket']\n        ext = info['jsplayer']['video_extension']\n        video_url = compat_urlparse.urljoin(bucket, doc + '-SD.' + ext)\n        description = get_element_by_id('slideshow-description-paragraph', webpage) or self._html_search_regex(\n            r'(?s)<p[^>]+itemprop=\"description\"[^>]*>(.+?)</p>', webpage,\n            'description', fatal=False)\n\n        return {\n            '_type': 'video',\n            'id': info['slideshow']['id'],\n            'title': info['slideshow']['title'],\n            'ext': ext,\n            'url': video_url,\n            'thumbnail': info['slideshow']['pin_image_url'],\n            'description': description.strip() if description else None,\n        }",
        "begin_line": 29,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.slutload.SlutloadIE._real_extract#20",
        "src_path": "youtube_dl/extractor/slutload.py",
        "class_name": "youtube_dl.extractor.slutload.SlutloadIE",
        "signature": "youtube_dl.extractor.slutload.SlutloadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<h1><strong>([^<]+)</strong>',\n                                              webpage, 'title').strip()\n\n        video_url = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+data-url=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+.*?previewer-file=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': 18\n        }",
        "begin_line": 20,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._extract_url#144",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<embed[^>]src=([\"\\'])(?P<url>http://pics\\.smotri\\.com/(?:player|scrubber_custom8)\\.swf\\?file=v.+?\\1)',\n            webpage)\n        if mobj is not None:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'''(?x)<div\\s+class=\"video_file\">http://smotri\\.com/video/download/file/[^<]+</div>\\s*\n                    <div\\s+class=\"video_image\">[^<]+</div>\\s*\n                    <div\\s+class=\"video_id\">(?P<id>[^<]+)</div>''', webpage)\n        if mobj is not None:\n            return 'http://smotri.com/video/view/?id=%s' % mobj.group('id')",
        "begin_line": 144,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._search_meta#158",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._search_meta(self, name, html, display_name=None)",
        "snippet": "    def _search_meta(self, name, html, display_name=None):\n        if display_name is None:\n            display_name = name\n        return self._html_search_meta(name, html, display_name)",
        "begin_line": 158,
        "end_line": 161,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._real_extract#163",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_form = {\n            'ticket': video_id,\n            'video_url': '1',\n            'frame_url': '1',\n            'devid': 'LoadupFlashPlayer',\n            'getvideoinfo': '1',\n        }\n\n        video_password = self._downloader.params.get('videopassword')\n        if video_password:\n            video_form['pass'] = hashlib.md5(video_password.encode('utf-8')).hexdigest()\n\n        video = self._download_json(\n            'http://smotri.com/video/view/url/bot/',\n            video_id, 'Downloading video JSON',\n            data=urlencode_postdata(video_form),\n            headers={'Content-Type': 'application/x-www-form-urlencoded'})\n\n        video_url = video.get('_vidURL') or video.get('_vidURL_mp4')\n\n        if not video_url:\n            if video.get('_moderate_no'):\n                raise ExtractorError(\n                    'Video %s has not been approved by moderator' % video_id, expected=True)\n\n            if video.get('error'):\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n            if video.get('_pass_protected') == 1:\n                msg = ('Invalid video password' if video_password\n                       else 'This video is protected by a password, use the --video-password option')\n                raise ExtractorError(msg, expected=True)\n\n        title = video['title']\n        thumbnail = video.get('_imgURL')\n        upload_date = unified_strdate(video.get('added'))\n        uploader = video.get('userNick')\n        uploader_id = video.get('userLogin')\n        duration = int_or_none(video.get('duration'))\n\n        # Video JSON does not provide enough meta data\n        # We will extract some from the video web page instead\n        webpage_url = 'http://smotri.com/video/view/?id=%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id, 'Downloading video page')\n\n        # Warning if video is unavailable\n        warning = self._html_search_regex(\n            r'<div[^>]+class=\"videoUnModer\"[^>]*>(.+?)</div>', webpage,\n            'warning message', default=None)\n        if warning is not None:\n            self._downloader.report_warning(\n                'Video %s may not be available; smotri said: %s ' %\n                (video_id, warning))\n\n        # Adult content\n        if 'EroConfirmText\">' in webpage:\n            self.report_age_confirmation()\n            confirm_string = self._html_search_regex(\n                r'<a[^>]+href=\"/video/view/\\?id=%s&confirm=([^\"]+)\"' % video_id,\n                webpage, 'confirm string')\n            confirm_url = webpage_url + '&confirm=%s' % confirm_string\n            webpage = self._download_webpage(\n                confirm_url, video_id,\n                'Downloading video page (age confirmed)')\n            adult_content = True\n        else:\n            adult_content = False\n\n        view_count = self._html_search_regex(\n            r'(?s)\u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432.*?<span class=\"Number\">(\\d+)</span>',\n            webpage, 'view count', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'age_limit': 18 if adult_content else 0,\n        }",
        "begin_line": 163,
        "end_line": 249,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract#264",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriCommunityIE",
        "signature": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        community_id = self._match_id(url)\n\n        rss = self._download_xml(\n            'http://smotri.com/export/rss/video/by/community/-/%s/video.xml' % community_id,\n            community_id, 'Downloading community RSS')\n\n        entries = [\n            self.url_result(video_url.text, SmotriIE.ie_key())\n            for video_url in rss.findall('./channel/item/link')]\n\n        return self.playlist_result(entries, community_id)",
        "begin_line": 264,
        "end_line": 275,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract#291",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriUserIE",
        "signature": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n\n        rss = self._download_xml(\n            'http://smotri.com/export/rss/user/video/-/%s/video.xml' % user_id,\n            user_id, 'Downloading user RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = xpath_text(rss, './channel/description') or ''\n        user_nickname = self._search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0440\u0435\u0436\u0438\u0441\u0441\u0435\u0440\u0430 (.+)$', description_text,\n            'user nickname', fatal=False)\n\n        return self.playlist_result(entries, user_id, user_nickname)",
        "begin_line": 291,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract#314",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriBroadcastIE",
        "signature": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        broadcast_id = mobj.group('id')\n\n        broadcast_url = 'http://' + mobj.group('url')\n        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, 'Downloading broadcast page')\n\n        if re.search('>\u0420\u0435\u0436\u0438\u0441\u0441\u0435\u0440 \u0441 \u043b\u043e\u0433\u0438\u043d\u043e\u043c <br/>\"%s\"<br/> <span>\u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442<' % broadcast_id, broadcast_page) is not None:\n            raise ExtractorError(\n                'Broadcast %s does not exist' % broadcast_id, expected=True)\n\n        # Adult content\n        if re.search('EroConfirmText\">', broadcast_page) is not None:\n\n            (username, password) = self._get_login_info()\n            if username is None:\n                self.raise_login_required(\n                    'Erotic broadcasts allowed only for registered users')\n\n            login_form = {\n                'login-hint53': '1',\n                'confirm_erotic': '1',\n                'login': username,\n                'password': password,\n            }\n\n            request = sanitized_Request(\n                broadcast_url + '/?no_redirect=1', urlencode_postdata(login_form))\n            request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            broadcast_page = self._download_webpage(\n                request, broadcast_id, 'Logging in and confirming age')\n\n            if '>\u041d\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u043b\u043e\u0433\u0438\u043d \u0438\u043b\u0438 \u043f\u0430\u0440\u043e\u043b\u044c<' in broadcast_page:\n                raise ExtractorError(\n                    'Unable to log in: bad username or password', expected=True)\n\n            adult_content = True\n        else:\n            adult_content = False\n\n        ticket = self._html_search_regex(\n            r\"window\\.broadcast_control\\.addFlashVar\\('file'\\s*,\\s*'([^']+)'\\)\",\n            broadcast_page, 'broadcast ticket')\n\n        url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket\n\n        broadcast_password = self._downloader.params.get('videopassword')\n        if broadcast_password:\n            url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()\n\n        broadcast_json_page = self._download_webpage(\n            url, broadcast_id, 'Downloading broadcast JSON')\n\n        try:\n            broadcast_json = json.loads(broadcast_json_page)\n\n            protected_broadcast = broadcast_json['_pass_protected'] == 1\n            if protected_broadcast and not broadcast_password:\n                raise ExtractorError(\n                    'This broadcast is protected by a password, use the --video-password option',\n                    expected=True)\n\n            broadcast_offline = broadcast_json['is_play'] == 0\n            if broadcast_offline:\n                raise ExtractorError('Broadcast %s is offline' % broadcast_id, expected=True)\n\n            rtmp_url = broadcast_json['_server']\n            mobj = re.search(r'^rtmp://[^/]+/(?P<app>.+)/?$', rtmp_url)\n            if not mobj:\n                raise ExtractorError('Unexpected broadcast rtmp URL')\n\n            broadcast_playpath = broadcast_json['_streamName']\n            broadcast_app = '%s/%s' % (mobj.group('app'), broadcast_json['_vidURL'])\n            broadcast_thumbnail = broadcast_json.get('_imgURL')\n            broadcast_title = self._live_title(broadcast_json['title'])\n            broadcast_description = broadcast_json.get('description')\n            broadcaster_nick = broadcast_json.get('nick')\n            broadcaster_login = broadcast_json.get('login')\n            rtmp_conn = 'S:%s' % uuid.uuid4().hex\n        except KeyError:\n            if protected_broadcast:\n                raise ExtractorError('Bad broadcast password', expected=True)\n            raise ExtractorError('Unexpected broadcast JSON')\n\n        return {\n            'id': broadcast_id,\n            'url': rtmp_url,\n            'title': broadcast_title,\n            'thumbnail': broadcast_thumbnail,\n            'description': broadcast_description,\n            'uploader': broadcaster_nick,\n            'uploader_id': broadcaster_login,\n            'age_limit': 18 if adult_content else 0,\n            'ext': 'flv',\n            'play_path': broadcast_playpath,\n            'player_url': 'http://pics.smotri.com/broadcast_play.swf',\n            'app': broadcast_app,\n            'rtmp_live': True,\n            'rtmp_conn': rtmp_conn,\n            'is_live': True,\n        }",
        "begin_line": 314,
        "end_line": 414,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.snotr.SnotrIE._real_extract#41",
        "src_path": "youtube_dl/extractor/snotr.py",
        "class_name": "youtube_dl.extractor.snotr.SnotrIE",
        "signature": "youtube_dl.extractor.snotr.SnotrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n\n        description = self._og_search_description(webpage)\n        info_dict = self._parse_html5_media_entries(\n            url, webpage, video_id, m3u8_entry_protocol='m3u8_native')[0]\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<p[^>]*>\\s*<strong[^>]*>Views:</strong>\\s*<span[^>]*>([\\d,\\.]+)',\n            webpage, 'view count', fatal=False))\n\n        duration = parse_duration(self._html_search_regex(\n            r'<p[^>]*>\\s*<strong[^>]*>Length:</strong>\\s*<span[^>]*>([\\d:]+)',\n            webpage, 'duration', fatal=False))\n\n        filesize_approx = parse_filesize(self._html_search_regex(\n            r'<p[^>]*>\\s*<strong[^>]*>Filesize:</strong>\\s*<span[^>]*>([^<]+)',\n            webpage, 'filesize', fatal=False))\n\n        info_dict.update({\n            'id': video_id,\n            'description': description,\n            'title': title,\n            'view_count': view_count,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n        })\n\n        return info_dict",
        "begin_line": 41,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sohu.SohuIE._real_extract#87",
        "src_path": "youtube_dl/extractor/sohu.py",
        "class_name": "youtube_dl.extractor.sohu.SohuIE",
        "signature": "youtube_dl.extractor.sohu.SohuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        def _fetch_data(vid_id, mytv=False):\n            if mytv:\n                base_data_url = 'http://my.tv.sohu.com/play/videonew.do?vid='\n            else:\n                base_data_url = 'http://hot.vrs.sohu.com/vrs_flash.action?vid='\n\n            return self._download_json(\n                base_data_url + vid_id, video_id,\n                'Downloading JSON data for %s' % vid_id,\n                headers=self.geo_verification_headers())\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        mytv = mobj.group('mytv') is not None\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = re.sub(r' - \u641c\u72d0\u89c6\u9891$', '', self._og_search_title(webpage))\n\n        vid = self._html_search_regex(\n            r'var vid ?= ?[\"\\'](\\d+)[\"\\']',\n            webpage, 'video path')\n        vid_data = _fetch_data(vid, mytv)\n        if vid_data['play'] != 1:\n            if vid_data.get('status') == 12:\n                raise ExtractorError(\n                    '%s said: There\\'s something wrong in the video.' % self.IE_NAME,\n                    expected=True)\n            else:\n                self.raise_geo_restricted(\n                    '%s said: The video is only licensed to users in Mainland China.' % self.IE_NAME)\n\n        formats_json = {}\n        for format_id in ('nor', 'high', 'super', 'ori', 'h2644k', 'h2654k'):\n            vid_id = vid_data['data'].get('%sVid' % format_id)\n            if not vid_id:\n                continue\n            vid_id = compat_str(vid_id)\n            formats_json[format_id] = vid_data if vid == vid_id else _fetch_data(vid_id, mytv)\n\n        part_count = vid_data['data']['totalBlocks']\n\n        playlist = []\n        for i in range(part_count):\n            formats = []\n            for format_id, format_data in formats_json.items():\n                allot = format_data['allot']\n\n                data = format_data['data']\n                clips_url = data['clipsURL']\n                su = data['su']\n\n                video_url = 'newflv.sohu.ccgslb.net'\n                cdnId = None\n                retries = 0\n\n                while 'newflv.sohu.ccgslb.net' in video_url:\n                    params = {\n                        'prot': 9,\n                        'file': clips_url[i],\n                        'new': su[i],\n                        'prod': 'flash',\n                        'rb': 1,\n                    }\n\n                    if cdnId is not None:\n                        params['idc'] = cdnId\n\n                    download_note = 'Downloading %s video URL part %d of %d' % (\n                        format_id, i + 1, part_count)\n\n                    if retries > 0:\n                        download_note += ' (retry #%d)' % retries\n                    part_info = self._parse_json(self._download_webpage(\n                        'http://%s/?%s' % (allot, compat_urllib_parse_urlencode(params)),\n                        video_id, download_note), video_id)\n\n                    video_url = part_info['url']\n                    cdnId = part_info.get('nid')\n\n                    retries += 1\n                    if retries > 5:\n                        raise ExtractorError('Failed to get video URL')\n\n                formats.append({\n                    'url': video_url,\n                    'format_id': format_id,\n                    'filesize': int_or_none(\n                        try_get(data, lambda x: x['clipsBytes'][i])),\n                    'width': int_or_none(data.get('width')),\n                    'height': int_or_none(data.get('height')),\n                    'fps': int_or_none(data.get('fps')),\n                })\n            self._sort_formats(formats)\n\n            playlist.append({\n                'id': '%s_part%d' % (video_id, i + 1),\n                'title': title,\n                'duration': vid_data['data']['clipsDuration'][i],\n                'formats': formats,\n            })\n\n        if len(playlist) == 1:\n            info = playlist[0]\n            info['id'] = video_id\n        else:\n            info = {\n                '_type': 'multi_video',\n                'entries': playlist,\n                'id': video_id,\n                'title': title,\n            }\n\n        return info",
        "begin_line": 87,
        "end_line": 202,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sonyliv.SonyLIVIE._real_extract#31",
        "src_path": "youtube_dl/extractor/sonyliv.py",
        "class_name": "youtube_dl.extractor.sonyliv.SonyLIVIE",
        "signature": "youtube_dl.extractor.sonyliv.SonyLIVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        brightcove_id = self._match_id(url)\n        return self.url_result(\n            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)",
        "begin_line": 31,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_urls#129",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [m.group('url') for m in re.finditer(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?://)?(?:w\\.)?soundcloud\\.com/player.+?)\\1',\n            webpage)]",
        "begin_line": 129,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve#134",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve(self, video_id)",
        "snippet": "    def report_resolve(self, video_id):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Resolving id' % video_id)",
        "begin_line": 134,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url#139",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url(cls, url)",
        "snippet": "    def _resolv_url(cls, url):\n        return 'https://api.soundcloud.com/resolve.json?url=' + url + '&client_id=' + cls._CLIENT_ID",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict#142",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None)",
        "snippet": "    def _extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None):\n        track_id = compat_str(info['id'])\n        name = full_title or track_id\n        if quiet:\n            self.report_extraction(name)\n        thumbnail = info.get('artwork_url')\n        if isinstance(thumbnail, compat_str):\n            thumbnail = thumbnail.replace('-large', '-t500x500')\n        ext = 'mp3'\n        result = {\n            'id': track_id,\n            'uploader': info.get('user', {}).get('username'),\n            'upload_date': unified_strdate(info.get('created_at')),\n            'title': info['title'],\n            'description': info.get('description'),\n            'thumbnail': thumbnail,\n            'duration': int_or_none(info.get('duration'), 1000),\n            'webpage_url': info.get('permalink_url'),\n            'license': info.get('license'),\n        }\n        formats = []\n        if info.get('downloadable', False):\n            # We can build a direct link to the song\n            format_url = (\n                'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(\n                    track_id, self._CLIENT_ID))\n            formats.append({\n                'format_id': 'download',\n                'ext': info.get('original_format', 'mp3'),\n                'url': format_url,\n                'vcodec': 'none',\n                'preference': 10,\n            })\n\n        # We have to retrieve the url\n        format_dict = self._download_json(\n            'https://api.soundcloud.com/i1/tracks/%s/streams' % track_id,\n            track_id, 'Downloading track url', query={\n                'client_id': self._CLIENT_ID,\n                'secret_token': secret_token,\n            })\n\n        for key, stream_url in format_dict.items():\n            abr = int_or_none(self._search_regex(\n                r'_(\\d+)_url', key, 'audio bitrate', default=None))\n            if key.startswith('http'):\n                stream_formats = [{\n                    'format_id': key,\n                    'ext': ext,\n                    'url': stream_url,\n                }]\n            elif key.startswith('rtmp'):\n                # The url doesn't have an rtmp app, we have to extract the playpath\n                url, path = stream_url.split('mp3:', 1)\n                stream_formats = [{\n                    'format_id': key,\n                    'url': url,\n                    'play_path': 'mp3:' + path,\n                    'ext': 'flv',\n                }]\n            elif key.startswith('hls'):\n                stream_formats = self._extract_m3u8_formats(\n                    stream_url, track_id, 'mp3', entry_protocol='m3u8_native',\n                    m3u8_id=key, fatal=False)\n            else:\n                continue\n\n            for f in stream_formats:\n                f['abr'] = abr\n\n            formats.extend(stream_formats)\n\n        if not formats:\n            # We fallback to the stream_url in the original info, this\n            # cannot be always used, sometimes it can give an HTTP 404 error\n            formats.append({\n                'format_id': 'fallback',\n                'url': info['stream_url'] + '?client_id=' + self._CLIENT_ID,\n                'ext': ext,\n            })\n\n        for f in formats:\n            f['vcodec'] = 'none'\n\n        self._check_formats(formats, track_id)\n        self._sort_formats(formats)\n        result['formats'] = formats\n\n        return result",
        "begin_line": 142,
        "end_line": 230,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract#232",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        track_id = mobj.group('track_id')\n\n        if track_id is not None:\n            info_json_url = 'https://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID\n            full_title = track_id\n            token = mobj.group('secret_token')\n            if token:\n                info_json_url += '&secret_token=' + token\n        elif mobj.group('player'):\n            query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n            real_url = query['url'][0]\n            # If the token is in the query of the original url we have to\n            # manually add it\n            if 'secret_token' in query:\n                real_url += '?secret_token=' + query['secret_token'][0]\n            return self.url_result(real_url)\n        else:\n            # extract uploader (which is in the url)\n            uploader = mobj.group('uploader')\n            # extract simple title (uploader + slug of song title)\n            slug_title = mobj.group('title')\n            token = mobj.group('token')\n            full_title = resolve_title = '%s/%s' % (uploader, slug_title)\n            if token:\n                resolve_title += '/%s' % token\n\n            self.report_resolve(full_title)\n\n            url = 'https://soundcloud.com/%s' % resolve_title\n            info_json_url = self._resolv_url(url)\n        info = self._download_json(info_json_url, full_title, 'Downloading info JSON')\n\n        return self._extract_info_dict(info, full_title, secret_token=token)",
        "begin_line": 232,
        "end_line": 269,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE._extract_id#274",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE._extract_id(e)",
        "snippet": "    def _extract_id(e):\n        return compat_str(e['id']) if e.get('id') else None",
        "begin_line": 274,
        "end_line": 275,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE._extract_track_entries#277",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistBaseIE._extract_track_entries(self, tracks)",
        "snippet": "    def _extract_track_entries(self, tracks):\n        return [\n            self.url_result(\n                track['permalink_url'], SoundcloudIE.ie_key(),\n                video_id=self._extract_id(track))\n            for track in tracks if track.get('permalink_url')]",
        "begin_line": 277,
        "end_line": 282,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract#300",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        # extract uploader (which is in the url)\n        uploader = mobj.group('uploader')\n        # extract simple title (uploader + slug of song title)\n        slug_title = mobj.group('slug_title')\n        full_title = '%s/sets/%s' % (uploader, slug_title)\n        url = 'https://soundcloud.com/%s/sets/%s' % (uploader, slug_title)\n\n        token = mobj.group('token')\n        if token:\n            full_title += '/' + token\n            url += '/' + token\n\n        self.report_resolve(full_title)\n\n        resolv_url = self._resolv_url(url)\n        info = self._download_json(resolv_url, full_title)\n\n        if 'errors' in info:\n            msgs = (compat_str(err['error_message']) for err in info['errors'])\n            raise ExtractorError('unable to download video webpage: %s' % ','.join(msgs))\n\n        entries = self._extract_track_entries(info['tracks'])\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': '%s' % info['id'],\n            'title': info['title'],\n        }",
        "begin_line": 300,
        "end_line": 331,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPagedPlaylistBaseIE._extract_playlist#338",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPagedPlaylistBaseIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPagedPlaylistBaseIE._extract_playlist(self, base_url, playlist_id, playlist_title)",
        "snippet": "    def _extract_playlist(self, base_url, playlist_id, playlist_title):\n        COMMON_QUERY = {\n            'limit': 50,\n            'client_id': self._CLIENT_ID,\n            'linked_partitioning': '1',\n        }\n\n        query = COMMON_QUERY.copy()\n        query['offset'] = 0\n\n        next_href = base_url + '?' + compat_urllib_parse_urlencode(query)\n\n        entries = []\n        for i in itertools.count():\n            response = self._download_json(\n                next_href, playlist_id, 'Downloading track page %s' % (i + 1))\n\n            collection = response['collection']\n            if not collection:\n                break\n\n            def resolve_permalink_url(candidates):\n                for cand in candidates:\n                    if isinstance(cand, dict):\n                        permalink_url = cand.get('permalink_url')\n                        entry_id = self._extract_id(cand)\n                        if permalink_url and permalink_url.startswith('http'):\n                            return permalink_url, entry_id\n\n            for e in collection:\n                permalink_url, entry_id = resolve_permalink_url((e, e.get('track'), e.get('playlist')))\n                if permalink_url:\n                    entries.append(self.url_result(permalink_url, video_id=entry_id))\n\n            next_href = response.get('next_href')\n            if not next_href:\n                break\n\n            parsed_next_href = compat_urlparse.urlparse(response['next_href'])\n            qs = compat_urlparse.parse_qs(parsed_next_href.query)\n            qs.update(COMMON_QUERY)\n            next_href = compat_urlparse.urlunparse(\n                parsed_next_href._replace(query=compat_urllib_parse_urlencode(qs, True)))\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'entries': entries,\n        }",
        "begin_line": 338,
        "end_line": 387,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract#463",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group('user')\n\n        url = 'https://soundcloud.com/%s/' % uploader\n        resolv_url = self._resolv_url(url)\n        user = self._download_json(\n            resolv_url, uploader, 'Downloading user info')\n\n        resource = mobj.group('rsrc') or 'all'\n\n        return self._extract_playlist(\n            self._BASE_URL_MAP[resource] % user['id'], compat_str(user['id']),\n            '%s (%s)' % (user['username'], self._TITLE_MAP[resource]))",
        "begin_line": 463,
        "end_line": 476,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudTrackStationIE._real_extract#491",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudTrackStationIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudTrackStationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        track_name = self._match_id(url)\n\n        webpage = self._download_webpage(url, track_name)\n\n        track_id = self._search_regex(\n            r'soundcloud:track-stations:(\\d+)', webpage, 'track id')\n\n        return self._extract_playlist(\n            '%s/stations/soundcloud:track-stations:%s/tracks'\n            % (self._API_V2_BASE, track_id),\n            track_id, 'Track station: %s' % track_name)",
        "begin_line": 491,
        "end_line": 502,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract#518",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        base_url = '%s//api.soundcloud.com/playlists/%s.json?' % (self.http_scheme(), playlist_id)\n\n        data_dict = {\n            'client_id': self._CLIENT_ID,\n        }\n        token = mobj.group('token')\n\n        if token:\n            data_dict['secret_token'] = token\n\n        data = compat_urllib_parse_urlencode(data_dict)\n        data = self._download_json(\n            base_url + data, playlist_id, 'Downloading playlist')\n\n        entries = self._extract_track_entries(data['tracks'])\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': data.get('title'),\n            'description': data.get('description'),\n            'entries': entries,\n        }",
        "begin_line": 518,
        "end_line": 543,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE._get_collection#563",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE._get_collection(self, endpoint, collection_id, **query)",
        "snippet": "    def _get_collection(self, endpoint, collection_id, **query):\n        limit = min(\n            query.get('limit', self._DEFAULT_RESULTS_PER_PAGE),\n            self._MAX_RESULTS_PER_PAGE)\n        query['limit'] = limit\n        query['client_id'] = self._CLIENT_ID\n        query['linked_partitioning'] = '1'\n        query['offset'] = 0\n        data = compat_urllib_parse_urlencode(query)\n        next_url = '{0}{1}?{2}'.format(self._API_V2_BASE, endpoint, data)\n\n        collected_results = 0\n\n        for i in itertools.count(1):\n            response = self._download_json(\n                next_url, collection_id, 'Downloading page {0}'.format(i),\n                'Unable to download API page')\n\n            collection = response.get('collection', [])\n            if not collection:\n                break\n\n            collection = list(filter(bool, collection))\n            collected_results += len(collection)\n\n            for item in collection:\n                yield self.url_result(item['uri'], SoundcloudIE.ie_key())\n\n            if not collection or collected_results >= limit:\n                break\n\n            next_url = response.get('next_href')\n            if not next_url:\n                break",
        "begin_line": 563,
        "end_line": 596,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE._get_n_results#598",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        tracks = self._get_collection('/search/tracks', query, limit=n, q=query)\n        return self.playlist_result(tracks, playlist_title=query)",
        "begin_line": 598,
        "end_line": 600,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract#23",
        "src_path": "youtube_dl/extractor/soundgasm.py",
        "class_name": "youtube_dl.extractor.soundgasm.SoundgasmIE",
        "signature": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('title')\n        audio_title = mobj.group('user') + '_' + mobj.group('title')\n        webpage = self._download_webpage(url, display_id)\n        audio_url = self._html_search_regex(\n            r'(?s)m4a\\:\\s\"([^\"]+)\"', webpage, 'audio URL')\n        audio_id = re.split(r'\\/|\\.', audio_url)[-2]\n        description = self._html_search_regex(\n            r'(?s)<li>Description:\\s(.*?)<\\/li>', webpage, 'description',\n            fatal=False)\n\n        return {\n            'id': audio_id,\n            'display_id': display_id,\n            'url': audio_url,\n            'title': audio_title,\n            'description': description\n        }",
        "begin_line": 23,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE._real_extract#55",
        "src_path": "youtube_dl/extractor/soundgasm.py",
        "class_name": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE",
        "signature": "youtube_dl.extractor.soundgasm.SoundgasmProfileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        profile_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, profile_id)\n\n        entries = [\n            self.url_result(audio_url, 'Soundgasm')\n            for audio_url in re.findall(r'href=\"([^\"]+/u/%s/[^\"]+)' % profile_id, webpage)]\n\n        return self.playlist_result(entries, profile_id)",
        "begin_line": 55,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spankbang.SpankBangIE._real_extract#32",
        "src_path": "youtube_dl/extractor/spankbang.py",
        "class_name": "youtube_dl.extractor.spankbang.SpankBangIE",
        "signature": "youtube_dl.extractor.spankbang.SpankBangIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        stream_key = self._html_search_regex(\n            r'''var\\s+stream_key\\s*=\\s*['\"](.+?)['\"]''',\n            webpage, 'stream key')\n\n        formats = [{\n            'url': 'http://spankbang.com/_%s/%s/title/%sp__mp4' % (video_id, stream_key, height),\n            'ext': 'mp4',\n            'format_id': '%sp' % height,\n            'height': int(height),\n        } for height in re.findall(r'<(?:span|li|p)[^>]+[qb]_(\\d+)p', webpage)]\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'(?s)<h1[^>]*>(.+?)</h1>', webpage, 'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._search_regex(\n            r'class=\"user\"[^>]*><img[^>]+>([^<]+)',\n            webpage, 'uploader', default=None)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 32,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract#50",
        "src_path": "youtube_dl/extractor/spankwire.py",
        "class_name": "youtube_dl.extractor.spankwire.SpankwireIE",
        "signature": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        req = sanitized_Request('http://www.' + mobj.group('url'))\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(\n            r'<h1>([^<]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div\\s+id=\"descriptionContent\">(.+?)</div>',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'playerData\\.screenShot\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']',\n            webpage, 'thumbnail', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'by:\\s*<a [^>]*>(.+?)</a>',\n            webpage, 'uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'by:\\s*<a href=\"/(?:user/viewProfile|Profile\\.aspx)\\?.*?UserId=(\\d+).*?\"',\n            webpage, 'uploader id', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'</a> on (.+?) at \\d+:\\d+',\n            webpage, 'upload date', fatal=False))\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<div id=\"viewsCounter\"><span>([\\d,\\.]+)</span> views</div>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span\\s+id=\"spCommentCount\"[^>]*>([\\d,\\.]+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        videos = re.findall(\n            r'playerData\\.cdnPath([0-9]{3,})\\s*=\\s*(?:encodeURIComponent\\()?[\"\\']([^\"\\']+)[\"\\']', webpage)\n        heights = [int(video[0]) for video in videos]\n        video_urls = list(map(compat_urllib_parse_unquote, [video[1] for video in videos]))\n        if webpage.find(r'flashvars\\.encrypted = \"true\"') != -1:\n            password = self._search_regex(\n                r'flashvars\\.video_title = \"([^\"]+)',\n                webpage, 'password').replace('+', ' ')\n            video_urls = list(map(\n                lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'),\n                video_urls))\n\n        formats = []\n        for height, video_url in zip(heights, video_urls):\n            path = compat_urllib_parse_urlparse(video_url).path\n            m = re.search(r'/(?P<height>\\d+)[pP]_(?P<tbr>\\d+)[kK]', path)\n            if m:\n                tbr = int(m.group('tbr'))\n                height = int(m.group('height'))\n            else:\n                tbr = None\n            formats.append({\n                'url': video_url,\n                'format_id': '%dp' % height,\n                'height': height,\n                'tbr': tbr,\n            })\n        self._sort_formats(formats)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 50,
        "end_line": 127,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract#56",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage, handle = self._download_webpage_handle(url, video_id)\n\n        # 302 to spiegel.tv, like http://www.spiegel.de/video/der-film-zum-wochenende-die-wahrheit-ueber-maenner-video-99003272.html\n        if SpiegeltvIE.suitable(handle.geturl()):\n            return self.url_result(handle.geturl(), 'Spiegeltv')\n\n        video_data = extract_attributes(self._search_regex(r'(<div[^>]+id=\"spVideoElements\"[^>]+>)', webpage, 'video element', default=''))\n\n        title = video_data.get('data-video-title') or get_element_by_attribute('class', 'module-title', webpage)\n        description = video_data.get('data-video-teaser') or self._html_search_meta('description', webpage, 'description')\n\n        base_url = self._search_regex(\n            [r'server\\s*:\\s*([\"\\'])(?P<url>.+?)\\1', r'var\\s+server\\s*=\\s*\"(?P<url>[^\"]+)\\\"'],\n            webpage, 'server URL', group='url')\n\n        xml_url = base_url + video_id + '.xml'\n        idoc = self._download_xml(xml_url, video_id)\n\n        formats = []\n        for n in list(idoc):\n            if n.tag.startswith('type') and n.tag != 'type6':\n                format_id = n.tag.rpartition('type')[2]\n                video_url = base_url + n.find('./filename').text\n                formats.append({\n                    'format_id': format_id,\n                    'url': video_url,\n                    'width': int(n.find('./width').text),\n                    'height': int(n.find('./height').text),\n                    'abr': int(n.find('./audiobitrate').text),\n                    'vbr': int(n.find('./videobitrate').text),\n                    'vcodec': n.find('./codec').text,\n                    'acodec': 'MP4A',\n                })\n        duration = float(idoc[0].findall('./duration')[0].text)\n\n        self._check_formats(formats, video_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description.strip() if description else None,\n            'duration': duration,\n            'upload_date': unified_strdate(video_data.get('data-video-date')),\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract#147",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelArticleIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        # Single video on top of the page\n        video_link = self._search_regex(\n            r'<a href=\"([^\"]+)\" onclick=\"return spOpenVideo\\(this,', webpage,\n            'video page URL', default=None)\n        if video_link:\n            video_url = compat_urlparse.urljoin(\n                self.http_scheme() + '//spiegel.de/', video_link)\n            return self.url_result(video_url)\n\n        # Multiple embedded videos\n        embeds = re.findall(\n            r'<div class=\"vid_holder[0-9]+.*?</div>\\s*.*?url\\s*=\\s*\"([^\"]+)\"',\n            webpage)\n        entries = [\n            self.url_result(compat_urlparse.urljoin(\n                self.http_scheme() + '//spiegel.de/', embed_path))\n            for embed_path in embeds]\n        if embeds:\n            return self.playlist_result(entries)\n\n        return self.playlist_from_matches(\n            NexxEmbedIE._extract_urls(webpage), ie=NexxEmbedIE.ie_key())",
        "begin_line": 147,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract#14",
        "src_path": "youtube_dl/extractor/spiegeltv.py",
        "class_name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE",
        "signature": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result(\n            'https://api.nexx.cloud/v3/748/videos/byid/%s'\n            % self._match_id(url), ie=NexxIE.ie_key())",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.spike.SpikeIE._extract_mgid#48",
        "src_path": "youtube_dl/extractor/spike.py",
        "class_name": "youtube_dl.extractor.spike.SpikeIE",
        "signature": "youtube_dl.extractor.spike.SpikeIE._extract_mgid(self, webpage)",
        "snippet": "    def _extract_mgid(self, webpage):\n        mgid = super(SpikeIE, self)._extract_mgid(webpage)\n        if mgid is None:\n            url_parts = self._search_regex(self._CUSTOM_URL_REGEX, webpage, 'episode_id')\n            video_type, episode_id = url_parts.split('/', 1)\n            mgid = 'mgid:arc:{0}:spike.com:{1}'.format(video_type, episode_id)\n        return mgid",
        "begin_line": 48,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sport5.Sport5IE._real_extract#38",
        "src_path": "youtube_dl/extractor/sport5.py",
        "class_name": "youtube_dl.extractor.sport5.Sport5IE",
        "signature": "youtube_dl.extractor.sport5.Sport5IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        media_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, media_id)\n\n        video_id = self._html_search_regex(r'clipId=([\\w-]+)', webpage, 'video id')\n\n        metadata = self._download_xml(\n            'http://sport5-metadata-rr-d.nsacdn.com/vod/vod/%s/HDS/metadata.xml' % video_id,\n            video_id)\n\n        error = metadata.find('./Error')\n        if error is not None:\n            raise ExtractorError(\n                '%s returned error: %s - %s' % (\n                    self.IE_NAME,\n                    error.find('./Name').text,\n                    error.find('./Description').text),\n                expected=True)\n\n        title = metadata.find('./Title').text\n        description = metadata.find('./Description').text\n        duration = int(metadata.find('./Duration').text)\n\n        posters_el = metadata.find('./PosterLinks')\n        thumbnails = [{\n            'url': thumbnail.text,\n            'width': int(thumbnail.get('width')),\n            'height': int(thumbnail.get('height')),\n        } for thumbnail in posters_el.findall('./PosterIMG')] if posters_el is not None else []\n\n        categories_el = metadata.find('./Categories')\n        categories = [\n            cat.get('name') for cat in categories_el.findall('./Category')\n        ] if categories_el is not None else []\n\n        formats = [{\n            'url': fmt.text,\n            'ext': 'mp4',\n            'vbr': int(fmt.get('bitrate')),\n            'width': int(fmt.get('width')),\n            'height': int(fmt.get('height')),\n        } for fmt in metadata.findall('./PlaybackLinks/FileURL')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls#39",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=\"(https?://news\\.sportbox\\.ru/vdl/player[^\"]+)\"',\n            webpage)",
        "begin_line": 39,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._real_extract#44",
        "src_path": "youtube_dl/extractor/sportbox.py",
        "class_name": "youtube_dl.extractor.sportbox.SportBoxEmbedIE",
        "signature": "youtube_dl.extractor.sportbox.SportBoxEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        wjplayer_data = self._parse_json(\n            self._search_regex(\n                r'(?s)wjplayer\\(({.+?})\\);', webpage, 'wjplayer settings'),\n            video_id, transform_source=js_to_json)\n\n        formats = []\n        for source in wjplayer_data['sources']:\n            src = source.get('src')\n            if not src:\n                continue\n            if determine_ext(src) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    src, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': src,\n                })\n        self._sort_formats(formats)\n\n        view_count = int_or_none(self._search_regex(\n            r'\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432\\s*:\\s*(\\d+)', webpage, 'view count', default=None))\n\n        return {\n            'id': video_id,\n            'title': video_id,\n            'thumbnail': wjplayer_data.get('poster'),\n            'duration': int_or_none(wjplayer_data.get('duration')),\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 44,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract#48",
        "src_path": "youtube_dl/extractor/sportdeutschland.py",
        "class_name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE",
        "signature": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        sport_id = mobj.group('sport')\n\n        api_url = 'http://proxy.vidibusdynamic.net/sportdeutschland.tv/api/permalinks/%s/%s?access_token=true' % (\n            sport_id, video_id)\n        req = sanitized_Request(api_url, headers={\n            'Accept': 'application/vnd.vidibus.v2.html+json',\n            'Referer': url,\n        })\n        data = self._download_json(req, video_id)\n\n        asset = data['asset']\n        categories = [data['section']['title']]\n\n        formats = []\n        smil_url = asset['video']\n        if '.smil' in smil_url:\n            m3u8_url = smil_url.replace('.smil', '.m3u8')\n            formats.extend(\n                self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4'))\n\n            smil_doc = self._download_xml(\n                smil_url, video_id, note='Downloading SMIL metadata')\n            base_url_el = smil_doc.find('./head/meta')\n            if base_url_el:\n                base_url = base_url_el.attrib['base']\n            formats.extend([{\n                'format_id': 'rmtp',\n                'url': base_url if base_url_el else n.attrib['src'],\n                'play_path': n.attrib['src'],\n                'ext': 'flv',\n                'preference': -100,\n                'format_note': 'Seems to fail at example stream',\n            } for n in smil_doc.findall('./body/video')])\n        else:\n            formats.append({'url': smil_url})\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': asset['title'],\n            'thumbnail': asset.get('image'),\n            'description': asset.get('teaser'),\n            'duration': asset.get('duration'),\n            'categories': categories,\n            'view_count': asset.get('views'),\n            'rtmp_live': asset.get('live'),\n            'timestamp': parse_iso8601(asset.get('date')),\n        }",
        "begin_line": 48,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sportschau.SportschauIE._real_extract#24",
        "src_path": "youtube_dl/extractor/sportschau.py",
        "class_name": "youtube_dl.extractor.sportschau.SportschauIE",
        "signature": "youtube_dl.extractor.sportschau.SportschauIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = get_element_by_attribute('class', 'headline', webpage)\n        description = self._html_search_meta('description', webpage, 'description')\n\n        info = self._extract_wdr_video(webpage, video_id)\n\n        info.update({\n            'title': title,\n            'description': description,\n        })\n\n        return info",
        "begin_line": 24,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sprout.SproutIE._real_extract#28",
        "src_path": "youtube_dl/extractor/sprout.py",
        "class_name": "youtube_dl.extractor.sprout.SproutIE",
        "signature": "youtube_dl.extractor.sprout.SproutIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_component = self._search_regex(\n            r'(?s)(<div[^>]+data-component=\"video\"[^>]*?>)',\n            webpage, 'video component', default=None)\n        if video_component:\n            options = self._parse_json(extract_attributes(\n                video_component)['data-options'], video_id)\n            theplatform_url = options['video']\n            query = {\n                'mbr': 'true',\n                'manifest': 'm3u',\n            }\n            if options.get('protected'):\n                query['auth'] = self._extract_mvpd_auth(url, options['pid'], 'sprout', 'sprout')\n            theplatform_url = smuggle_url(update_url_query(\n                theplatform_url, query), {'force_smil_url': True})\n        else:\n            iframe = self._search_regex(\n                r'(<iframe[^>]+id=\"sproutVideoIframe\"[^>]*?>)',\n                webpage, 'iframe')\n            theplatform_url = extract_attributes(iframe)['src']\n\n        return self.url_result(theplatform_url, 'ThePlatform')",
        "begin_line": 28,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.srgssr.SRGSSRIE._get_tokenized_src#29",
        "src_path": "youtube_dl/extractor/srgssr.py",
        "class_name": "youtube_dl.extractor.srgssr.SRGSSRIE",
        "signature": "youtube_dl.extractor.srgssr.SRGSSRIE._get_tokenized_src(self, url, video_id, format_id)",
        "snippet": "    def _get_tokenized_src(self, url, video_id, format_id):\n        sp = compat_urllib_parse_urlparse(url).path.split('/')\n        token = self._download_json(\n            'http://tp.srgssr.ch/akahd/token?acl=/%s/%s/*' % (sp[1], sp[2]),\n            video_id, 'Downloading %s token' % format_id, fatal=False) or {}\n        auth_params = token.get('token', {}).get('authparams')\n        if auth_params:\n            url += '?' + auth_params\n        return url",
        "begin_line": 29,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.srgssr.SRGSSRIE.get_media_data#39",
        "src_path": "youtube_dl/extractor/srgssr.py",
        "class_name": "youtube_dl.extractor.srgssr.SRGSSRIE",
        "signature": "youtube_dl.extractor.srgssr.SRGSSRIE.get_media_data(self, bu, media_type, media_id)",
        "snippet": "    def get_media_data(self, bu, media_type, media_id):\n        media_data = self._download_json(\n            'http://il.srgssr.ch/integrationlayer/1.0/ue/%s/%s/play/%s.json' % (bu, media_type, media_id),\n            media_id)[media_type.capitalize()]\n\n        if media_data.get('block') and media_data['block'] in self._ERRORS:\n            message = self._ERRORS[media_data['block']]\n            if media_data['block'] == 'GEOBLOCK':\n                self.raise_geo_restricted(\n                    msg=message, countries=self._GEO_COUNTRIES)\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, message), expected=True)\n\n        return media_data",
        "begin_line": 39,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.srgssr.SRGSSRIE._real_extract#54",
        "src_path": "youtube_dl/extractor/srgssr.py",
        "class_name": "youtube_dl.extractor.srgssr.SRGSSRIE",
        "signature": "youtube_dl.extractor.srgssr.SRGSSRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        bu, media_type, media_id = re.match(self._VALID_URL, url).groups()\n\n        media_data = self.get_media_data(bu, media_type, media_id)\n\n        metadata = media_data['AssetMetadatas']['AssetMetadata'][0]\n        title = metadata['title']\n        description = metadata.get('description')\n        created_date = media_data.get('createdDate') or metadata.get('createdDate')\n        timestamp = parse_iso8601(created_date)\n\n        thumbnails = [{\n            'id': image.get('id'),\n            'url': image['url'],\n        } for image in media_data.get('Image', {}).get('ImageRepresentations', {}).get('ImageRepresentation', [])]\n\n        preference = qualities(['LQ', 'MQ', 'SD', 'HQ', 'HD'])\n        formats = []\n        for source in media_data.get('Playlists', {}).get('Playlist', []) + media_data.get('Downloads', {}).get('Download', []):\n            protocol = source.get('@protocol')\n            for asset in source['url']:\n                asset_url = asset['text']\n                quality = asset['@quality']\n                format_id = '%s-%s' % (protocol, quality)\n                if protocol.startswith('HTTP-HDS') or protocol.startswith('HTTP-HLS'):\n                    asset_url = self._get_tokenized_src(asset_url, media_id, format_id)\n                    if protocol.startswith('HTTP-HDS'):\n                        formats.extend(self._extract_f4m_formats(\n                            asset_url + ('?' if '?' not in asset_url else '&') + 'hdcore=3.4.0',\n                            media_id, f4m_id=format_id, fatal=False))\n                    elif protocol.startswith('HTTP-HLS'):\n                        formats.extend(self._extract_m3u8_formats(\n                            asset_url, media_id, 'mp4', 'm3u8_native',\n                            m3u8_id=format_id, fatal=False))\n                else:\n                    formats.append({\n                        'format_id': format_id,\n                        'url': asset_url,\n                        'preference': preference(quality),\n                        'ext': 'flv' if protocol == 'RTMP' else None,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': media_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 54,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.srgssr.SRGSSRPlayIE._real_extract#168",
        "src_path": "youtube_dl/extractor/srgssr.py",
        "class_name": "youtube_dl.extractor.srgssr.SRGSSRPlayIE",
        "signature": "youtube_dl.extractor.srgssr.SRGSSRPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        bu, media_type, media_id = re.match(self._VALID_URL, url).groups()\n        # other info can be extracted from url + '&layout=json'\n        return self.url_result('srgssr:%s:%s:%s' % (bu[:3], media_type, media_id), 'SRGSSR')",
        "begin_line": 168,
        "end_line": 171,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.srmediathek.SRMediathekIE._real_extract#43",
        "src_path": "youtube_dl/extractor/srmediathek.py",
        "class_name": "youtube_dl.extractor.srmediathek.SRMediathekIE",
        "signature": "youtube_dl.extractor.srmediathek.SRMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if '>Der gew&uuml;nschte Beitrag ist leider nicht mehr verf&uuml;gbar.<' in webpage:\n            raise ExtractorError('Video %s is no longer available' % video_id, expected=True)\n\n        media_collection_url = self._search_regex(\n            r'data-mediacollection-ardplayer=\"([^\"]+)\"', webpage, 'media collection url')\n        info = self._extract_media_info(media_collection_url, webpage, video_id)\n        info.update({\n            'id': video_id,\n            'title': get_element_by_attribute('class', 'ardplayer-title', webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        })\n        return info",
        "begin_line": 43,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract#27",
        "src_path": "youtube_dl/extractor/stanfordoc.py",
        "class_name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE",
        "signature": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        if mobj.group('course') and mobj.group('video'):  # A specific video\n            course = mobj.group('course')\n            video = mobj.group('video')\n            info = {\n                'id': course + '_' + video,\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            baseUrl = 'http://openclassroom.stanford.edu/MainFolder/courses/' + course + '/videos/'\n            xmlUrl = baseUrl + video + '.xml'\n            mdoc = self._download_xml(xmlUrl, info['id'])\n            try:\n                info['title'] = mdoc.findall('./title')[0].text\n                info['url'] = baseUrl + mdoc.findall('./videoFile')[0].text\n            except IndexError:\n                raise ExtractorError('Invalid metadata XML file')\n            return info\n        elif mobj.group('course'):  # A course page\n            course = mobj.group('course')\n            info = {\n                'id': course,\n                '_type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            coursepage = self._download_webpage(\n                url, info['id'],\n                note='Downloading course info page',\n                errnote='Unable to download course info page')\n\n            info['title'] = self._html_search_regex(\n                r'<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])\n\n            info['description'] = self._html_search_regex(\n                r'(?s)<description>([^<]+)</description>',\n                coursepage, 'description', fatal=False)\n\n            links = orderedSet(re.findall(r'<a href=\"(VideoPage.php\\?[^\"]+)\">', coursepage))\n            info['entries'] = [self.url_result(\n                'http://openclassroom.stanford.edu/MainFolder/%s' % unescapeHTML(l)\n            ) for l in links]\n            return info\n        else:  # Root page\n            info = {\n                'id': 'Stanford OpenClassroom',\n                '_type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n            info['title'] = info['id']\n\n            rootURL = 'http://openclassroom.stanford.edu/MainFolder/HomePage.php'\n            rootpage = self._download_webpage(rootURL, info['id'],\n                                              errnote='Unable to download course info page')\n\n            links = orderedSet(re.findall(r'<a href=\"(CoursePage.php\\?[^\"]+)\">', rootpage))\n            info['entries'] = [self.url_result(\n                'http://openclassroom.stanford.edu/MainFolder/%s' % unescapeHTML(l)\n            ) for l in links]\n            return info",
        "begin_line": 27,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE._real_extract#62",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        fileID = m.group('fileID')\n        if fileID:\n            videourl = url\n            playlist_id = fileID\n        else:\n            gameID = m.group('gameID')\n            playlist_id = gameID\n            videourl = self._VIDEO_PAGE_TEMPLATE % playlist_id\n        webpage = self._download_webpage(videourl, playlist_id)\n\n        if re.search('<h2>Please enter your birth date to continue:</h2>', webpage) is not None:\n            videourl = self._AGECHECK_TEMPLATE % playlist_id\n            self.report_age_confirmation()\n            webpage = self._download_webpage(videourl, playlist_id)\n\n        if fileID:\n            playlist_title = self._html_search_regex(\n                r'<div class=\"workshopItemTitle\">(.+)</div>', webpage, 'title')\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                YOUTUBE_VIDEO_ID:\\s*\"(?P<youtube_id>[^\"]+)\",\n                ''', webpage)\n            videos = [{\n                '_type': 'url',\n                'url': vid.group('youtube_id'),\n                'ie_key': 'Youtube',\n            } for vid in mweb]\n        else:\n            playlist_title = self._html_search_regex(\n                r'<h2 class=\"pageheader\">(.*?)</h2>', webpage, 'game title')\n\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                FILENAME:\\s*\"(?P<videoURL>[\\w:/\\.\\?=]+)\"\n                (,\\s*MOVIE_NAME:\\s*\\\"(?P<videoName>[\\w:/\\.\\?=\\+-]+)\\\")?\\s*\\},\n                ''', webpage)\n            titles = re.finditer(\n                r'<span class=\"title\">(?P<videoName>.+?)</span>', webpage)\n            thumbs = re.finditer(\n                r'<img class=\"movie_thumb\" src=\"(?P<thumbnail>.+?)\">', webpage)\n            videos = []\n\n            for vid, vtitle, thumb in zip(mweb, titles, thumbs):\n                video_id = vid.group('videoID')\n                title = vtitle.group('videoName')\n                video_url = vid.group('videoURL')\n                video_thumb = thumb.group('thumbnail')\n                if not video_url:\n                    raise ExtractorError('Cannot find video url for %s' % video_id)\n                videos.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'ext': 'flv',\n                    'title': unescapeHTML(title),\n                    'thumbnail': video_thumb\n                })\n        if not videos:\n            raise ExtractorError('Could not find any videos')\n\n        return self.playlist_result(videos, playlist_id, playlist_title)",
        "begin_line": 62,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.stitcher.StitcherIE._real_extract#50",
        "src_path": "youtube_dl/extractor/stitcher.py",
        "class_name": "youtube_dl.extractor.stitcher.StitcherIE",
        "signature": "youtube_dl.extractor.stitcher.StitcherIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        audio_id = mobj.group('id')\n        display_id = mobj.group('display_id') or audio_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        episode = self._parse_json(\n            js_to_json(self._search_regex(\n                r'(?s)var\\s+stitcher(?:Config)?\\s*=\\s*({.+?});\\n', webpage, 'episode config')),\n            display_id)['config']['episode']\n\n        title = unescapeHTML(episode['title'])\n        formats = [{\n            'url': episode[episode_key],\n            'ext': determine_ext(episode[episode_key]) or 'mp3',\n            'vcodec': 'none',\n        } for episode_key in ('episodeURL',) if episode.get(episode_key)]\n        description = self._search_regex(\n            r'Episode Info:\\s*</span>([^<]+)<', webpage, 'description', fatal=False)\n        duration = int_or_none(episode.get('duration'))\n        thumbnail = episode.get('episodeImage')\n\n        return {\n            'id': audio_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 50,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamable.StreamableIE._extract_url#58",
        "src_path": "youtube_dl/extractor/streamable.py",
        "class_name": "youtube_dl.extractor.streamable.StreamableIE",
        "signature": "youtube_dl.extractor.streamable.StreamableIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=(?P<q1>[\\'\"])(?P<src>(?:https?:)?//streamable\\.com/(?:(?!\\1).+))(?P=q1)',\n            webpage)\n        if mobj:\n            return mobj.group('src')",
        "begin_line": 58,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamable.StreamableIE._real_extract#65",
        "src_path": "youtube_dl/extractor/streamable.py",
        "class_name": "youtube_dl.extractor.streamable.StreamableIE",
        "signature": "youtube_dl.extractor.streamable.StreamableIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # Note: Using the ajax API, as the public Streamable API doesn't seem\n        # to return video info like the title properly sometimes, and doesn't\n        # include info like the video duration\n        video = self._download_json(\n            'https://ajax.streamable.com/videos/%s' % video_id, video_id)\n\n        # Format IDs:\n        # 0 The video is being uploaded\n        # 1 The video is being processed\n        # 2 The video has at least one file ready\n        # 3 The video is unavailable due to an error\n        status = video.get('status')\n        if status != 2:\n            raise ExtractorError(\n                'This video is currently unavailable. It may still be uploading or processing.',\n                expected=True)\n\n        title = video.get('reddit_title') or video['title']\n\n        formats = []\n        for key, info in video['files'].items():\n            if not info.get('url'):\n                continue\n            formats.append({\n                'format_id': key,\n                'url': self._proto_relative_url(info['url']),\n                'width': int_or_none(info.get('width')),\n                'height': int_or_none(info.get('height')),\n                'filesize': int_or_none(info.get('size')),\n                'fps': int_or_none(info.get('framerate')),\n                'vbr': float_or_none(info.get('bitrate'), 1000)\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnail': self._proto_relative_url(video.get('thumbnail_url')),\n            'uploader': video.get('owner', {}).get('user_name'),\n            'timestamp': float_or_none(video.get('date_added')),\n            'duration': float_or_none(video.get('duration')),\n            'view_count': int_or_none(video.get('plays')),\n            'formats': formats\n        }",
        "begin_line": 65,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamango.StreamangoIE._real_extract#40",
        "src_path": "youtube_dl/extractor/streamango.py",
        "class_name": "youtube_dl.extractor.streamango.StreamangoIE",
        "signature": "youtube_dl.extractor.streamango.StreamangoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage, default=video_id)\n\n        formats = []\n        for format_ in re.findall(r'({[^}]*\\bsrc\\s*:\\s*[^}]*})', webpage):\n            video = self._parse_json(\n                format_, video_id, transform_source=js_to_json, fatal=False)\n            if not video:\n                continue\n            src = video.get('src')\n            if not src:\n                continue\n            ext = determine_ext(src, default_ext=None)\n            if video.get('type') == 'application/dash+xml' or ext == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    src, video_id, mpd_id='dash', fatal=False))\n            else:\n                formats.append({\n                    'url': src,\n                    'ext': ext or 'mp4',\n                    'width': int_or_none(video.get('width')),\n                    'height': int_or_none(video.get('height')),\n                    'tbr': int_or_none(video.get('bitrate')),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'url': url,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract#31",
        "src_path": "youtube_dl/extractor/streamcloud.py",
        "class_name": "youtube_dl.extractor.streamcloud.StreamcloudIE",
        "signature": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url = 'http://streamcloud.eu/%s' % video_id\n\n        orig_webpage = self._download_webpage(url, video_id)\n\n        if '>File Not Found<' in orig_webpage:\n            raise ExtractorError(\n                'Video %s does not exist' % video_id, expected=True)\n\n        fields = re.findall(r'''(?x)<input\\s+\n            type=\"(?:hidden|submit)\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', orig_webpage)\n\n        self._sleep(12, video_id)\n\n        webpage = self._download_webpage(\n            url, video_id, data=urlencode_postdata(fields), headers={\n                b'Content-Type': b'application/x-www-form-urlencoded',\n            })\n\n        try:\n            title = self._html_search_regex(\n                r'<h1[^>]*>([^<]+)<', webpage, 'title')\n            video_url = self._search_regex(\n                r'file:\\s*\"([^\"]+)\"', webpage, 'video URL')\n        except ExtractorError:\n            message = self._html_search_regex(\n                r'(?s)<div[^>]+class=([\"\\']).*?msgboxinfo.*?\\1[^>]*>(?P<message>.+?)</div>',\n                webpage, 'message', default=None, group='message')\n            if message:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, message), expected=True)\n            raise\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, 'thumbnail URL', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 31,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamcz._get_api_key#14",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz",
        "signature": "youtube_dl.extractor.streamcz._get_api_key(api_path)",
        "snippet": "def _get_api_key(api_path):\n    if api_path.endswith('?'):\n        api_path = api_path[:-1]\n\n    api_key = 'fb5f58a820353bd7095de526253c14fd'\n    a = '{0:}{1:}{2:}'.format(api_key, api_path, int(round(time.time() / 24 / 3600)))\n    return hashlib.md5(a.encode('ascii')).hexdigest()",
        "begin_line": 14,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract#51",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz.StreamCZIE",
        "signature": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        api_path = '/episode/%s' % video_id\n\n        req = sanitized_Request(self._API_URL + api_path)\n        req.add_header('Api-Password', _get_api_key(api_path))\n        data = self._download_json(req, video_id)\n\n        formats = []\n        for quality, video in enumerate(data['video_qualities']):\n            for f in video['formats']:\n                typ = f['type'].partition('/')[2]\n                qlabel = video.get('quality_label')\n                formats.append({\n                    'format_note': '%s-%s' % (qlabel, typ) if qlabel else typ,\n                    'format_id': '%s-%s' % (typ, f['quality']),\n                    'url': f['source'],\n                    'height': int_or_none(f['quality'].rstrip('p')),\n                    'quality': quality,\n                })\n        self._sort_formats(formats)\n\n        image = data.get('image')\n        if image:\n            thumbnail = self._proto_relative_url(\n                image.replace('{width}', '1240').replace('{height}', '697'),\n                scheme='http:',\n            )\n        else:\n            thumbnail = None\n\n        stream = data.get('_embedded', {}).get('stream:show', {}).get('name')\n        if stream:\n            title = '%s: %s' % (stream, data['name'])\n        else:\n            title = data['name']\n\n        subtitles = {}\n        srt_url = data.get('subtitles_srt')\n        if srt_url:\n            subtitles['cs'] = [{\n                'ext': 'srt',\n                'url': srt_url,\n            }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'description': data.get('web_site_text'),\n            'duration': int_or_none(data.get('duration')),\n            'view_count': int_or_none(data.get('views')),\n            'subtitles': subtitles,\n        }",
        "begin_line": 51,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.streetvoice.StreetVoiceIE._real_extract#30",
        "src_path": "youtube_dl/extractor/streetvoice.py",
        "class_name": "youtube_dl.extractor.streetvoice.StreetVoiceIE",
        "signature": "youtube_dl.extractor.streetvoice.StreetVoiceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        song = self._download_json(\n            'https://streetvoice.com/api/v1/public/song/%s/' % song_id, song_id, data=b'')\n\n        title = song['name']\n        author = song['user']['nickname']\n\n        return {\n            'id': song_id,\n            'url': song['file'],\n            'title': title,\n            'description': '%s - %s' % (author, title),\n            'thumbnail': self._proto_relative_url(song.get('image'), 'http:'),\n            'duration': song.get('length'),\n            'upload_date': unified_strdate(song.get('created_at')),\n            'uploader': author,\n            'uploader_id': compat_str(song['user']['id']),\n        }",
        "begin_line": 30,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract#33",
        "src_path": "youtube_dl/extractor/sunporno.py",
        "class_name": "youtube_dl.extractor.sunporno.SunPornoIE",
        "signature": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.sunporno.com/videos/%s' % video_id, video_id)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title')\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        duration = parse_duration(self._search_regex(\n            (r'itemprop=\"duration\"[^>]*>\\s*(\\d+:\\d+)\\s*<',\n             r'>Duration:\\s*<span[^>]+>\\s*(\\d+:\\d+)\\s*<'),\n            webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'class=\"views\">(?:<noscript>)?\\s*(\\d+)\\s*<',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._html_search_regex(\n            r'(\\d+)</b> Comments?',\n            webpage, 'comment count', fatal=False, default=None))\n\n        formats = []\n        quality = qualities(['mp4', 'flv'])\n        for video_url in re.findall(r'<(?:source|video) src=\"([^\"]+)\"', webpage):\n            video_ext = determine_ext(video_url)\n            formats.append({\n                'url': video_url,\n                'format_id': video_ext,\n                'quality': quality(video_ext),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 33,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.svt.SVTBaseIE._extract_video#18",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTBaseIE",
        "signature": "youtube_dl.extractor.svt.SVTBaseIE._extract_video(self, video_info, video_id)",
        "snippet": "    def _extract_video(self, video_info, video_id):\n        formats = []\n        for vr in video_info['videoReferences']:\n            player_type = vr.get('playerType') or vr.get('format')\n            vurl = vr['url']\n            ext = determine_ext(vurl)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    vurl, video_id,\n                    ext='mp4', entry_protocol='m3u8_native',\n                    m3u8_id=player_type, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    vurl + '?hdcore=3.3.0', video_id,\n                    f4m_id=player_type, fatal=False))\n            elif ext == 'mpd':\n                if player_type == 'dashhbbtv':\n                    formats.extend(self._extract_mpd_formats(\n                        vurl, video_id, mpd_id=player_type, fatal=False))\n            else:\n                formats.append({\n                    'format_id': player_type,\n                    'url': vurl,\n                })\n        if not formats and video_info.get('rights', {}).get('geoBlockedSweden'):\n            self.raise_geo_restricted(\n                'This video is only available in Sweden',\n                countries=self._GEO_COUNTRIES)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        subtitle_references = dict_get(video_info, ('subtitles', 'subtitleReferences'))\n        if isinstance(subtitle_references, list):\n            for sr in subtitle_references:\n                subtitle_url = sr.get('url')\n                subtitle_lang = sr.get('language', 'sv')\n                if subtitle_url:\n                    if determine_ext(subtitle_url) == 'm3u8':\n                        # TODO(yan12125): handle WebVTT in m3u8 manifests\n                        continue\n\n                    subtitles.setdefault(subtitle_lang, []).append({'url': subtitle_url})\n\n        title = video_info.get('title')\n\n        series = video_info.get('programTitle')\n        season_number = int_or_none(video_info.get('season'))\n        episode = video_info.get('episodeTitle')\n        episode_number = int_or_none(video_info.get('episodeNumber'))\n\n        duration = int_or_none(dict_get(video_info, ('materialLength', 'contentDuration')))\n        age_limit = None\n        adult = dict_get(\n            video_info, ('inappropriateForChildren', 'blockedForChildren'),\n            skip_false_values=False)\n        if adult is not None:\n            age_limit = 18 if adult else 0\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'duration': duration,\n            'age_limit': age_limit,\n            'series': series,\n            'season_number': season_number,\n            'episode': episode,\n            'episode_number': episode_number,\n        }",
        "begin_line": 18,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.svt.SVTIE._extract_url#105",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTIE",
        "signature": "youtube_dl.extractor.svt.SVTIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'(?:<iframe src|href)=\"(?P<url>%s[^\"]*)\"' % SVTIE._VALID_URL, webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 105,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.svt.SVTIE._real_extract#111",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTIE",
        "signature": "youtube_dl.extractor.svt.SVTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        widget_id = mobj.group('widget_id')\n        article_id = mobj.group('id')\n\n        info = self._download_json(\n            'http://www.svt.se/wd?widgetId=%s&articleId=%s&format=json&type=embed&output=json' % (widget_id, article_id),\n            article_id)\n\n        info_dict = self._extract_video(info['video'], article_id)\n        info_dict['title'] = info['context']['title']\n        return info_dict",
        "begin_line": 111,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.svt.SVTPlayIE._real_extract#153",
        "src_path": "youtube_dl/extractor/svt.py",
        "class_name": "youtube_dl.extractor.svt.SVTPlayIE",
        "signature": "youtube_dl.extractor.svt.SVTPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r'root\\[\"__svtplay\"\\]\\s*=\\s*([^;]+);',\n                webpage, 'embedded data', default='{}'),\n            video_id, fatal=False)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        if data:\n            video_info = try_get(\n                data, lambda x: x['context']['dispatcher']['stores']['VideoTitlePageStore']['data']['video'],\n                dict)\n            if video_info:\n                info_dict = self._extract_video(video_info, video_id)\n                info_dict.update({\n                    'title': data['context']['dispatcher']['stores']['MetaStore']['title'],\n                    'thumbnail': thumbnail,\n                })\n                return info_dict\n\n        video_id = self._search_regex(\n            r'<video[^>]+data-video-id=[\"\\']([\\da-zA-Z-]+)',\n            webpage, 'video id', default=None)\n\n        if video_id:\n            data = self._download_json(\n                'https://api.svt.se/videoplayer-api/video/%s' % video_id,\n                video_id, headers=self.geo_verification_headers())\n            info_dict = self._extract_video(data, video_id)\n            if not info_dict.get('title'):\n                info_dict['title'] = re.sub(\n                    r'\\s*\\|\\s*.+?$', '',\n                    info_dict.get('episode') or self._og_search_title(webpage))\n            return info_dict",
        "begin_line": 153,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract#61",
        "src_path": "youtube_dl/extractor/swrmediathek.py",
        "class_name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE",
        "signature": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://swrmediathek.de/AjaxEntry?ekey=%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        attr = video['attr']\n        title = attr['entry_title']\n        media_type = attr.get('entry_etype')\n\n        formats = []\n        for entry in video.get('sub', []):\n            if entry.get('name') != 'entry_media':\n                continue\n\n            entry_attr = entry.get('attr', {})\n            f_url = entry_attr.get('val2')\n            if not f_url:\n                continue\n            codec = entry_attr.get('val0')\n            if codec == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    f_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif codec == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    f_url + '?hdcore=3.7.0', video_id,\n                    f4m_id='hds', fatal=False))\n            else:\n                formats.append({\n                    'format_id': determine_protocol({'url': f_url}),\n                    'url': f_url,\n                    'quality': int_or_none(entry_attr.get('val1')),\n                    'vcodec': codec if media_type == 'Video' else 'none',\n                    'acodec': codec if media_type == 'Audio' else None,\n                })\n        self._sort_formats(formats)\n\n        upload_date = None\n        entry_pdatet = attr.get('entry_pdatet')\n        if entry_pdatet:\n            upload_date = entry_pdatet[:-4]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': attr.get('entry_descl'),\n            'thumbnail': attr.get('entry_image_16_9'),\n            'duration': parse_duration(attr.get('entry_durat')),\n            'upload_date': upload_date,\n            'uploader': attr.get('channel_title'),\n            'uploader_id': attr.get('channel_idkey'),\n            'formats': formats,\n        }",
        "begin_line": 61,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.syfy.SyfyIE._real_extract#30",
        "src_path": "youtube_dl/extractor/syfy.py",
        "class_name": "youtube_dl.extractor.syfy.SyfyIE",
        "signature": "youtube_dl.extractor.syfy.SyfyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        syfy_mpx = list(self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);', webpage, 'drupal settings'),\n            display_id)['syfy']['syfy_mpx'].values())[0]\n        video_id = syfy_mpx['mpxGUID']\n        title = syfy_mpx['episodeTitle']\n        query = {\n            'mbr': 'true',\n            'manifest': 'm3u',\n        }\n        if syfy_mpx.get('entitlement') == 'auth':\n            resource = self._get_mvpd_resource(\n                'syfy', title, video_id,\n                syfy_mpx.get('mpxRating', 'TV-14'))\n            query['auth'] = self._extract_mvpd_auth(\n                url, video_id, 'syfy', resource)\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'ThePlatform',\n            'url': smuggle_url(update_url_query(\n                self._proto_relative_url(syfy_mpx['releaseURL']), query),\n                {'force_smil_url': True}),\n            'title': title,\n            'id': video_id,\n            'display_id': display_id,\n        }",
        "begin_line": 30,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract#20",
        "src_path": "youtube_dl/extractor/sztvhu.py",
        "class_name": "youtube_dl.extractor.sztvhu.SztvHuIE",
        "signature": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        video_file = self._search_regex(\n            r'file: \"...:(.*?)\",', webpage, 'video file')\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*?) - [^-]*? - [^-]*?\"',\n            webpage, 'video title')\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"/>',\n            webpage, 'video description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video_url = 'http://media.sztv.hu/vod/' + video_file\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 20,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE._extract_via_api#53",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE._extract_via_api(self, kind, video_id)",
        "snippet": "    def _extract_via_api(self, kind, video_id):\n        info = self._download_json(\n            'https://www.tagesschau.de/api/multimedia/{0}/{0}-{1}.json'.format(kind, video_id),\n            video_id)\n        title = info['headline']\n        formats = []\n        for media in info['mediadata']:\n            for format_id, format_url in media.items():\n                if determine_ext(format_url) == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        format_url, video_id, 'mp4',\n                        entry_protocol='m3u8_native', m3u8_id='hls'))\n                else:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': format_id,\n                        'vcodec': 'none' if kind == 'audio' else None,\n                    })\n        self._sort_formats(formats)\n        timestamp = parse_iso8601(info.get('date'))\n        return {\n            'id': video_id,\n            'title': title,\n            'timestamp': timestamp,\n            'formats': formats,\n        }",
        "begin_line": 53,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE._real_extract#80",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # kind = mobj.group('kind').lower()\n        # if kind == 'video':\n        #     return self._extract_via_api(kind, video_id)\n\n        # JSON api does not provide some audio formats (e.g. ogg) thus\n        # extractiong audio via webpage\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage).strip()\n        formats = []\n\n        for media_json in re.findall(r'({src\\s*:\\s*[\"\\']http[^}]+type\\s*:[^}]+})', webpage):\n            media = self._parse_json(js_to_json(media_json), video_id, fatal=False)\n            if not media:\n                continue\n            src = media.get('src')\n            if not src:\n                return\n            quality = media.get('quality')\n            kind = media.get('type', '').split('/')[0]\n            ext = determine_ext(src)\n            f = {\n                'url': src,\n                'format_id': '%s_%s' % (quality, ext) if quality else ext,\n                'ext': ext,\n                'vcodec': 'none' if kind == 'audio' else None,\n            }\n            f.update(self._FORMATS.get(quality, {}))\n            formats.append(f)\n\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 80,
        "end_line": 124,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauIE.suitable#210",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if TagesschauPlayerIE.suitable(url) else super(TagesschauIE, cls).suitable(url)",
        "begin_line": 210,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauIE._extract_formats#213",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauIE._extract_formats(self, download_text, media_kind)",
        "snippet": "    def _extract_formats(self, download_text, media_kind):\n        links = re.finditer(\n            r'<div class=\"button\" title=\"(?P<title>[^\"]*)\"><a href=\"(?P<url>[^\"]+)\">(?P<name>.+?)</a></div>',\n            download_text)\n        formats = []\n        for l in links:\n            link_url = l.group('url')\n            if not link_url:\n                continue\n            format_id = self._search_regex(\n                r'.*/[^/.]+\\.([^/]+)\\.[^/.]+$', link_url, 'format ID',\n                default=determine_ext(link_url))\n            format = {\n                'format_id': format_id,\n                'url': l.group('url'),\n                'format_name': l.group('name'),\n            }\n            title = l.group('title')\n            if title:\n                if media_kind.lower() == 'video':\n                    m = re.match(\n                        r'''(?x)\n                            Video:\\s*(?P<vcodec>[a-zA-Z0-9/._-]+)\\s*&\\#10;\n                            (?P<width>[0-9]+)x(?P<height>[0-9]+)px&\\#10;\n                            (?P<vbr>[0-9]+)kbps&\\#10;\n                            Audio:\\s*(?P<abr>[0-9]+)kbps,\\s*(?P<audio_desc>[A-Za-z\\.0-9]+)&\\#10;\n                            Gr&ouml;&szlig;e:\\s*(?P<filesize_approx>[0-9.,]+\\s+[a-zA-Z]*B)''',\n                        title)\n                    if m:\n                        format.update({\n                            'format_note': m.group('audio_desc'),\n                            'vcodec': m.group('vcodec'),\n                            'width': int(m.group('width')),\n                            'height': int(m.group('height')),\n                            'abr': int(m.group('abr')),\n                            'vbr': int(m.group('vbr')),\n                            'filesize_approx': parse_filesize(m.group('filesize_approx')),\n                        })\n                else:\n                    m = re.match(\n                        r'(?P<format>.+?)-Format\\s*:\\s*(?P<abr>\\d+)kbps\\s*,\\s*(?P<note>.+)',\n                        title)\n                    if m:\n                        format.update({\n                            'format_note': '%s, %s' % (m.group('format'), m.group('note')),\n                            'vcodec': 'none',\n                            'abr': int(m.group('abr')),\n                        })\n            formats.append(format)\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 213,
        "end_line": 263,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract#265",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('path')\n        display_id = video_id.lstrip('-')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'<span[^>]*class=\"headline\"[^>]*>(.+?)</span>',\n            webpage, 'title', default=None) or self._og_search_title(webpage)\n\n        DOWNLOAD_REGEX = r'(?s)<p>Wir bieten dieses (?P<kind>Video|Audio) in folgenden Formaten zum Download an:</p>\\s*<div class=\"controls\">(?P<links>.*?)</div>\\s*<p>'\n\n        webpage_type = self._og_search_property('type', webpage, default=None)\n        if webpage_type == 'website':  # Article\n            entries = []\n            for num, (entry_title, media_kind, download_text) in enumerate(re.findall(\n                    r'(?s)<p[^>]+class=\"infotext\"[^>]*>\\s*(?:<a[^>]+>)?\\s*<strong>(.+?)</strong>.*?</p>.*?%s' % DOWNLOAD_REGEX,\n                    webpage), 1):\n                entries.append({\n                    'id': '%s-%d' % (display_id, num),\n                    'title': '%s' % entry_title,\n                    'formats': self._extract_formats(download_text, media_kind),\n                })\n            if len(entries) > 1:\n                return self.playlist_result(entries, display_id, title)\n            formats = entries[0]['formats']\n        else:  # Assume single video\n            download_text = self._search_regex(\n                DOWNLOAD_REGEX, webpage, 'download links', group='links')\n            media_kind = self._search_regex(\n                DOWNLOAD_REGEX, webpage, 'media kind', default='Video', group='kind')\n            formats = self._extract_formats(download_text, media_kind)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._html_search_regex(\n            r'(?s)<p class=\"teasertext\">(.*?)</p>',\n            webpage, 'description', default=None)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'description': description,\n        }",
        "begin_line": 265,
        "end_line": 311,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tass.TassIE._real_extract#33",
        "src_path": "youtube_dl/extractor/tass.py",
        "class_name": "youtube_dl.extractor.tass.TassIE",
        "signature": "youtube_dl.extractor.tass.TassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        sources = json.loads(js_to_json(self._search_regex(\n            r'(?s)sources\\s*:\\s*(\\[.+?\\])', webpage, 'sources')))\n\n        quality = qualities(['sd', 'hd'])\n\n        formats = []\n        for source in sources:\n            video_url = source.get('file')\n            if not video_url or not video_url.startswith('http') or not video_url.endswith('.mp4'):\n                continue\n            label = source.get('label')\n            formats.append({\n                'url': video_url,\n                'format_id': label,\n                'quality': quality(label),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n        }",
        "begin_line": 33,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tastytrade.TastyTradeIE._real_extract#28",
        "src_path": "youtube_dl/extractor/tastytrade.py",
        "class_name": "youtube_dl.extractor.tastytrade.TastyTradeIE",
        "signature": "youtube_dl.extractor.tastytrade.TastyTradeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        ooyala_code = self._search_regex(\n            r'data-media-id=([\"\\'])(?P<code>(?:(?!\\1).)+)\\1',\n            webpage, 'ooyala code', group='code')\n\n        info = self._search_json_ld(webpage, display_id, fatal=False)\n        info.update({\n            '_type': 'url_transparent',\n            'ie_key': OoyalaIE.ie_key(),\n            'url': 'ooyala:%s' % ooyala_code,\n            'display_id': display_id,\n        })\n        return info",
        "begin_line": 28,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tbs.TBSIE._real_extract#37",
        "src_path": "youtube_dl/extractor/tbs.py",
        "class_name": "youtube_dl.extractor.tbs.TBSIE",
        "signature": "youtube_dl.extractor.tbs.TBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, display_id = re.match(self._VALID_URL, url).groups()\n        site = domain[:3]\n        webpage = self._download_webpage(url, display_id)\n        video_params = extract_attributes(self._search_regex(r'(<[^>]+id=\"page-video\"[^>]*>)', webpage, 'video params'))\n        query = None\n        clip_id = video_params.get('clipid')\n        if clip_id:\n            query = 'id=' + clip_id\n        else:\n            query = 'titleId=' + video_params['titleid']\n        return self._extract_cvp_info(\n            'http://www.%s.com/service/cvpXml?%s' % (domain, query), display_id, {\n                'default': {\n                    'media_src': 'http://ht.cdn.turner.com/%s/big' % site,\n                },\n                'secure': {\n                    'media_src': 'http://androidhls-secure.cdn.turner.com/%s/big' % site,\n                    'tokenizer_src': 'http://www.%s.com/video/processors/services/token_ipadAdobe.do' % domain,\n                },\n            }, {\n                'url': url,\n                'site_name': site.upper(),\n                'auth_required': video_params.get('isAuthRequired') != 'false',\n            })",
        "begin_line": 37,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tdslifeway.TDSLifewayIE._real_extract#31",
        "src_path": "youtube_dl/extractor/tdslifeway.py",
        "class_name": "youtube_dl.extractor.tdslifeway.TDSLifewayIE",
        "signature": "youtube_dl.extractor.tdslifeway.TDSLifewayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        brightcove_id = self._match_id(url)\n        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)",
        "begin_line": 31,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract#59",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('title', webpage, 'title', fatal=True)\n        TITLE_SUFFIX = ' - TeacherTube'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)].strip()\n\n        description = self._html_search_meta('description', webpage, 'description')\n        if description:\n            description = description.strip()\n\n        quality = qualities(['mp3', 'flv', 'mp4'])\n\n        media_urls = re.findall(r'data-contenturl=\"([^\"]+)\"', webpage)\n        media_urls.extend(re.findall(r'var\\s+filePath\\s*=\\s*\"([^\"]+)\"', webpage))\n        media_urls.extend(re.findall(r'\\'file\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\'],', webpage))\n\n        formats = [\n            {\n                'url': media_url,\n                'quality': quality(determine_ext(media_url))\n            } for media_url in set(media_urls)\n        ]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._html_search_regex(r'\\'image\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\']', webpage, 'thumbnail'),\n            'formats': formats,\n            'description': description,\n        }",
        "begin_line": 59,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract#115",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user')\n\n        urls = []\n        webpage = self._download_webpage(url, user_id)\n        urls.extend(re.findall(self._MEDIA_RE, webpage))\n\n        pages = re.findall(r'/ajax-user/user-videos/%s\\?page=([0-9]+)' % user_id, webpage)[:-1]\n        for p in pages:\n            more = 'http://www.teachertube.com/ajax-user/user-videos/%s?page=%s' % (user_id, p)\n            webpage = self._download_webpage(more, user_id, 'Downloading page %s/%s' % (p, len(pages)))\n            video_urls = re.findall(self._MEDIA_RE, webpage)\n            urls.extend(video_urls)\n\n        entries = [self.url_result(vurl, 'TeacherTube') for vurl in urls]\n        return self.playlist_result(entries, user_id)",
        "begin_line": 115,
        "end_line": 131,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract#28",
        "src_path": "youtube_dl/extractor/teachingchannel.py",
        "class_name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE",
        "signature": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        ooyala_code = self._search_regex(\n            r'data-embed-code=\\'(.+?)\\'', webpage, 'ooyala code')\n\n        return OoyalaIE._build_url_result(ooyala_code)",
        "begin_line": 28,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract#73",
        "src_path": "youtube_dl/extractor/teamcoco.py",
        "class_name": "youtube_dl.extractor.teamcoco.TeamcocoIE",
        "signature": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        display_id = mobj.group('display_id')\n        webpage, urlh = self._download_webpage_handle(url, display_id)\n        if 'src=expired' in urlh.geturl():\n            raise ExtractorError('This video is expired.', expected=True)\n\n        video_id = mobj.group('video_id')\n        if not video_id:\n            video_id = self._html_search_regex(\n                self._VIDEO_ID_REGEXES, webpage, 'video id')\n\n        data = None\n\n        preload_codes = self._html_search_regex(\n            r'(function.+)setTimeout\\(function\\(\\)\\{playlist',\n            webpage, 'preload codes')\n        base64_fragments = re.findall(r'\"([a-zA-Z0-9+/=]+)\"', preload_codes)\n        base64_fragments.remove('init')\n\n        def _check_sequence(cur_fragments):\n            if not cur_fragments:\n                return\n            for i in range(len(cur_fragments)):\n                cur_sequence = (''.join(cur_fragments[i:] + cur_fragments[:i])).encode('ascii')\n                try:\n                    raw_data = base64.b64decode(cur_sequence)\n                    if compat_ord(raw_data[0]) == compat_ord('{'):\n                        return json.loads(raw_data.decode('utf-8'))\n                except (TypeError, binascii.Error, UnicodeDecodeError, ValueError):\n                    continue\n\n        def _check_data():\n            for i in range(len(base64_fragments) + 1):\n                for j in range(i, len(base64_fragments) + 1):\n                    data = _check_sequence(base64_fragments[:i] + base64_fragments[j:])\n                    if data:\n                        return data\n\n        self.to_screen('Try to compute possible data sequence. This may take some time.')\n        data = _check_data()\n\n        if not data:\n            raise ExtractorError(\n                'Preload information could not be extracted', expected=True)\n\n        formats = []\n        get_quality = qualities(['500k', '480p', '1000k', '720p', '1080p'])\n        for filed in data['files']:\n            if determine_ext(filed['url']) == 'm3u8':\n                # compat_urllib_parse.urljoin does not work here\n                if filed['url'].startswith('/'):\n                    m3u8_url = 'http://ht.cdn.turner.com/tbs/big/teamcoco' + filed['url']\n                else:\n                    m3u8_url = filed['url']\n                m3u8_formats = self._extract_m3u8_formats(\n                    m3u8_url, video_id, ext='mp4')\n                for m3u8_format in m3u8_formats:\n                    if m3u8_format not in formats:\n                        formats.append(m3u8_format)\n            elif determine_ext(filed['url']) == 'f4m':\n                # TODO Correct f4m extraction\n                continue\n            else:\n                if filed['url'].startswith('/mp4:protected/'):\n                    # TODO Correct extraction for these files\n                    continue\n                m_format = re.search(r'(\\d+(k|p))\\.mp4', filed['url'])\n                if m_format is not None:\n                    format_id = m_format.group(1)\n                else:\n                    format_id = filed['bitrate']\n                tbr = (\n                    int(filed['bitrate'])\n                    if filed['bitrate'].isdigit()\n                    else None)\n\n                formats.append({\n                    'url': filed['url'],\n                    'ext': 'mp4',\n                    'tbr': tbr,\n                    'format_id': format_id,\n                    'quality': get_quality(format_id),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': data['title'],\n            'thumbnail': data.get('thumb', {}).get('href'),\n            'description': data.get('teaser'),\n            'duration': data.get('duration'),\n            'age_limit': self._family_friendly_search(webpage),\n        }",
        "begin_line": 73,
        "end_line": 170,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract#46",
        "src_path": "youtube_dl/extractor/techtalks.py",
        "class_name": "youtube_dl.extractor.techtalks.TechTalksIE",
        "signature": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        talk_id = mobj.group('id')\n        webpage = self._download_webpage(url, talk_id)\n        rtmp_url = self._search_regex(\n            r'netConnectionUrl: \\'(.*?)\\'', webpage, 'rtmp url')\n        play_path = self._search_regex(\n            r'href=\\'(.*?)\\' [^>]*id=\"flowplayer_presenter\"',\n            webpage, 'presenter play path')\n        title = clean_html(get_element_by_attribute('class', 'title', webpage))\n        video_info = {\n            'id': talk_id,\n            'title': title,\n            'url': rtmp_url,\n            'play_path': play_path,\n            'ext': 'flv',\n        }\n        m_slides = re.search(r'<a class=\"slides\" href=\\'(.*?)\\'', webpage)\n        if m_slides is None:\n            return video_info\n        else:\n            return {\n                '_type': 'playlist',\n                'id': talk_id,\n                'title': title,\n                'entries': [\n                    video_info,\n                    # The slides video\n                    {\n                        'id': talk_id + '-slides',\n                        'title': title,\n                        'url': rtmp_url,\n                        'play_path': m_slides.group(1),\n                        'ext': 'flv',\n                    },\n                ],\n            }",
        "begin_line": 46,
        "end_line": 82,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._extract_info#118",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._extract_info(self, webpage)",
        "snippet": "    def _extract_info(self, webpage):\n        info_json = self._search_regex(\n            r'(?s)q\\(\\s*\"\\w+.init\"\\s*,\\s*({.+})\\)\\s*</script>',\n            webpage, 'info json')\n        return json.loads(info_json)",
        "begin_line": 118,
        "end_line": 122,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._real_extract#124",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        if m.group('type').startswith('embed'):\n            desktop_url = m.group('proto') + 'www' + m.group('urlmain')\n            return self.url_result(desktop_url, 'TED')\n        name = m.group('name')\n        if m.group('type_talk'):\n            return self._talk_info(url, name)\n        elif m.group('type_watch'):\n            return self._watch_info(url, name)\n        else:\n            return self._playlist_videos_info(url, name)",
        "begin_line": 124,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info#137",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info(self, url, name)",
        "snippet": "    def _playlist_videos_info(self, url, name):\n        '''Returns the videos of the playlist'''\n\n        webpage = self._download_webpage(url, name,\n                                         'Downloading playlist webpage')\n        info = self._extract_info(webpage)\n\n        playlist_info = try_get(\n            info, lambda x: x['__INITIAL_DATA__']['playlist'],\n            dict) or info['playlist']\n\n        playlist_entries = [\n            self.url_result('http://www.ted.com/talks/' + talk['slug'], self.ie_key())\n            for talk in try_get(\n                info, lambda x: x['__INITIAL_DATA__']['talks'],\n                dict) or info['talks']\n        ]\n        return self.playlist_result(\n            playlist_entries,\n            playlist_id=compat_str(playlist_info['id']),\n            playlist_title=playlist_info['title'])",
        "begin_line": 137,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._talk_info#159",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._talk_info(self, url, video_name)",
        "snippet": "    def _talk_info(self, url, video_name):\n        webpage = self._download_webpage(url, video_name)\n\n        info = self._extract_info(webpage)\n\n        talk_info = try_get(\n            info, lambda x: x['__INITIAL_DATA__']['talks'][0],\n            dict) or info['talks'][0]\n\n        title = talk_info['title'].strip()\n\n        external = talk_info.get('external')\n        if external:\n            service = external['service']\n            self.to_screen('Found video from %s' % service)\n            ext_url = None\n            if service.lower() == 'youtube':\n                ext_url = external.get('code')\n            return {\n                '_type': 'url',\n                'url': ext_url or external['uri'],\n            }\n\n        native_downloads = try_get(\n            talk_info, lambda x: x['downloads']['nativeDownloads'],\n            dict) or talk_info['nativeDownloads']\n\n        formats = [{\n            'url': format_url,\n            'format_id': format_id,\n            'format': format_id,\n        } for (format_id, format_url) in native_downloads.items() if format_url is not None]\n        if formats:\n            for f in formats:\n                finfo = self._NATIVE_FORMATS.get(f['format_id'])\n                if finfo:\n                    f.update(finfo)\n\n        player_talk = talk_info['player_talks'][0]\n\n        resources_ = player_talk.get('resources') or talk_info.get('resources')\n\n        http_url = None\n        for format_id, resources in resources_.items():\n            if format_id == 'h264':\n                for resource in resources:\n                    h264_url = resource.get('file')\n                    if not h264_url:\n                        continue\n                    bitrate = int_or_none(resource.get('bitrate'))\n                    formats.append({\n                        'url': h264_url,\n                        'format_id': '%s-%sk' % (format_id, bitrate),\n                        'tbr': bitrate,\n                    })\n                    if re.search(r'\\d+k', h264_url):\n                        http_url = h264_url\n            elif format_id == 'rtmp':\n                streamer = talk_info.get('streamer')\n                if not streamer:\n                    continue\n                for resource in resources:\n                    formats.append({\n                        'format_id': '%s-%s' % (format_id, resource.get('name')),\n                        'url': streamer,\n                        'play_path': resource['file'],\n                        'ext': 'flv',\n                        'width': int_or_none(resource.get('width')),\n                        'height': int_or_none(resource.get('height')),\n                        'tbr': int_or_none(resource.get('bitrate')),\n                    })\n            elif format_id == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    resources.get('stream'), video_name, 'mp4', m3u8_id=format_id, fatal=False))\n\n        m3u8_formats = list(filter(\n            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none',\n            formats))\n        if http_url:\n            for m3u8_format in m3u8_formats:\n                bitrate = self._search_regex(r'(\\d+k)', m3u8_format['url'], 'bitrate', default=None)\n                if not bitrate:\n                    continue\n                f = m3u8_format.copy()\n                f.update({\n                    'url': re.sub(r'\\d+k', bitrate, http_url),\n                    'format_id': m3u8_format['format_id'].replace('hls', 'http'),\n                    'protocol': 'http',\n                })\n                formats.append(f)\n\n        audio_download = talk_info.get('audioDownload')\n        if audio_download:\n            formats.append({\n                'url': audio_download,\n                'format_id': 'audio',\n                'vcodec': 'none',\n            })\n\n        self._sort_formats(formats)\n\n        video_id = compat_str(talk_info['id'])\n\n        return {\n            'id': video_id,\n            'title': title,\n            'uploader': player_talk.get('speaker') or talk_info.get('speaker'),\n            'thumbnail': player_talk.get('thumb') or talk_info.get('thumb'),\n            'description': self._og_search_description(webpage),\n            'subtitles': self._get_subtitles(video_id, talk_info),\n            'formats': formats,\n            'duration': talk_info.get('duration'),\n        }",
        "begin_line": 159,
        "end_line": 271,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._get_subtitles#273",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._get_subtitles(self, video_id, talk_info)",
        "snippet": "    def _get_subtitles(self, video_id, talk_info):\n        sub_lang_list = {}\n        for language in try_get(\n                talk_info,\n                (lambda x: x['downloads']['languages'],\n                 lambda x: x['languages']), list):\n            lang_code = language.get('languageCode') or language.get('ianaCode')\n            if not lang_code:\n                continue\n            sub_lang_list[lang_code] = [\n                {\n                    'url': 'http://www.ted.com/talks/subtitles/id/%s/lang/%s/format/%s' % (video_id, lang_code, ext),\n                    'ext': ext,\n                }\n                for ext in ['ted', 'srt']\n            ]\n        return sub_lang_list",
        "begin_line": 273,
        "end_line": 289,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._watch_info#291",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._watch_info(self, url, name)",
        "snippet": "    def _watch_info(self, url, name):\n        webpage = self._download_webpage(url, name)\n\n        config_json = self._html_search_regex(\n            r'\"pages\\.jwplayer\"\\s*,\\s*({.+?})\\s*\\)\\s*</script>',\n            webpage, 'config', default=None)\n        if not config_json:\n            embed_url = self._search_regex(\n                r\"<iframe[^>]+class='pages-video-embed__video__object'[^>]+src='([^']+)'\", webpage, 'embed url')\n            return self.url_result(self._proto_relative_url(embed_url))\n        config = json.loads(config_json)['config']\n        video_url = config['video']['url']\n        thumbnail = config.get('image', {}).get('url')\n\n        title = self._html_search_regex(\n            r\"(?s)<h1(?:\\s+class='[^']+')?>(.+?)</h1>\", webpage, 'title')\n        description = self._html_search_regex(\n            [\n                r'(?s)<h4 class=\"[^\"]+\" id=\"h3--about-this-talk\">.*?</h4>(.*?)</div>',\n                r'(?s)<p><strong>About this talk:</strong>\\s+(.*?)</p>',\n            ],\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': name,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 291,
        "end_line": 320,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tele13.Tele13IE._real_extract#45",
        "src_path": "youtube_dl/extractor/tele13.py",
        "class_name": "youtube_dl.extractor.tele13.Tele13IE",
        "signature": "youtube_dl.extractor.tele13.Tele13IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        setup_js = self._search_regex(\n            r\"(?s)jwplayer\\('player-vivo'\\).setup\\((\\{.*?\\})\\)\",\n            webpage, 'setup code')\n        sources = self._parse_json(self._search_regex(\n            r'sources\\s*:\\s*(\\[[^\\]]+\\])', setup_js, 'sources'),\n            display_id, js_to_json)\n\n        preference = qualities(['M\u00f3vil', 'SD', 'HD'])\n        formats = []\n        urls = []\n        for f in sources:\n            format_url = f['file']\n            if format_url and format_url not in urls:\n                ext = determine_ext(format_url)\n                if ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        format_url, display_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls', fatal=False))\n                elif YoutubeIE.suitable(format_url):\n                    return self.url_result(format_url, 'Youtube')\n                else:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': f.get('label'),\n                        'preference': preference(f.get('label')),\n                        'ext': ext,\n                    })\n                urls.append(format_url)\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'title': self._search_regex(\n                r'title\\s*:\\s*\"([^\"]+)\"', setup_js, 'title'),\n            'description': self._html_search_meta(\n                'description', webpage, 'description'),\n            'thumbnail': self._search_regex(\n                r'image\\s*:\\s*\"([^\"]+)\"', setup_js, 'thumbnail', default=None),\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE._real_extract#36",
        "src_path": "youtube_dl/extractor/telebruxelles.py",
        "class_name": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE",
        "signature": "youtube_dl.extractor.telebruxelles.TeleBruxellesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        article_id = self._html_search_regex(\n            r\"<article id=\\\"post-(\\d+)\\\"\", webpage, 'article ID', default=None)\n        title = self._html_search_regex(\n            r'<h1 class=\\\"entry-title\\\">(.*?)</h1>', webpage, 'title')\n        description = self._og_search_description(webpage, default=None)\n\n        rtmp_url = self._html_search_regex(\n            r'file\\s*:\\s*\"(rtmp://[^/]+/vod/mp4:\"\\s*\\+\\s*\"[^\"]+\"\\s*\\+\\s*\".mp4)\"',\n            webpage, 'RTMP url')\n        rtmp_url = re.sub(r'\"\\s*\\+\\s*\"', '', rtmp_url)\n        formats = self._extract_wowza_formats(rtmp_url, article_id or display_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': article_id or display_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 36,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telecinco.TelecincoIE._real_extract#53",
        "src_path": "youtube_dl/extractor/telecinco.py",
        "class_name": "youtube_dl.extractor.telecinco.TelecincoIE",
        "signature": "youtube_dl.extractor.telecinco.TelecincoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        title = self._html_search_meta(\n            ['og:title', 'twitter:title'], webpage, 'title')\n        info = self._get_player_info(url, webpage)\n        info.update({\n            'display_id': display_id,\n            'title': title,\n            'description': self._html_search_meta(\n                ['og:description', 'twitter:description'],\n                webpage, 'title', fatal=False),\n        })\n        return info",
        "begin_line": 53,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telegraaf.TelegraafIE._real_extract#29",
        "src_path": "youtube_dl/extractor/telegraaf.py",
        "class_name": "youtube_dl.extractor.telegraaf.TelegraafIE",
        "signature": "youtube_dl.extractor.telegraaf.TelegraafIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        player_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"([^\"]+\")', webpage, 'player URL')\n        player_page = self._download_webpage(\n            player_url, video_id, note='Download player webpage')\n        playlist_url = self._search_regex(\n            r'playlist\\s*:\\s*\"([^\"]+)\"', player_page, 'playlist URL')\n        playlist_data = self._download_json(playlist_url, video_id)\n\n        item = playlist_data['items'][0]\n        formats = []\n        locations = item['locations']\n        for location in locations.get('adaptive', []):\n            manifest_url = location['src']\n            ext = determine_ext(manifest_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    manifest_url, video_id, ext='mp4', m3u8_id='hls', fatal=False))\n            elif ext == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    manifest_url, video_id, mpd_id='dash', fatal=False))\n            else:\n                self.report_warning('Unknown adaptive format %s' % ext)\n        for location in locations.get('progressive', []):\n            formats.append({\n                'url': location['sources'][0]['src'],\n                'width': location.get('width'),\n                'height': location.get('height'),\n                'format_id': 'http-%s' % location['label'],\n            })\n\n        self._sort_formats(formats)\n\n        title = remove_end(self._og_search_title(webpage), ' - VIDEO')\n        description = self._og_search_description(webpage)\n        duration = item.get('duration')\n        thumbnail = item.get('poster')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 29,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telemb.TeleMBIE._real_extract#40",
        "src_path": "youtube_dl/extractor/telemb.py",
        "class_name": "youtube_dl.extractor.telemb.TeleMBIE",
        "signature": "youtube_dl.extractor.telemb.TeleMBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        formats = []\n        for video_url in re.findall(r'file\\s*:\\s*\"([^\"]+)\"', webpage):\n            fmt = {\n                'url': video_url,\n                'format_id': video_url.split(':')[0]\n            }\n            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', video_url)\n            if rtmp:\n                fmt.update({\n                    'play_path': rtmp.group('playpath'),\n                    'app': rtmp.group('app'),\n                    'player_url': 'http://p.jwpcdn.com/6/10/jwplayer.flash.swf',\n                    'page_url': 'http://www.telemb.be',\n                    'preference': -1,\n                })\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        title = remove_start(self._og_search_title(webpage), 'T\u00e9l\u00e9MB : ')\n        description = self._html_search_regex(\n            r'<meta property=\"og:description\" content=\"(.+?)\" />',\n            webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telequebec.TeleQuebecIE._real_extract#32",
        "src_path": "youtube_dl/extractor/telequebec.py",
        "class_name": "youtube_dl.extractor.telequebec.TeleQuebecIE",
        "signature": "youtube_dl.extractor.telequebec.TeleQuebecIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n        media_data = self._download_json(\n            'https://mnmedias.api.telequebec.tv/api/v2/media/' + media_id,\n            media_id)['media']\n        return {\n            '_type': 'url_transparent',\n            'id': media_id,\n            'url': smuggle_url(\n                'limelight:media:' + media_data['streamInfo']['sourceId'],\n                {'geo_countries': ['CA']}),\n            'title': media_data['title'],\n            'description': try_get(\n                media_data, lambda x: x['descriptions'][0]['text'], compat_str),\n            'duration': int_or_none(\n                media_data.get('durationInMilliseconds'), 1000),\n            'ie_key': 'LimelightMedia',\n        }",
        "begin_line": 32,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.teletask.TeleTaskIE._real_extract#36",
        "src_path": "youtube_dl/extractor/teletask.py",
        "class_name": "youtube_dl.extractor.teletask.TeleTaskIE",
        "signature": "youtube_dl.extractor.teletask.TeleTaskIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lecture_id = self._match_id(url)\n        webpage = self._download_webpage(url, lecture_id)\n\n        title = self._html_search_regex(\n            r'itemprop=\"name\">([^<]+)</a>', webpage, 'title')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'Date:</td><td>([^<]+)</td>', webpage, 'date', fatal=False))\n\n        entries = [{\n            'id': '%s-%s' % (lecture_id, format_id),\n            'url': video_url,\n            'title': title,\n            'upload_date': upload_date,\n        } for format_id, video_url in re.findall(\n            r'<video class=\"([^\"]+)\"[^>]*>\\s*<source src=\"([^\"]+)\"', webpage)]\n\n        return self.playlist_result(entries, lecture_id, title)",
        "begin_line": 36,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.telewebion.TelewebionIE._real_extract#25",
        "src_path": "youtube_dl/extractor/telewebion.py",
        "class_name": "youtube_dl.extractor.telewebion.TelewebionIE",
        "signature": "youtube_dl.extractor.telewebion.TelewebionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        secure_token = self._download_webpage(\n            'http://m.s2.telewebion.com/op/op?action=getSecurityToken', video_id)\n        episode_details = self._download_json(\n            'http://m.s2.telewebion.com/op/op', video_id,\n            query={'action': 'getEpisodeDetails', 'episode_id': video_id})\n\n        m3u8_url = 'http://m.s1.telewebion.com/smil/%s.m3u8?filepath=%s&m3u8=1&secure_token=%s' % (\n            video_id, episode_details['file_path'], secure_token)\n        formats = self._extract_m3u8_formats(\n            m3u8_url, video_id, ext='mp4', m3u8_id='hls')\n\n        picture_paths = [\n            episode_details.get('picture_path'),\n            episode_details.get('large_picture_path'),\n        ]\n\n        thumbnails = [{\n            'url': picture_path,\n            'preference': idx,\n        } for idx, picture_path in enumerate(picture_paths) if picture_path is not None]\n\n        return {\n            'id': video_id,\n            'title': episode_details['title'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'view_count': episode_details.get('view_count'),\n        }",
        "begin_line": 25,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.testurl.TestURLIE._real_extract#15",
        "src_path": "youtube_dl/extractor/testurl.py",
        "class_name": "youtube_dl.extractor.testurl.TestURLIE",
        "signature": "youtube_dl.extractor.testurl.TestURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        from ..extractor import gen_extractors\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        extractor_id = mobj.group('extractor')\n        all_extractors = gen_extractors()\n\n        rex = re.compile(extractor_id, flags=re.IGNORECASE)\n        matching_extractors = [\n            e for e in all_extractors if rex.search(e.IE_NAME)]\n\n        if len(matching_extractors) == 0:\n            raise ExtractorError(\n                'No extractors matching %r found' % extractor_id,\n                expected=True)\n        elif len(matching_extractors) > 1:\n            # Is it obvious which one to pick?\n            try:\n                extractor = next(\n                    ie for ie in matching_extractors\n                    if ie.IE_NAME.lower() == extractor_id.lower())\n            except StopIteration:\n                raise ExtractorError(\n                    ('Found multiple matching extractors: %s' %\n                        ' '.join(ie.IE_NAME for ie in matching_extractors)),\n                    expected=True)\n        else:\n            extractor = matching_extractors[0]\n\n        num_str = mobj.group('num')\n        num = int(num_str) if num_str else 0\n\n        testcases = []\n        t = getattr(extractor, '_TEST', None)\n        if t:\n            testcases.append(t)\n        testcases.extend(getattr(extractor, '_TESTS', []))\n\n        try:\n            tc = testcases[num]\n        except IndexError:\n            raise ExtractorError(\n                ('Test case %d not found, got only %d tests' %\n                    (num, len(testcases))),\n                expected=True)\n\n        self.to_screen('Test URL: %s' % tc['url'])\n\n        return {\n            '_type': 'url',\n            'url': tc['url'],\n            'id': video_id,\n        }",
        "begin_line": 15,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tf1.TF1IE._real_extract#47",
        "src_path": "youtube_dl/extractor/tf1.py",
        "class_name": "youtube_dl.extractor.tf1.TF1IE",
        "signature": "youtube_dl.extractor.tf1.TF1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        wat_id = self._html_search_regex(\n            r'([\"\\'])(?:https?:)?//www\\.wat\\.tv/embedframe/.*?(?P<id>\\d{8})\\1',\n            webpage, 'wat id', group='id')\n        return self.url_result('wat:%s' % wat_id, 'Wat')",
        "begin_line": 47,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tfo.TFOIE._real_extract#31",
        "src_path": "youtube_dl/extractor/tfo.py",
        "class_name": "youtube_dl.extractor.tfo.TFOIE",
        "signature": "youtube_dl.extractor.tfo.TFOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        self._request_webpage(HEADRequest('http://www.tfo.org/'), video_id)\n        infos = self._download_json(\n            'http://www.tfo.org/api/web/video/get_infos', video_id, data=json.dumps({\n                'product_id': video_id,\n            }).encode(), headers={\n                'X-tfo-session': self._get_cookies('http://www.tfo.org/')['tfo-session'].value,\n            })\n        if infos.get('success') == 0:\n            if infos.get('code') == 'ErrGeoBlocked':\n                self.raise_geo_restricted(countries=self._GEO_COUNTRIES)\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, clean_html(infos['msg'])), expected=True)\n        video_data = infos['data']\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': 'limelight:media:' + video_data['llid'],\n            'title': video_data['title'],\n            'description': video_data.get('description'),\n            'series': video_data.get('collection'),\n            'season_number': int_or_none(video_data.get('season')),\n            'episode_number': int_or_none(video_data.get('episode')),\n            'duration': int_or_none(video_data.get('duration')),\n            'ie_key': 'LimelightMedia',\n        }",
        "begin_line": 31,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theintercept.TheInterceptIE._real_extract#29",
        "src_path": "youtube_dl/extractor/theintercept.py",
        "class_name": "youtube_dl.extractor.theintercept.TheInterceptIE",
        "signature": "youtube_dl.extractor.theintercept.TheInterceptIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        json_data = self._parse_json(self._search_regex(\n            r'initialStoreTree\\s*=\\s*(?P<json_data>{.+})', webpage,\n            'initialStoreTree'), display_id)\n\n        for post in json_data['resources']['posts'].values():\n            if post['slug'] == display_id:\n                return {\n                    '_type': 'url_transparent',\n                    'url': 'jwplatform:%s' % post['fov_videoid'],\n                    'id': compat_str(post['ID']),\n                    'display_id': display_id,\n                    'title': post['title'],\n                    'description': post.get('excerpt'),\n                    'timestamp': parse_iso8601(post.get('date')),\n                    'comment_count': int_or_none(post.get('comments_number')),\n                }\n        raise ExtractorError('Unable to find the current post')",
        "begin_line": 29,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_smil#35",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data')",
        "snippet": "    def _extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data'):\n        meta = self._download_xml(\n            smil_url, video_id, note=note, query={'format': 'SMIL'},\n            headers=self.geo_verification_headers())\n        error_element = find_xpath_attr(meta, _x('.//smil:ref'), 'src')\n        if error_element is not None and error_element.attrib['src'].startswith(\n                'http://link.theplatform.com/s/errorFiles/Unavailable.'):\n            raise ExtractorError(error_element.attrib['abstract'], expected=True)\n\n        smil_formats = self._parse_smil_formats(\n            meta, smil_url, video_id, namespace=default_ns,\n            # the parameters are from syfy.com, other sites may use others,\n            # they also work for nbc.com\n            f4m_params={'g': 'UXWGVKRWHFSP', 'hdcore': '3.0.3'},\n            transform_rtmp_url=lambda streamer, src: (streamer, 'mp4:' + src))\n\n        formats = []\n        for _format in smil_formats:\n            if OnceIE.suitable(_format['url']):\n                formats.extend(self._extract_once_formats(_format['url']))\n            else:\n                media_url = _format['url']\n                if determine_ext(media_url) == 'm3u8':\n                    hdnea2 = self._get_cookies(media_url).get('hdnea2')\n                    if hdnea2:\n                        _format['url'] = update_url_query(media_url, {'hdnea3': hdnea2.value})\n\n                formats.append(_format)\n\n        subtitles = self._parse_smil_subtitles(meta, default_ns)\n\n        return formats, subtitles",
        "begin_line": 35,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._download_theplatform_metadata#68",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._download_theplatform_metadata(self, path, video_id)",
        "snippet": "    def _download_theplatform_metadata(self, path, video_id):\n        info_url = 'http://link.theplatform.com/s/%s?format=preview' % path\n        return self._download_json(info_url, video_id)",
        "begin_line": 68,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._parse_theplatform_metadata#72",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._parse_theplatform_metadata(self, info)",
        "snippet": "    def _parse_theplatform_metadata(self, info):\n        subtitles = {}\n        captions = info.get('captions')\n        if isinstance(captions, list):\n            for caption in captions:\n                lang, src, mime = caption.get('lang', 'en'), caption.get('src'), caption.get('type')\n                subtitles.setdefault(lang, []).append({\n                    'ext': mimetype2ext(mime),\n                    'url': src,\n                })\n\n        duration = info.get('duration')\n        tp_chapters = info.get('chapters', [])\n        chapters = []\n        if tp_chapters:\n            def _add_chapter(start_time, end_time):\n                start_time = float_or_none(start_time, 1000)\n                end_time = float_or_none(end_time, 1000)\n                if start_time is None or end_time is None:\n                    return\n                chapters.append({\n                    'start_time': start_time,\n                    'end_time': end_time,\n                })\n\n            for chapter in tp_chapters[:-1]:\n                _add_chapter(chapter.get('startTime'), chapter.get('endTime'))\n            _add_chapter(tp_chapters[-1].get('startTime'), tp_chapters[-1].get('endTime') or duration)\n\n        return {\n            'title': info['title'],\n            'subtitles': subtitles,\n            'description': info['description'],\n            'thumbnail': info['defaultThumbnailUrl'],\n            'duration': float_or_none(duration, 1000),\n            'timestamp': int_or_none(info.get('pubDate'), 1000) or None,\n            'uploader': info.get('billingCode'),\n            'chapters': chapters,\n        }",
        "begin_line": 72,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_metadata#112",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformBaseIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformBaseIE._extract_theplatform_metadata(self, path, video_id)",
        "snippet": "    def _extract_theplatform_metadata(self, path, video_id):\n        info = self._download_theplatform_metadata(path, video_id)\n        return self._parse_theplatform_metadata(info)",
        "begin_line": 112,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._extract_urls#191",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._extract_urls(cls, webpage)",
        "snippet": "    def _extract_urls(cls, webpage):\n        m = re.search(\n            r'''(?x)\n                    <meta\\s+\n                        property=([\"'])(?:og:video(?::(?:secure_)?url)?|twitter:player)\\1\\s+\n                        content=([\"'])(?P<url>https?://player\\.theplatform\\.com/p/.+?)\\2\n            ''', webpage)\n        if m:\n            return [m.group('url')]\n\n        # Are whitesapces ignored in URLs?\n        # https://github.com/rg3/youtube-dl/issues/12044\n        matches = re.findall(\n            r'(?s)<(?:iframe|script)[^>]+src=([\"\\'])((?:https?:)?//player\\.theplatform\\.com/p/.+?)\\1', webpage)\n        if matches:\n            return [re.sub(r'\\s', '', list(zip(*matches))[1][0])]",
        "begin_line": 191,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._sign_url#209",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._sign_url(url, sig_key, sig_secret, life=600, include_qs=False)",
        "snippet": "    def _sign_url(url, sig_key, sig_secret, life=600, include_qs=False):\n        flags = '10' if include_qs else '00'\n        expiration_date = '%x' % (int(time.time()) + life)\n\n        def str_to_hex(str):\n            return binascii.b2a_hex(str.encode('ascii')).decode('ascii')\n\n        def hex_to_bytes(hex):\n            return binascii.a2b_hex(hex.encode('ascii'))\n\n        relative_path = re.match(r'https?://link.theplatform.com/s/([^?]+)', url).group(1)\n        clear_text = hex_to_bytes(flags + expiration_date + str_to_hex(relative_path))\n        checksum = hmac.new(sig_key.encode('ascii'), clear_text, hashlib.sha1).hexdigest()\n        sig = flags + expiration_date + checksum + str_to_hex(sig_secret)\n        return '%s&sig=%s' % (url, sig)",
        "begin_line": 209,
        "end_line": 223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract#225",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        mobj = re.match(self._VALID_URL, url)\n        provider_id = mobj.group('provider_id')\n        video_id = mobj.group('id')\n\n        if not provider_id:\n            provider_id = 'dJ5BDC'\n\n        path = provider_id + '/'\n        if mobj.group('media'):\n            path += mobj.group('media')\n        path += video_id\n\n        qs_dict = compat_parse_qs(compat_urllib_parse_urlparse(url).query)\n        if 'guid' in qs_dict:\n            webpage = self._download_webpage(url, video_id)\n            scripts = re.findall(r'<script[^>]+src=\"([^\"]+)\"', webpage)\n            feed_id = None\n            # feed id usually locates in the last script.\n            # Seems there's no pattern for the interested script filename, so\n            # I try one by one\n            for script in reversed(scripts):\n                feed_script = self._download_webpage(\n                    self._proto_relative_url(script, 'http:'),\n                    video_id, 'Downloading feed script')\n                feed_id = self._search_regex(\n                    r'defaultFeedId\\s*:\\s*\"([^\"]+)\"', feed_script,\n                    'default feed id', default=None)\n                if feed_id is not None:\n                    break\n            if feed_id is None:\n                raise ExtractorError('Unable to find feed id')\n            return self.url_result('http://feed.theplatform.com/f/%s/%s?byGuid=%s' % (\n                provider_id, feed_id, qs_dict['guid'][0]))\n\n        if smuggled_data.get('force_smil_url', False):\n            smil_url = url\n        # Explicitly specified SMIL (see https://github.com/rg3/youtube-dl/issues/7385)\n        elif '/guid/' in url:\n            headers = {}\n            source_url = smuggled_data.get('source_url')\n            if source_url:\n                headers['Referer'] = source_url\n            request = sanitized_Request(url, headers=headers)\n            webpage = self._download_webpage(request, video_id)\n            smil_url = self._search_regex(\n                r'<link[^>]+href=([\"\\'])(?P<url>.+?)\\1[^>]+type=[\"\\']application/smil\\+xml',\n                webpage, 'smil url', group='url')\n            path = self._search_regex(\n                r'link\\.theplatform\\.com/s/((?:[^/?#&]+/)+[^/?#&]+)', smil_url, 'path')\n            smil_url += '?' if '?' not in smil_url else '&' + 'formats=m3u,mpeg4'\n        elif mobj.group('config'):\n            config_url = url + '&form=json'\n            config_url = config_url.replace('swf/', 'config/')\n            config_url = config_url.replace('onsite/', 'onsite/config/')\n            config = self._download_json(config_url, video_id, 'Downloading config')\n            if 'releaseUrl' in config:\n                release_url = config['releaseUrl']\n            else:\n                release_url = 'http://link.theplatform.com/s/%s?mbr=true' % path\n            smil_url = release_url + '&formats=MPEG4&manifest=f4m'\n        else:\n            smil_url = 'http://link.theplatform.com/s/%s?mbr=true' % path\n\n        sig = smuggled_data.get('sig')\n        if sig:\n            smil_url = self._sign_url(smil_url, sig['key'], sig['secret'])\n\n        formats, subtitles = self._extract_theplatform_smil(smil_url, video_id)\n        self._sort_formats(formats)\n\n        ret = self._extract_theplatform_metadata(path, video_id)\n        combined_subtitles = self._merge_subtitles(ret.get('subtitles', {}), subtitles)\n        ret.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': combined_subtitles,\n        })\n\n        return ret",
        "begin_line": 225,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._extract_feed_info#330",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}, account_id=None)",
        "snippet": "    def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}, account_id=None):\n        real_url = self._URL_TEMPLATE % (self.http_scheme(), provider_id, feed_id, filter_query)\n        entry = self._download_json(real_url, video_id)['entries'][0]\n        main_smil_url = 'http://link.theplatform.com/s/%s/media/guid/%d/%s' % (provider_id, account_id, entry['guid']) if account_id else None\n\n        formats = []\n        subtitles = {}\n        first_video_id = None\n        duration = None\n        asset_types = []\n        for item in entry['media$content']:\n            smil_url = item['plfile$url']\n            cur_video_id = ThePlatformIE._match_id(smil_url)\n            if first_video_id is None:\n                first_video_id = cur_video_id\n                duration = float_or_none(item.get('plfile$duration'))\n            for asset_type in item['plfile$assetTypes']:\n                if asset_type in asset_types:\n                    continue\n                asset_types.append(asset_type)\n                query = {\n                    'mbr': 'true',\n                    'formats': item['plfile$format'],\n                    'assetTypes': asset_type,\n                }\n                if asset_type in asset_types_query:\n                    query.update(asset_types_query[asset_type])\n                cur_formats, cur_subtitles = self._extract_theplatform_smil(update_url_query(\n                    main_smil_url or smil_url, query), video_id, 'Downloading SMIL data for %s' % asset_type)\n                formats.extend(cur_formats)\n                subtitles = self._merge_subtitles(subtitles, cur_subtitles)\n\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': thumbnail['plfile$url'],\n            'width': int_or_none(thumbnail.get('plfile$width')),\n            'height': int_or_none(thumbnail.get('plfile$height')),\n        } for thumbnail in entry.get('media$thumbnails', [])]\n\n        timestamp = int_or_none(entry.get('media$availableDate'), scale=1000)\n        categories = [item['media$name'] for item in entry.get('media$categories', [])]\n\n        ret = self._extract_theplatform_metadata('%s/%s' % (provider_id, first_video_id), video_id)\n        subtitles = self._merge_subtitles(subtitles, ret['subtitles'])\n        ret.update({\n            'id': video_id,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'timestamp': timestamp,\n            'categories': categories,\n        })\n        if custom_fields:\n            ret.update(custom_fields(entry))\n\n        return ret",
        "begin_line": 330,
        "end_line": 387,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._real_extract#389",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformFeedIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        provider_id = mobj.group('provider_id')\n        feed_id = mobj.group('feed_id')\n        filter_query = mobj.group('filter')\n\n        return self._extract_feed_info(provider_id, feed_id, filter_query, video_id)",
        "begin_line": 389,
        "end_line": 397,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thescene.TheSceneIE._real_extract#29",
        "src_path": "youtube_dl/extractor/thescene.py",
        "class_name": "youtube_dl.extractor.thescene.TheSceneIE",
        "signature": "youtube_dl.extractor.thescene.TheSceneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        player_url = compat_urlparse.urljoin(\n            url,\n            self._html_search_regex(\n                r'id=\\'js-player-script\\'[^>]+src=\\'(.+?)\\'', webpage, 'player url'))\n\n        return {\n            '_type': 'url_transparent',\n            'display_id': display_id,\n            'url': player_url,\n            'ie_key': 'CondeNast',\n        }",
        "begin_line": 29,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE._real_extract#73",
        "src_path": "youtube_dl/extractor/thesixtyone.py",
        "class_name": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE",
        "signature": "youtube_dl.extractor.thesixtyone.TheSixtyOneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        song_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            self._SONG_URL_TEMPLATE.format(song_id), song_id)\n\n        song_data = self._parse_json(self._search_regex(\n            r'\"%s\":\\s(\\{.*?\\})' % song_id, webpage, 'song_data'), song_id)\n\n        if self._search_regex(r'(t61\\.s3_audio_load\\s*=\\s*1\\.0;)', webpage, 's3_audio_load marker', default=None):\n            song_data['audio_server'] = 's3.amazonaws.com'\n        else:\n            song_data['audio_server'] = song_data['audio_server'] + '.thesixtyone.com'\n\n        keys = [self._DECODE_MAP.get(s, s) for s in song_data['key']]\n        url = self._SONG_FILE_URL_TEMPLATE.format(\n            \"\".join(reversed(keys)), **song_data)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': 'mp3',\n        }]\n\n        return {\n            'id': song_id,\n            'title': '{artist:} - {name:}'.format(**song_data),\n            'formats': formats,\n            'comment_count': song_data.get('comments_count'),\n            'duration': song_data.get('play_time'),\n            'like_count': song_data.get('score'),\n            'thumbnail': self._THUMBNAIL_URL_TEMPLATE.format(**song_data),\n            'upload_date': unified_strdate(song_data.get('publish_date')),\n        }",
        "begin_line": 73,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thestar.TheStarIE._real_extract#28",
        "src_path": "youtube_dl/extractor/thestar.py",
        "class_name": "youtube_dl.extractor.thestar.TheStarIE",
        "signature": "youtube_dl.extractor.thestar.TheStarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        brightcove_id = self._search_regex(\n            r'mainartBrightcoveVideoId[\"\\']?\\s*:\\s*[\"\\']?(\\d+)',\n            webpage, 'brightcove id')\n        return self.url_result(\n            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,\n            'BrightcoveNew', brightcove_id)",
        "begin_line": 28,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thesun.TheSunIE._real_extract#20",
        "src_path": "youtube_dl/extractor/thesun.py",
        "class_name": "youtube_dl.extractor.thesun.TheSunIE",
        "signature": "youtube_dl.extractor.thesun.TheSunIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        article_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, article_id)\n\n        entries = []\n        for ooyala_id in re.findall(\n                r'<[^>]+\\b(?:id\\s*=\\s*\"thesun-ooyala-player-|data-content-id\\s*=\\s*\")([^\"]+)',\n                webpage):\n            entries.append(OoyalaIE._build_url_result(ooyala_id))\n\n        return self.playlist_result(\n            entries, article_id, self._og_search_title(webpage, fatal=False))",
        "begin_line": 20,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.theweatherchannel.TheWeatherChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/theweatherchannel.py",
        "class_name": "youtube_dl.extractor.theweatherchannel.TheWeatherChannelIE",
        "signature": "youtube_dl.extractor.theweatherchannel.TheWeatherChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        drupal_settings = self._parse_json(self._search_regex(\n            r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n            webpage, 'drupal settings'), display_id)\n        video_id = drupal_settings['twc']['contexts']['node']['uuid']\n        video_data = self._download_json(\n            'https://dsx.weather.com/cms/v4/asset-collection/en_US/' + video_id, video_id)\n        seo_meta = video_data.get('seometa', {})\n        title = video_data.get('title') or seo_meta['title']\n\n        urls = []\n        thumbnails = []\n        formats = []\n        for variant_id, variant_url in video_data.get('variants', []).items():\n            variant_url = variant_url.strip()\n            if not variant_url or variant_url in urls:\n                continue\n            urls.append(variant_url)\n            ext = determine_ext(variant_url)\n            if ext == 'jpg':\n                thumbnails.append({\n                    'url': variant_url,\n                    'id': variant_id,\n                })\n            elif ThePlatformIE.suitable(variant_url):\n                tp_formats, _ = self._extract_theplatform_smil(variant_url, video_id)\n                formats.extend(tp_formats)\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    variant_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=variant_id, fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    variant_url, video_id, f4m_id=variant_id, fatal=False))\n            else:\n                formats.append({\n                    'url': variant_url,\n                    'format_id': variant_id,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': video_data.get('description') or seo_meta.get('description') or seo_meta.get('og:description'),\n            'duration': parse_duration(video_data.get('duration')),\n            'uploader': video_data.get('providername'),\n            'uploader_id': video_data.get('providerid'),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE._real_extract#23",
        "src_path": "youtube_dl/extractor/thisamericanlife.py",
        "class_name": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE",
        "signature": "youtube_dl.extractor.thisamericanlife.ThisAmericanLifeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.thisamericanlife.org/radio-archives/episode/%s' % video_id, video_id)\n\n        return {\n            'id': video_id,\n            'url': 'http://stream.thisamericanlife.org/{0}/stream/{0}_64k.m3u8'.format(video_id),\n            'protocol': 'm3u8_native',\n            'ext': 'm4a',\n            'acodec': 'aac',\n            'vcodec': 'none',\n            'abr': 64,\n            'title': self._html_search_meta(r'twitter:title', webpage, 'title', fatal=True),\n            'description': self._html_search_meta(r'description', webpage, 'description'),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thisav.ThisAVIE._real_extract#36",
        "src_path": "youtube_dl/extractor/thisav.py",
        "class_name": "youtube_dl.extractor.thisav.ThisAVIE",
        "signature": "youtube_dl.extractor.thisav.ThisAVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        title = remove_end(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'),\n            ' - \u8996\u983b - ThisAV.com-\u4e16\u754c\u7b2c\u4e00\u4e2d\u6587\u6210\u4eba\u5a1b\u6a02\u7db2\u7ad9')\n        video_url = self._html_search_regex(\n            r\"addVariable\\('file','([^']+)'\\);\", webpage, 'video url', default=None)\n        if video_url:\n            info_dict = {\n                'formats': [{\n                    'url': video_url,\n                }],\n            }\n        else:\n            entries = self._parse_html5_media_entries(url, webpage, video_id)\n            if entries:\n                info_dict = entries[0]\n            else:\n                info_dict = self._extract_jwplayer_data(\n                    webpage, video_id, require_title=False)\n        uploader = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/(?:[^\"]+)\">([^<]+)</a>',\n            webpage, 'uploader name', fatal=False)\n        uploader_id = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/([^\"]+)\">(?:[^<]+)</a>',\n            webpage, 'uploader id', fatal=False)\n\n        info_dict.update({\n            'id': video_id,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'title': title,\n        })\n\n        return info_dict",
        "begin_line": 36,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.thisoldhouse.ThisOldHouseIE._real_extract#30",
        "src_path": "youtube_dl/extractor/thisoldhouse.py",
        "class_name": "youtube_dl.extractor.thisoldhouse.ThisOldHouseIE",
        "signature": "youtube_dl.extractor.thisoldhouse.ThisOldHouseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        video_id = self._search_regex(\n            (r'data-mid=([\"\\'])(?P<id>(?:(?!\\1).)+)\\1',\n             r'id=([\"\\'])inline-video-player-(?P<id>(?:(?!\\1).)+)\\1'),\n            webpage, 'video id', default=None, group='id')\n        if not video_id:\n            drupal_settings = self._parse_json(self._search_regex(\n                r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n                webpage, 'drupal settings'), display_id)\n            video_id = try_get(\n                drupal_settings, lambda x: x['jwplatform']['video_id'],\n                compat_str) or list(drupal_settings['comScore'])[0]\n        return self.url_result('jwplatform:' + video_id, 'JWPlatform', video_id)",
        "begin_line": 30,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE._extract_url#64",
        "src_path": "youtube_dl/extractor/threeqsdn.py",
        "class_name": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE",
        "signature": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+\\b(?:data-)?src=([\"\\'])(?P<url>%s.*?)\\1' % ThreeQSDNIE._VALID_URL, webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 64,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE._real_extract#70",
        "src_path": "youtube_dl/extractor/threeqsdn.py",
        "class_name": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE",
        "signature": "youtube_dl.extractor.threeqsdn.ThreeQSDNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        js = self._download_webpage(\n            'http://playout.3qsdn.com/%s' % video_id, video_id,\n            query={'js': 'true'})\n\n        if any(p in js for p in (\n                '>This content is not available in your country',\n                'playout.3qsdn.com/forbidden')):\n            self.raise_geo_restricted()\n\n        stream_content = self._search_regex(\n            r'streamContent\\s*:\\s*([\"\\'])(?P<content>.+?)\\1', js,\n            'stream content', default='demand', group='content')\n\n        live = stream_content == 'live'\n\n        stream_type = self._search_regex(\n            r'streamType\\s*:\\s*([\"\\'])(?P<type>audio|video)\\1', js,\n            'stream type', default='video', group='type')\n\n        formats = []\n        urls = set()\n\n        def extract_formats(item_url, item={}):\n            if not item_url or item_url in urls:\n                return\n            urls.add(item_url)\n            ext = mimetype2ext(item.get('type')) or determine_ext(item_url, default_ext=None)\n            if ext == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    item_url, video_id, mpd_id='mpd', fatal=False))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    item_url, video_id, 'mp4',\n                    entry_protocol='m3u8' if live else 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    item_url, video_id, f4m_id='hds', fatal=False))\n            else:\n                if not self._is_valid_url(item_url, video_id):\n                    return\n                formats.append({\n                    'url': item_url,\n                    'format_id': item.get('quality'),\n                    'ext': 'mp4' if item_url.startswith('rtsp') else ext,\n                    'vcodec': 'none' if stream_type == 'audio' else None,\n                })\n\n        for item_js in re.findall(r'({[^{]*?\\b(?:src|source)\\s*:\\s*[\"\\'].+?})', js):\n            f = self._parse_json(\n                item_js, video_id, transform_source=js_to_json, fatal=False)\n            if not f:\n                continue\n            extract_formats(f.get('src'), f)\n\n        # More relaxed version to collect additional URLs and acting\n        # as a future-proof fallback\n        for _, src in re.findall(r'\\b(?:src|source)\\s*:\\s*([\"\\'])((?:https?|rtsp)://.+?)\\1', js):\n            extract_formats(src)\n\n        self._sort_formats(formats)\n\n        title = self._live_title(video_id) if live else video_id\n\n        return {\n            'id': video_id,\n            'title': title,\n            'is_live': live,\n            'formats': formats,\n        }",
        "begin_line": 70,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract#30",
        "src_path": "youtube_dl/extractor/tinypic.py",
        "class_name": "youtube_dl.extractor.tinypic.TinyPicIE",
        "signature": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(r'(?m)fo\\.addVariable\\(\"file\",\\s\"(?P<fileid>[\\da-z]+)\"\\);\\n'\n                         r'\\s+fo\\.addVariable\\(\"s\",\\s\"(?P<serverid>\\d+)\"\\);', webpage)\n        if mobj is None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        file_id = mobj.group('fileid')\n        server_id = mobj.group('serverid')\n\n        KEYWORDS_SUFFIX = ', Video, images, photos, videos, myspace, ebay, video hosting, photo hosting'\n        keywords = self._html_search_meta('keywords', webpage, 'title')\n        title = keywords[:-len(KEYWORDS_SUFFIX)] if keywords.endswith(KEYWORDS_SUFFIX) else ''\n\n        video_url = 'http://v%s.tinypic.com/%s.flv' % (server_id, file_id)\n        thumbnail = 'http://v%s.tinypic.com/%s_th.jpg' % (server_id, file_id)\n\n        return {\n            'id': file_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title\n        }",
        "begin_line": 30,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tmz.TMZIE._real_extract#26",
        "src_path": "youtube_dl/extractor/tmz.py",
        "class_name": "youtube_dl.extractor.tmz.TMZIE",
        "signature": "youtube_dl.extractor.tmz.TMZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url).replace('-', '_')\n        return self.url_result('kaltura:591531:%s' % video_id, 'Kaltura', video_id)",
        "begin_line": 26,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tmz.TMZArticleIE._real_extract#47",
        "src_path": "youtube_dl/extractor/tmz.py",
        "class_name": "youtube_dl.extractor.tmz.TMZArticleIE",
        "signature": "youtube_dl.extractor.tmz.TMZArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        embedded_video_info = self._parse_json(self._html_search_regex(\n            r'tmzVideoEmbed\\(({.+?})\\);', webpage, 'embedded video info'),\n            video_id)\n\n        return self.url_result(\n            'http://www.tmz.com/videos/%s/' % embedded_video_info['id'])",
        "begin_line": 47,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._extract_thumbnails#32",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._extract_thumbnails(self, flix_xml)",
        "snippet": "    def _extract_thumbnails(self, flix_xml):\n\n        def get_child(elem, names):\n            for name in names:\n                child = elem.find(name)\n                if child is not None:\n                    return child\n\n        timeline = get_child(flix_xml, ['timeline', 'rolloverBarImage'])\n        if timeline is None:\n            return\n\n        pattern_el = get_child(timeline, ['imagePattern', 'pattern'])\n        if pattern_el is None or not pattern_el.text:\n            return\n\n        first_el = get_child(timeline, ['imageFirst', 'first'])\n        last_el = get_child(timeline, ['imageLast', 'last'])\n        if first_el is None or last_el is None:\n            return\n\n        first_text = first_el.text\n        last_text = last_el.text\n        if not first_text.isdigit() or not last_text.isdigit():\n            return\n\n        first = int(first_text)\n        last = int(last_text)\n        if first > last:\n            return\n\n        width = int_or_none(xpath_text(timeline, './imageWidth', 'thumbnail width'))\n        height = int_or_none(xpath_text(timeline, './imageHeight', 'thumbnail height'))\n\n        return [{\n            'url': self._proto_relative_url(pattern_el.text.replace('#', compat_str(i)), 'http:'),\n            'width': width,\n            'height': height,\n        } for i in range(first, last + 1)]",
        "begin_line": 32,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._real_extract#72",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixNetworkBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') if 'display_id' in mobj.groupdict() else video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        cfg_url = self._proto_relative_url(self._html_search_regex(\n            self._CONFIG_REGEX, webpage, 'flashvars.config', default=None), 'http:')\n\n        if not cfg_url:\n            inputs = self._hidden_inputs(webpage)\n            cfg_url = ('https://cdn-fck.tnaflix.com/tnaflix/%s.fid?key=%s&VID=%s&premium=1&vip=1&alpha'\n                       % (inputs['vkey'], inputs['nkey'], video_id))\n\n        cfg_xml = self._download_xml(\n            cfg_url, display_id, 'Downloading metadata',\n            transform_source=fix_xml_ampersands)\n\n        formats = []\n\n        def extract_video_url(vl):\n            return re.sub(r'speed=\\d+', 'speed=', unescapeHTML(vl.text))\n\n        video_link = cfg_xml.find('./videoLink')\n        if video_link is not None:\n            formats.append({\n                'url': extract_video_url(video_link),\n                'ext': xpath_text(cfg_xml, './videoConfig/type', 'type', default='flv'),\n            })\n\n        for item in cfg_xml.findall('./quality/item'):\n            video_link = item.find('./videoLink')\n            if video_link is None:\n                continue\n            res = item.find('res')\n            format_id = None if res is None else res.text\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]', format_id, 'height', default=None))\n            formats.append({\n                'url': self._proto_relative_url(extract_video_url(video_link), 'http:'),\n                'format_id': format_id,\n                'height': height,\n            })\n\n        self._sort_formats(formats)\n\n        thumbnail = self._proto_relative_url(\n            xpath_text(cfg_xml, './startThumb', 'thumbnail'), 'http:')\n        thumbnails = self._extract_thumbnails(cfg_xml)\n\n        title = None\n        if self._TITLE_REGEX:\n            title = self._html_search_regex(\n                self._TITLE_REGEX, webpage, 'title', default=None)\n        if not title:\n            title = self._og_search_title(webpage)\n\n        age_limit = self._rta_search(webpage) or 18\n\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration', default=None))\n\n        def extract_field(pattern, name):\n            return self._html_search_regex(pattern, webpage, name, default=None) if pattern else None\n\n        description = extract_field(self._DESCRIPTION_REGEX, 'description')\n        uploader = extract_field(self._UPLOADER_REGEX, 'uploader')\n        view_count = str_to_int(extract_field(self._VIEW_COUNT_REGEX, 'view count'))\n        comment_count = str_to_int(extract_field(self._COMMENT_COUNT_REGEX, 'comment count'))\n        average_rating = float_or_none(extract_field(self._AVERAGE_RATING_REGEX, 'average rating'))\n\n        categories_str = extract_field(self._CATEGORIES_REGEX, 'categories')\n        categories = [c.strip() for c in categories_str.split(',')] if categories_str is not None else []\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'age_limit': age_limit,\n            'uploader': uploader,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'average_rating': average_rating,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 72,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkEmbedIE._extract_urls#189",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixNetworkEmbedIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixNetworkEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.(?:tna|emp)flix\\.com/video/\\d+)\\1',\n            webpage)]",
        "begin_line": 189,
        "end_line": 192,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toggle.ToggleIE._real_extract#93",
        "src_path": "youtube_dl/extractor/toggle.py",
        "class_name": "youtube_dl.extractor.toggle.ToggleIE",
        "signature": "youtube_dl.extractor.toggle.ToggleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            url, video_id, note='Downloading video page')\n\n        api_user = self._search_regex(\n            r'apiUser\\s*:\\s*([\"\\'])(?P<user>.+?)\\1', webpage, 'apiUser',\n            default=self._API_USER, group='user')\n        api_pass = self._search_regex(\n            r'apiPass\\s*:\\s*([\"\\'])(?P<pass>.+?)\\1', webpage, 'apiPass',\n            default=self._API_PASS, group='pass')\n\n        params = {\n            'initObj': {\n                'Locale': {\n                    'LocaleLanguage': '',\n                    'LocaleCountry': '',\n                    'LocaleDevice': '',\n                    'LocaleUserState': 0\n                },\n                'Platform': 0,\n                'SiteGuid': 0,\n                'DomainID': '0',\n                'UDID': '',\n                'ApiUser': api_user,\n                'ApiPass': api_pass\n            },\n            'MediaID': video_id,\n            'mediaType': 0,\n        }\n\n        req = sanitized_Request(\n            'http://tvpapi.as.tvinci.com/v2_9/gateways/jsonpostgw.aspx?m=GetMediaInfo',\n            json.dumps(params).encode('utf-8'))\n        info = self._download_json(req, video_id, 'Downloading video info json')\n\n        title = info['MediaName']\n\n        formats = []\n        for video_file in info.get('Files', []):\n            video_url, vid_format = video_file.get('URL'), video_file.get('Format')\n            if not video_url or not vid_format:\n                continue\n            ext = determine_ext(video_url)\n            vid_format = vid_format.replace(' ', '')\n            # if geo-restricted, m3u8 is inaccessible, but mp4 is okay\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, ext='mp4', m3u8_id=vid_format,\n                    note='Downloading %s m3u8 information' % vid_format,\n                    errnote='Failed to download %s m3u8 information' % vid_format,\n                    fatal=False))\n            elif ext in ('mp4', 'wvm'):\n                # wvm are drm-protected files\n                formats.append({\n                    'ext': ext,\n                    'url': video_url,\n                    'format_id': vid_format,\n                    'preference': self._FORMAT_PREFERENCES.get(ext + '-' + vid_format) or -1,\n                    'format_note': 'DRM-protected video' if ext == 'wvm' else None\n                })\n        if not formats:\n            # Most likely because geo-blocked\n            raise ExtractorError('No downloadable videos found', expected=True)\n        self._sort_formats(formats)\n\n        duration = int_or_none(info.get('Duration'))\n        description = info.get('Description')\n        created_at = parse_iso8601(info.get('CreationDate') or None)\n\n        average_rating = float_or_none(info.get('Rating'))\n        view_count = int_or_none(info.get('ViewCounter') or info.get('view_counter'))\n        like_count = int_or_none(info.get('LikeCounter') or info.get('like_counter'))\n\n        thumbnails = []\n        for picture in info.get('Pictures', []):\n            if not isinstance(picture, dict):\n                continue\n            pic_url = picture.get('URL')\n            if not pic_url:\n                continue\n            thumbnail = {\n                'url': pic_url,\n            }\n            pic_size = picture.get('PicSize', '')\n            m = re.search(r'(?P<width>\\d+)[xX](?P<height>\\d+)', pic_size)\n            if m:\n                thumbnail.update({\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n            thumbnails.append(thumbnail)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': created_at,\n            'average_rating': average_rating,\n            'view_count': view_count,\n            'like_count': like_count,\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 93,
        "end_line": 198,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tonline.TOnlineIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tonline.py",
        "class_name": "youtube_dl.extractor.tonline.TOnlineIE",
        "signature": "youtube_dl.extractor.tonline.TOnlineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'http://www.t-online.de/tv/id_%s/tid_json_video' % video_id, video_id)\n        title = video_data['subtitle']\n\n        formats = []\n        for asset in video_data.get('assets', []):\n            asset_source = asset.get('source') or asset.get('source2')\n            if not asset_source:\n                continue\n            formats_id = []\n            for field_key in ('type', 'profile'):\n                field_value = asset.get(field_key)\n                if field_value:\n                    formats_id.append(field_value)\n            formats.append({\n                'format_id': '-'.join(formats_id),\n                'url': asset_source,\n            })\n\n        thumbnails = []\n        for image in video_data.get('images', []):\n            image_source = image.get('source')\n            if not image_source:\n                continue\n            thumbnails.append({\n                'url': image_source,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'duration': int_or_none(video_data.get('duration')),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 22,
        "end_line": 59,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toongoggles.ToonGogglesIE._call_api#36",
        "src_path": "youtube_dl/extractor/toongoggles.py",
        "class_name": "youtube_dl.extractor.toongoggles.ToonGogglesIE",
        "signature": "youtube_dl.extractor.toongoggles.ToonGogglesIE._call_api(self, action, page_id, query)",
        "snippet": "    def _call_api(self, action, page_id, query):\n        query.update({\n            'for_ng': 1,\n            'for_web': 1,\n            'show_meta': 1,\n            'version': 7.0,\n        })\n        return self._download_json('http://api.toongoggles.com/' + action, page_id, query=query)",
        "begin_line": 36,
        "end_line": 43,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toongoggles.ToonGogglesIE._parse_episode_data#45",
        "src_path": "youtube_dl/extractor/toongoggles.py",
        "class_name": "youtube_dl.extractor.toongoggles.ToonGogglesIE",
        "signature": "youtube_dl.extractor.toongoggles.ToonGogglesIE._parse_episode_data(self, episode_data)",
        "snippet": "    def _parse_episode_data(self, episode_data):\n        title = episode_data['episode_name']\n\n        return {\n            '_type': 'url_transparent',\n            'id': episode_data['episode_id'],\n            'title': title,\n            'url': 'kaltura:513551:' + episode_data['entry_id'],\n            'thumbnail': episode_data.get('thumbnail_url'),\n            'description': episode_data.get('description'),\n            'duration': parse_duration(episode_data.get('hms')),\n            'series': episode_data.get('show_name'),\n            'season_number': int_or_none(episode_data.get('season_num')),\n            'episode_id': episode_data.get('episode_id'),\n            'episode': title,\n            'episode_number': int_or_none(episode_data.get('episode_num')),\n            'categories': episode_data.get('categories'),\n            'ie_key': 'Kaltura',\n        }",
        "begin_line": 45,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toongoggles.ToonGogglesIE._real_extract#65",
        "src_path": "youtube_dl/extractor/toongoggles.py",
        "class_name": "youtube_dl.extractor.toongoggles.ToonGogglesIE",
        "signature": "youtube_dl.extractor.toongoggles.ToonGogglesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id, episode_id = re.match(self._VALID_URL, url).groups()\n        if episode_id:\n            episode_data = self._call_api('search', episode_id, {\n                'filter': 'episode',\n                'id': episode_id,\n            })['objects'][0]\n            return self._parse_episode_data(episode_data)\n        else:\n            show_data = self._call_api('getepisodesbyshow', show_id, {\n                'max': 1000000000,\n                'showid': show_id,\n            })\n            entries = []\n            for episode_data in show_data.get('objects', []):\n                entries.append(self._parse_episode_data(episode_data))\n            return self.playlist_result(entries, show_id, show_data.get('show_name'))",
        "begin_line": 65,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toutv.TouTvIE._real_initialize#41",
        "src_path": "youtube_dl/extractor/toutv.py",
        "class_name": "youtube_dl.extractor.toutv.TouTvIE",
        "signature": "youtube_dl.extractor.toutv.TouTvIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        email, password = self._get_login_info()\n        if email is None:\n            return\n        state = 'http://ici.tou.tv//'\n        webpage = self._download_webpage(state, None, 'Downloading homepage')\n        toutvlogin = self._parse_json(self._search_regex(\n            r'(?s)toutvlogin\\s*=\\s*({.+?});', webpage, 'toutvlogin'), None, js_to_json)\n        authorize_url = toutvlogin['host'] + '/auth/oauth/v2/authorize'\n        login_webpage = self._download_webpage(\n            authorize_url, None, 'Downloading login page', query={\n                'client_id': toutvlogin['clientId'],\n                'redirect_uri': 'https://ici.tou.tv/login/loginCallback',\n                'response_type': 'token',\n                'scope': 'media-drmt openid profile email id.write media-validation.read.privileged',\n                'state': state,\n            })\n        login_form = self._search_regex(\n            r'(?s)(<form[^>]+(?:id|name)=\"Form-login\".+?</form>)', login_webpage, 'login form')\n        form_data = self._hidden_inputs(login_form)\n        form_data.update({\n            'login-email': email,\n            'login-password': password,\n        })\n        post_url = extract_attributes(login_form).get('action') or authorize_url\n        _, urlh = self._download_webpage_handle(\n            post_url, None, 'Logging in', data=urlencode_postdata(form_data))\n        self._access_token = self._search_regex(\n            r'access_token=([\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})',\n            urlh.geturl(), 'access token')\n        self._claims = self._download_json(\n            'https://services.radio-canada.ca/media/validation/v2/getClaims',\n            None, 'Extracting Claims', query={\n                'token': self._access_token,\n                'access_token': self._access_token,\n            })['claims']",
        "begin_line": 41,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toutv.TouTvIE._real_extract#78",
        "src_path": "youtube_dl/extractor/toutv.py",
        "class_name": "youtube_dl.extractor.toutv.TouTvIE",
        "signature": "youtube_dl.extractor.toutv.TouTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path = self._match_id(url)\n        metadata = self._download_json('http://ici.tou.tv/presentation/%s' % path, path)\n        if metadata.get('IsDrm'):\n            raise ExtractorError('This video is DRM protected.', expected=True)\n        video_id = metadata['IdMedia']\n        details = metadata['Details']\n        title = details['OriginalTitle']\n        video_url = 'radiocanada:%s:%s' % (metadata.get('AppCode', 'toutv'), video_id)\n        if self._access_token and self._claims:\n            video_url = smuggle_url(video_url, {\n                'access_token': self._access_token,\n                'claims': self._claims,\n            })\n\n        return {\n            '_type': 'url_transparent',\n            'url': video_url,\n            'id': video_id,\n            'title': title,\n            'thumbnail': details.get('ImageUrl'),\n            'duration': int_or_none(details.get('LengthInSeconds')),\n        }",
        "begin_line": 78,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsIE._real_extract#23",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        formats = self._parse_html5_media_entries(\n            url, webpage, video_id)[0]['formats']\n        title = self._html_search_regex([\n            r'<h1[^>]+class=[\"\\']view-video-title[^>]+>([^<]+)</h',\n            r'<title>([^<]+) - Toypics</title>',\n        ], webpage, 'title')\n\n        uploader = self._html_search_regex(\n            r'More videos from <strong>([^<]+)</strong>', webpage, 'uploader',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'uploader': uploader,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract#59",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsUserIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        username = self._match_id(url)\n\n        profile_page = self._download_webpage(\n            url, username, note='Retrieving profile page')\n\n        video_count = int(self._search_regex(\n            r'public/\">Public Videos \\(([0-9]+)\\)</a></li>', profile_page,\n            'video count'))\n\n        PAGE_SIZE = 8\n        urls = []\n        page_count = (video_count + PAGE_SIZE + 1) // PAGE_SIZE\n        for n in range(1, page_count + 1):\n            lpage_url = url + '/public/%d' % n\n            lpage = self._download_webpage(\n                lpage_url, username,\n                note='Downloading page %d/%d' % (n, page_count))\n            urls.extend(\n                re.findall(\n                    r'<div[^>]+class=[\"\\']preview[^>]+>\\s*<a[^>]+href=\"(https?://videos\\.toypics\\.net/view/[^\"]+)\"',\n                    lpage))\n\n        return {\n            '_type': 'playlist',\n            'id': username,\n            'entries': [{\n                '_type': 'url',\n                'url': eurl,\n                'ie_key': 'Toypics',\n            } for eurl in urls]\n        }",
        "begin_line": 59,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract#22",
        "src_path": "youtube_dl/extractor/traileraddict.py",
        "class_name": "youtube_dl.extractor.traileraddict.TrailerAddictIE",
        "signature": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('movie') + '/' + mobj.group('trailer_name')\n        webpage = self._download_webpage(url, name)\n\n        title = self._search_regex(r'<title>(.+?)</title>',\n                                   webpage, 'video title').replace(' - Trailer Addict', '')\n        view_count_str = self._search_regex(\n            r'<span class=\"views_n\">([0-9,.]+)</span>',\n            webpage, 'view count', fatal=False)\n        view_count = (\n            None if view_count_str is None\n            else int(view_count_str.replace(',', '')))\n        video_id = self._search_regex(\n            r'<param\\s+name=\"movie\"\\s+value=\"/emb/([0-9]+)\"\\s*/>',\n            webpage, 'video id')\n\n        # Presence of (no)watchplus function indicates HD quality is available\n        if re.search(r'function (no)?watchplus()', webpage):\n            fvar = 'fvarhd'\n        else:\n            fvar = 'fvar'\n\n        info_url = 'http://www.traileraddict.com/%s.php?tid=%s' % (fvar, str(video_id))\n        info_webpage = self._download_webpage(info_url, video_id, 'Downloading the info webpage')\n\n        final_url = self._search_regex(r'&fileurl=(.+)',\n                                       info_webpage, 'Download url').replace('%3F', '?')\n        thumbnail_url = self._search_regex(r'&image=(.+?)&',\n                                           info_webpage, 'thumbnail url')\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"synopsis\">.*?<div class=\"movie_label_info\"[^>]*>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n            'view_count': view_count,\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract#48",
        "src_path": "youtube_dl/extractor/trilulilu.py",
        "class_name": "youtube_dl.extractor.trilulilu.TriluliluIE",
        "signature": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        media_info = self._download_json('http://m.trilulilu.ro/%s?format=json' % display_id, display_id)\n\n        age_limit = 0\n        errors = media_info.get('errors', {})\n        if errors.get('friends'):\n            raise ExtractorError('This video is private.', expected=True)\n        elif errors.get('geoblock'):\n            raise ExtractorError('This video is not available in your country.', expected=True)\n        elif errors.get('xxx_unlogged'):\n            age_limit = 18\n\n        media_class = media_info.get('class')\n        if media_class not in ('video', 'audio'):\n            raise ExtractorError('not a video or an audio')\n\n        user = media_info.get('user', {})\n\n        thumbnail = media_info.get('cover_url')\n        if thumbnail:\n            thumbnail.format(width='1600', height='1200')\n\n        # TODO: get correct ext for audio files\n        stream_type = media_info.get('stream_type')\n        formats = [{\n            'url': media_info['href'],\n            'ext': stream_type,\n        }]\n        if media_info.get('is_hd'):\n            formats.append({\n                'format_id': 'hd',\n                'url': media_info['hrefhd'],\n                'ext': stream_type,\n            })\n        if media_class == 'audio':\n            formats[0]['vcodec'] = 'none'\n        else:\n            formats[0]['format_id'] = 'sd'\n\n        return {\n            'id': media_info['identifier'].split('|')[1],\n            'display_id': display_id,\n            'formats': formats,\n            'title': media_info['title'],\n            'description': media_info.get('description'),\n            'thumbnail': thumbnail,\n            'uploader_id': user.get('username'),\n            'uploader': user.get('fullname'),\n            'timestamp': parse_iso8601(media_info.get('published'), ' '),\n            'duration': int_or_none(media_info.get('duration')),\n            'view_count': int_or_none(media_info.get('count_views')),\n            'like_count': int_or_none(media_info.get('count_likes')),\n            'comment_count': int_or_none(media_info.get('count_comments')),\n            'age_limit': age_limit,\n        }",
        "begin_line": 48,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.trutv.TruTVIE._real_extract#23",
        "src_path": "youtube_dl/extractor/trutv.py",
        "class_name": "youtube_dl.extractor.trutv.TruTVIE",
        "signature": "youtube_dl.extractor.trutv.TruTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path, video_id = re.match(self._VALID_URL, url).groups()\n        auth_required = False\n        if path:\n            data_src = 'http://www.trutv.com/video/cvp/v2/xml/content.xml?id=%s.xml' % path\n        else:\n            webpage = self._download_webpage(url, video_id)\n            video_id = self._search_regex(\n                r\"TTV\\.TVE\\.episodeId\\s*=\\s*'([^']+)';\",\n                webpage, 'video id', default=video_id)\n            auth_required = self._search_regex(\n                r'TTV\\.TVE\\.authRequired\\s*=\\s*(true|false);',\n                webpage, 'auth required', default='false') == 'true'\n            data_src = 'http://www.trutv.com/tveverywhere/services/cvpXML.do?titleId=' + video_id\n        return self._extract_cvp_info(\n            data_src, path, {\n                'secure': {\n                    'media_src': 'http://androidhls-secure.cdn.turner.com/trutv/big',\n                    'tokenizer_src': 'http://www.trutv.com/tveverywhere/processors/services/token_ipadAdobe.do',\n                },\n            }, {\n                'url': url,\n                'site_name': 'truTV',\n                'auth_required': auth_required,\n            })",
        "begin_line": 23,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tube8.Tube8IE._real_extract#34",
        "src_path": "youtube_dl/extractor/tube8.py",
        "class_name": "youtube_dl.extractor.tube8.Tube8IE",
        "signature": "youtube_dl.extractor.tube8.Tube8IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage, info = self._extract_info(url)\n\n        if not info['title']:\n            info['title'] = self._html_search_regex(\n                r'videoTitle\\s*=\\s*\"([^\"]+)', webpage, 'title')\n\n        description = self._html_search_regex(\n            r'>Description:</strong>\\s*(.+?)\\s*<', webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<span class=\"username\">\\s*(.+?)\\s*<',\n            webpage, 'uploader', fatal=False)\n\n        like_count = int_or_none(self._search_regex(\n            r'rupVar\\s*=\\s*\"(\\d+)\"', webpage, 'like count', fatal=False))\n        dislike_count = int_or_none(self._search_regex(\n            r'rdownVar\\s*=\\s*\"(\\d+)\"', webpage, 'dislike count', fatal=False))\n        view_count = str_to_int(self._search_regex(\n            r'<strong>Views: </strong>([\\d,\\.]+)\\s*</li>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._search_regex(\n            r'<span id=\"allCommentsCount\">(\\d+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        category = self._search_regex(\n            r'Category:\\s*</strong>\\s*<a[^>]+href=[^>]+>([^<]+)',\n            webpage, 'category', fatal=False)\n        categories = [category] if category else None\n\n        tags_str = self._search_regex(\n            r'(?s)Tags:\\s*</strong>(.+?)</(?!a)',\n            webpage, 'tags', fatal=False)\n        tags = [t for t in re.findall(\n            r'<a[^>]+href=[^>]+>([^<]+)', tags_str)] if tags_str else None\n\n        info.update({\n            'description': description,\n            'uploader': uploader,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'tags': tags,\n        })\n\n        return info",
        "begin_line": 34,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._login#32",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        form_data = {\n            'username': username,\n            'password': password,\n        }\n        payload = urlencode_postdata(form_data)\n        request = sanitized_Request(self._LOGIN_URL, payload)\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_page = self._download_webpage(\n            request, None, False, 'Wrong login info')\n        if not re.search(r'id=\"tubi-logout\"', login_page):\n            raise ExtractorError(\n                'Login failed (invalid username/password)', expected=True)",
        "begin_line": 32,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._real_initialize#50",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tubitv.TubiTvIE._real_extract#53",
        "src_path": "youtube_dl/extractor/tubitv.py",
        "class_name": "youtube_dl.extractor.tubitv.TubiTvIE",
        "signature": "youtube_dl.extractor.tubitv.TubiTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'http://tubitv.com/oz/videos/%s/content' % video_id, video_id)\n        title = video_data['title']\n\n        formats = self._extract_m3u8_formats(\n            self._proto_relative_url(video_data['url']),\n            video_id, 'mp4', 'm3u8_native')\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for thumbnail_url in video_data.get('thumbnails', []):\n            if not thumbnail_url:\n                continue\n            thumbnails.append({\n                'url': self._proto_relative_url(thumbnail_url),\n            })\n\n        subtitles = {}\n        for sub in video_data.get('subtitles', []):\n            sub_url = sub.get('url')\n            if not sub_url:\n                continue\n            subtitles.setdefault(sub.get('lang', 'English'), []).append({\n                'url': self._proto_relative_url(sub_url),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'description': video_data.get('description'),\n            'duration': int_or_none(video_data.get('duration')),\n            'uploader_id': video_data.get('publisher_id'),\n        }",
        "begin_line": 53,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tumblr.TumblrIE._real_extract#100",
        "src_path": "youtube_dl/extractor/tumblr.py",
        "class_name": "youtube_dl.extractor.tumblr.TumblrIE",
        "signature": "youtube_dl.extractor.tumblr.TumblrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m_url = re.match(self._VALID_URL, url)\n        video_id = m_url.group('id')\n        blog = m_url.group('blog_name')\n\n        url = 'http://%s.tumblr.com/post/%s/' % (blog, video_id)\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n\n        iframe_url = self._search_regex(\n            r'src=\\'(https?://www\\.tumblr\\.com/video/[^\\']+)\\'',\n            webpage, 'iframe url', default=None)\n        if iframe_url is None:\n            return self.url_result(urlh.geturl(), 'Generic')\n\n        iframe = self._download_webpage(iframe_url, video_id, 'Downloading iframe page')\n\n        duration = None\n        sources = []\n\n        sd_url = self._search_regex(\n            r'<source[^>]+src=([\"\\'])(?P<url>.+?)\\1', iframe,\n            'sd video url', default=None, group='url')\n        if sd_url:\n            sources.append((sd_url, 'sd'))\n\n        options = self._parse_json(\n            self._search_regex(\n                r'data-crt-options=([\"\\'])(?P<options>.+?)\\1', iframe,\n                'hd video url', default='', group='options'),\n            video_id, fatal=False)\n        if options:\n            duration = int_or_none(options.get('duration'))\n            hd_url = options.get('hdUrl')\n            if hd_url:\n                sources.append((hd_url, 'hd'))\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': format_id,\n            'height': int_or_none(self._search_regex(\n                r'/(\\d{3,4})$', video_url, 'height', default=None)),\n            'quality': quality,\n        } for quality, (video_url, format_id) in enumerate(sources)]\n\n        self._sort_formats(formats)\n\n        # The only place where you can get a title, it's not complete,\n        # but searching in other places doesn't work for all videos\n        video_title = self._html_search_regex(\n            r'(?s)<title>(?P<title>.*?)(?: \\| Tumblr)?</title>',\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 100,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tunein.TuneInBaseIE._extract_urls#15",
        "src_path": "youtube_dl/extractor/tunein.py",
        "class_name": "youtube_dl.extractor.tunein.TuneInBaseIE",
        "signature": "youtube_dl.extractor.tunein.TuneInBaseIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=[\"\\'](?P<url>(?:https?://)?tunein\\.com/embed/player/[pst]\\d+)',\n            webpage)",
        "begin_line": 15,
        "end_line": 18,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tunein.TuneInBaseIE._real_extract#20",
        "src_path": "youtube_dl/extractor/tunein.py",
        "class_name": "youtube_dl.extractor.tunein.TuneInBaseIE",
        "signature": "youtube_dl.extractor.tunein.TuneInBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        content_id = self._match_id(url)\n\n        content_info = self._download_json(\n            self._API_BASE_URL + self._API_URL_QUERY % content_id,\n            content_id, note='Downloading JSON metadata')\n\n        title = content_info['Title']\n        thumbnail = content_info.get('Logo')\n        location = content_info.get('Location')\n        streams_url = content_info.get('StreamUrl')\n        if not streams_url:\n            raise ExtractorError('No downloadable streams found', expected=True)\n        if not streams_url.startswith('http://'):\n            streams_url = compat_urlparse.urljoin(url, streams_url)\n\n        streams = self._download_json(\n            streams_url, content_id, note='Downloading stream data',\n            transform_source=lambda s: re.sub(r'^\\s*\\((.*)\\);\\s*$', r'\\1', s))['Streams']\n\n        is_live = None\n        formats = []\n        for stream in streams:\n            if stream.get('Type') == 'Live':\n                is_live = True\n            reliability = stream.get('Reliability')\n            format_note = (\n                'Reliability: %d%%' % reliability\n                if reliability is not None else None)\n            formats.append({\n                'preference': (\n                    0 if reliability is None or reliability > 90\n                    else 1),\n                'abr': stream.get('Bandwidth'),\n                'ext': stream.get('MediaType').lower(),\n                'acodec': stream.get('MediaType'),\n                'vcodec': 'none',\n                'url': stream.get('Url'),\n                'source_preference': reliability,\n                'format_note': format_note,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': content_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'location': location,\n            'is_live': is_live,\n        }",
        "begin_line": 20,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tunein.TuneInStationIE.suitable#95",
        "src_path": "youtube_dl/extractor/tunein.py",
        "class_name": "youtube_dl.extractor.tunein.TuneInStationIE",
        "signature": "youtube_dl.extractor.tunein.TuneInStationIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if TuneInClipIE.suitable(url) else super(TuneInStationIE, cls).suitable(url)",
        "begin_line": 95,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tunein.TuneInShortenerIE._real_extract#176",
        "src_path": "youtube_dl/extractor/tunein.py",
        "class_name": "youtube_dl.extractor.tunein.TuneInShortenerIE",
        "signature": "youtube_dl.extractor.tunein.TuneInShortenerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        redirect_id = self._match_id(url)\n        # The server doesn't support HEAD requests\n        urlh = self._request_webpage(\n            url, redirect_id, note='Downloading redirect page')\n        url = urlh.geturl()\n        self.to_screen('Following redirect: %s' % url)\n        return self.url_result(url)",
        "begin_line": 176,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tunepk.TunePkIE._real_extract#44",
        "src_path": "youtube_dl/extractor/tunepk.py",
        "class_name": "youtube_dl.extractor.tunepk.TunePkIE",
        "signature": "youtube_dl.extractor.tunepk.TunePkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://tune.pk/video/%s' % video_id, video_id)\n\n        details = self._parse_json(\n            self._search_regex(\n                r'new\\s+TunePlayer\\(({.+?})\\)\\s*;\\s*\\n', webpage, 'tune player'),\n            video_id)['details']\n\n        video = details['video']\n        title = video.get('title') or self._og_search_title(\n            webpage, default=None) or self._html_search_meta(\n            'title', webpage, 'title', fatal=True)\n\n        formats = self._parse_jwplayer_formats(\n            details['player']['sources'], video_id)\n        self._sort_formats(formats)\n\n        description = self._og_search_description(\n            webpage, default=None) or self._html_search_meta(\n            'description', webpage, 'description')\n\n        thumbnail = video.get('thumb') or self._og_search_thumbnail(\n            webpage, default=None) or self._html_search_meta(\n            'thumbnail', webpage, 'thumbnail')\n\n        timestamp = unified_timestamp(video.get('date_added'))\n        uploader = try_get(\n            video, lambda x: x['uploader']['name'],\n            compat_str) or self._html_search_meta('author', webpage, 'author')\n\n        duration = int_or_none(video.get('duration'))\n        view_count = int_or_none(video.get('views'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 44,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.turbo.TurboIE._real_extract#32",
        "src_path": "youtube_dl/extractor/turbo.py",
        "class_name": "youtube_dl.extractor.turbo.TurboIE",
        "signature": "youtube_dl.extractor.turbo.TurboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        playlist = self._download_xml(self._API_URL.format(video_id), video_id)\n        item = playlist.find('./channel/item')\n        if item is None:\n            raise ExtractorError('Playlist item was not found', expected=True)\n\n        title = xpath_text(item, './title', 'title')\n        duration = int_or_none(xpath_text(item, './durate', 'duration'))\n        thumbnail = xpath_text(item, './visuel_clip', 'thumbnail')\n        description = self._html_search_meta('description', webpage)\n\n        formats = []\n        get_quality = qualities(['3g', 'sd', 'hq'])\n        for child in item:\n            m = re.search(r'url_video_(?P<quality>.+)', child.tag)\n            if m:\n                quality = compat_str(m.group('quality'))\n                formats.append({\n                    'format_id': quality,\n                    'url': child.text,\n                    'quality': get_quality(quality),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'description': description,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.turner.TurnerBaseIE._extract_timestamp#21",
        "src_path": "youtube_dl/extractor/turner.py",
        "class_name": "youtube_dl.extractor.turner.TurnerBaseIE",
        "signature": "youtube_dl.extractor.turner.TurnerBaseIE._extract_timestamp(self, video_data)",
        "snippet": "    def _extract_timestamp(self, video_data):\n        return int_or_none(xpath_attr(video_data, 'dateCreated', 'uts'))",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.turner.TurnerBaseIE._extract_cvp_info#24",
        "src_path": "youtube_dl/extractor/turner.py",
        "class_name": "youtube_dl.extractor.turner.TurnerBaseIE",
        "signature": "youtube_dl.extractor.turner.TurnerBaseIE._extract_cvp_info(self, data_src, video_id, path_data={}, ap_data={})",
        "snippet": "    def _extract_cvp_info(self, data_src, video_id, path_data={}, ap_data={}):\n        video_data = self._download_xml(data_src, video_id)\n        video_id = video_data.attrib['id']\n        title = xpath_text(video_data, 'headline', fatal=True)\n        content_id = xpath_text(video_data, 'contentId') or video_id\n        # rtmp_src = xpath_text(video_data, 'akamai/src')\n        # if rtmp_src:\n        #     splited_rtmp_src = rtmp_src.split(',')\n        #     if len(splited_rtmp_src) == 2:\n        #         rtmp_src = splited_rtmp_src[1]\n        # aifp = xpath_text(video_data, 'akamai/aifp', default='')\n\n        tokens = {}\n        urls = []\n        formats = []\n        rex = re.compile(\n            r'(?P<width>[0-9]+)x(?P<height>[0-9]+)(?:_(?P<bitrate>[0-9]+))?')\n        # Possible formats locations: files/file, files/groupFiles/files\n        # and maybe others\n        for video_file in video_data.findall('.//file'):\n            video_url = video_file.text.strip()\n            if not video_url:\n                continue\n            ext = determine_ext(video_url)\n            if video_url.startswith('/mp4:protected/'):\n                continue\n                # TODO Correct extraction for these files\n                # protected_path_data = path_data.get('protected')\n                # if not protected_path_data or not rtmp_src:\n                #     continue\n                # protected_path = self._search_regex(\n                #     r'/mp4:(.+)\\.[a-z0-9]', video_url, 'secure path')\n                # auth = self._download_webpage(\n                #     protected_path_data['tokenizer_src'], query={\n                #         'path': protected_path,\n                #         'videoId': content_id,\n                #         'aifp': aifp,\n                #     })\n                # token = xpath_text(auth, 'token')\n                # if not token:\n                #     continue\n                # video_url = rtmp_src + video_url + '?' + token\n            elif video_url.startswith('/secure/'):\n                secure_path_data = path_data.get('secure')\n                if not secure_path_data:\n                    continue\n                video_url = secure_path_data['media_src'] + video_url\n                secure_path = self._search_regex(r'https?://[^/]+(.+/)', video_url, 'secure path') + '*'\n                token = tokens.get(secure_path)\n                if not token:\n                    query = {\n                        'path': secure_path,\n                        'videoId': content_id,\n                    }\n                    if ap_data.get('auth_required'):\n                        query['accessToken'] = self._extract_mvpd_auth(ap_data['url'], video_id, ap_data['site_name'], ap_data['site_name'])\n                    auth = self._download_xml(\n                        secure_path_data['tokenizer_src'], video_id, query=query)\n                    error_msg = xpath_text(auth, 'error/msg')\n                    if error_msg:\n                        raise ExtractorError(error_msg, expected=True)\n                    token = xpath_text(auth, 'token')\n                    if not token:\n                        continue\n                    tokens[secure_path] = token\n                video_url = video_url + '?hdnea=' + token\n            elif not re.match('https?://', video_url):\n                base_path_data = path_data.get(ext, path_data.get('default', {}))\n                media_src = base_path_data.get('media_src')\n                if not media_src:\n                    continue\n                video_url = media_src + video_url\n            if video_url in urls:\n                continue\n            urls.append(video_url)\n            format_id = video_file.get('bitrate')\n            if ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    video_url, video_id, fatal=False))\n            elif ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4',\n                    m3u8_id=format_id or 'hls', fatal=False)\n                if '/secure/' in video_url and '?hdnea=' in video_url:\n                    for f in m3u8_formats:\n                        f['_seekable'] = False\n                formats.extend(m3u8_formats)\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    update_url_query(video_url, {'hdcore': '3.7.0'}),\n                    video_id, f4m_id=format_id or 'hds', fatal=False))\n            else:\n                f = {\n                    'format_id': format_id,\n                    'url': video_url,\n                    'ext': ext,\n                }\n                mobj = rex.search(format_id + video_url)\n                if mobj:\n                    f.update({\n                        'width': int(mobj.group('width')),\n                        'height': int(mobj.group('height')),\n                        'tbr': int_or_none(mobj.group('bitrate')),\n                    })\n                elif isinstance(format_id, compat_str):\n                    if format_id.isdigit():\n                        f['tbr'] = int(format_id)\n                    else:\n                        mobj = re.match(r'ios_(audio|[0-9]+)$', format_id)\n                        if mobj:\n                            if mobj.group(1) == 'audio':\n                                f.update({\n                                    'vcodec': 'none',\n                                    'ext': 'm4a',\n                                })\n                            else:\n                                f['tbr'] = int(mobj.group(1))\n                formats.append(f)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for source in video_data.findall('closedCaptions/source'):\n            for track in source.findall('track'):\n                track_url = track.get('url')\n                if not isinstance(track_url, compat_str) or track_url.endswith('/big'):\n                    continue\n                lang = track.get('lang') or track.get('label') or 'en'\n                subtitles.setdefault(lang, []).append({\n                    'url': track_url,\n                    'ext': {\n                        'scc': 'scc',\n                        'webvtt': 'vtt',\n                        'smptett': 'tt',\n                    }.get(source.get('format'))\n                })\n\n        thumbnails = [{\n            'id': image.get('cut'),\n            'url': image.text,\n            'width': int_or_none(image.get('width')),\n            'height': int_or_none(image.get('height')),\n        } for image in video_data.findall('images/image')]\n\n        is_live = xpath_text(video_data, 'isLive') == 'true'\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'thumbnail': xpath_text(video_data, 'poster'),\n            'description': strip_or_none(xpath_text(video_data, 'description')),\n            'duration': parse_duration(xpath_text(video_data, 'length') or xpath_text(video_data, 'trt')),\n            'timestamp': self._extract_timestamp(video_data),\n            'upload_date': xpath_attr(video_data, 'metas', 'version'),\n            'series': xpath_text(video_data, 'showTitle'),\n            'season_number': int_or_none(xpath_text(video_data, 'seasonNumber')),\n            'episode_number': int_or_none(xpath_text(video_data, 'episodeNumber')),\n            'is_live': is_live,\n        }",
        "begin_line": 24,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tutv.TutvIE._real_extract#21",
        "src_path": "youtube_dl/extractor/tutv.py",
        "class_name": "youtube_dl.extractor.tutv.TutvIE",
        "signature": "youtube_dl.extractor.tutv.TutvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, 'internal video ID')\n\n        data_content = self._download_webpage(\n            'http://tu.tv/flvurl.php?codVideo=%s' % internal_id, video_id, 'Downloading video info')\n        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0].encode('utf-8')).decode('utf-8')\n\n        return {\n            'id': internal_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 21,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv2.TV2IE._real_extract#38",
        "src_path": "youtube_dl/extractor/tv2.py",
        "class_name": "youtube_dl.extractor.tv2.TV2IE",
        "signature": "youtube_dl.extractor.tv2.TV2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        formats = []\n        format_urls = []\n        for protocol in ('HDS', 'HLS'):\n            data = self._download_json(\n                'http://sumo.tv2.no/api/web/asset/%s/play.json?protocol=%s&videoFormat=SMIL+ISMUSP' % (video_id, protocol),\n                video_id, 'Downloading play JSON')['playback']\n            for item in data['items']['item']:\n                video_url = item.get('url')\n                if not video_url or video_url in format_urls:\n                    continue\n                format_id = '%s-%s' % (protocol.lower(), item.get('mediaFormat'))\n                if not self._is_valid_url(video_url, video_id, format_id):\n                    continue\n                format_urls.append(video_url)\n                ext = determine_ext(video_url)\n                if ext == 'f4m':\n                    formats.extend(self._extract_f4m_formats(\n                        video_url, video_id, f4m_id=format_id, fatal=False))\n                elif ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id=format_id, fatal=False))\n                elif ext == 'ism' or video_url.endswith('.ism/Manifest'):\n                    pass\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': format_id,\n                        'tbr': int_or_none(item.get('bitrate')),\n                        'filesize': int_or_none(item.get('fileSize')),\n                    })\n        self._sort_formats(formats)\n\n        asset = self._download_json(\n            'http://sumo.tv2.no/api/web/asset/%s.json' % video_id,\n            video_id, 'Downloading metadata JSON')['asset']\n\n        title = asset['title']\n        description = asset.get('description')\n        timestamp = parse_iso8601(asset.get('createTime'))\n        duration = float_or_none(asset.get('accurateDuration') or asset.get('duration'))\n        view_count = int_or_none(asset.get('views'))\n        categories = asset.get('keywords', '').split(',')\n\n        thumbnails = [{\n            'id': thumbnail.get('@type'),\n            'url': thumbnail.get('url'),\n        } for _, thumbnail in asset.get('imageVersions', {}).items()]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv2.TV2ArticleIE._real_extract#119",
        "src_path": "youtube_dl/extractor/tv2.py",
        "class_name": "youtube_dl.extractor.tv2.TV2ArticleIE",
        "signature": "youtube_dl.extractor.tv2.TV2ArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        # Old embed pattern (looks unused nowadays)\n        assets = re.findall(r'data-assetid=[\"\\'](\\d+)', webpage)\n\n        if not assets:\n            # New embed pattern\n            for v in re.findall(r'TV2ContentboxVideo\\(({.+?})\\)', webpage):\n                video = self._parse_json(\n                    v, playlist_id, transform_source=js_to_json, fatal=False)\n                if not video:\n                    continue\n                asset = video.get('assetId')\n                if asset:\n                    assets.append(asset)\n\n        entries = [\n            self.url_result('http://www.tv2.no/v/%s' % asset_id, 'TV2')\n            for asset_id in assets]\n\n        title = remove_end(self._og_search_title(webpage), ' - TV2.no')\n        description = remove_end(self._og_search_description(webpage), ' - TV2.no')\n\n        return self.playlist_result(entries, playlist_id, title, description)",
        "begin_line": 119,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv2hu.TV2HuIE._real_extract#29",
        "src_path": "youtube_dl/extractor/tv2hu.py",
        "class_name": "youtube_dl.extractor.tv2hu.TV2HuIE",
        "signature": "youtube_dl.extractor.tv2hu.TV2HuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        json_url = self._search_regex(\n            r'jsonUrl\\s*=\\s*\"([^\"]+)\"', webpage, 'json url')\n        json_data = self._download_json(json_url, video_id)\n\n        formats = []\n        for b in ('bitrates', 'backupBitrates'):\n            bitrates = json_data.get(b, {})\n            m3u8_url = bitrates.get('hls')\n            if m3u8_url:\n                formats.extend(self._extract_wowza_formats(\n                    m3u8_url, video_id, skip_protocols=['rtmp', 'rtsp']))\n\n            for mp4_url in bitrates.get('mp4', []):\n                height = int_or_none(self._search_regex(\n                    r'\\.(\\d+)p\\.mp4', mp4_url, 'height', default=None))\n                formats.append({\n                    'format_id': 'http' + ('-%d' % height if height else ''),\n                    'url': mp4_url,\n                    'height': height,\n                    'width': int_or_none(height / 9.0 * 16.0 if height else None),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage).strip(),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': self._search_regex(\n                r'/vod/(\\d{8})/', json_url, 'upload_date', default=None),\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv3.TV3IE._real_extract#30",
        "src_path": "youtube_dl/extractor/tv3.py",
        "class_name": "youtube_dl.extractor.tv3.TV3IE",
        "signature": "youtube_dl.extractor.tv3.TV3IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n        brightcove_id = self._search_regex(r'<param\\s*name=\"@videoPlayer\"\\s*value=\"(\\d+)\"', webpage, 'brightcove id')\n        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)",
        "begin_line": 30,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv4.TV4IE._real_extract#68",
        "src_path": "youtube_dl/extractor/tv4.py",
        "class_name": "youtube_dl.extractor.tv4.TV4IE",
        "signature": "youtube_dl.extractor.tv4.TV4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://www.tv4play.se/player/assets/%s.json' % video_id,\n            video_id, 'Downloading video info JSON')\n\n        title = info['title']\n\n        subtitles = {}\n        formats = []\n        # http formats are linked with unresolvable host\n        for kind in ('hls3', ''):\n            data = self._download_json(\n                'https://prima.tv4play.se/api/web/asset/%s/play.json' % video_id,\n                video_id, 'Downloading sources JSON', query={\n                    'protocol': kind,\n                    'videoFormat': 'MP4+WEBVTT',\n                })\n            items = try_get(data, lambda x: x['playback']['items']['item'])\n            if not items:\n                continue\n            if isinstance(items, dict):\n                items = [items]\n            for item in items:\n                manifest_url = item.get('url')\n                if not isinstance(manifest_url, compat_str):\n                    continue\n                ext = determine_ext(manifest_url)\n                if ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        manifest_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id=kind, fatal=False))\n                elif ext == 'f4m':\n                    formats.extend(self._extract_akamai_formats(\n                        manifest_url, video_id, {\n                            'hls': 'tv4play-i.akamaihd.net',\n                        }))\n                elif ext == 'webvtt':\n                    subtitles = self._merge_subtitles(\n                        subtitles, {\n                            'sv': [{\n                                'url': manifest_url,\n                                'ext': 'vtt',\n                            }]})\n\n        if not formats and info.get('is_geo_restricted'):\n            self.raise_geo_restricted(countries=self._GEO_COUNTRIES)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'description': info.get('description'),\n            'timestamp': parse_iso8601(info.get('broadcast_date_time')),\n            'duration': int_or_none(info.get('duration')),\n            'thumbnail': info.get('image'),\n            'is_live': info.get('is_live') is True,\n        }",
        "begin_line": 68,
        "end_line": 129,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tv5mondeplus.TV5MondePlusIE._real_extract#33",
        "src_path": "youtube_dl/extractor/tv5mondeplus.py",
        "class_name": "youtube_dl.extractor.tv5mondeplus.TV5MondePlusIE",
        "signature": "youtube_dl.extractor.tv5mondeplus.TV5MondePlusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        if \">Ce programme n'est malheureusement pas disponible pour votre zone g\u00e9ographique.<\" in webpage:\n            self.raise_geo_restricted(countries=['FR'])\n\n        series = get_element_by_class('video-detail__title', webpage)\n        title = episode = get_element_by_class(\n            'video-detail__subtitle', webpage) or series\n        if series and series != title:\n            title = '%s - %s' % (series, title)\n        vpl_data = extract_attributes(self._search_regex(\n            r'(<[^>]+class=\"video_player_loader\"[^>]+>)',\n            webpage, 'video player loader'))\n\n        video_files = self._parse_json(\n            vpl_data['data-broadcast'], display_id).get('files', [])\n        formats = []\n        for video_file in video_files:\n            v_url = video_file.get('url')\n            if not v_url:\n                continue\n            video_format = video_file.get('format') or determine_ext(v_url)\n            if video_format == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    v_url, display_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': v_url,\n                    'format_id': video_format,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'display_id': display_id,\n            'title': title,\n            'description': clean_html(get_element_by_class('video-detail__description', webpage)),\n            'thumbnail': vpl_data.get('data-image'),\n            'duration': int_or_none(vpl_data.get('data-duration')) or parse_duration(self._html_search_meta('duration', webpage)),\n            'timestamp': parse_iso8601(self._html_search_meta('uploadDate', webpage)),\n            'formats': formats,\n            'episode': episode,\n            'series': series,\n        }",
        "begin_line": 33,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tva.TVAIE._real_extract#30",
        "src_path": "youtube_dl/extractor/tva.py",
        "class_name": "youtube_dl.extractor.tva.TVAIE",
        "signature": "youtube_dl.extractor.tva.TVAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            \"https://d18jmrhziuoi7p.cloudfront.net/isl/api/v1/dataservice/Items('%s')\" % video_id,\n            video_id, query={\n                '$expand': 'Metadata,CustomId',\n                '$select': 'Metadata,Id,Title,ShortDescription,LongDescription,CreatedDate,CustomId,AverageUserRating,Categories,ShowName',\n                '$format': 'json',\n            })\n        metadata = video_data.get('Metadata', {})\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': video_data['Title'],\n            'url': smuggle_url('ooyala:' + video_data['CustomId'], {'supportedformats': 'm3u8,hds'}),\n            'description': video_data.get('LongDescription') or video_data.get('ShortDescription'),\n            'series': video_data.get('ShowName'),\n            'episode': metadata.get('EpisodeTitle'),\n            'episode_number': int_or_none(metadata.get('EpisodeNumber')),\n            'categories': video_data.get('Categories'),\n            'average_rating': video_data.get('AverageUserRating'),\n            'timestamp': parse_iso8601(video_data.get('CreatedDate')),\n            'ie_key': 'Ooyala',\n        }",
        "begin_line": 30,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvanouvelles.TVANouvellesIE._real_extract#27",
        "src_path": "youtube_dl/extractor/tvanouvelles.py",
        "class_name": "youtube_dl.extractor.tvanouvelles.TVANouvellesIE",
        "signature": "youtube_dl.extractor.tvanouvelles.TVANouvellesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        brightcove_id = self._match_id(url)\n        return self.url_result(\n            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,\n            BrightcoveNewIE.ie_key(), brightcove_id)",
        "begin_line": 27,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE.suitable#47",
        "src_path": "youtube_dl/extractor/tvanouvelles.py",
        "class_name": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE",
        "signature": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if TVANouvellesIE.suitable(url) else super(TVANouvellesArticleIE, cls).suitable(url)",
        "begin_line": 47,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE._real_extract#50",
        "src_path": "youtube_dl/extractor/tvanouvelles.py",
        "class_name": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE",
        "signature": "youtube_dl.extractor.tvanouvelles.TVANouvellesArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        entries = [\n            self.url_result(\n                'http://www.tvanouvelles.ca/videos/%s' % mobj.group('id'),\n                ie=TVANouvellesIE.ie_key(), video_id=mobj.group('id'))\n            for mobj in re.finditer(\n                r'data-video-id=([\"\\'])?(?P<id>\\d+)', webpage)]\n\n        title = self._og_search_title(webpage, fatal=False)\n        description = self._og_search_description(webpage)\n\n        return self.playlist_result(entries, display_id, title, description)",
        "begin_line": 50,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCIE._extract_url#28",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCIE",
        "signature": "youtube_dl.extractor.tvc.TVCIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:http:)?//(?:www\\.)?tvc\\.ru/video/iframe/id/[^\"]+)\\1', webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 28,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCIE._real_extract#34",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCIE",
        "signature": "youtube_dl.extractor.tvc.TVCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://www.tvc.ru/video/json/id/%s' % video_id, video_id)\n\n        formats = []\n        for info in video.get('path', {}).get('quality', []):\n            video_url = info.get('url')\n            if not video_url:\n                continue\n            format_id = self._search_regex(\n                r'cdnvideo/([^/]+?)(?:-[^/]+?)?/', video_url,\n                'format id', default=None)\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'width': int_or_none(info.get('width')),\n                'height': int_or_none(info.get('height')),\n                'tbr': int_or_none(info.get('bitrate')),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'thumbnail': video.get('picture'),\n            'duration': int_or_none(video.get('duration')),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvc.TVCArticleIE._real_extract#100",
        "src_path": "youtube_dl/extractor/tvc.py",
        "class_name": "youtube_dl.extractor.tvc.TVCArticleIE",
        "signature": "youtube_dl.extractor.tvc.TVCArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, self._match_id(url))\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'TVC',\n            'url': self._og_search_video_url(webpage),\n            'title': clean_html(self._og_search_title(webpage)),\n            'description': clean_html(self._og_search_description(webpage)),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 100,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvigle.TvigleIE._real_extract#56",
        "src_path": "youtube_dl/extractor/tvigle.py",
        "class_name": "youtube_dl.extractor.tvigle.TvigleIE",
        "signature": "youtube_dl.extractor.tvigle.TvigleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        if not video_id:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._html_search_regex(\n                (r'<div[^>]+class=[\"\\']player[\"\\'][^>]+id=[\"\\'](\\d+)',\n                 r'var\\s+cloudId\\s*=\\s*[\"\\'](\\d+)',\n                 r'class=\"video-preview current_playing\" id=\"(\\d+)\"'),\n                webpage, 'video id')\n\n        video_data = self._download_json(\n            'http://cloud.tvigle.ru/api/play/video/%s/' % video_id, display_id)\n\n        item = video_data['playlist']['items'][0]\n\n        videos = item.get('videos')\n\n        error_message = item.get('errorMessage')\n        if not videos and error_message:\n            if item.get('isGeoBlocked') is True:\n                self.raise_geo_restricted(\n                    msg=error_message, countries=self._GEO_COUNTRIES)\n            else:\n                raise ExtractorError(\n                    '%s returned error: %s' % (self.IE_NAME, error_message),\n                    expected=True)\n\n        title = item['title']\n        description = item.get('description')\n        thumbnail = item.get('thumbnail')\n        duration = float_or_none(item.get('durationMilliseconds'), 1000)\n        age_limit = parse_age_limit(item.get('ageRestrictions'))\n\n        formats = []\n        for vcodec, fmts in item['videos'].items():\n            if vcodec == 'hls':\n                continue\n            for format_id, video_url in fmts.items():\n                if format_id == 'm3u8':\n                    continue\n                height = self._search_regex(\n                    r'^(\\d+)[pP]$', format_id, 'height', default=None)\n                formats.append({\n                    'url': video_url,\n                    'format_id': '%s-%s' % (vcodec, format_id),\n                    'vcodec': vcodec,\n                    'height': int_or_none(height),\n                    'filesize': int_or_none(item.get('video_files_size', {}).get(vcodec, {}).get(format_id)),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvn24.TVN24IE._real_extract#34",
        "src_path": "youtube_dl/extractor/tvn24.py",
        "class_name": "youtube_dl.extractor.tvn24.TVN24IE",
        "signature": "youtube_dl.extractor.tvn24.TVN24IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n\n        def extract_json(attr, name, fatal=True):\n            return self._parse_json(\n                self._search_regex(\n                    r'\\b%s=([\"\\'])(?P<json>(?!\\1).+?)\\1' % attr, webpage,\n                    name, group='json', fatal=fatal) or '{}',\n                video_id, transform_source=unescapeHTML, fatal=fatal)\n\n        quality_data = extract_json('data-quality', 'formats')\n\n        formats = []\n        for format_id, url in quality_data.items():\n            formats.append({\n                'url': url,\n                'format_id': format_id,\n                'height': int_or_none(format_id.rstrip('p')),\n            })\n        self._sort_formats(formats)\n\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(\n            webpage, default=None) or self._html_search_regex(\n            r'\\bdata-poster=([\"\\'])(?P<url>(?!\\1).+?)\\1', webpage,\n            'thumbnail', group='url')\n\n        share_params = extract_json(\n            'data-share-params', 'share params', fatal=False)\n        if isinstance(share_params, dict):\n            video_id = share_params.get('id') or video_id\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvnoe.TVNoeIE._real_extract#26",
        "src_path": "youtube_dl/extractor/tvnoe.py",
        "class_name": "youtube_dl.extractor.tvnoe.TVNoeIE",
        "signature": "youtube_dl.extractor.tvnoe.TVNoeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        iframe_url = self._search_regex(\n            r'<iframe[^>]+src=\"([^\"]+)\"', webpage, 'iframe URL')\n\n        ifs_page = self._download_webpage(iframe_url, video_id)\n        jwplayer_data = self._find_jwplayer_data(\n            ifs_page, video_id, transform_source=js_to_json)\n        info_dict = self._parse_jwplayer_data(\n            jwplayer_data, video_id, require_title=False, base_url=iframe_url)\n\n        info_dict.update({\n            'id': video_id,\n            'title': clean_html(get_element_by_class(\n                'field-name-field-podnazev', webpage)),\n            'description': clean_html(get_element_by_class(\n                'field-name-body', webpage)),\n            'series': clean_html(get_element_by_class('title', webpage))\n        })\n\n        return info_dict",
        "begin_line": 26,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvp.TVPIE._real_extract#67",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TVPIE",
        "signature": "youtube_dl.extractor.tvp.TVPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n        video_id = self._search_regex([\n            r'<iframe[^>]+src=\"[^\"]*?object_id=(\\d+)',\n            r\"object_id\\s*:\\s*'(\\d+)'\",\n            r'data-video-id=\"(\\d+)\"'], webpage, 'video id', default=page_id)\n        return {\n            '_type': 'url_transparent',\n            'url': 'tvp:' + video_id,\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'ie_key': 'TVPEmbed',\n        }",
        "begin_line": 67,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvp.TVPEmbedIE._real_extract#101",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TVPEmbedIE",
        "signature": "youtube_dl.extractor.tvp.TVPEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.tvp.pl/sess/tvplayer.php?object_id=%s' % video_id, video_id)\n\n        error_massage = get_element_by_attribute('class', 'msg error', webpage)\n        if error_massage:\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, clean_html(error_massage)), expected=True)\n\n        title = self._search_regex(\n            r'name\\s*:\\s*([\\'\"])Title\\1\\s*,\\s*value\\s*:\\s*\\1(?P<title>.+?)\\1',\n            webpage, 'title', group='title')\n        series_title = self._search_regex(\n            r'name\\s*:\\s*([\\'\"])SeriesTitle\\1\\s*,\\s*value\\s*:\\s*\\1(?P<series>.+?)\\1',\n            webpage, 'series', group='series', default=None)\n        if series_title:\n            title = '%s, %s' % (series_title, title)\n\n        thumbnail = self._search_regex(\n            r\"poster\\s*:\\s*'([^']+)'\", webpage, 'thumbnail', default=None)\n\n        video_url = self._search_regex(\n            r'0:{src:([\\'\"])(?P<url>.*?)\\1', webpage,\n            'formats', group='url', default=None)\n        if not video_url or 'material_niedostepny.mp4' in video_url:\n            video_url = self._download_json(\n                'http://www.tvp.pl/pub/stat/videofileinfo?video_id=%s' % video_id,\n                video_id)['video_url']\n\n        formats = []\n        video_url_base = self._search_regex(\n            r'(https?://.+?/video)(?:\\.(?:ism|f4m|m3u8)|-\\d+\\.mp4)',\n            video_url, 'video base url', default=None)\n        if video_url_base:\n            # TODO: <Group> found instead of <AdaptationSet> in MPD manifest.\n            # It's not mentioned in MPEG-DASH standard. Figure that out.\n            # formats.extend(self._extract_mpd_formats(\n            #     video_url_base + '.ism/video.mpd',\n            #     video_id, mpd_id='dash', fatal=False))\n            formats.extend(self._extract_ism_formats(\n                video_url_base + '.ism/Manifest',\n                video_id, 'mss', fatal=False))\n            formats.extend(self._extract_f4m_formats(\n                video_url_base + '.ism/video.f4m',\n                video_id, f4m_id='hds', fatal=False))\n            m3u8_formats = self._extract_m3u8_formats(\n                video_url_base + '.ism/video.m3u8', video_id,\n                'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)\n            self._sort_formats(m3u8_formats)\n            m3u8_formats = list(filter(\n                lambda f: f.get('vcodec') != 'none', m3u8_formats))\n            formats.extend(m3u8_formats)\n            for i, m3u8_format in enumerate(m3u8_formats, 2):\n                http_url = '%s-%d.mp4' % (video_url_base, i)\n                if self._is_valid_url(http_url, video_id):\n                    f = m3u8_format.copy()\n                    f.update({\n                        'url': http_url,\n                        'format_id': f['format_id'].replace('hls', 'http'),\n                        'protocol': 'http',\n                    })\n                    formats.append(f)\n        else:\n            formats = [{\n                'format_id': 'direct',\n                'url': video_url,\n                'ext': determine_ext(video_url, 'mp4'),\n            }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 101,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvp.TVPSeriesIE._real_extract#202",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TVPSeriesIE",
        "signature": "youtube_dl.extractor.tvp.TVPSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id, tries=5)\n\n        title = self._html_search_regex(\n            r'(?s) id=[\\'\"]path[\\'\"]>(?:.*? / ){2}(.*?)</span>', webpage, 'series')\n        playlist_id = self._search_regex(r'nodeId:\\s*(\\d+)', webpage, 'playlist id')\n        playlist = self._download_webpage(\n            'http://vod.tvp.pl/vod/seriesAjax?type=series&nodeId=%s&recommend'\n            'edId=0&sort=&page=0&pageSize=10000' % playlist_id, display_id, tries=5,\n            note='Downloading playlist')\n\n        videos_paths = re.findall(\n            '(?s)class=\"shortTitle\">.*?href=\"(/[^\"]+)', playlist)\n        entries = [\n            self.url_result('http://vod.tvp.pl%s' % v_path, ie=TVPIE.ie_key())\n            for v_path in videos_paths]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': display_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 202,
        "end_line": 226,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract#226",
        "src_path": "youtube_dl/extractor/tvplay.py",
        "class_name": "youtube_dl.extractor.tvplay.TVPlayIE",
        "signature": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        geo_country = self._search_regex(\n            r'https?://[^/]+\\.([a-z]{2})', url,\n            'geo country', default=None)\n        if geo_country:\n            self._initialize_geo_bypass([geo_country.upper()])\n        video = self._download_json(\n            'http://playapi.mtgx.tv/v3/videos/%s' % video_id, video_id, 'Downloading video JSON')\n\n        title = video['title']\n\n        try:\n            streams = self._download_json(\n                'http://playapi.mtgx.tv/v3/videos/stream/%s' % video_id,\n                video_id, 'Downloading streams JSON')\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403:\n                msg = self._parse_json(e.cause.read().decode('utf-8'), video_id)\n                raise ExtractorError(msg['msg'], expected=True)\n            raise\n\n        quality = qualities(['hls', 'medium', 'high'])\n        formats = []\n        for format_id, video_url in streams.get('streams', {}).items():\n            if not video_url or not isinstance(video_url, compat_str):\n                continue\n            ext = determine_ext(video_url)\n            if ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    update_url_query(video_url, {\n                        'hdcore': '3.5.0',\n                        'plugin': 'aasp-3.5.0.151.81'\n                    }), video_id, f4m_id='hds', fatal=False))\n            elif ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                fmt = {\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                    'ext': ext,\n                }\n                if video_url.startswith('rtmp'):\n                    m = re.search(\n                        r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', video_url)\n                    if not m:\n                        continue\n                    fmt.update({\n                        'ext': 'flv',\n                        'url': m.group('url'),\n                        'app': m.group('app'),\n                        'play_path': m.group('playpath'),\n                    })\n                else:\n                    fmt.update({\n                        'url': video_url,\n                    })\n                formats.append(fmt)\n\n        if not formats and video.get('is_geo_blocked'):\n            self.raise_geo_restricted(\n                'This content might not be available in your country due to copyright reasons')\n\n        self._sort_formats(formats)\n\n        # TODO: webvtt in m3u8\n        subtitles = {}\n        sami_path = video.get('sami_path')\n        if sami_path:\n            lang = self._search_regex(\n                r'_([a-z]{2})\\.xml', sami_path, 'lang',\n                default=compat_urlparse.urlparse(url).netloc.rsplit('.', 1)[-1])\n            subtitles[lang] = [{\n                'url': sami_path,\n            }]\n\n        series = video.get('format_title')\n        episode_number = int_or_none(video.get('format_position', {}).get('episode'))\n        season = video.get('_embedded', {}).get('season', {}).get('title')\n        season_number = int_or_none(video.get('format_position', {}).get('season'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video.get('description'),\n            'series': series,\n            'episode_number': episode_number,\n            'season': season,\n            'season_number': season_number,\n            'duration': int_or_none(video.get('duration')),\n            'timestamp': parse_iso8601(video.get('created_at')),\n            'view_count': try_get(video, lambda x: x['views']['total'], int),\n            'age_limit': int_or_none(video.get('age_limit', 0)),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 226,
        "end_line": 323,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvplay.ViafreeIE.suitable#387",
        "src_path": "youtube_dl/extractor/tvplay.py",
        "class_name": "youtube_dl.extractor.tvplay.ViafreeIE",
        "signature": "youtube_dl.extractor.tvplay.ViafreeIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if TVPlayIE.suitable(url) else super(ViafreeIE, cls).suitable(url)",
        "begin_line": 387,
        "end_line": 388,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvplay.ViafreeIE._real_extract#390",
        "src_path": "youtube_dl/extractor/tvplay.py",
        "class_name": "youtube_dl.extractor.tvplay.ViafreeIE",
        "signature": "youtube_dl.extractor.tvplay.ViafreeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        data = self._parse_json(\n            self._search_regex(\n                r'(?s)window\\.App\\s*=\\s*({.+?})\\s*;\\s*</script',\n                webpage, 'data', default='{}'),\n            video_id, transform_source=lambda x: re.sub(\n                r'(?s)function\\s+[a-zA-Z_][\\da-zA-Z_]*\\s*\\([^)]*\\)\\s*{[^}]*}\\s*',\n                'null', x), fatal=False)\n\n        video_id = None\n\n        if data:\n            video_id = try_get(\n                data, lambda x: x['context']['dispatcher']['stores'][\n                    'ContentPageProgramStore']['currentVideo']['id'],\n                compat_str)\n\n        # Fallback #1 (extract from og:image URL schema)\n        if not video_id:\n            thumbnail = self._og_search_thumbnail(webpage, default=None)\n            if thumbnail:\n                video_id = self._search_regex(\n                    # Patterns seen:\n                    #  http://cdn.playapi.mtgx.tv/imagecache/600x315/cloud/content-images/inbox/765166/a2e95e5f1d735bab9f309fa345cc3f25.jpg\n                    #  http://cdn.playapi.mtgx.tv/imagecache/600x315/cloud/content-images/seasons/15204/758770/4a5ba509ca8bc043e1ebd1a76131cdf2.jpg\n                    r'https?://[^/]+/imagecache/(?:[^/]+/)+(\\d{6,})/',\n                    thumbnail, 'video id', default=None)\n\n        # Fallback #2. Extract from raw JSON string.\n        # May extract wrong video id if relatedClips is present.\n        if not video_id:\n            video_id = self._search_regex(\n                r'currentVideo[\"\\']\\s*:\\s*.+?[\"\\']id[\"\\']\\s*:\\s*[\"\\'](\\d{6,})',\n                webpage, 'video id')\n\n        return self.url_result('mtg:%s' % video_id, TVPlayIE.ie_key())",
        "begin_line": 390,
        "end_line": 429,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tvplayer.TVPlayerIE._real_extract#32",
        "src_path": "youtube_dl/extractor/tvplayer.py",
        "class_name": "youtube_dl.extractor.tvplayer.TVPlayerIE",
        "signature": "youtube_dl.extractor.tvplayer.TVPlayerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        current_channel = extract_attributes(self._search_regex(\n            r'(<div[^>]+class=\"[^\"]*current-channel[^\"]*\"[^>]*>)',\n            webpage, 'channel element'))\n        title = current_channel['data-name']\n\n        resource_id = current_channel['data-id']\n\n        token = self._search_regex(\n            r'data-token=([\"\\'])(?P<token>(?!\\1).+)\\1', webpage,\n            'token', group='token')\n\n        context = self._download_json(\n            'https://tvplayer.com/watch/context', display_id,\n            'Downloading JSON context', query={\n                'resource': resource_id,\n                'gen': token,\n            })\n\n        validate = context['validate']\n        platform = try_get(\n            context, lambda x: x['platform']['key'], compat_str) or 'firefox'\n\n        try:\n            response = self._download_json(\n                'http://api.tvplayer.com/api/v2/stream/live',\n                display_id, 'Downloading JSON stream', headers={\n                    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n                }, data=urlencode_postdata({\n                    'id': resource_id,\n                    'service': 1,\n                    'platform': platform,\n                    'validate': validate,\n                }))['tvplayer']['response']\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                response = self._parse_json(\n                    e.cause.read().decode(), resource_id)['tvplayer']['response']\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, response['error']), expected=True)\n            raise\n\n        formats = self._extract_m3u8_formats(response['stream'], display_id, 'mp4')\n        self._sort_formats(formats)\n\n        return {\n            'id': resource_id,\n            'display_id': display_id,\n            'title': self._live_title(title),\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 32,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.tweakers.TweakersIE._real_extract#27",
        "src_path": "youtube_dl/extractor/tweakers.py",
        "class_name": "youtube_dl.extractor.tweakers.TweakersIE",
        "signature": "youtube_dl.extractor.tweakers.TweakersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'https://tweakers.net/video/s1playlist/%s/1920/1080/playlist.json' % video_id,\n            video_id)['items'][0]\n\n        title = video_data['title']\n\n        formats = []\n        for location in video_data.get('locations', {}).get('progressive', []):\n            format_id = location.get('label')\n            width = int_or_none(location.get('width'))\n            height = int_or_none(location.get('height'))\n            for source in location.get('sources', []):\n                source_url = source.get('src')\n                if not source_url:\n                    continue\n                ext = mimetype2ext(source.get('type')) or determine_ext(source_url)\n                formats.append({\n                    'format_id': format_id,\n                    'url': source_url,\n                    'width': width,\n                    'height': height,\n                    'ext': ext,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'thumbnail': video_data.get('poster'),\n            'duration': int_or_none(video_data.get('duration')),\n            'uploader_id': video_data.get('account'),\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE._real_extract#47",
        "src_path": "youtube_dl/extractor/twentyfourvideo.py",
        "class_name": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE",
        "signature": "youtube_dl.extractor.twentyfourvideo.TwentyFourVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n\n        webpage = self._download_webpage(\n            'http://%s/video/view/%s' % (host, video_id), video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'<(p|span)[^>]+itemprop=\"description\"[^>]*>(?P<description>[^<]+)</\\1>',\n            webpage, 'description', fatal=False, group='description')\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = int_or_none(self._og_search_property(\n            'duration', webpage, 'duration', fatal=False))\n        timestamp = parse_iso8601(self._search_regex(\n            r'<time id=\"video-timeago\" datetime=\"([^\"]+)\" itemprop=\"uploadDate\">',\n            webpage, 'upload date'))\n\n        uploader = self._html_search_regex(\n            r'class=\"video-uploaded\"[^>]*>\\s*<a href=\"/jsecUser/movies/[^\"]+\"[^>]*>([^<]+)</a>',\n            webpage, 'uploader', fatal=False)\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<span class=\"video-views\">(\\d+) \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._html_search_regex(\n            r'<a[^>]+href=\"#tab-comments\"[^>]*>(\\d+) \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438',\n            webpage, 'comment count', fatal=False))\n\n        # Sets some cookies\n        self._download_xml(\n            r'http://%s/video/xml/%s?mode=init' % (host, video_id),\n            video_id, 'Downloading init XML')\n\n        video_xml = self._download_xml(\n            'http://%s/video/xml/%s?mode=play' % (host, video_id),\n            video_id, 'Downloading video XML')\n\n        video = xpath_element(video_xml, './/video', 'video', fatal=True)\n\n        formats = [{\n            'url': xpath_attr(video, '', 'url', 'video URL', fatal=True),\n        }]\n\n        like_count = int_or_none(video.get('ratingPlus'))\n        dislike_count = int_or_none(video.get('ratingMinus'))\n        age_limit = 18 if video.get('adult') == 'true' else 0\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentymin.TwentyMinutenIE._extract_urls#51",
        "src_path": "youtube_dl/extractor/twentymin.py",
        "class_name": "youtube_dl.extractor.twentymin.TwentyMinutenIE",
        "signature": "youtube_dl.extractor.twentymin.TwentyMinutenIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [m.group('url') for m in re.finditer(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:(?:https?:)?//)?(?:www\\.)?20min\\.ch/videoplayer/videoplayer.html\\?.*?\\bvideoId@\\d+.*?)\\1',\n            webpage)]",
        "begin_line": 51,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentymin.TwentyMinutenIE._real_extract#56",
        "src_path": "youtube_dl/extractor/twentymin.py",
        "class_name": "youtube_dl.extractor.twentymin.TwentyMinutenIE",
        "signature": "youtube_dl.extractor.twentymin.TwentyMinutenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_json(\n            'http://api.20min.ch/video/%s/show' % video_id,\n            video_id)['content']\n\n        title = video['title']\n\n        formats = [{\n            'format_id': format_id,\n            'url': 'http://podcast.20min-tv.ch/podcast/20min/%s%s.mp4' % (video_id, p),\n            'quality': quality,\n        } for quality, (format_id, p) in enumerate([('sd', ''), ('hd', 'h')])]\n        self._sort_formats(formats)\n\n        description = video.get('lead')\n        thumbnail = video.get('thumbnail')\n\n        def extract_count(kind):\n            return try_get(\n                video,\n                lambda x: int_or_none(x['communityobject']['thumbs_%s' % kind]))\n\n        like_count = extract_count('up')\n        dislike_count = extract_count('down')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'formats': formats,\n        }",
        "begin_line": 56,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_info#18",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_info(self, city, genre_name, track_id=None)",
        "snippet": "    def _extract_info(self, city, genre_name, track_id=None):\n        item_id = track_id if track_id else genre_name\n\n        cities = self._download_json(\n            '%s/cities' % self._API_BASE, item_id,\n            'Downloading cities info',\n            'Unable to download cities info')\n        city_id = [x['id'] for x in cities if x['slug'] == city][0]\n\n        genres = self._download_json(\n            '%s/genres/%s' % (self._API_BASE, city_id), item_id,\n            'Downloading %s genres info' % city,\n            'Unable to download %s genres info' % city)\n        genre = [x for x in genres if x['slug'] == genre_name][0]\n        genre_id = genre['id']\n\n        tracks = self._download_json(\n            '%s/tracks/%s' % (self._API_BASE, genre_id), item_id,\n            'Downloading %s genre tracks info' % genre_name,\n            'Unable to download track info')\n\n        return [x for x in tracks if x['id'] == item_id][0] if track_id else [genre['title'], tracks]",
        "begin_line": 18,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._get_track_url#41",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._get_track_url(self, filename, track_id)",
        "snippet": "    def _get_track_url(self, filename, track_id):\n        token = self._download_json(\n            'http://22tracks.com/token.php?desktop=true&u=/128/%s' % filename,\n            track_id, 'Downloading token', 'Unable to download token')\n        return 'http://audio.22tracks.com%s?st=%s&e=%d' % (token['filename'], token['st'], token['e'])",
        "begin_line": 41,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_track_info#47",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._extract_track_info(self, track_info, track_id)",
        "snippet": "    def _extract_track_info(self, track_info, track_id):\n        download_url = self._get_track_url(track_info['filename'], track_id)\n        title = '%s - %s' % (track_info['artist'].strip(), track_info['title'].strip())\n        return {\n            'id': track_id,\n            'url': download_url,\n            'ext': 'mp3',\n            'title': title,\n            'duration': int_or_none(track_info.get('duration')),\n            'timestamp': int_or_none(track_info.get('published_at') or track_info.get('created'))\n        }",
        "begin_line": 47,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._real_extract#59",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        city = mobj.group('city')\n        genre = mobj.group('genre')\n        track_id = mobj.group('id')\n\n        track_info = self._extract_info(city, genre, track_id)\n        return self._extract_track_info(track_info, track_id)",
        "begin_line": 59,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE._real_extract#74",
        "src_path": "youtube_dl/extractor/twentytwotracks.py",
        "class_name": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE",
        "signature": "youtube_dl.extractor.twentytwotracks.TwentyTwoTracksGenreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        city = mobj.group('city')\n        genre = mobj.group('genre')\n\n        genre_title, tracks = self._extract_info(city, genre)\n\n        entries = [\n            self._extract_track_info(track_info, track_info['id'])\n            for track_info in tracks]\n\n        return self.playlist_result(entries, genre, genre_title)",
        "begin_line": 74,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._handle_error#39",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s - %s' % (self.IE_NAME, error, response.get('message')),\n                expected=True)",
        "begin_line": 39,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._call_api#48",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._call_api(self, path, item_id, note)",
        "snippet": "    def _call_api(self, path, item_id, note):\n        response = self._download_json(\n            '%s/%s' % (self._API_BASE, path), item_id, note,\n            headers={'Client-ID': self._CLIENT_ID})\n        self._handle_error(response)\n        return response",
        "begin_line": 48,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._real_initialize#55",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._login#58",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        def fail(message):\n            raise ExtractorError(\n                'Unable to login. Twitch said: %s' % message, expected=True)\n\n        def login_step(page, urlh, note, data):\n            form = self._hidden_inputs(page)\n            form.update(data)\n\n            page_url = urlh.geturl()\n            post_url = self._search_regex(\n                r'<form[^>]+action=([\"\\'])(?P<url>.+?)\\1', page,\n                'post url', default=page_url, group='url')\n            post_url = urljoin(page_url, post_url)\n\n            headers = {'Referer': page_url}\n\n            try:\n                response = self._download_json(\n                    post_url, None, note,\n                    data=urlencode_postdata(form),\n                    headers=headers)\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code == 400:\n                    response = self._parse_json(\n                        e.cause.read().decode('utf-8'), None)\n                    fail(response['message'])\n                raise\n\n            redirect_url = urljoin(post_url, response['redirect'])\n            return self._download_webpage_handle(\n                redirect_url, None, 'Downloading login redirect page',\n                headers=headers)\n\n        login_page, handle = self._download_webpage_handle(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        # Some TOR nodes and public proxies are blocked completely\n        if 'blacklist_message' in login_page:\n            fail(clean_html(login_page))\n\n        redirect_page, handle = login_step(\n            login_page, handle, 'Logging in as %s' % username, {\n                'username': username,\n                'password': password,\n            })\n\n        if re.search(r'(?i)<form[^>]+id=\"two-factor-submit\"', redirect_page) is not None:\n            # TODO: Add mechanism to request an SMS or phone call\n            tfa_token = self._get_tfa_info('two-factor authentication token')\n            login_step(redirect_page, handle, 'Submitting TFA token', {\n                'authy_token': tfa_token,\n                'remember_2fa': 'true',\n            })",
        "begin_line": 58,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source#117",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchBaseIE._prefer_source(self, formats)",
        "snippet": "    def _prefer_source(self, formats):\n        try:\n            source = next(f for f in formats if f['format_id'] == 'Source')\n            source['preference'] = 10\n        except StopIteration:\n            pass  # No Source stream present\n        self._sort_formats(formats)",
        "begin_line": 117,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info#127",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._download_info(self, item, item_id)",
        "snippet": "    def _download_info(self, item, item_id):\n        return self._extract_info(self._call_api(\n            'kraken/videos/%s%s' % (item, item_id), item_id,\n            'Downloading %s info JSON' % self._ITEM_TYPE))",
        "begin_line": 127,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media#132",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_media(self, item_id)",
        "snippet": "    def _extract_media(self, item_id):\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        response = self._call_api(\n            'api/videos/%s%s' % (self._ITEM_SHORTCUT, item_id), item_id,\n            'Downloading %s playlist JSON' % self._ITEM_TYPE)\n        entries = []\n        chunks = response['chunks']\n        qualities = list(chunks.keys())\n        for num, fragment in enumerate(zip(*chunks.values()), start=1):\n            formats = []\n            for fmt_num, fragment_fmt in enumerate(fragment):\n                format_id = qualities[fmt_num]\n                fmt = {\n                    'url': fragment_fmt['url'],\n                    'format_id': format_id,\n                    'quality': 1 if format_id == 'live' else 0,\n                }\n                m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n                if m:\n                    fmt['height'] = int(m.group('height'))\n                formats.append(fmt)\n            self._sort_formats(formats)\n            entry = dict(info)\n            entry['id'] = '%s_%d' % (entry['id'], num)\n            entry['title'] = '%s part %d' % (entry['title'], num)\n            entry['formats'] = formats\n            entries.append(entry)\n        return self.playlist_result(entries, info['id'], info['title'])",
        "begin_line": 132,
        "end_line": 159,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info#161",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._extract_info(self, info)",
        "snippet": "    def _extract_info(self, info):\n        return {\n            'id': info['_id'],\n            'title': info.get('title') or 'Untitled Broadcast',\n            'description': info.get('description'),\n            'duration': int_or_none(info.get('length')),\n            'thumbnail': info.get('preview'),\n            'uploader': info.get('channel', {}).get('display_name'),\n            'uploader_id': info.get('channel', {}).get('name'),\n            'timestamp': parse_iso8601(info.get('recorded_at')),\n            'view_count': int_or_none(info.get('views')),\n        }",
        "begin_line": 161,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract#174",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchItemBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchItemBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_media(self._match_id(url))",
        "begin_line": 174,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract#275",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchVodIE",
        "signature": "youtube_dl.extractor.twitch.TwitchVodIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        item_id = self._match_id(url)\n\n        info = self._download_info(self._ITEM_SHORTCUT, item_id)\n        access_token = self._call_api(\n            'api/vods/%s/access_token' % item_id, item_id,\n            'Downloading %s access token' % self._ITEM_TYPE)\n\n        formats = self._extract_m3u8_formats(\n            '%s/vod/%s?%s' % (\n                self._USHER_BASE, item_id,\n                compat_urllib_parse_urlencode({\n                    'allow_source': 'true',\n                    'allow_audio_only': 'true',\n                    'allow_spectre': 'true',\n                    'player': 'twitchweb',\n                    'nauth': access_token['token'],\n                    'nauthsig': access_token['sig'],\n                })),\n            item_id, 'mp4', entry_protocol='m3u8_native')\n\n        self._prefer_source(formats)\n        info['formats'] = formats\n\n        parsed_url = compat_urllib_parse_urlparse(url)\n        query = compat_parse_qs(parsed_url.query)\n        if 't' in query:\n            info['start_time'] = parse_duration(query['t'][0])\n\n        if info.get('timestamp') is not None:\n            info['subtitles'] = {\n                'rechat': [{\n                    'url': update_url_query(\n                        'https://rechat.twitch.tv/rechat-messages', {\n                            'video_id': 'v%s' % item_id,\n                            'start': info['timestamp'],\n                        }),\n                    'ext': 'json',\n                }],\n            }\n\n        return info",
        "begin_line": 275,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist#323",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist(self, channel_id)",
        "snippet": "    def _extract_playlist(self, channel_id):\n        info = self._call_api(\n            'kraken/channels/%s' % channel_id,\n            channel_id, 'Downloading channel info JSON')\n        channel_name = info.get('display_name') or info.get('name')\n        entries = []\n        offset = 0\n        limit = self._PAGE_LIMIT\n        broken_paging_detected = False\n        counter_override = None\n        for counter in itertools.count(1):\n            response = self._call_api(\n                self._PLAYLIST_PATH % (channel_id, offset, limit),\n                channel_id,\n                'Downloading %s JSON page %s'\n                % (self._PLAYLIST_TYPE, counter_override or counter))\n            page_entries = self._extract_playlist_page(response)\n            if not page_entries:\n                break\n            total = int_or_none(response.get('_total'))\n            # Since the beginning of March 2016 twitch's paging mechanism\n            # is completely broken on the twitch side. It simply ignores\n            # a limit and returns the whole offset number of videos.\n            # Working around by just requesting all videos at once.\n            # Upd: pagination bug was fixed by twitch on 15.03.2016.\n            if not broken_paging_detected and total and len(page_entries) > limit:\n                self.report_warning(\n                    'Twitch pagination is broken on twitch side, requesting all videos at once',\n                    channel_id)\n                broken_paging_detected = True\n                offset = total\n                counter_override = '(all at once)'\n                continue\n            entries.extend(page_entries)\n            if broken_paging_detected or total and len(page_entries) >= total:\n                break\n            offset += limit\n        return self.playlist_result(\n            [self.url_result(entry) for entry in orderedSet(entries)],\n            channel_id, channel_name)",
        "begin_line": 323,
        "end_line": 362,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page#364",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._extract_playlist_page(self, response)",
        "snippet": "    def _extract_playlist_page(self, response):\n        videos = response.get('videos')\n        return [video['url'] for video in videos] if videos else []",
        "begin_line": 364,
        "end_line": 366,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract#368",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE",
        "signature": "youtube_dl.extractor.twitch.TwitchPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_playlist(self._match_id(url))",
        "begin_line": 368,
        "end_line": 369,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchStreamIE.suitable#495",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchStreamIE",
        "signature": "youtube_dl.extractor.twitch.TwitchStreamIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return (False\n                if any(ie.suitable(url) for ie in (\n                    TwitchVideoIE,\n                    TwitchChapterIE,\n                    TwitchVodIE,\n                    TwitchProfileIE,\n                    TwitchAllVideosIE,\n                    TwitchUploadsIE,\n                    TwitchPastBroadcastsIE,\n                    TwitchHighlightsIE))\n                else super(TwitchStreamIE, cls).suitable(url))",
        "begin_line": 495,
        "end_line": 506,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract#508",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchStreamIE",
        "signature": "youtube_dl.extractor.twitch.TwitchStreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        stream = self._call_api(\n            'kraken/streams/%s?stream_type=all' % channel_id, channel_id,\n            'Downloading stream JSON').get('stream')\n\n        if not stream:\n            raise ExtractorError('%s is offline' % channel_id, expected=True)\n\n        # Channel name may be typed if different case than the original channel name\n        # (e.g. http://www.twitch.tv/TWITCHPLAYSPOKEMON) that will lead to constructing\n        # an invalid m3u8 URL. Working around by use of original channel name from stream\n        # JSON and fallback to lowercase if it's not available.\n        channel_id = stream.get('channel', {}).get('name') or channel_id.lower()\n\n        access_token = self._call_api(\n            'api/channels/%s/access_token' % channel_id, channel_id,\n            'Downloading channel access token')\n\n        query = {\n            'allow_source': 'true',\n            'allow_audio_only': 'true',\n            'allow_spectre': 'true',\n            'p': random.randint(1000000, 10000000),\n            'player': 'twitchweb',\n            'segment_preference': '4',\n            'sig': access_token['sig'].encode('utf-8'),\n            'token': access_token['token'].encode('utf-8'),\n        }\n        formats = self._extract_m3u8_formats(\n            '%s/api/channel/hls/%s.m3u8?%s'\n            % (self._USHER_BASE, channel_id, compat_urllib_parse_urlencode(query)),\n            channel_id, 'mp4')\n        self._prefer_source(formats)\n\n        view_count = stream.get('viewers')\n        timestamp = parse_iso8601(stream.get('created_at'))\n\n        channel = stream['channel']\n        title = self._live_title(channel.get('display_name') or channel.get('name'))\n        description = channel.get('status')\n\n        thumbnails = []\n        for thumbnail_key, thumbnail_url in stream['preview'].items():\n            m = re.search(r'(?P<width>\\d+)x(?P<height>\\d+)\\.jpg$', thumbnail_key)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n\n        return {\n            'id': compat_str(stream['_id']),\n            'display_id': channel_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'uploader': channel.get('display_name'),\n            'uploader_id': channel.get('name'),\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'formats': formats,\n            'is_live': True,\n        }",
        "begin_line": 508,
        "end_line": 574,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitch.TwitchClipsIE._real_extract#599",
        "src_path": "youtube_dl/extractor/twitch.py",
        "class_name": "youtube_dl.extractor.twitch.TwitchClipsIE",
        "signature": "youtube_dl.extractor.twitch.TwitchClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        clip = self._parse_json(\n            self._search_regex(\n                r'(?s)clipInfo\\s*=\\s*({.+?});', webpage, 'clip info'),\n            video_id, transform_source=js_to_json)\n\n        title = clip.get('channel_title') or self._og_search_title(webpage)\n\n        formats = [{\n            'url': option['source'],\n            'format_id': option.get('quality'),\n            'height': int_or_none(option.get('quality')),\n        } for option in clip.get('quality_options', []) if option.get('source')]\n\n        if not formats:\n            formats = [{\n                'url': clip['clip_video_url'],\n            }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'creator': clip.get('broadcaster_display_name') or clip.get('broadcaster_login'),\n            'uploader': clip.get('curator_login'),\n            'uploader_id': clip.get('curator_display_name'),\n            'formats': formats,\n        }",
        "begin_line": 599,
        "end_line": 632,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterBaseIE._extract_formats_from_vmap_url#23",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterBaseIE",
        "signature": "youtube_dl.extractor.twitter.TwitterBaseIE._extract_formats_from_vmap_url(self, vmap_url, video_id)",
        "snippet": "    def _extract_formats_from_vmap_url(self, vmap_url, video_id):\n        vmap_data = self._download_xml(vmap_url, video_id)\n        video_url = xpath_text(vmap_data, './/MediaFile').strip()\n        if determine_ext(video_url) == 'm3u8':\n            return self._extract_m3u8_formats(\n                video_url, video_id, ext='mp4', m3u8_id='hls',\n                entry_protocol='m3u8_native')\n        return [{\n            'url': video_url,\n        }]",
        "begin_line": 23,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterBaseIE._search_dimensions_in_video_url#35",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterBaseIE",
        "signature": "youtube_dl.extractor.twitter.TwitterBaseIE._search_dimensions_in_video_url(a_format, video_url)",
        "snippet": "    def _search_dimensions_in_video_url(a_format, video_url):\n        m = re.search(r'/(?P<width>\\d+)x(?P<height>\\d+)/', video_url)\n        if m:\n            a_format.update({\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })",
        "begin_line": 35,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterCardIE._parse_media_info#114",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterCardIE",
        "signature": "youtube_dl.extractor.twitter.TwitterCardIE._parse_media_info(self, media_info, video_id)",
        "snippet": "    def _parse_media_info(self, media_info, video_id):\n        formats = []\n        for media_variant in media_info.get('variants', []):\n            media_url = media_variant['url']\n            if media_url.endswith('.m3u8'):\n                formats.extend(self._extract_m3u8_formats(media_url, video_id, ext='mp4', m3u8_id='hls'))\n            elif media_url.endswith('.mpd'):\n                formats.extend(self._extract_mpd_formats(media_url, video_id, mpd_id='dash'))\n            else:\n                vbr = int_or_none(dict_get(media_variant, ('bitRate', 'bitrate')), scale=1000)\n                a_format = {\n                    'url': media_url,\n                    'format_id': 'http-%d' % vbr if vbr else 'http',\n                    'vbr': vbr,\n                }\n                # Reported bitRate may be zero\n                if not a_format['vbr']:\n                    del a_format['vbr']\n\n                self._search_dimensions_in_video_url(a_format, media_url)\n\n                formats.append(a_format)\n        return formats",
        "begin_line": 114,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterCardIE._extract_mobile_formats#138",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterCardIE",
        "signature": "youtube_dl.extractor.twitter.TwitterCardIE._extract_mobile_formats(self, username, video_id)",
        "snippet": "    def _extract_mobile_formats(self, username, video_id):\n        webpage = self._download_webpage(\n            'https://mobile.twitter.com/%s/status/%s' % (username, video_id),\n            video_id, 'Downloading mobile webpage',\n            headers={\n                # A recent mobile UA is necessary for `gt` cookie\n                'User-Agent': 'Mozilla/5.0 (Android 6.0.1; Mobile; rv:54.0) Gecko/54.0 Firefox/54.0',\n            })\n        main_script_url = self._html_search_regex(\n            r'<script[^>]+src=\"([^\"]+main\\.[^\"]+)\"', webpage, 'main script URL')\n        main_script = self._download_webpage(\n            main_script_url, video_id, 'Downloading main script')\n        bearer_token = self._search_regex(\n            r'BEARER_TOKEN\\s*:\\s*\"([^\"]+)\"',\n            main_script, 'bearer token')\n        guest_token = self._search_regex(\n            r'document\\.cookie\\s*=\\s*decodeURIComponent\\(\"gt=(\\d+)',\n            webpage, 'guest token')\n        api_data = self._download_json(\n            'https://api.twitter.com/2/timeline/conversation/%s.json' % video_id,\n            video_id, 'Downloading mobile API data',\n            headers={\n                'Authorization': 'Bearer ' + bearer_token,\n                'x-guest-token': guest_token,\n            })\n        media_info = try_get(api_data, lambda o: o['globalObjects']['tweets'][video_id]\n                                                  ['extended_entities']['media'][0]['video_info']) or {}\n        return self._parse_media_info(media_info, video_id)",
        "begin_line": 138,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterCardIE._real_extract#167",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterCardIE",
        "signature": "youtube_dl.extractor.twitter.TwitterCardIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = None\n        formats = []\n        duration = None\n\n        webpage = self._download_webpage(url, video_id)\n\n        iframe_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//(?:www.youtube.com/embed/[^\"]+|(?:www\\.)?vine\\.co/v/\\w+/card))\"',\n            webpage, 'video iframe', default=None)\n        if iframe_url:\n            return self.url_result(iframe_url)\n\n        config = self._parse_json(self._html_search_regex(\n            r'data-(?:player-)?config=\"([^\"]+)\"', webpage,\n            'data player config', default='{}'),\n            video_id)\n\n        if config.get('source_type') == 'vine':\n            return self.url_result(config['player_url'], 'Vine')\n\n        periscope_url = PeriscopeIE._extract_url(webpage)\n        if periscope_url:\n            return self.url_result(periscope_url, PeriscopeIE.ie_key())\n\n        video_url = config.get('video_url') or config.get('playlist', [{}])[0].get('source')\n\n        if video_url:\n            if determine_ext(video_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(video_url, video_id, ext='mp4', m3u8_id='hls'))\n            else:\n                f = {\n                    'url': video_url,\n                }\n\n                self._search_dimensions_in_video_url(f, video_url)\n\n                formats.append(f)\n\n        vmap_url = config.get('vmapUrl') or config.get('vmap_url')\n        if vmap_url:\n            formats.extend(\n                self._extract_formats_from_vmap_url(vmap_url, video_id))\n\n        media_info = None\n\n        for entity in config.get('status', {}).get('entities', []):\n            if 'mediaInfo' in entity:\n                media_info = entity['mediaInfo']\n\n        if media_info:\n            formats.extend(self._parse_media_info(media_info, video_id))\n            duration = float_or_none(media_info.get('duration', {}).get('nanos'), scale=1e9)\n\n        username = config.get('user', {}).get('screen_name')\n        if username:\n            formats.extend(self._extract_mobile_formats(username, video_id))\n\n        self._remove_duplicate_formats(formats)\n        self._sort_formats(formats)\n\n        title = self._search_regex(r'<title>([^<]+)</title>', webpage, 'title')\n        thumbnail = config.get('posterImageUrl') or config.get('image_src')\n        duration = float_or_none(config.get('duration')) or duration\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 167,
        "end_line": 240,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterIE._real_extract#373",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterIE",
        "signature": "youtube_dl.extractor.twitter.TwitterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user_id')\n        twid = mobj.group('id')\n\n        webpage, urlh = self._download_webpage_handle(\n            self._TEMPLATE_URL % (user_id, twid), twid)\n\n        if 'twitter.com/account/suspended' in urlh.geturl():\n            raise ExtractorError('Account suspended by Twitter.', expected=True)\n\n        username = remove_end(self._og_search_title(webpage), ' on Twitter')\n\n        title = description = self._og_search_description(webpage).strip('').replace('\\n', ' ').strip('\u201c\u201d')\n\n        # strip  'https -_t.co_BJYgOjSeGA' junk from filenames\n        title = re.sub(r'\\s+(https?://[^ ]+)', '', title)\n\n        info = {\n            'uploader_id': user_id,\n            'uploader': username,\n            'webpage_url': url,\n            'description': '%s on Twitter: \"%s\"' % (username, description),\n            'title': username + ' - ' + title,\n        }\n\n        mobj = re.search(r'''(?x)\n            <video[^>]+class=\"animated-gif\"(?P<more_info>[^>]+)>\\s*\n                <source[^>]+video-src=\"(?P<url>[^\"]+)\"\n        ''', webpage)\n\n        if mobj:\n            more_info = mobj.group('more_info')\n            height = int_or_none(self._search_regex(\n                r'data-height=\"(\\d+)\"', more_info, 'height', fatal=False))\n            width = int_or_none(self._search_regex(\n                r'data-width=\"(\\d+)\"', more_info, 'width', fatal=False))\n            thumbnail = self._search_regex(\n                r'poster=\"([^\"]+)\"', more_info, 'poster', fatal=False)\n            info.update({\n                'id': twid,\n                'url': mobj.group('url'),\n                'height': height,\n                'width': width,\n                'thumbnail': thumbnail,\n            })\n            return info\n\n        twitter_card_url = None\n        if 'class=\"PlayableMedia' in webpage:\n            twitter_card_url = '%s//twitter.com/i/videos/tweet/%s' % (self.http_scheme(), twid)\n        else:\n            twitter_card_iframe_url = self._search_regex(\n                r'data-full-card-iframe-url=([\\'\"])(?P<url>(?:(?!\\1).)+)\\1',\n                webpage, 'Twitter card iframe URL', default=None, group='url')\n            if twitter_card_iframe_url:\n                twitter_card_url = compat_urlparse.urljoin(url, twitter_card_iframe_url)\n\n        if twitter_card_url:\n            info.update({\n                '_type': 'url_transparent',\n                'ie_key': 'TwitterCard',\n                'url': twitter_card_url,\n            })\n            return info\n\n        raise ExtractorError('There\\'s no video in this tweet.')",
        "begin_line": 373,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.twitter.TwitterAmplifyIE._real_extract#457",
        "src_path": "youtube_dl/extractor/twitter.py",
        "class_name": "youtube_dl.extractor.twitter.TwitterAmplifyIE",
        "signature": "youtube_dl.extractor.twitter.TwitterAmplifyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        vmap_url = self._html_search_meta(\n            'twitter:amplify:vmap', webpage, 'vmap url')\n        formats = self._extract_formats_from_vmap_url(vmap_url, video_id)\n\n        thumbnails = []\n        thumbnail = self._html_search_meta(\n            'twitter:image:src', webpage, 'thumbnail', fatal=False)\n\n        def _find_dimension(target):\n            w = int_or_none(self._html_search_meta(\n                'twitter:%s:width' % target, webpage, fatal=False))\n            h = int_or_none(self._html_search_meta(\n                'twitter:%s:height' % target, webpage, fatal=False))\n            return w, h\n\n        if thumbnail:\n            thumbnail_w, thumbnail_h = _find_dimension('image')\n            thumbnails.append({\n                'url': thumbnail,\n                'width': thumbnail_w,\n                'height': thumbnail_h,\n            })\n\n        video_w, video_h = _find_dimension('player')\n        formats[0].update({\n            'width': video_w,\n            'height': video_h,\n        })\n\n        return {\n            'id': video_id,\n            'title': 'Twitter Video',\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 457,
        "end_line": 495,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._extract_course_info#62",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._extract_course_info(self, webpage, video_id)",
        "snippet": "    def _extract_course_info(self, webpage, video_id):\n        course = self._parse_json(\n            unescapeHTML(self._search_regex(\n                r'ng-init=[\"\\'].*\\bcourse=({.+?});', webpage, 'course', default='{}')),\n            video_id, fatal=False) or {}\n        course_id = course.get('id') or self._search_regex(\n            (r'&quot;id&quot;\\s*:\\s*(\\d+)', r'data-course-id=[\"\\'](\\d+)'),\n            webpage, 'course id')\n        return course_id, course.get('title')",
        "begin_line": 62,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._enroll_course#72",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._enroll_course(self, base_url, webpage, course_id)",
        "snippet": "    def _enroll_course(self, base_url, webpage, course_id):\n        def combine_url(base_url, url):\n            return compat_urlparse.urljoin(base_url, url) if not url.startswith('http') else url\n\n        checkout_url = unescapeHTML(self._search_regex(\n            r'href=([\"\\'])(?P<url>(?:https?://(?:www\\.)?udemy\\.com)?/(?:payment|cart)/checkout/.+?)\\1',\n            webpage, 'checkout url', group='url', default=None))\n        if checkout_url:\n            raise ExtractorError(\n                'Course %s is not free. You have to pay for it before you can download. '\n                'Use this URL to confirm purchase: %s'\n                % (course_id, combine_url(base_url, checkout_url)),\n                expected=True)\n\n        enroll_url = unescapeHTML(self._search_regex(\n            r'href=([\"\\'])(?P<url>(?:https?://(?:www\\.)?udemy\\.com)?/course/subscribe/.+?)\\1',\n            webpage, 'enroll url', group='url', default=None))\n        if enroll_url:\n            webpage = self._download_webpage(\n                combine_url(base_url, enroll_url),\n                course_id, 'Enrolling in the course',\n                headers={'Referer': base_url})\n            if '>You have enrolled in' in webpage:\n                self.to_screen('%s: Successfully enrolled in the course' % course_id)",
        "begin_line": 72,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._download_lecture#97",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._download_lecture(self, course_id, lecture_id)",
        "snippet": "    def _download_lecture(self, course_id, lecture_id):\n        return self._download_json(\n            'https://www.udemy.com/api-2.0/users/me/subscribed-courses/%s/lectures/%s?'\n            % (course_id, lecture_id),\n            lecture_id, 'Downloading lecture JSON', query={\n                'fields[lecture]': 'title,description,view_html,asset',\n                'fields[asset]': 'asset_type,stream_url,thumbnail_url,download_urls,data',\n            })",
        "begin_line": 97,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._handle_error#106",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            error_str = 'Udemy returned error #%s: %s' % (error.get('code'), error.get('message'))\n            error_data = error.get('data')\n            if error_data:\n                error_str += ' - %s' % error_data.get('formErrors')\n            raise ExtractorError(error_str, expected=True)",
        "begin_line": 106,
        "end_line": 115,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._download_json#117",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._download_json(self, url_or_request, *args, **kwargs)",
        "snippet": "    def _download_json(self, url_or_request, *args, **kwargs):\n        headers = {\n            'X-Udemy-Snail-Case': 'true',\n            'X-Requested-With': 'XMLHttpRequest',\n        }\n        for cookie in self._downloader.cookiejar:\n            if cookie.name == 'client_id':\n                headers['X-Udemy-Client-Id'] = cookie.value\n            elif cookie.name == 'access_token':\n                headers['X-Udemy-Bearer-Token'] = cookie.value\n                headers['X-Udemy-Authorization'] = 'Bearer %s' % cookie.value\n\n        if isinstance(url_or_request, compat_urllib_request.Request):\n            for header, value in headers.items():\n                url_or_request.add_header(header, value)\n        else:\n            url_or_request = sanitized_Request(url_or_request, headers=headers)\n\n        response = super(UdemyIE, self)._download_json(url_or_request, *args, **kwargs)\n        self._handle_error(response)\n        return response",
        "begin_line": 117,
        "end_line": 137,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_initialize#139",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._login#142",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_popup = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login popup')\n\n        def is_logged(webpage):\n            return any(re.search(p, webpage) for p in (\n                r'href=[\"\\'](?:https://www\\.udemy\\.com)?/user/logout/',\n                r'>Logout<'))\n\n        # already logged in\n        if is_logged(login_popup):\n            return\n\n        login_form = self._form_hidden_inputs('login-form', login_popup)\n\n        login_form.update({\n            'email': username,\n            'password': password,\n        })\n\n        response = self._download_webpage(\n            self._LOGIN_URL, None, 'Logging in as %s' % username,\n            data=urlencode_postdata(login_form),\n            headers={\n                'Referer': self._ORIGIN_URL,\n                'Origin': self._ORIGIN_URL,\n            })\n\n        if not is_logged(response):\n            error = self._html_search_regex(\n                r'(?s)<div[^>]+class=\"form-errors[^\"]*\">(.+?)</div>',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')",
        "begin_line": 142,
        "end_line": 180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_extract#182",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lecture_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, lecture_id)\n\n        course_id, _ = self._extract_course_info(webpage, lecture_id)\n\n        try:\n            lecture = self._download_lecture(course_id, lecture_id)\n        except ExtractorError as e:\n            # Error could possibly mean we are not enrolled in the course\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403:\n                self._enroll_course(url, webpage, course_id)\n                lecture = self._download_lecture(course_id, lecture_id)\n            else:\n                raise\n\n        title = lecture['title']\n        description = lecture.get('description')\n\n        asset = lecture['asset']\n\n        asset_type = asset.get('asset_type') or asset.get('assetType')\n        if asset_type != 'Video':\n            raise ExtractorError(\n                'Lecture %s is not a video' % lecture_id, expected=True)\n\n        stream_url = asset.get('stream_url') or asset.get('streamUrl')\n        if stream_url:\n            youtube_url = self._search_regex(\n                r'(https?://www\\.youtube\\.com/watch\\?v=.*)', stream_url, 'youtube URL', default=None)\n            if youtube_url:\n                return self.url_result(youtube_url, 'Youtube')\n\n        video_id = compat_str(asset['id'])\n        thumbnail = asset.get('thumbnail_url') or asset.get('thumbnailUrl')\n        duration = float_or_none(asset.get('data', {}).get('duration'))\n\n        subtitles = {}\n        automatic_captions = {}\n\n        formats = []\n\n        def extract_output_format(src, f_id):\n            return {\n                'url': src.get('url'),\n                'format_id': '%sp' % (src.get('height') or f_id),\n                'width': int_or_none(src.get('width')),\n                'height': int_or_none(src.get('height')),\n                'vbr': int_or_none(src.get('video_bitrate_in_kbps')),\n                'vcodec': src.get('video_codec'),\n                'fps': int_or_none(src.get('frame_rate')),\n                'abr': int_or_none(src.get('audio_bitrate_in_kbps')),\n                'acodec': src.get('audio_codec'),\n                'asr': int_or_none(src.get('audio_sample_rate')),\n                'tbr': int_or_none(src.get('total_bitrate_in_kbps')),\n                'filesize': int_or_none(src.get('file_size_in_bytes')),\n            }\n\n        outputs = asset.get('data', {}).get('outputs')\n        if not isinstance(outputs, dict):\n            outputs = {}\n\n        def add_output_format_meta(f, key):\n            output = outputs.get(key)\n            if isinstance(output, dict):\n                output_format = extract_output_format(output, key)\n                output_format.update(f)\n                return output_format\n            return f\n\n        def extract_formats(source_list):\n            if not isinstance(source_list, list):\n                return\n            for source in source_list:\n                video_url = source.get('file') or source.get('src')\n                if not video_url or not isinstance(video_url, compat_str):\n                    continue\n                format_id = source.get('label')\n                f = {\n                    'url': video_url,\n                    'format_id': '%sp' % format_id,\n                    'height': int_or_none(format_id),\n                }\n                if format_id:\n                    # Some videos contain additional metadata (e.g.\n                    # https://www.udemy.com/ios9-swift/learn/#/lecture/3383208)\n                    f = add_output_format_meta(f, format_id)\n                formats.append(f)\n\n        def extract_subtitles(track_list):\n            if not isinstance(track_list, list):\n                return\n            for track in track_list:\n                if not isinstance(track, dict):\n                    continue\n                if track.get('kind') != 'captions':\n                    continue\n                src = track.get('src')\n                if not src or not isinstance(src, compat_str):\n                    continue\n                lang = track.get('language') or track.get(\n                    'srclang') or track.get('label')\n                sub_dict = automatic_captions if track.get(\n                    'autogenerated') is True else subtitles\n                sub_dict.setdefault(lang, []).append({\n                    'url': src,\n                })\n\n        download_urls = asset.get('download_urls')\n        if isinstance(download_urls, dict):\n            extract_formats(download_urls.get('Video'))\n\n        view_html = lecture.get('view_html')\n        if view_html:\n            view_html_urls = set()\n            for source in re.findall(r'<source[^>]+>', view_html):\n                attributes = extract_attributes(source)\n                src = attributes.get('src')\n                if not src:\n                    continue\n                res = attributes.get('data-res')\n                height = int_or_none(res)\n                if src in view_html_urls:\n                    continue\n                view_html_urls.add(src)\n                if attributes.get('type') == 'application/x-mpegURL' or determine_ext(src) == 'm3u8':\n                    m3u8_formats = self._extract_m3u8_formats(\n                        src, video_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id='hls', fatal=False)\n                    for f in m3u8_formats:\n                        m = re.search(r'/hls_(?P<height>\\d{3,4})_(?P<tbr>\\d{2,})/', f['url'])\n                        if m:\n                            if not f.get('height'):\n                                f['height'] = int(m.group('height'))\n                            if not f.get('tbr'):\n                                f['tbr'] = int(m.group('tbr'))\n                    formats.extend(m3u8_formats)\n                else:\n                    formats.append(add_output_format_meta({\n                        'url': src,\n                        'format_id': '%dp' % height if height else None,\n                        'height': height,\n                    }, res))\n\n            # react rendition since 2017.04.15 (see\n            # https://github.com/rg3/youtube-dl/issues/12744)\n            data = self._parse_json(\n                self._search_regex(\n                    r'videojs-setup-data=([\"\\'])(?P<data>{.+?})\\1', view_html,\n                    'setup data', default='{}', group='data'), video_id,\n                transform_source=unescapeHTML, fatal=False)\n            if data and isinstance(data, dict):\n                extract_formats(data.get('sources'))\n                if not duration:\n                    duration = int_or_none(data.get('duration'))\n                extract_subtitles(data.get('tracks'))\n\n            if not subtitles and not automatic_captions:\n                text_tracks = self._parse_json(\n                    self._search_regex(\n                        r'text-tracks=([\"\\'])(?P<data>\\[.+?\\])\\1', view_html,\n                        'text tracks', default='{}', group='data'), video_id,\n                    transform_source=lambda s: js_to_json(unescapeHTML(s)),\n                    fatal=False)\n                extract_subtitles(text_tracks)\n\n        self._sort_formats(formats, field_preference=('height', 'width', 'tbr', 'format_id'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n            'automatic_captions': automatic_captions,\n        }",
        "begin_line": 182,
        "end_line": 360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable#369",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if UdemyIE.suitable(url) else super(UdemyCourseIE, cls).suitable(url)",
        "begin_line": 369,
        "end_line": 370,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract#372",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_path = self._match_id(url)\n\n        webpage = self._download_webpage(url, course_path)\n\n        course_id, title = self._extract_course_info(webpage, course_path)\n\n        self._enroll_course(url, webpage, course_id)\n\n        response = self._download_json(\n            'https://www.udemy.com/api-2.0/courses/%s/cached-subscriber-curriculum-items' % course_id,\n            course_id, 'Downloading course curriculum', query={\n                'fields[chapter]': 'title,object_index',\n                'fields[lecture]': 'title,asset',\n                'page_size': '1000',\n            })\n\n        entries = []\n        chapter, chapter_number = [None] * 2\n        for entry in response['results']:\n            clazz = entry.get('_class')\n            if clazz == 'lecture':\n                asset = entry.get('asset')\n                if isinstance(asset, dict):\n                    asset_type = asset.get('asset_type') or asset.get('assetType')\n                    if asset_type != 'Video':\n                        continue\n                lecture_id = entry.get('id')\n                if lecture_id:\n                    entry = {\n                        '_type': 'url_transparent',\n                        'url': 'https://www.udemy.com/%s/learn/v4/t/lecture/%s' % (course_path, entry['id']),\n                        'title': entry.get('title'),\n                        'ie_key': UdemyIE.ie_key(),\n                    }\n                    if chapter_number:\n                        entry['chapter_number'] = chapter_number\n                    if chapter:\n                        entry['chapter'] = chapter\n                    entries.append(entry)\n            elif clazz == 'chapter':\n                chapter_number = entry.get('object_index')\n                chapter = entry.get('title')\n\n        return self.playlist_result(entries, course_id, title)",
        "begin_line": 372,
        "end_line": 416,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.udn.UDNEmbedIE._real_extract#41",
        "src_path": "youtube_dl/extractor/udn.py",
        "class_name": "youtube_dl.extractor.udn.UDNEmbedIE",
        "signature": "youtube_dl.extractor.udn.UDNEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        page = self._download_webpage(url, video_id)\n\n        options = json.loads(js_to_json(self._html_search_regex(\n            r'var\\s+options\\s*=\\s*([^;]+);', page, 'video urls dictionary')))\n\n        video_urls = options['video']\n\n        if video_urls.get('youtube'):\n            return self.url_result(video_urls.get('youtube'), 'Youtube')\n\n        formats = []\n        for video_type, api_url in video_urls.items():\n            if not api_url:\n                continue\n\n            video_url = self._download_webpage(\n                compat_urlparse.urljoin(url, api_url), video_id,\n                note='retrieve url for %s video' % video_type)\n\n            ext = determine_ext(video_url)\n            if ext == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    video_url, video_id, ext='mp4', m3u8_id='hls'))\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    video_url, video_id, f4m_id='hds'))\n            else:\n                mobj = re.search(r'_(?P<height>\\d+)p_(?P<tbr>\\d+).mp4', video_url)\n                a_format = {\n                    'url': video_url,\n                    # video_type may be 'mp4', which confuses YoutubeDL\n                    'format_id': 'http-' + video_type,\n                }\n                if mobj:\n                    a_format.update({\n                        'height': int_or_none(mobj.group('height')),\n                        'tbr': int_or_none(mobj.group('tbr')),\n                    })\n                formats.append(a_format)\n\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'url': img_url,\n            'id': img_type,\n        } for img_type, img_url in options.get('gallery', [{}])[0].items() if img_url]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': options['title'],\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 41,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.uktvplay.UKTVPlayIE._real_extract#29",
        "src_path": "youtube_dl/extractor/uktvplay.py",
        "class_name": "youtube_dl.extractor.uktvplay.UKTVPlayIE",
        "signature": "youtube_dl.extractor.uktvplay.UKTVPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        return self.url_result(\n            self.BRIGHTCOVE_URL_TEMPLATE % video_id,\n            'BrightcoveNew', video_id)",
        "begin_line": 29,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.unistra.UnistraIE._real_extract#35",
        "src_path": "youtube_dl/extractor/unistra.py",
        "class_name": "youtube_dl.extractor.unistra.UnistraIE",
        "signature": "youtube_dl.extractor.unistra.UnistraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        files = set(re.findall(r'file\\s*:\\s*\"(/[^\"]+)\"', webpage))\n\n        quality = qualities(['SD', 'HD'])\n        formats = []\n        for file_path in files:\n            format_id = 'HD' if file_path.endswith('-HD.mp4') else 'SD'\n            formats.append({\n                'url': 'http://vod-flash.u-strasbg.fr:8080%s' % file_path,\n                'format_id': format_id,\n                'quality': quality(format_id)\n            })\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'<title>UTV - (.*?)</', webpage, 'title')\n        description = self._html_search_regex(\n            r'<meta name=\"Description\" content=\"(.*?)\"', webpage, 'description', flags=re.DOTALL)\n        thumbnail = self._search_regex(\n            r'image: \"(.*?)\"', webpage, 'thumbnail')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats\n        }",
        "begin_line": 35,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.uol.UOLIE._real_extract#85",
        "src_path": "youtube_dl/extractor/uol.py",
        "class_name": "youtube_dl.extractor.uol.UOLIE",
        "signature": "youtube_dl.extractor.uol.UOLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        media_id = None\n\n        if video_id.isdigit():\n            media_id = video_id\n\n        if not media_id:\n            embed_page = self._download_webpage(\n                'https://jsuol.com.br/c/tv/uol/embed/?params=[embed,%s]' % video_id,\n                video_id, 'Downloading embed page', fatal=False)\n            if embed_page:\n                media_id = self._search_regex(\n                    (r'uol\\.com\\.br/(\\d+)', r'mediaId=(\\d+)'),\n                    embed_page, 'media id', default=None)\n\n        if not media_id:\n            webpage = self._download_webpage(url, video_id)\n            media_id = self._search_regex(r'mediaId=(\\d+)', webpage, 'media id')\n\n        video_data = self._download_json(\n            'http://mais.uol.com.br/apiuol/v3/player/getMedia/%s.json' % media_id,\n            media_id)['item']\n        title = video_data['title']\n\n        query = {\n            'ver': video_data.get('numRevision', 2),\n            'r': 'http://mais.uol.com.br',\n        }\n        formats = []\n        for f in video_data.get('formats', []):\n            f_url = f.get('url') or f.get('secureUrl')\n            if not f_url:\n                continue\n            format_id = str_or_none(f.get('id'))\n            fmt = {\n                'format_id': format_id,\n                'url': update_url_query(f_url, query),\n            }\n            fmt.update(self._FORMATS.get(format_id, {}))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        tags = []\n        for tag in video_data.get('tags', []):\n            tag_description = tag.get('description')\n            if not tag_description:\n                continue\n            tags.append(tag_description)\n\n        return {\n            'id': media_id,\n            'title': title,\n            'description': clean_html(video_data.get('desMedia')),\n            'thumbnail': video_data.get('thumbnail'),\n            'duration': int_or_none(video_data.get('durationSeconds')) or parse_duration(video_data.get('duration')),\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 85,
        "end_line": 143,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.uplynk.UplynkIE._extract_uplynk_info#30",
        "src_path": "youtube_dl/extractor/uplynk.py",
        "class_name": "youtube_dl.extractor.uplynk.UplynkIE",
        "signature": "youtube_dl.extractor.uplynk.UplynkIE._extract_uplynk_info(self, uplynk_content_url)",
        "snippet": "    def _extract_uplynk_info(self, uplynk_content_url):\n        path, external_id, video_id, session_id = re.match(UplynkIE._VALID_URL, uplynk_content_url).groups()\n        display_id = video_id or external_id\n        formats = self._extract_m3u8_formats(\n            'http://content.uplynk.com/%s.m3u8' % path,\n            display_id, 'mp4', 'm3u8_native')\n        if session_id:\n            for f in formats:\n                f['extra_param_to_segment_url'] = 'pbs=' + session_id\n        self._sort_formats(formats)\n        asset = self._download_json('http://content.uplynk.com/player/assetinfo/%s.json' % path, display_id)\n        if asset.get('error') == 1:\n            raise ExtractorError('% said: %s' % (self.IE_NAME, asset['msg']), expected=True)\n\n        return {\n            'id': asset['asset'],\n            'title': asset['desc'],\n            'thumbnail': asset.get('default_poster_url'),\n            'duration': float_or_none(asset.get('duration')),\n            'uploader_id': asset.get('owner'),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.uplynk.UplynkIE._real_extract#53",
        "src_path": "youtube_dl/extractor/uplynk.py",
        "class_name": "youtube_dl.extractor.uplynk.UplynkIE",
        "signature": "youtube_dl.extractor.uplynk.UplynkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_uplynk_info(url)",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.uplynk.UplynkPreplayIE._real_extract#62",
        "src_path": "youtube_dl/extractor/uplynk.py",
        "class_name": "youtube_dl.extractor.uplynk.UplynkPreplayIE",
        "signature": "youtube_dl.extractor.uplynk.UplynkPreplayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        path, external_id, video_id = re.match(self._VALID_URL, url).groups()\n        display_id = video_id or external_id\n        preplay = self._download_json(url, display_id)\n        content_url = 'http://content.uplynk.com/%s.m3u8' % path\n        session_id = preplay.get('sid')\n        if session_id:\n            content_url += '?pbs=' + session_id\n        return self._extract_uplynk_info(content_url)",
        "begin_line": 62,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.upskill.UpskillBaseIE._real_initialize#21",
        "src_path": "youtube_dl/extractor/upskill.py",
        "class_name": "youtube_dl.extractor.upskill.UpskillBaseIE",
        "signature": "youtube_dl.extractor.upskill.UpskillBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.upskill.UpskillBaseIE._login#24",
        "src_path": "youtube_dl/extractor/upskill.py",
        "class_name": "youtube_dl.extractor.upskill.UpskillBaseIE",
        "signature": "youtube_dl.extractor.upskill.UpskillBaseIE._login(self)",
        "snippet": "    def _login(self):\n        username, password = self._get_login_info()\n        if username is None:\n            return\n\n        login_page, urlh = self._download_webpage_handle(\n            self._LOGIN_URL, None, 'Downloading login page')\n\n        login_url = compat_str(urlh.geturl())\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'user[email]': username,\n            'user[password]': password,\n        })\n\n        post_url = self._search_regex(\n            r'<form[^>]+action=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', login_page,\n            'post url', default=login_url, group='url')\n\n        if not post_url.startswith('http'):\n            post_url = urljoin(login_url, post_url)\n\n        response = self._download_webpage(\n            post_url, None, 'Logging in',\n            data=urlencode_postdata(login_form),\n            headers={\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Referer': login_url,\n            })\n\n        # Successful login\n        if any(re.search(p, response) for p in (\n                r'class=[\"\\']user-signout',\n                r'<a[^>]+\\bhref=[\"\\']/sign_out',\n                r'>\\s*Log out\\s*<')):\n            return\n\n        message = get_element_by_class('alert', response)\n        if message is not None:\n            raise ExtractorError(\n                'Unable to login: %s' % clean_html(message), expected=True)\n\n        raise ExtractorError('Unable to log in')",
        "begin_line": 24,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.upskill.UpskillIE._real_extract#93",
        "src_path": "youtube_dl/extractor/upskill.py",
        "class_name": "youtube_dl.extractor.upskill.UpskillIE",
        "signature": "youtube_dl.extractor.upskill.UpskillIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        wistia_url = WistiaIE._extract_url(webpage)\n        if not wistia_url:\n            if any(re.search(p, webpage) for p in (\n                    r'class=[\"\\']lecture-contents-locked',\n                    r'>\\s*Lecture contents locked',\n                    r'id=[\"\\']lecture-locked')):\n                self.raise_login_required('Lecture contents locked')\n\n        title = self._og_search_title(webpage, default=None)\n\n        return {\n            '_type': 'url_transparent',\n            'url': wistia_url,\n            'ie_key': WistiaIE.ie_key(),\n            'title': title,\n        }",
        "begin_line": 93,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.upskill.UpskillCourseIE.suitable#134",
        "src_path": "youtube_dl/extractor/upskill.py",
        "class_name": "youtube_dl.extractor.upskill.UpskillCourseIE",
        "signature": "youtube_dl.extractor.upskill.UpskillCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if UpskillIE.suitable(url) else super(\n            UpskillCourseIE, cls).suitable(url)",
        "begin_line": 134,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.upskill.UpskillCourseIE._real_extract#138",
        "src_path": "youtube_dl/extractor/upskill.py",
        "class_name": "youtube_dl.extractor.upskill.UpskillCourseIE",
        "signature": "youtube_dl.extractor.upskill.UpskillCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        course_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, course_id)\n\n        course_id = self._search_regex(\n            r'data-course-id=[\"\\'](\\d+)', webpage, 'course id',\n            default=course_id)\n\n        entries = []\n\n        for mobj in re.finditer(\n                r'(?s)(?P<li><li[^>]+class=([\"\\'])(?:(?!\\2).)*?section-item[^>]+>.+?</li>)',\n                webpage):\n            li = mobj.group('li')\n            if 'fa-youtube-play' not in li:\n                continue\n            lecture_url = self._search_regex(\n                r'<a[^>]+href=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', li,\n                'lecture url', default=None, group='url')\n            if not lecture_url:\n                continue\n            lecture_id = self._search_regex(\n                r'/lectures/(\\d+)', lecture_url, 'lecture id', default=None)\n            title = self._html_search_regex(\n                r'<span[^>]+class=[\"\\']lecture-name[^>]+>([^<]+)', li,\n                'title', default=None)\n            entries.append(\n                self.url_result(\n                    urljoin('http://upskillcourses.com/', lecture_url),\n                    ie=UpskillIE.ie_key(), video_id=lecture_id,\n                    video_title=clean_html(title)))\n\n        course_title = self._html_search_regex(\n            (r'(?s)<img[^>]+class=[\"\\']course-image[^>]+>\\s*<h\\d>(.+?)</h',\n             r'(?s)<h\\d[^>]+class=[\"\\']course-title[^>]+>(.+?)</h'),\n            webpage, 'course title', fatal=False)\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 138,
        "end_line": 176,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.urort.UrortIE._real_extract#34",
        "src_path": "youtube_dl/extractor/urort.py",
        "class_name": "youtube_dl.extractor.urort.UrortIE",
        "signature": "youtube_dl.extractor.urort.UrortIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        fstr = compat_urllib_parse.quote(\"InternalBandUrl eq '%s'\" % playlist_id)\n        json_url = 'http://urort.p3.no/breeze/urort/TrackDTOViews?$filter=%s&$orderby=Released%%20desc&$expand=Tags%%2CFiles' % fstr\n        songs = self._download_json(json_url, playlist_id)\n        entries = []\n        for s in songs:\n            formats = [{\n                'tbr': f.get('Quality'),\n                'ext': f['FileType'],\n                'format_id': '%s-%s' % (f['FileType'], f.get('Quality', '')),\n                'url': 'http://p3urort.blob.core.windows.net/tracks/%s' % f['FileRef'],\n                'preference': 3 if f['FileType'] == 'mp3' else 2,\n            } for f in s['Files']]\n            self._sort_formats(formats)\n            e = {\n                'id': '%d-%s' % (s['BandId'], s['$id']),\n                'title': s['Title'],\n                'uploader_id': playlist_id,\n                'uploader': s.get('BandName', playlist_id),\n                'thumbnail': 'http://urort.p3.no/cloud/images/%s' % s['Image'],\n                'upload_date': unified_strdate(s.get('Released')),\n                'formats': formats,\n            }\n            entries.append(e)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_id,\n            'entries': entries,\n        }",
        "begin_line": 34,
        "end_line": 66,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.urplay.URPlayIE._real_extract#23",
        "src_path": "youtube_dl/extractor/urplay.py",
        "class_name": "youtube_dl.extractor.urplay.URPlayIE",
        "signature": "youtube_dl.extractor.urplay.URPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        urplayer_data = self._parse_json(self._search_regex(\n            r'urPlayer\\.init\\(({.+?})\\);', webpage, 'urplayer data'), video_id)\n        host = self._download_json('http://streaming-loadbalancer.ur.se/loadbalancer.json', video_id)['redirect']\n\n        formats = []\n        for quality_attr, quality, preference in (('', 'sd', 0), ('_hd', 'hd', 1)):\n            file_http = urplayer_data.get('file_http' + quality_attr) or urplayer_data.get('file_http_sub' + quality_attr)\n            if file_http:\n                formats.extend(self._extract_wowza_formats(\n                    'http://%s/%splaylist.m3u8' % (host, file_http), video_id, skip_protocols=['rtmp', 'rtsp']))\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for subtitle in urplayer_data.get('subtitles', []):\n            subtitle_url = subtitle.get('file')\n            kind = subtitle.get('kind')\n            if not subtitle_url or (kind and kind != 'captions'):\n                continue\n            subtitles.setdefault(subtitle.get('label', 'Svenska'), []).append({\n                'url': subtitle_url,\n            })\n\n        return {\n            'id': video_id,\n            'title': urplayer_data['title'],\n            'description': self._og_search_description(webpage),\n            'thumbnail': urplayer_data.get('image'),\n            'series': urplayer_data.get('series_title'),\n            'subtitles': subtitles,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.usanetwork.USANetworkIE._real_extract#30",
        "src_path": "youtube_dl/extractor/usanetwork.py",
        "class_name": "youtube_dl.extractor.usanetwork.USANetworkIE",
        "signature": "youtube_dl.extractor.usanetwork.USANetworkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(url, display_id)\n\n        player_params = extract_attributes(self._search_regex(\n            r'(<div[^>]+data-usa-tve-player-container[^>]*>)', webpage, 'player params'))\n        video_id = player_params['data-mpx-guid']\n        title = player_params['data-episode-title']\n\n        account_pid, path = re.search(\n            r'data-src=\"(?:https?)?//player\\.theplatform\\.com/p/([^/]+)/.*?/(media/guid/\\d+/\\d+)',\n            webpage).groups()\n\n        query = {\n            'mbr': 'true',\n        }\n        if player_params.get('data-is-full-episode') == '1':\n            query['manifest'] = 'm3u'\n\n        if player_params.get('data-entitlement') == 'auth':\n            adobe_pass = {}\n            drupal_settings = self._search_regex(\n                r'jQuery\\.extend\\(Drupal\\.settings\\s*,\\s*({.+?})\\);',\n                webpage, 'drupal settings', fatal=False)\n            if drupal_settings:\n                drupal_settings = self._parse_json(drupal_settings, video_id, fatal=False)\n                if drupal_settings:\n                    adobe_pass = drupal_settings.get('adobePass', {})\n            resource = self._get_mvpd_resource(\n                adobe_pass.get('adobePassResourceId', 'usa'),\n                title, video_id, player_params.get('data-episode-rating', 'TV-14'))\n            query['auth'] = self._extract_mvpd_auth(\n                url, video_id, adobe_pass.get('adobePassRequestorId', 'usa'), resource)\n\n        info = self._search_json_ld(webpage, video_id, default={})\n        info.update({\n            '_type': 'url_transparent',\n            'url': smuggle_url(update_url_query(\n                'http://link.theplatform.com/s/%s/%s' % (account_pid, path),\n                query), {'force_smil_url': True}),\n            'id': video_id,\n            'title': title,\n            'series': player_params.get('data-show-title'),\n            'episode': title,\n            'ie_key': 'ThePlatform',\n        })\n        return info",
        "begin_line": 30,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.usatoday.USATodayIE._real_extract#31",
        "src_path": "youtube_dl/extractor/usatoday.py",
        "class_name": "youtube_dl.extractor.usatoday.USATodayIE",
        "signature": "youtube_dl.extractor.usatoday.USATodayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = self._download_webpage(update_url_query(url, {'ajax': 'true'}), display_id)\n        ui_video_data = get_element_by_attribute('class', 'ui-video-data', webpage)\n        if not ui_video_data:\n            raise ExtractorError('no video on the webpage', expected=True)\n        video_data = self._parse_json(ui_video_data, display_id)\n\n        return {\n            '_type': 'url_transparent',\n            'url': self.BRIGHTCOVE_URL_TEMPLATE % video_data['brightcove_id'],\n            'id': compat_str(video_data['id']),\n            'title': video_data['title'],\n            'thumbnail': video_data.get('thumbnail'),\n            'description': video_data.get('description'),\n            'duration': parse_duration(video_data.get('length')),\n            'ie_key': 'BrightcoveNew',\n        }",
        "begin_line": 31,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._extract_url#73",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://www\\.ustream\\.tv/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return mobj.group('url')",
        "begin_line": 73,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._get_stream_info#79",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._get_stream_info(self, url, video_id, app_id_ver, extra_note=None)",
        "snippet": "    def _get_stream_info(self, url, video_id, app_id_ver, extra_note=None):\n        def num_to_hex(n):\n            return hex(n)[2:]\n\n        rnd = random.randrange\n\n        if not extra_note:\n            extra_note = ''\n\n        conn_info = self._download_json(\n            'http://r%d-1-%s-recorded-lp-live.ums.ustream.tv/1/ustream' % (rnd(1e8), video_id),\n            video_id, note='Downloading connection info' + extra_note,\n            query={\n                'type': 'viewer',\n                'appId': app_id_ver[0],\n                'appVersion': app_id_ver[1],\n                'rsid': '%s:%s' % (num_to_hex(rnd(1e8)), num_to_hex(rnd(1e8))),\n                'rpin': '_rpin.%d' % rnd(1e15),\n                'referrer': url,\n                'media': video_id,\n                'application': 'recorded',\n            })\n        host = conn_info[0]['args'][0]['host']\n        connection_id = conn_info[0]['args'][0]['connectionId']\n\n        return self._download_json(\n            'http://%s/1/ustream?connectionId=%s' % (host, connection_id),\n            video_id, note='Downloading stream info' + extra_note)",
        "begin_line": 79,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._get_streams#108",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._get_streams(self, url, video_id, app_id_ver)",
        "snippet": "    def _get_streams(self, url, video_id, app_id_ver):\n        # Sometimes the return dict does not have 'stream'\n        for trial_count in range(3):\n            stream_info = self._get_stream_info(\n                url, video_id, app_id_ver,\n                extra_note=' (try %d)' % (trial_count + 1) if trial_count > 0 else '')\n            if 'stream' in stream_info[0]['args'][0]:\n                return stream_info[0]['args'][0]['stream']\n        return []",
        "begin_line": 108,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._parse_segmented_mp4#118",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._parse_segmented_mp4(self, dash_stream_info)",
        "snippet": "    def _parse_segmented_mp4(self, dash_stream_info):\n        def resolve_dash_template(template, idx, chunk_hash):\n            return template.replace('%', compat_str(idx), 1).replace('%', chunk_hash)\n\n        formats = []\n        for stream in dash_stream_info['streams']:\n            # Use only one provider to avoid too many formats\n            provider = dash_stream_info['providers'][0]\n            fragments = [{\n                'url': resolve_dash_template(\n                    provider['url'] + stream['initUrl'], 0, dash_stream_info['hashes']['0'])\n            }]\n            for idx in range(dash_stream_info['videoLength'] // dash_stream_info['chunkTime']):\n                fragments.append({\n                    'url': resolve_dash_template(\n                        provider['url'] + stream['segmentUrl'], idx,\n                        dash_stream_info['hashes'][compat_str(idx // 10 * 10)])\n                })\n            content_type = stream['contentType']\n            kind = content_type.split('/')[0]\n            f = {\n                'format_id': '-'.join(filter(None, [\n                    'dash', kind, str_or_none(stream.get('bitrate'))])),\n                'protocol': 'http_dash_segments',\n                # TODO: generate a MPD doc for external players?\n                'url': encode_data_uri(b'<MPD/>', 'text/xml'),\n                'ext': mimetype2ext(content_type),\n                'height': stream.get('height'),\n                'width': stream.get('width'),\n                'fragments': fragments,\n            }\n            if kind == 'video':\n                f.update({\n                    'vcodec': stream.get('codec'),\n                    'acodec': 'none',\n                    'vbr': stream.get('bitrate'),\n                })\n            else:\n                f.update({\n                    'vcodec': 'none',\n                    'acodec': stream.get('codec'),\n                    'abr': stream.get('bitrate'),\n                })\n            formats.append(f)\n        return formats",
        "begin_line": 118,
        "end_line": 162,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._real_extract#164",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        # some sites use this embed format (see: https://github.com/rg3/youtube-dl/issues/2990)\n        if m.group('type') == 'embed/recorded':\n            video_id = m.group('id')\n            desktop_url = 'http://www.ustream.tv/recorded/' + video_id\n            return self.url_result(desktop_url, 'Ustream')\n        if m.group('type') == 'embed':\n            video_id = m.group('id')\n            webpage = self._download_webpage(url, video_id)\n            content_video_ids = self._parse_json(self._search_regex(\n                r'ustream\\.vars\\.offAirContentVideoIds=([^;]+);', webpage,\n                'content video IDs'), video_id)\n            return self.playlist_result(\n                map(lambda u: self.url_result('http://www.ustream.tv/recorded/' + u, 'Ustream'), content_video_ids),\n                video_id)\n\n        params = self._download_json(\n            'https://api.ustream.tv/videos/%s.json' % video_id, video_id)\n\n        error = params.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        video = params['video']\n\n        title = video['title']\n        filesize = float_or_none(video.get('file_size'))\n\n        formats = [{\n            'id': video_id,\n            'url': video_url,\n            'ext': format_id,\n            'filesize': filesize,\n        } for format_id, video_url in video['media_urls'].items() if video_url]\n\n        if not formats:\n            hls_streams = self._get_streams(url, video_id, app_id_ver=(11, 2))\n            if hls_streams:\n                # m3u8_native leads to intermittent ContentTooShortError\n                formats.extend(self._extract_m3u8_formats(\n                    hls_streams[0]['url'], video_id, ext='mp4', m3u8_id='hls'))\n\n            '''\n            # DASH streams handling is incomplete as 'url' is missing\n            dash_streams = self._get_streams(url, video_id, app_id_ver=(3, 1))\n            if dash_streams:\n                formats.extend(self._parse_segmented_mp4(dash_streams))\n            '''\n\n        self._sort_formats(formats)\n\n        description = video.get('description')\n        timestamp = int_or_none(video.get('created_at'))\n        duration = float_or_none(video.get('length'))\n        view_count = int_or_none(video.get('views'))\n\n        uploader = video.get('owner', {}).get('username')\n        uploader_id = video.get('owner', {}).get('id')\n\n        thumbnails = [{\n            'id': thumbnail_id,\n            'url': thumbnail_url,\n        } for thumbnail_id, thumbnail_url in video.get('thumbnail', {}).items()]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnails': thumbnails,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 164,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract#257",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamChannelIE",
        "signature": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        display_id = m.group('slug')\n        webpage = self._download_webpage(url, display_id)\n        channel_id = self._html_search_meta('ustream:channel_id', webpage)\n\n        BASE = 'http://www.ustream.tv'\n        next_url = '/ajax/socialstream/videos/%s/1.json' % channel_id\n        video_ids = []\n        while next_url:\n            reply = self._download_json(\n                compat_urlparse.urljoin(BASE, next_url), display_id,\n                note='Downloading video information (next: %d)' % (len(video_ids) + 1))\n            video_ids.extend(re.findall(r'data-content-id=\"(\\d.*)\"', reply['data']))\n            next_url = reply['nextUrl']\n\n        entries = [\n            self.url_result('http://www.ustream.tv/recorded/' + vid, 'Ustream')\n            for vid in video_ids]\n        return {\n            '_type': 'playlist',\n            'id': channel_id,\n            'display_id': display_id,\n            'entries': entries,\n        }",
        "begin_line": 257,
        "end_line": 281,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustudio.UstudioIE._real_extract#31",
        "src_path": "youtube_dl/extractor/ustudio.py",
        "class_name": "youtube_dl.extractor.ustudio.UstudioIE",
        "signature": "youtube_dl.extractor.ustudio.UstudioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id = re.match(self._VALID_URL, url).groups()\n\n        config = self._download_xml(\n            'http://v1.ustudio.com/embed/%s/ustudio/config.xml' % video_id,\n            display_id)\n\n        def extract(kind):\n            return [{\n                'url': unescapeHTML(item.attrib['url']),\n                'width': int_or_none(item.get('width')),\n                'height': int_or_none(item.get('height')),\n            } for item in config.findall('./qualities/quality/%s' % kind) if item.get('url')]\n\n        formats = extract('video')\n        self._sort_formats(formats)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n        upload_date = unified_strdate(self._search_regex(\n            r'(?s)Uploaded by\\s*.+?\\s*on\\s*<span>([^<]+)</span>',\n            webpage, 'upload date', fatal=False))\n        uploader = self._search_regex(\n            r'Uploaded by\\s*<a[^>]*>([^<]+)<',\n            webpage, 'uploader', fatal=False)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnails': extract('image'),\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ustudio.UstudioEmbedIE._real_extract#85",
        "src_path": "youtube_dl/extractor/ustudio.py",
        "class_name": "youtube_dl.extractor.ustudio.UstudioEmbedIE",
        "signature": "youtube_dl.extractor.ustudio.UstudioEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        uploader_id, video_id = re.match(self._VALID_URL, url).groups()\n        video_data = self._download_json(\n            'http://app.ustudio.com/embed/%s/%s/config.json' % (uploader_id, video_id),\n            video_id)['videos'][0]\n        title = video_data['name']\n\n        formats = []\n        for ext, qualities in video_data.get('transcodes', {}).items():\n            for quality in qualities:\n                quality_url = quality.get('url')\n                if not quality_url:\n                    continue\n                height = int_or_none(quality.get('height'))\n                formats.append({\n                    'format_id': '%s-%dp' % (ext, height) if height else ext,\n                    'url': quality_url,\n                    'width': int_or_none(quality.get('width')),\n                    'height': height,\n                })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for image in video_data.get('images', []):\n            image_url = image.get('url')\n            if not image_url:\n                continue\n            thumbnails.append({\n                'url': image_url,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'duration': int_or_none(video_data.get('duration')),\n            'uploader_id': uploader_id,\n            'tags': video_data.get('keywords'),\n            'thumbnails': thumbnails,\n            'formats': formats,\n        }",
        "begin_line": 85,
        "end_line": 125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.varzesh3.Varzesh3IE._real_extract#40",
        "src_path": "youtube_dl/extractor/varzesh3.py",
        "class_name": "youtube_dl.extractor.varzesh3.Varzesh3IE",
        "signature": "youtube_dl.extractor.varzesh3.Varzesh3IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', webpage, 'video url')\n\n        title = remove_start(self._html_search_regex(\n            r'<title>([^<]+)</title>', webpage, 'title'), '\u0648\u06cc\u062f\u06cc\u0648 \u0648\u0631\u0632\u0634 3 | ')\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"matn\">(.+?)</div>',\n            webpage, 'description', default=None)\n        if description is None:\n            description = clean_html(self._html_search_meta('description', webpage))\n\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n        if thumbnail is None:\n            fb_sharer_url = self._search_regex(\n                r'<a[^>]+href=\"(https?://www\\.facebook\\.com/sharer/sharer\\.php?[^\"]+)\"',\n                webpage, 'facebook sharer URL', fatal=False)\n            sharer_params = compat_parse_qs(compat_urllib_parse_urlparse(fb_sharer_url).query)\n            thumbnail = sharer_params.get('p[images][0]', [None])[0]\n\n        video_id = self._search_regex(\n            r\"<link[^>]+rel='(?:canonical|shortlink)'[^>]+href='/\\?p=([^']+)'\",\n            webpage, display_id, default=None)\n        if video_id is None:\n            video_id = self._search_regex(\n                r'var\\s+VideoId\\s*=\\s*(\\d+);', webpage, 'video id',\n                default=display_id)\n\n        return {\n            'url': video_url,\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 40,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vbox7.Vbox7IE._extract_url#58",
        "src_path": "youtube_dl/extractor/vbox7.py",
        "class_name": "youtube_dl.extractor.vbox7.Vbox7IE",
        "signature": "youtube_dl.extractor.vbox7.Vbox7IE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=(?P<q>[\"\\'])(?P<url>(?:https?:)?//vbox7\\.com/emb/external\\.php.+?)(?P=q)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 58,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract#65",
        "src_path": "youtube_dl/extractor/vbox7.py",
        "class_name": "youtube_dl.extractor.vbox7.Vbox7IE",
        "signature": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        response = self._download_json(\n            'https://www.vbox7.com/ajax/video/nextvideo.php?vid=%s' % video_id,\n            video_id)\n\n        if 'error' in response:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, response['error']), expected=True)\n\n        video = response['options']\n\n        title = video['title']\n        video_url = video['src']\n\n        if '/na.mp4' in video_url:\n            self.raise_geo_restricted(countries=self._GEO_COUNTRIES)\n\n        uploader = video.get('uploader')\n\n        webpage = self._download_webpage(\n            'http://vbox7.com/play:%s' % video_id, video_id, fatal=None)\n\n        info = {}\n\n        if webpage:\n            info = self._search_json_ld(\n                webpage.replace('\"/*@context\"', '\"@context\"'), video_id,\n                fatal=False)\n\n        info.update({\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'uploader': uploader,\n            'thumbnail': self._proto_relative_url(\n                info.get('thumbnail') or self._og_search_thumbnail(webpage),\n                'http:'),\n        })\n        return info",
        "begin_line": 65,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.veehd.VeeHDIE._real_extract#53",
        "src_path": "youtube_dl/extractor/veehd.py",
        "class_name": "youtube_dl.extractor.veehd.VeeHDIE",
        "signature": "youtube_dl.extractor.veehd.VeeHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        # VeeHD seems to send garbage on the first request.\n        # See https://github.com/rg3/youtube-dl/issues/2102\n        self._download_webpage(url, video_id, 'Requesting webpage')\n        webpage = self._download_webpage(url, video_id)\n\n        if 'This video has been removed<' in webpage:\n            raise ExtractorError('Video %s has been removed' % video_id, expected=True)\n\n        player_path = self._search_regex(\n            r'\\$\\(\"#playeriframe\"\\).attr\\({src : \"(.+?)\"',\n            webpage, 'player path')\n        player_url = compat_urlparse.urljoin(url, player_path)\n\n        self._download_webpage(player_url, video_id, 'Requesting player page')\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n\n        video_url = None\n\n        config_json = self._search_regex(\n            r'value=\\'config=({.+?})\\'', player_page, 'config json', default=None)\n\n        if config_json:\n            config = json.loads(config_json)\n            video_url = compat_urllib_parse_unquote(config['clip']['url'])\n\n        if not video_url:\n            video_url = self._html_search_regex(\n                r'<embed[^>]+type=\"video/divx\"[^>]+src=\"([^\"]+)\"',\n                player_page, 'video url', default=None)\n\n        if not video_url:\n            iframe_src = self._search_regex(\n                r'<iframe[^>]+src=\"/?([^\"]+)\"', player_page, 'iframe url')\n            iframe_url = 'http://veehd.com/%s' % iframe_src\n\n            self._download_webpage(iframe_url, video_id, 'Requesting iframe page')\n            iframe_page = self._download_webpage(\n                iframe_url, video_id, 'Downloading iframe page')\n\n            video_url = self._search_regex(\n                r\"file\\s*:\\s*'([^']+)'\", iframe_page, 'video url')\n\n        title = clean_html(get_element_by_id('videoName', webpage).rpartition('|')[0])\n        uploader_id = self._html_search_regex(\n            r'<a href=\"/profile/\\d+\">(.+?)</a>',\n            webpage, 'uploader')\n        thumbnail = self._search_regex(\n            r'<img id=\"veehdpreview\" src=\"(.+?)\"',\n            webpage, 'thumbnail')\n        description = self._html_search_regex(\n            r'<td class=\"infodropdown\".*?<div>(.*?)<ul',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 53,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_formats#56",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_formats(self, source)",
        "snippet": "    def _extract_formats(self, source):\n        formats = []\n        link = source.get('aowPermalink')\n        if link:\n            formats.append({\n                'url': link,\n                'ext': 'mp4',\n                'format_id': 'aow',\n            })\n        link = source.get('fullPreviewHashLowPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'low',\n            })\n        link = source.get('fullPreviewHashHighPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'high',\n            })\n        return formats",
        "begin_line": 56,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_video#79",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_video(self, source)",
        "snippet": "    def _extract_video(self, source):\n        return {\n            'id': source.get('videoId'),\n            'title': source.get('title'),\n            'description': source.get('description'),\n            'thumbnail': source.get('highResImage') or source.get('medResImage'),\n            'uploader': source.get('username'),\n            'duration': int_or_none(source.get('length')),\n            'view_count': int_or_none(source.get('views')),\n            'age_limit': 18 if source.get('isMature') == 'true' or source.get('isSexy') == 'true' else 0,\n            'formats': self._extract_formats(source),\n        }",
        "begin_line": 79,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._real_extract#92",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if video_id.startswith('v'):\n            rsp = self._download_xml(\n                r'http://www.veoh.com/api/findByPermalink?permalink=%s' % video_id, video_id, 'Downloading video XML')\n            stat = rsp.get('stat')\n            if stat == 'ok':\n                return self._extract_video(rsp.find('./videoList/video'))\n            elif stat == 'fail':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, rsp.find('./errorList/error').get('errorMessage')), expected=True)\n\n        webpage = self._download_webpage(url, video_id)\n        age_limit = 0\n        if 'class=\"adultwarning-container\"' in webpage:\n            self.report_age_confirmation()\n            age_limit = 18\n            request = sanitized_Request(url)\n            request.add_header('Cookie', 'confirmedAdult=true')\n            webpage = self._download_webpage(request, video_id)\n\n        m_youtube = re.search(r'http://www\\.youtube\\.com/v/(.*?)(\\&|\"|\\?)', webpage)\n        if m_youtube is not None:\n            youtube_id = m_youtube.group(1)\n            self.to_screen('%s: detected Youtube video.' % video_id)\n            return self.url_result(youtube_id, 'Youtube')\n\n        info = json.loads(\n            self._search_regex(r'videoDetailsJSON = \\'({.*?})\\';', webpage, 'info').replace('\\\\\\'', '\\''))\n\n        video = self._extract_video(info)\n        video['age_limit'] = age_limit\n\n        return video",
        "begin_line": 92,
        "end_line": 127,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._extract_urls#44",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+src=([\"\\'])((?:https?:)?//(?:www\\.)?vessel\\.com/embed/[0-9a-zA-Z-_]+.*?)\\1',\n            webpage)]",
        "begin_line": 44,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE.make_json_request#50",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE.make_json_request(url, data)",
        "snippet": "    def make_json_request(url, data):\n        payload = json.dumps(data).encode('utf-8')\n        req = sanitized_Request(url, payload)\n        req.add_header('Content-Type', 'application/json; charset=utf-8')\n        return req",
        "begin_line": 50,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE.find_assets#57",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE.find_assets(data, asset_type, asset_id=None)",
        "snippet": "    def find_assets(data, asset_type, asset_id=None):\n        for asset in data.get('assets', []):\n            if not asset.get('type') == asset_type:\n                continue\n            elif asset_id is not None and not asset.get('id') == asset_id:\n                continue\n            else:\n                yield asset",
        "begin_line": 57,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._check_access_rights#66",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._check_access_rights(self, data)",
        "snippet": "    def _check_access_rights(self, data):\n        access_info = data.get('__view', {})\n        if not access_info.get('allow_access', True):\n            err_code = access_info.get('error_code') or ''\n            if err_code == 'ITEM_PAID_ONLY':\n                raise ExtractorError(\n                    'This video requires subscription.', expected=True)\n            else:\n                raise ExtractorError(\n                    'Access to this content is restricted. (%s said: %s)' % (self.IE_NAME, err_code), expected=True)",
        "begin_line": 66,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._login#77",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        data = {\n            'client_id': 'web',\n            'type': 'password',\n            'user_key': username,\n            'password': password,\n        }\n        login_request = VesselIE.make_json_request(self._LOGIN_URL, data)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 77,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._real_initialize#91",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 91,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vessel.VesselIE._real_extract#94",
        "src_path": "youtube_dl/extractor/vessel.py",
        "class_name": "youtube_dl.extractor.vessel.VesselIE",
        "signature": "youtube_dl.extractor.vessel.VesselIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        data = self._parse_json(self._search_regex(\n            r'App\\.bootstrapData\\((.*?)\\);', webpage, 'data'), video_id)\n        asset_id = data['model']['data']['id']\n\n        req = VesselIE.make_json_request(\n            self._API_URL_TEMPLATE % asset_id, {'client': 'web'})\n        data = self._download_json(req, video_id)\n        video_asset_id = data.get('main_video_asset')\n\n        self._check_access_rights(data)\n\n        try:\n            video_asset = next(\n                VesselIE.find_assets(data, 'video', asset_id=video_asset_id))\n        except StopIteration:\n            raise ExtractorError('No video assets found')\n\n        formats = []\n        for f in video_asset.get('sources', []):\n            location = f.get('location')\n            if not location:\n                continue\n            name = f.get('name')\n            if name == 'hls-index':\n                formats.extend(self._extract_m3u8_formats(\n                    location, video_id, ext='mp4',\n                    entry_protocol='m3u8_native', m3u8_id='m3u8', fatal=False))\n            elif name == 'dash-index':\n                formats.extend(self._extract_mpd_formats(\n                    location, video_id, mpd_id='dash', fatal=False))\n            else:\n                formats.append({\n                    'format_id': name,\n                    'tbr': f.get('bitrate'),\n                    'height': f.get('height'),\n                    'width': f.get('width'),\n                    'url': location,\n                })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        for im_asset in VesselIE.find_assets(data, 'image'):\n            thumbnails.append({\n                'url': im_asset['location'],\n                'width': im_asset.get('width', 0),\n                'height': im_asset.get('height', 0),\n            })\n\n        return {\n            'id': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'description': data.get('short_description'),\n            'duration': data.get('duration'),\n            'comment_count': data.get('comment_count'),\n            'like_count': data.get('like_count'),\n            'view_count': data.get('view_count'),\n            'timestamp': parse_iso8601(data.get('released_at')),\n        }",
        "begin_line": 94,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vesti.VestiIE._real_extract#103",
        "src_path": "youtube_dl/extractor/vesti.py",
        "class_name": "youtube_dl.extractor.vesti.VestiIE",
        "signature": "youtube_dl.extractor.vesti.VestiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=\"og:video\"[^>]+?content=\"http://www\\.vesti\\.ru/i/flvplayer_videoHost\\.swf\\?vid=(?P<id>\\d+)',\n            page)\n        if mobj:\n            video_id = mobj.group('id')\n            page = self._download_webpage('http://www.vesti.ru/only_video.html?vid=%s' % video_id, video_id,\n                                          'Downloading video page')\n\n        rutv_url = RUTVIE._extract_url(page)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        raise ExtractorError('No video found', expected=True)",
        "begin_line": 103,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoBaseIE._extract_json#20",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoBaseIE",
        "signature": "youtube_dl.extractor.vevo.VevoBaseIE._extract_json(self, webpage, video_id)",
        "snippet": "    def _extract_json(self, webpage, video_id):\n        return self._parse_json(\n            self._search_regex(\n                r'window\\.__INITIAL_STORE__\\s*=\\s*({.+?});\\s*</script>',\n                webpage, 'initial store'),\n            video_id)",
        "begin_line": 20,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._initialize_api#156",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._initialize_api(self, video_id)",
        "snippet": "    def _initialize_api(self, video_id):\n        webpage = self._download_webpage(\n            'https://accounts.vevo.com/token', None,\n            note='Retrieving oauth token',\n            errnote='Unable to retrieve oauth token',\n            data=json.dumps({\n                'client_id': 'SPupX1tvqFEopQ1YS6SS',\n                'grant_type': 'urn:vevo:params:oauth:grant-type:anonymous',\n            }).encode('utf-8'),\n            headers={\n                'Content-Type': 'application/json',\n            })\n\n        if re.search(r'(?i)THIS PAGE IS CURRENTLY UNAVAILABLE IN YOUR REGION', webpage):\n            self.raise_geo_restricted(\n                '%s said: This page is currently unavailable in your region' % self.IE_NAME)\n\n        auth_info = self._parse_json(webpage, video_id)\n        self._api_url_template = self.http_scheme() + '//apiv2.vevo.com/%s?token=' + auth_info['legacy_token']",
        "begin_line": 156,
        "end_line": 174,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._call_api#176",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._call_api(self, path, *args, **kwargs)",
        "snippet": "    def _call_api(self, path, *args, **kwargs):\n        try:\n            data = self._download_json(self._api_url_template % path, *args, **kwargs)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                errors = self._parse_json(e.cause.read().decode(), None)['errors']\n                error_message = ', '.join([error['message'] for error in errors])\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, error_message), expected=True)\n            raise\n        return data",
        "begin_line": 176,
        "end_line": 185,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._real_extract#187",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        self._initialize_api(video_id)\n\n        video_info = self._call_api(\n            'video/%s' % video_id, video_id, 'Downloading api video info',\n            'Failed to download video info')\n\n        video_versions = self._call_api(\n            'video/%s/streams' % video_id, video_id,\n            'Downloading video versions info',\n            'Failed to download video versions info',\n            fatal=False)\n\n        # Some videos are only available via webpage (e.g.\n        # https://github.com/rg3/youtube-dl/issues/9366)\n        if not video_versions:\n            webpage = self._download_webpage(url, video_id)\n            json_data = self._extract_json(webpage, video_id)\n            if 'streams' in json_data.get('default', {}):\n                video_versions = json_data['default']['streams'][video_id][0]\n            else:\n                video_versions = [\n                    value\n                    for key, value in json_data['apollo']['data'].items()\n                    if key.startswith('%s.streams' % video_id)]\n\n        uploader = None\n        artist = None\n        featured_artist = None\n        artists = video_info.get('artists')\n        for curr_artist in artists:\n            if curr_artist.get('role') == 'Featured':\n                featured_artist = curr_artist['name']\n            else:\n                artist = uploader = curr_artist['name']\n\n        formats = []\n        for video_version in video_versions:\n            version = self._VERSIONS.get(video_version.get('version'), 'generic')\n            version_url = video_version.get('url')\n            if not version_url:\n                continue\n\n            if '.ism' in version_url:\n                continue\n            elif '.mpd' in version_url:\n                formats.extend(self._extract_mpd_formats(\n                    version_url, video_id, mpd_id='dash-%s' % version,\n                    note='Downloading %s MPD information' % version,\n                    errnote='Failed to download %s MPD information' % version,\n                    fatal=False))\n            elif '.m3u8' in version_url:\n                formats.extend(self._extract_m3u8_formats(\n                    version_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id='hls-%s' % version,\n                    note='Downloading %s m3u8 information' % version,\n                    errnote='Failed to download %s m3u8 information' % version,\n                    fatal=False))\n            else:\n                m = re.search(r'''(?xi)\n                    _(?P<width>[0-9]+)x(?P<height>[0-9]+)\n                    _(?P<vcodec>[a-z0-9]+)\n                    _(?P<vbr>[0-9]+)\n                    _(?P<acodec>[a-z0-9]+)\n                    _(?P<abr>[0-9]+)\n                    \\.(?P<ext>[a-z0-9]+)''', version_url)\n                if not m:\n                    continue\n\n                formats.append({\n                    'url': version_url,\n                    'format_id': 'http-%s-%s' % (version, video_version['quality']),\n                    'vcodec': m.group('vcodec'),\n                    'acodec': m.group('acodec'),\n                    'vbr': int(m.group('vbr')),\n                    'abr': int(m.group('abr')),\n                    'ext': m.group('ext'),\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n        self._sort_formats(formats)\n\n        track = video_info['title']\n        if featured_artist:\n            artist = '%s ft. %s' % (artist, featured_artist)\n        title = '%s - %s' % (artist, track) if artist else track\n\n        genres = video_info.get('genres')\n        genre = (\n            genres[0] if genres and isinstance(genres, list) and\n            isinstance(genres[0], compat_str) else None)\n\n        is_explicit = video_info.get('isExplicit')\n        if is_explicit is True:\n            age_limit = 18\n        elif is_explicit is False:\n            age_limit = 0\n        else:\n            age_limit = None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': video_info.get('imageUrl') or video_info.get('thumbnailUrl'),\n            'timestamp': parse_iso8601(video_info.get('releaseDate')),\n            'uploader': uploader,\n            'duration': int_or_none(video_info.get('duration')),\n            'view_count': int_or_none(video_info.get('views', {}).get('total')),\n            'age_limit': age_limit,\n            'track': track,\n            'artist': uploader,\n            'genre': genre,\n        }",
        "begin_line": 187,
        "end_line": 302,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoPlaylistIE._real_extract#342",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoPlaylistIE",
        "signature": "youtube_dl.extractor.vevo.VevoPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        playlist_kind = mobj.group('kind')\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        index = qs.get('index', [None])[0]\n\n        if index:\n            video_id = self._search_regex(\n                r'<meta[^>]+content=([\"\\'])vevo://video/(?P<id>.+?)\\1[^>]*>',\n                webpage, 'video id', default=None, group='id')\n            if video_id:\n                return self.url_result('vevo:%s' % video_id, VevoIE.ie_key())\n\n        playlists = self._extract_json(webpage, playlist_id)['default']['%ss' % playlist_kind]\n\n        playlist = (list(playlists.values())[0]\n                    if playlist_kind == 'playlist' else playlists[playlist_id])\n\n        entries = [\n            self.url_result('vevo:%s' % src, VevoIE.ie_key())\n            for src in playlist['isrcs']]\n\n        return self.playlist_result(\n            entries, playlist.get('playlistId') or playlist_id,\n            playlist.get('name'), playlist.get('description'))",
        "begin_line": 342,
        "end_line": 370,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vgtv.VGTVIE._real_extract#152",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.VGTVIE",
        "signature": "youtube_dl.extractor.vgtv.VGTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        host = mobj.group('host')\n        appname = self._HOST_TO_APPNAME[host] if host else mobj.group('appname')\n        vendor = self._APP_NAME_TO_VENDOR[appname]\n\n        data = self._download_json(\n            'http://svp.vg.no/svp/api/v1/%s/assets/%s?appName=%s-website'\n            % (vendor, video_id, appname),\n            video_id, 'Downloading media JSON')\n\n        if data.get('status') == 'inactive':\n            raise ExtractorError(\n                'Video %s is no longer available' % video_id, expected=True)\n\n        info = {\n            'formats': [],\n        }\n        if len(video_id) == 5:\n            if appname == 'bttv':\n                info = self._extract_video_info('btno', video_id)\n\n        streams = data['streamUrls']\n        stream_type = data.get('streamType')\n\n        formats = []\n\n        hls_url = streams.get('hls')\n        if hls_url:\n            formats.extend(self._extract_m3u8_formats(\n                hls_url, video_id, 'mp4', m3u8_id='hls', fatal=False))\n\n        hds_url = streams.get('hds')\n        if hds_url:\n            hdcore_sign = 'hdcore=3.7.0'\n            f4m_formats = self._extract_f4m_formats(\n                hds_url + '?%s' % hdcore_sign, video_id, f4m_id='hds', fatal=False)\n            if f4m_formats:\n                for entry in f4m_formats:\n                    # URLs without the extra param induce an 404 error\n                    entry.update({'extra_param_to_segment_url': hdcore_sign})\n                    formats.append(entry)\n\n        mp4_urls = streams.get('pseudostreaming') or []\n        mp4_url = streams.get('mp4')\n        if mp4_url:\n            mp4_urls.append(mp4_url)\n        for mp4_url in mp4_urls:\n            format_info = {\n                'url': mp4_url,\n            }\n            mobj = re.search(r'(\\d+)_(\\d+)_(\\d+)', mp4_url)\n            if mobj:\n                tbr = int(mobj.group(3))\n                format_info.update({\n                    'width': int(mobj.group(1)),\n                    'height': int(mobj.group(2)),\n                    'tbr': tbr,\n                    'format_id': 'mp4-%s' % tbr,\n                })\n            formats.append(format_info)\n\n        info['formats'].extend(formats)\n\n        if not info['formats']:\n            properties = try_get(\n                data, lambda x: x['streamConfiguration']['properties'], list)\n            if properties and 'geoblocked' in properties:\n                raise self.raise_geo_restricted(\n                    countries=[host.rpartition('.')[-1].partition('/')[0].upper()])\n\n        self._sort_formats(info['formats'])\n\n        info.update({\n            'id': video_id,\n            'title': self._live_title(data['title']) if stream_type == 'live' else data['title'],\n            'description': data['description'],\n            'thumbnail': data['images']['main'] + '?t[]=900x506q80',\n            'timestamp': data['published'],\n            'duration': float_or_none(data['duration'], 1000),\n            'view_count': data['displays'],\n            'is_live': True if stream_type == 'live' else False,\n        })\n        return info",
        "begin_line": 152,
        "end_line": 236,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vgtv.BTArticleIE._real_extract#259",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.BTArticleIE",
        "signature": "youtube_dl.extractor.vgtv.BTArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, self._match_id(url))\n        video_id = self._search_regex(\n            r'<video[^>]+data-id=\"(\\d+)\"', webpage, 'video id')\n        return self.url_result('bttv:%s' % video_id, 'VGTV')",
        "begin_line": 259,
        "end_line": 263,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vgtv.BTVestlendingenIE._real_extract#295",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.BTVestlendingenIE",
        "signature": "youtube_dl.extractor.vgtv.BTVestlendingenIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self.url_result('bttv:%s' % self._match_id(url), 'VGTV')",
        "begin_line": 295,
        "end_line": 296,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vh1.VH1IE._real_extract#111",
        "src_path": "youtube_dl/extractor/vh1.py",
        "class_name": "youtube_dl.extractor.vh1.VH1IE",
        "signature": "youtube_dl.extractor.vh1.VH1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj.group('music_id'):\n            id_field = 'vid'\n            video_id = mobj.group('music_id')\n        else:\n            video_id = mobj.group('playlist_id') or mobj.group('video_id')\n            id_field = 'id'\n        doc_url = '%s?%s=%s' % (self._FEED_URL, id_field, video_id)\n\n        idoc = self._download_xml(\n            doc_url, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n\n        entries = []\n        for item in idoc.findall('.//item'):\n            info = self._get_video_info(item)\n            if info:\n                entries.append(info)\n\n        return self.playlist_result(entries, playlist_id=video_id)",
        "begin_line": 111,
        "end_line": 131,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vice.ViceBaseIE._extract_preplay_video#23",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceBaseIE",
        "signature": "youtube_dl.extractor.vice.ViceBaseIE._extract_preplay_video(self, url, locale, webpage)",
        "snippet": "    def _extract_preplay_video(self, url, locale, webpage):\n        watch_hub_data = extract_attributes(self._search_regex(\n            r'(?s)(<watch-hub\\s*.+?</watch-hub>)', webpage, 'watch hub'))\n        video_id = watch_hub_data['vms-id']\n        title = watch_hub_data['video-title']\n\n        query = {}\n        is_locked = watch_hub_data.get('video-locked') == '1'\n        if is_locked:\n            resource = self._get_mvpd_resource(\n                'VICELAND', title, video_id,\n                watch_hub_data.get('video-rating'))\n            query['tvetoken'] = self._extract_mvpd_auth(\n                url, video_id, 'VICELAND', resource)\n\n        # signature generation algorithm is reverse engineered from signatureGenerator in\n        # webpack:///../shared/~/vice-player/dist/js/vice-player.js in\n        # https://www.viceland.com/assets/common/js/web.vendor.bundle.js\n        exp = int(time.time()) + 14400\n        query.update({\n            'exp': exp,\n            'sign': hashlib.sha512(('%s:GET:%d' % (video_id, exp)).encode()).hexdigest(),\n        })\n\n        try:\n            host = 'www.viceland' if is_locked else self._PREPLAY_HOST\n            preplay = self._download_json(\n                'https://%s.com/%s/preplay/%s' % (host, locale, video_id),\n                video_id, query=query)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 400:\n                error = json.loads(e.cause.read().decode())\n                raise ExtractorError('%s said: %s' % (\n                    self.IE_NAME, error['details']), expected=True)\n            raise\n\n        video_data = preplay['video']\n        base = video_data['base']\n        uplynk_preplay_url = preplay['preplayURL']\n        episode = video_data.get('episode', {})\n        channel = video_data.get('channel', {})\n\n        subtitles = {}\n        cc_url = preplay.get('ccURL')\n        if cc_url:\n            subtitles['en'] = [{\n                'url': cc_url,\n            }]\n\n        return {\n            '_type': 'url_transparent',\n            'url': uplynk_preplay_url,\n            'id': video_id,\n            'title': title,\n            'description': base.get('body') or base.get('display_body'),\n            'thumbnail': watch_hub_data.get('cover-image') or watch_hub_data.get('thumbnail'),\n            'duration': int_or_none(video_data.get('video_duration')) or parse_duration(watch_hub_data.get('video-duration')),\n            'timestamp': int_or_none(video_data.get('created_at'), 1000),\n            'age_limit': parse_age_limit(video_data.get('video_rating')),\n            'series': video_data.get('show_title') or watch_hub_data.get('show-title'),\n            'episode_number': int_or_none(episode.get('episode_number') or watch_hub_data.get('episode')),\n            'episode_id': str_or_none(episode.get('id') or video_data.get('episode_id')),\n            'season_number': int_or_none(watch_hub_data.get('season')),\n            'season_id': str_or_none(episode.get('season_id')),\n            'uploader': channel.get('base', {}).get('title') or watch_hub_data.get('channel-title'),\n            'uploader_id': str_or_none(channel.get('id')),\n            'subtitles': subtitles,\n            'ie_key': 'UplynkPreplay',\n        }",
        "begin_line": 23,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vice.ViceIE._real_extract#149",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceIE",
        "signature": "youtube_dl.extractor.vice.ViceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        locale, video_id = re.match(self._VALID_URL, url).groups()\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n        embed_code = self._search_regex(\n            r'embedCode=([^&\\'\"]+)', webpage,\n            'ooyala embed code', default=None)\n        if embed_code:\n            return self.url_result('ooyala:%s' % embed_code, 'Ooyala')\n        youtube_id = self._search_regex(\n            r'data-youtube-id=\"([^\"]+)\"', webpage, 'youtube id', default=None)\n        if youtube_id:\n            return self.url_result(youtube_id, 'Youtube')\n        return self._extract_preplay_video(urlh.geturl(), locale, webpage)",
        "begin_line": 149,
        "end_line": 161,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vice.ViceShowIE._real_extract#178",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceShowIE",
        "signature": "youtube_dl.extractor.vice.ViceShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n        webpage = self._download_webpage(url, show_id)\n\n        entries = [\n            self.url_result(video_url, ViceIE.ie_key())\n            for video_url, _ in re.findall(\n                r'<h2[^>]+class=\"article-title\"[^>]+data-id=\"\\d+\"[^>]*>\\s*<a[^>]+href=\"(%s.*?)\"'\n                % ViceIE._VALID_URL, webpage)]\n\n        title = self._search_regex(\n            r'<title>(.+?)</title>', webpage, 'title', default=None)\n        if title:\n            title = re.sub(r'(.+)\\s*\\|\\s*.+$', r'\\1', title).strip()\n        description = self._html_search_meta(\n            'description', webpage, 'description')\n\n        return self.playlist_result(entries, show_id, title, description)",
        "begin_line": 178,
        "end_line": 195,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vice.ViceArticleIE._real_extract#240",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceArticleIE",
        "signature": "youtube_dl.extractor.vice.ViceArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        prefetch_data = self._parse_json(self._search_regex(\n            r'window\\.__PREFETCH_DATA\\s*=\\s*({.*});',\n            webpage, 'prefetch data'), display_id)\n        body = prefetch_data['body']\n\n        def _url_res(video_url, ie_key):\n            return {\n                '_type': 'url_transparent',\n                'url': video_url,\n                'display_id': display_id,\n                'ie_key': ie_key,\n            }\n\n        embed_code = self._search_regex(\n            r'embedCode=([^&\\'\"]+)', body,\n            'ooyala embed code', default=None)\n        if embed_code:\n            return _url_res('ooyala:%s' % embed_code, 'Ooyala')\n\n        youtube_url = self._html_search_regex(\n            r'<iframe[^>]+src=\"(.*youtube\\.com/.*)\"',\n            body, 'YouTube URL', default=None)\n        if youtube_url:\n            return _url_res(youtube_url, 'Youtube')\n\n        video_url = self._html_search_regex(\n            r'data-video-url=\"([^\"]+)\"',\n            prefetch_data['embed_code'], 'video URL')\n\n        return _url_res(video_url, ViceIE.ie_key())",
        "begin_line": 240,
        "end_line": 274,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viceland.VicelandIE._real_extract#33",
        "src_path": "youtube_dl/extractor/viceland.py",
        "class_name": "youtube_dl.extractor.viceland.VicelandIE",
        "signature": "youtube_dl.extractor.viceland.VicelandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        locale = mobj.group('locale')\n        webpage = self._download_webpage(url, video_id)\n        return self._extract_preplay_video(url, locale, webpage)",
        "begin_line": 33,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidbit.VidbitIE._real_extract#33",
        "src_path": "youtube_dl/extractor/vidbit.py",
        "class_name": "youtube_dl.extractor.vidbit.VidbitIE",
        "signature": "youtube_dl.extractor.vidbit.VidbitIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            compat_urlparse.urljoin(url, '/watch?v=%s' % video_id), video_id)\n\n        video_url, title = [None] * 2\n\n        config = self._parse_json(self._search_regex(\n            r'(?s)\\.setup\\(({.+?})\\);', webpage, 'setup', default='{}'),\n            video_id, transform_source=js_to_json)\n        if config:\n            if config.get('file'):\n                video_url = compat_urlparse.urljoin(url, config['file'])\n            title = config.get('title')\n\n        if not video_url:\n            video_url = compat_urlparse.urljoin(url, self._search_regex(\n                r'file\\s*:\\s*([\"\\'])(?P<url>(?:(?!\\1).)+)\\1',\n                webpage, 'video URL', group='url'))\n\n        if not title:\n            title = remove_end(\n                self._html_search_regex(\n                    (r'<h1>(.+?)</h1>', r'<title>(.+?)</title>'),\n                    webpage, 'title', default=None) or self._og_search_title(webpage),\n                ' - VidBit')\n\n        description = self._html_search_meta(\n            ('description', 'og:description', 'twitter:description'),\n            webpage, 'description')\n\n        upload_date = unified_strdate(self._html_search_meta(\n            'datePublished', webpage, 'upload date'))\n\n        view_count = int_or_none(self._search_regex(\n            r'<strong>(\\d+)</strong> views',\n            webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._search_regex(\n            r'id=[\"\\']cmt_num[\"\\'][^>]*>\\((\\d+)\\)',\n            webpage, 'comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n        }",
        "begin_line": 33,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viddler.ViddlerIE._real_extract#80",
        "src_path": "youtube_dl/extractor/viddler.py",
        "class_name": "youtube_dl.extractor.viddler.ViddlerIE",
        "signature": "youtube_dl.extractor.viddler.ViddlerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        query = {\n            'video_id': video_id,\n            'key': 'v0vhrt7bg2xq1vyxhkct',\n        }\n\n        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        secret = qs.get('secret', [None])[0]\n        if secret:\n            query['secret'] = secret\n\n        headers = {'Referer': 'http://static.cdn-ec.viddler.com/js/arpeggio/v2/embed.html'}\n        request = sanitized_Request(\n            'http://api.viddler.com/api/v2/viddler.videos.getPlaybackDetails.json?%s'\n            % compat_urllib_parse_urlencode(query), None, headers)\n        data = self._download_json(request, video_id)['video']\n\n        formats = []\n        for filed in data['files']:\n            if filed.get('status', 'ready') != 'ready':\n                continue\n            format_id = filed.get('profile_id') or filed['profile_name']\n            f = {\n                'format_id': format_id,\n                'format_note': filed['profile_name'],\n                'url': self._proto_relative_url(filed['url']),\n                'width': int_or_none(filed.get('width')),\n                'height': int_or_none(filed.get('height')),\n                'filesize': int_or_none(filed.get('size')),\n                'ext': filed.get('ext'),\n                'source_preference': -1,\n            }\n            formats.append(f)\n\n            if filed.get('cdn_url'):\n                f = f.copy()\n                f['url'] = self._proto_relative_url(filed['cdn_url'], 'http:')\n                f['format_id'] = format_id + '-cdn'\n                f['source_preference'] = 1\n                formats.append(f)\n\n            if filed.get('html5_video_source'):\n                f = f.copy()\n                f['url'] = self._proto_relative_url(filed['html5_video_source'])\n                f['format_id'] = format_id + '-html5'\n                f['source_preference'] = 0\n                formats.append(f)\n        self._sort_formats(formats)\n\n        categories = [\n            t.get('text') for t in data.get('tags', []) if 'text' in t]\n\n        return {\n            'id': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'description': data.get('description'),\n            'timestamp': int_or_none(data.get('upload_time')),\n            'thumbnail': self._proto_relative_url(data.get('thumbnail_url')),\n            'uploader': data.get('author'),\n            'duration': float_or_none(data.get('length')),\n            'view_count': int_or_none(data.get('view_count')),\n            'comment_count': int_or_none(data.get('comment_count')),\n            'categories': categories,\n        }",
        "begin_line": 80,
        "end_line": 146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videa.VideaIE._extract_urls#49",
        "src_path": "youtube_dl/extractor/videa.py",
        "class_name": "youtube_dl.extractor.videa.VideaIE",
        "signature": "youtube_dl.extractor.videa.VideaIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?:)?//videa\\.hu/player\\?.*?\\bv=.+?)\\1',\n            webpage)]",
        "begin_line": 49,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videa.VideaIE._real_extract#54",
        "src_path": "youtube_dl/extractor/videa.py",
        "class_name": "youtube_dl.extractor.videa.VideaIE",
        "signature": "youtube_dl.extractor.videa.VideaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_xml(\n            'http://videa.hu/videaplayer_get_xml.php', video_id,\n            query={'v': video_id})\n\n        video = xpath_element(info, './/video', 'video', fatal=True)\n        sources = xpath_element(info, './/video_sources', 'sources', fatal=True)\n\n        title = xpath_text(video, './title', fatal=True)\n\n        formats = []\n        for source in sources.findall('./video_source'):\n            source_url = source.text\n            if not source_url:\n                continue\n            f = parse_codecs(source.get('codecs'))\n            f.update({\n                'url': source_url,\n                'ext': mimetype2ext(source.get('mimetype')) or 'mp4',\n                'format_id': source.get('name'),\n                'width': int_or_none(source.get('width')),\n                'height': int_or_none(source.get('height')),\n            })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        thumbnail = xpath_text(video, './poster_src')\n        duration = int_or_none(xpath_text(video, './duration'))\n\n        age_limit = None\n        is_adult = xpath_text(video, './is_adult_content', default=None)\n        if is_adult:\n            age_limit = 18 if is_adult == '1' else 0\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 54,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract#25",
        "src_path": "youtube_dl/extractor/videodetective.py",
        "class_name": "youtube_dl.extractor.videodetective.VideoDetectiveIE",
        "signature": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage)\n        query = compat_urlparse.urlparse(og_video).query\n        return self.url_result(InternetVideoArchiveIE._build_json_url(query), ie=InternetVideoArchiveIE.ie_key())",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract#32",
        "src_path": "youtube_dl/extractor/videofyme.py",
        "class_name": "youtube_dl.extractor.videofyme.VideofyMeIE",
        "signature": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        config = self._download_json('http://vf-player-info-loader.herokuapp.com/%s.json' % video_id, video_id)['videoinfo']\n\n        video = config.get('video')\n        blog = config.get('blog', {})\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'url': video['sources']['source']['url'],\n            'thumbnail': video.get('thumb'),\n            'description': video.get('description'),\n            'timestamp': parse_iso8601(video.get('date')),\n            'uploader': blog.get('name'),\n            'uploader_id': blog.get('identifier'),\n            'view_count': int_or_none(self._search_regex(r'([0-9]+)', video.get('views'), 'view count', fatal=False)),\n            'likes': int_or_none(video.get('likes')),\n            'comment_count': int_or_none(video.get('nrOfComments')),\n        }",
        "begin_line": 32,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomega.VideoMegaIE._real_extract#32",
        "src_path": "youtube_dl/extractor/videomega.py",
        "class_name": "youtube_dl.extractor.videomega.VideoMegaIE",
        "signature": "youtube_dl.extractor.videomega.VideoMegaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        iframe_url = 'http://videomega.tv/cdn.php?ref=%s' % video_id\n        req = sanitized_Request(iframe_url)\n        req.add_header('Referer', url)\n        req.add_header('Cookie', 'noadvtday=0')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+?)</title>', webpage, 'title')\n        title = re.sub(\n            r'(?:^[Vv]ideo[Mm]ega\\.tv\\s-\\s*|\\s*-\\svideomega\\.tv$)', '', title)\n        thumbnail = self._search_regex(\n            r'<video[^>]+?poster=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        real_codes = decode_packed_codes(webpage)\n        video_url = self._search_regex(\n            r'\"src\"\\s*,\\s*\"([^\"]+)\"', real_codes, 'video URL')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'http_headers': {\n                'Referer': iframe_url,\n            },\n        }",
        "begin_line": 32,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomore.VideomoreIE._extract_url#85",
        "src_path": "youtube_dl/extractor/videomore.py",
        "class_name": "youtube_dl.extractor.videomore.VideomoreIE",
        "signature": "youtube_dl.extractor.videomore.VideomoreIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<object[^>]+data=([\"\\'])https?://videomore\\.ru/player\\.swf\\?.*config=(?P<url>https?://videomore\\.ru/(?:[^/]+/)+\\d+\\.xml).*\\1',\n            webpage)\n        if not mobj:\n            mobj = re.search(\n                r'<iframe[^>]+src=([\\'\"])(?P<url>https?://videomore\\.ru/embed/\\d+)',\n                webpage)\n\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 85,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomore.VideomoreIE._real_extract#97",
        "src_path": "youtube_dl/extractor/videomore.py",
        "class_name": "youtube_dl.extractor.videomore.VideomoreIE",
        "signature": "youtube_dl.extractor.videomore.VideomoreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('sid') or mobj.group('id')\n\n        video = self._download_xml(\n            'http://videomore.ru/video/tracks/%s.xml' % video_id,\n            video_id, 'Downloading video XML')\n\n        item = xpath_element(video, './/playlist/item', fatal=True)\n\n        title = xpath_text(\n            item, ('./title', './episode_name'), 'title', fatal=True)\n\n        video_url = xpath_text(item, './video_url', 'video url', fatal=True)\n        formats = self._extract_f4m_formats(video_url, video_id, f4m_id='hds')\n        self._sort_formats(formats)\n\n        thumbnail = xpath_text(item, './thumbnail_url')\n        duration = int_or_none(xpath_text(item, './duration'))\n        view_count = int_or_none(xpath_text(item, './views'))\n        comment_count = int_or_none(xpath_text(item, './count_comments'))\n        age_limit = int_or_none(xpath_text(item, './min_age'))\n\n        series = xpath_text(item, './project_name')\n        episode = xpath_text(item, './episode_name')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'series': series,\n            'episode': episode,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 97,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomore.VideomoreVideoIE.suitable#182",
        "src_path": "youtube_dl/extractor/videomore.py",
        "class_name": "youtube_dl.extractor.videomore.VideomoreVideoIE",
        "signature": "youtube_dl.extractor.videomore.VideomoreVideoIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if VideomoreIE.suitable(url) else super(VideomoreVideoIE, cls).suitable(url)",
        "begin_line": 182,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomore.VideomoreVideoIE._real_extract#185",
        "src_path": "youtube_dl/extractor/videomore.py",
        "class_name": "youtube_dl.extractor.videomore.VideomoreVideoIE",
        "signature": "youtube_dl.extractor.videomore.VideomoreVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._og_search_property(\n            'video:iframe', webpage, 'video url', default=None)\n\n        if not video_url:\n            video_id = self._search_regex(\n                (r'config\\s*:\\s*[\"\\']https?://videomore\\.ru/video/tracks/(\\d+)\\.xml',\n                 r'track-id=[\"\\'](\\d+)',\n                 r'xcnt_product_id\\s*=\\s*(\\d+)'), webpage, 'video id')\n            video_url = 'videomore:%s' % video_id\n\n        return self.url_result(video_url, VideomoreIE.ie_key())",
        "begin_line": 185,
        "end_line": 200,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videomore.VideomoreSeasonIE._real_extract#215",
        "src_path": "youtube_dl/extractor/videomore.py",
        "class_name": "youtube_dl.extractor.videomore.VideomoreSeasonIE",
        "signature": "youtube_dl.extractor.videomore.VideomoreSeasonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n\n        entries = [\n            self.url_result(item) for item in re.findall(\n                r'<a[^>]+href=\"((?:https?:)?//videomore\\.ru/%s/[^/]+)\"[^>]+class=\"widget-item-desc\"'\n                % display_id, webpage)]\n\n        return self.playlist_result(entries, display_id, title)",
        "begin_line": 215,
        "end_line": 227,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract#24",
        "src_path": "youtube_dl/extractor/videopremium.py",
        "class_name": "youtube_dl.extractor.videopremium.VideoPremiumIE",
        "signature": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage_url = 'http://videopremium.tv/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        if re.match(r'^<html><head><script[^>]*>window.location\\s*=', webpage):\n            # Download again, we need a cookie\n            webpage = self._download_webpage(\n                webpage_url, video_id,\n                note='Downloading webpage again (with cookie)')\n\n        video_title = self._html_search_regex(\n            r'<h2(?:.*?)>\\s*(.+?)\\s*<', webpage, 'video title')\n\n        return {\n            'id': video_id,\n            'url': 'rtmp://e%d.md.iplay.md/play' % random.randint(1, 16),\n            'play_path': 'mp4:%s.f4v' % video_id,\n            'page_url': 'http://videopremium.tv/' + video_id,\n            'player_url': 'http://videopremium.tv/uplayer/uppod.swf',\n            'ext': 'f4v',\n            'title': video_title,\n        }",
        "begin_line": 24,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videopress.VideoPressIE._extract_urls#42",
        "src_path": "youtube_dl/extractor/videopress.py",
        "class_name": "youtube_dl.extractor.videopress.VideoPressIE",
        "signature": "youtube_dl.extractor.videopress.VideoPressIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=[\"\\']((?:https?://)?videopress\\.com/embed/[\\da-zA-Z]+)',\n            webpage)",
        "begin_line": 42,
        "end_line": 45,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.videopress.VideoPressIE._real_extract#47",
        "src_path": "youtube_dl/extractor/videopress.py",
        "class_name": "youtube_dl.extractor.videopress.VideoPressIE",
        "signature": "youtube_dl.extractor.videopress.VideoPressIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        query = random_birthday('birth_year', 'birth_month', 'birth_day')\n        video = self._download_json(\n            'https://public-api.wordpress.com/rest/v1.1/videos/%s' % video_id,\n            video_id, query=query)\n\n        title = video['title']\n\n        def base_url(scheme):\n            return try_get(\n                video, lambda x: x['file_url_base'][scheme], compat_str)\n\n        base_url = base_url('https') or base_url('http')\n\n        QUALITIES = ('std', 'dvd', 'hd')\n        quality = qualities(QUALITIES)\n\n        formats = []\n        for format_id, f in video['files'].items():\n            if not isinstance(f, dict):\n                continue\n            for ext, path in f.items():\n                if ext in ('mp4', 'ogg'):\n                    formats.append({\n                        'url': urljoin(base_url, path),\n                        'format_id': '%s-%s' % (format_id, ext),\n                        'ext': determine_ext(path, ext),\n                        'quality': quality(format_id),\n                    })\n        original_url = try_get(video, lambda x: x['original'], compat_str)\n        if original_url:\n            formats.append({\n                'url': original_url,\n                'format_id': 'original',\n                'quality': len(QUALITIES),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video.get('description'),\n            'thumbnail': video.get('poster'),\n            'duration': float_or_none(video.get('duration'), 1000),\n            'timestamp': unified_timestamp(video.get('upload_date')),\n            'age_limit': parse_age_limit(video.get('rating')),\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidio.VidioIE._real_extract#30",
        "src_path": "youtube_dl/extractor/vidio.py",
        "class_name": "youtube_dl.extractor.vidio.VidioIE",
        "signature": "youtube_dl.extractor.vidio.VidioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, display_id = mobj.group('id', 'display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._og_search_title(webpage)\n\n        m3u8_url, duration, thumbnail = [None] * 3\n\n        clips = self._parse_json(\n            self._html_search_regex(\n                r'data-json-clips\\s*=\\s*([\"\\'])(?P<data>\\[.+?\\])\\1',\n                webpage, 'video data', default='[]', group='data'),\n            display_id, fatal=False)\n        if clips:\n            clip = clips[0]\n            m3u8_url = clip.get('sources', [{}])[0].get('file')\n            duration = clip.get('clip_duration')\n            thumbnail = clip.get('image')\n\n        m3u8_url = m3u8_url or self._search_regex(\n            r'data(?:-vjs)?-clip-hls-url=([\"\\'])(?P<url>(?!\\1).+)\\1',\n            webpage, 'hls url')\n        formats = self._extract_m3u8_formats(\n            m3u8_url, display_id, 'mp4', entry_protocol='m3u8_native')\n        self._sort_formats(formats)\n\n        duration = int_or_none(duration or self._search_regex(\n            r'data-video-duration=([\"\\'])(?P<duration>\\d+)\\1', webpage,\n            'duration', fatal=False, group='duration'))\n        thumbnail = thumbnail or self._og_search_thumbnail(webpage)\n\n        like_count = int_or_none(self._search_regex(\n            (r'<span[^>]+data-comment-vote-count=[\"\\'](\\d+)',\n             r'<span[^>]+class=[\"\\'].*?\\blike(?:__|-)count\\b.*?[\"\\'][^>]*>\\s*(\\d+)'),\n            webpage, 'like count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'like_count': like_count,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidme.VidmeIE._real_extract#137",
        "src_path": "youtube_dl/extractor/vidme.py",
        "class_name": "youtube_dl.extractor.vidme.VidmeIE",
        "signature": "youtube_dl.extractor.vidme.VidmeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        try:\n            response = self._download_json(\n                'https://api.vid.me/videoByUrl/%s' % video_id, video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 400:\n                response = self._parse_json(e.cause.read(), video_id)\n            else:\n                raise\n\n        error = response.get('error')\n        if error:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error), expected=True)\n\n        video = response['video']\n\n        if video.get('state') == 'deleted':\n            raise ExtractorError(\n                'Vidme said: Sorry, this video has been deleted.',\n                expected=True)\n\n        if video.get('state') in ('user-disabled', 'suspended'):\n            raise ExtractorError(\n                'Vidme said: This video has been suspended either due to a copyright claim, '\n                'or for violating the terms of use.',\n                expected=True)\n\n        formats = []\n        for f in video.get('formats', []):\n            format_url = f.get('uri')\n            if not format_url or not isinstance(format_url, compat_str):\n                continue\n            format_type = f.get('type')\n            if format_type == 'dash':\n                formats.extend(self._extract_mpd_formats(\n                    format_url, video_id, mpd_id='dash', fatal=False))\n            elif format_type == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'format_id': f.get('type'),\n                    'url': format_url,\n                    'width': int_or_none(f.get('width')),\n                    'height': int_or_none(f.get('height')),\n                    'preference': 0 if f.get('type', '').endswith(\n                        'clip') else 1,\n                })\n\n        if not formats and video.get('complete_url'):\n            formats.append({\n                'url': video.get('complete_url'),\n                'width': int_or_none(video.get('width')),\n                'height': int_or_none(video.get('height')),\n            })\n\n        self._sort_formats(formats)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = video.get('thumbnail_url')\n        timestamp = parse_iso8601(video.get('date_created'), ' ')\n        uploader = video.get('user', {}).get('username')\n        uploader_id = video.get('user', {}).get('user_id')\n        age_limit = 18 if video.get('nsfw') is True else 0\n        duration = float_or_none(video.get('duration'))\n        view_count = int_or_none(video.get('view_count'))\n        like_count = int_or_none(video.get('likes_count'))\n        comment_count = int_or_none(video.get('comment_count'))\n\n        return {\n            'id': video_id,\n            'title': title or 'Video upload (%s)' % video_id,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'age_limit': age_limit,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 137,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidme.VidmeListBaseIE._entries#232",
        "src_path": "youtube_dl/extractor/vidme.py",
        "class_name": "youtube_dl.extractor.vidme.VidmeListBaseIE",
        "signature": "youtube_dl.extractor.vidme.VidmeListBaseIE._entries(self, user_id, user_name)",
        "snippet": "    def _entries(self, user_id, user_name):\n        for page_num in itertools.count(1):\n            page = self._download_json(\n                'https://api.vid.me/videos/%s?user=%s&limit=%d&offset=%d'\n                % (self._API_ITEM, user_id, self._LIMIT, (page_num - 1) * self._LIMIT),\n                user_name, 'Downloading user %s page %d' % (self._API_ITEM, page_num))\n\n            videos = page.get('videos', [])\n            if not videos:\n                break\n\n            for video in videos:\n                video_url = video.get('full_url') or video.get('embed_url')\n                if video_url:\n                    yield self.url_result(video_url, VidmeIE.ie_key())\n\n            total = int_or_none(page.get('page', {}).get('total'))\n            if total and self._LIMIT * page_num >= total:\n                break",
        "begin_line": 232,
        "end_line": 250,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidme.VidmeListBaseIE._real_extract#252",
        "src_path": "youtube_dl/extractor/vidme.py",
        "class_name": "youtube_dl.extractor.vidme.VidmeListBaseIE",
        "signature": "youtube_dl.extractor.vidme.VidmeListBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_name = self._match_id(url)\n\n        user_id = self._download_json(\n            'https://api.vid.me/userByUsername?username=%s' % user_name,\n            user_name)['user']['user_id']\n\n        return self.playlist_result(\n            self._entries(user_id, user_name), user_id,\n            '%s - %s' % (user_name, self._TITLE))",
        "begin_line": 252,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vidzi.VidziIE._real_extract#37",
        "src_path": "youtube_dl/extractor/vidzi.py",
        "class_name": "youtube_dl.extractor.vidzi.VidziIE",
        "signature": "youtube_dl.extractor.vidzi.VidziIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://vidzi.tv/%s' % video_id, video_id)\n        title = self._html_search_regex(\n            r'(?s)<h2 class=\"video-title\">(.*?)</h2>', webpage, 'title')\n\n        codes = [webpage]\n        codes.extend([\n            decode_packed_codes(mobj.group(0)).replace('\\\\\\'', '\\'')\n            for mobj in re.finditer(PACKED_CODES_RE, webpage)])\n        for num, code in enumerate(codes, 1):\n            jwplayer_data = self._parse_json(\n                self._search_regex(\n                    r'setup\\(([^)]+)\\)', code, 'jwplayer data',\n                    default=NO_DEFAULT if num == len(codes) else '{}'),\n                video_id, transform_source=js_to_json)\n            if jwplayer_data:\n                break\n\n        info_dict = self._parse_jwplayer_data(jwplayer_data, video_id, require_title=False)\n        info_dict['title'] = title\n\n        return info_dict",
        "begin_line": 37,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vier.VierIE._real_initialize#111",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierIE",
        "signature": "youtube_dl.extractor.vier.VierIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._logged_in = False",
        "begin_line": 111,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vier.VierIE._login#114",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierIE",
        "signature": "youtube_dl.extractor.vier.VierIE._login(self, site)",
        "snippet": "    def _login(self, site):\n        username, password = self._get_login_info()\n        if username is None or password is None:\n            return\n\n        login_page = self._download_webpage(\n            'http://www.%s.be/user/login' % site,\n            None, note='Logging in', errnote='Unable to log in',\n            data=urlencode_postdata({\n                'form_id': 'user_login',\n                'name': username,\n                'pass': password,\n            }),\n            headers={'Content-Type': 'application/x-www-form-urlencoded'})\n\n        login_error = self._html_search_regex(\n            r'(?s)<div class=\"messages error\">\\s*<div>\\s*<h2.+?</h2>(.+?)<',\n            login_page, 'login error', default=None)\n        if login_error:\n            self.report_warning('Unable to log in: %s' % login_error)\n        else:\n            self._logged_in = True",
        "begin_line": 114,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vier.VierIE._real_extract#137",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierIE",
        "signature": "youtube_dl.extractor.vier.VierIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        embed_id = mobj.group('embed_id')\n        display_id = mobj.group('display_id') or embed_id\n        video_id = mobj.group('id') or embed_id\n        site = mobj.group('site')\n\n        if not self._logged_in:\n            self._login(site)\n\n        webpage = self._download_webpage(url, display_id)\n\n        if r'id=\"user-login\"' in webpage:\n            self.report_warning(\n                'Log in to extract metadata', video_id=display_id)\n            webpage = self._download_webpage(\n                'http://www.%s.be/video/v3/embed/%s' % (site, video_id),\n                display_id)\n\n        video_id = self._search_regex(\n            [r'data-nid=\"(\\d+)\"', r'\"nid\"\\s*:\\s*\"(\\d+)\"'],\n            webpage, 'video id', default=video_id or display_id)\n\n        playlist_url = self._search_regex(\n            r'data-file=([\"\\'])(?P<url>(?:https?:)?//[^/]+/.+?\\.m3u8.*?)\\1',\n            webpage, 'm3u8 url', default=None, group='url')\n\n        if not playlist_url:\n            application = self._search_regex(\n                [r'data-application=\"([^\"]+)\"', r'\"application\"\\s*:\\s*\"([^\"]+)\"'],\n                webpage, 'application', default=site + '_vod')\n            filename = self._search_regex(\n                [r'data-filename=\"([^\"]+)\"', r'\"filename\"\\s*:\\s*\"([^\"]+)\"'],\n                webpage, 'filename')\n            playlist_url = 'http://vod.streamcloud.be/%s/_definst_/mp4:%s.mp4/playlist.m3u8' % (application, filename)\n\n        formats = self._extract_wowza_formats(\n            playlist_url, display_id, skip_protocols=['dash'])\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage, default=display_id)\n        description = self._html_search_regex(\n            r'(?s)<div\\b[^>]+\\bclass=([\"\\'])[^>]*?\\bfield-type-text-with-summary\\b[^>]*?\\1[^>]*>.*?<p>(?P<value>.+?)</p>',\n            webpage, 'description', default=None, group='value')\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n        upload_date = unified_strdate(self._html_search_regex(\n            r'(?s)<div\\b[^>]+\\bclass=([\"\\'])[^>]*?\\bfield-name-post-date\\b[^>]*?\\1[^>]*>.*?(?P<value>\\d{2}/\\d{2}/\\d{4})',\n            webpage, 'upload date', default=None, group='value'))\n\n        series = self._search_regex(\n            r'data-program=([\"\\'])(?P<value>(?:(?!\\1).)+)\\1', webpage,\n            'series', default=None, group='value')\n        episode_number = int_or_none(self._search_regex(\n            r'(?i)aflevering (\\d+)', title, 'episode number', default=None))\n        tags = re.findall(r'<a\\b[^>]+\\bhref=[\"\\']/tags/[^>]+>([^<]+)<', webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'series': series,\n            'episode_number': episode_number,\n            'tags': tags,\n            'formats': formats,\n        }",
        "begin_line": 137,
        "end_line": 204,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vier.VierVideosIE._real_extract#236",
        "src_path": "youtube_dl/extractor/vier.py",
        "class_name": "youtube_dl.extractor.vier.VierVideosIE",
        "signature": "youtube_dl.extractor.vier.VierVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        program = mobj.group('program')\n        site = mobj.group('site')\n\n        page_id = mobj.group('page')\n        if page_id:\n            page_id = int(page_id)\n            start_page = page_id\n            playlist_id = '%s-page%d' % (program, page_id)\n        else:\n            start_page = 0\n            playlist_id = program\n\n        entries = []\n        for current_page_id in itertools.count(start_page):\n            current_page = self._download_webpage(\n                'http://www.%s.be/%s/videos?page=%d' % (site, program, current_page_id),\n                program,\n                'Downloading page %d' % (current_page_id + 1))\n            page_entries = [\n                self.url_result('http://www.' + site + '.be' + video_url, 'Vier')\n                for video_url in re.findall(\n                    r'<h[23]><a href=\"(/[^/]+/videos/[^/]+(?:/\\d+)?)\">', current_page)]\n            entries.extend(page_entries)\n            if page_id or '>Meer<' not in current_page:\n                break\n\n        return self.playlist_result(entries, playlist_id)",
        "begin_line": 236,
        "end_line": 264,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE._extract_url#45",
        "src_path": "youtube_dl/extractor/viewlift.py",
        "class_name": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE",
        "signature": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:embed\\.)?(?:%s)/embed/player.+?)\\1' % ViewLiftBaseIE._DOMAINS_REGEX,\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 45,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE._real_extract#52",
        "src_path": "youtube_dl/extractor/viewlift.py",
        "class_name": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE",
        "signature": "youtube_dl.extractor.viewlift.ViewLiftEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>This film is not playable in your area.<' in webpage:\n            raise ExtractorError(\n                'Film %s is not playable in your area.' % video_id, expected=True)\n\n        formats = []\n        has_bitrate = False\n        for source in self._parse_json(js_to_json(self._search_regex(\n                r'(?s)sources:\\s*(\\[.+?\\]),', webpage, 'json')), video_id):\n            file_ = source.get('file')\n            if not file_:\n                continue\n            type_ = source.get('type')\n            ext = determine_ext(file_)\n            format_id = source.get('label') or ext\n            if all(v in ('m3u8', 'hls') for v in (type_, ext)):\n                formats.extend(self._extract_m3u8_formats(\n                    file_, video_id, 'mp4', m3u8_id='hls'))\n            else:\n                bitrate = int_or_none(self._search_regex(\n                    [r'(\\d+)kbps', r'_\\d{1,2}x\\d{1,2}_(\\d{3,})\\.%s' % ext],\n                    file_, 'bitrate', default=None))\n                if not has_bitrate and bitrate:\n                    has_bitrate = True\n                height = int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]$', format_id, 'height', default=None))\n                formats.append({\n                    'url': file_,\n                    'format_id': 'http-%s%s' % (format_id, ('-%dk' % bitrate if bitrate else '')),\n                    'tbr': bitrate,\n                    'height': height,\n                })\n        field_preference = None if has_bitrate else ('height', 'tbr', 'format_id')\n        self._sort_formats(formats, field_preference)\n\n        title = self._search_regex(\n            [r\"title\\s*:\\s*'([^']+)'\", r'<title>([^<]+)</title>'],\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 52,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viewlift.ViewLiftIE._real_extract#150",
        "src_path": "youtube_dl/extractor/viewlift.py",
        "class_name": "youtube_dl.extractor.viewlift.ViewLiftIE",
        "signature": "youtube_dl.extractor.viewlift.ViewLiftIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        domain, display_id = re.match(self._VALID_URL, url).groups()\n\n        webpage = self._download_webpage(url, display_id)\n\n        if \">Sorry, the Film you're looking for is not available.<\" in webpage:\n            raise ExtractorError(\n                'Film %s is not available.' % display_id, expected=True)\n\n        film_id = self._search_regex(r'filmId=([\\da-f-]{36})\"', webpage, 'film id')\n\n        snag = self._parse_json(\n            self._search_regex(\n                r'Snag\\.page\\.data\\s*=\\s*(\\[.+?\\]);', webpage, 'snag'),\n            display_id)\n\n        for item in snag:\n            if item.get('data', {}).get('film', {}).get('id') == film_id:\n                data = item['data']['film']\n                title = data['title']\n                description = clean_html(data.get('synopsis'))\n                thumbnail = data.get('image')\n                duration = int_or_none(data.get('duration') or data.get('runtime'))\n                categories = [\n                    category['title'] for category in data.get('categories', [])\n                    if category.get('title')]\n                break\n        else:\n            title = self._search_regex(\n                r'itemprop=\"title\">([^<]+)<', webpage, 'title')\n            description = self._html_search_regex(\n                r'(?s)<div itemprop=\"description\" class=\"film-synopsis-inner \">(.+?)</div>',\n                webpage, 'description', default=None) or self._og_search_description(webpage)\n            thumbnail = self._og_search_thumbnail(webpage)\n            duration = parse_duration(self._search_regex(\n                r'<span itemprop=\"duration\" class=\"film-duration strong\">([^<]+)<',\n                webpage, 'duration', fatal=False))\n            categories = re.findall(r'<a href=\"/movies/[^\"]+\">([^<]+)</a>', webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'http://%s/embed/player?filmId=%s' % (domain, film_id),\n            'id': film_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'categories': categories,\n            'ie_key': 'ViewLiftEmbed',\n        }",
        "begin_line": 150,
        "end_line": 200,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viewster.ViewsterIE._download_json#80",
        "src_path": "youtube_dl/extractor/viewster.py",
        "class_name": "youtube_dl.extractor.viewster.ViewsterIE",
        "signature": "youtube_dl.extractor.viewster.ViewsterIE._download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True, query={})",
        "snippet": "    def _download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True, query={}):\n        request = sanitized_Request(url)\n        request.add_header('Accept', self._ACCEPT_HEADER)\n        request.add_header('Auth-token', self._AUTH_TOKEN)\n        return super(ViewsterIE, self)._download_json(request, video_id, note, fatal=fatal, query=query)",
        "begin_line": 80,
        "end_line": 84,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viewster.ViewsterIE._real_extract#86",
        "src_path": "youtube_dl/extractor/viewster.py",
        "class_name": "youtube_dl.extractor.viewster.ViewsterIE",
        "signature": "youtube_dl.extractor.viewster.ViewsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        # Get 'api_token' cookie\n        self._request_webpage(\n            HEADRequest('http://www.viewster.com/'),\n            video_id, headers=self.geo_verification_headers())\n        cookies = self._get_cookies('http://www.viewster.com/')\n        self._AUTH_TOKEN = compat_urllib_parse_unquote(cookies['api_token'].value)\n\n        info = self._download_json(\n            'https://public-api.viewster.com/search/%s' % video_id,\n            video_id, 'Downloading entry JSON')\n\n        entry_id = info.get('Id') or info['id']\n\n        # unfinished serie has no Type\n        if info.get('Type') in ('Serie', None):\n            try:\n                episodes = self._download_json(\n                    'https://public-api.viewster.com/series/%s/episodes' % entry_id,\n                    video_id, 'Downloading series JSON')\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code == 404:\n                    self.raise_geo_restricted()\n                else:\n                    raise\n            entries = [\n                self.url_result(\n                    'http://www.viewster.com/movie/%s' % episode['OriginId'], 'Viewster')\n                for episode in episodes]\n            title = (info.get('Title') or info['Synopsis']['Title']).strip()\n            description = info.get('Synopsis', {}).get('Detailed')\n            return self.playlist_result(entries, video_id, title, description)\n\n        formats = []\n        for language_set in info.get('LanguageSets', []):\n            manifest_url = None\n            m3u8_formats = []\n            audio = language_set.get('Audio') or ''\n            subtitle = language_set.get('Subtitle') or ''\n            base_format_id = audio\n            if subtitle:\n                base_format_id += '-%s' % subtitle\n\n            def concat(suffix, sep='-'):\n                return (base_format_id + '%s%s' % (sep, suffix)) if base_format_id else suffix\n\n            for media_type in ('application/f4m+xml', 'application/x-mpegURL', 'video/mp4'):\n                media = self._download_json(\n                    'https://public-api.viewster.com/movies/%s/video' % entry_id,\n                    video_id, 'Downloading %s JSON' % concat(media_type, ' '), fatal=False, query={\n                        'mediaType': media_type,\n                        'language': audio,\n                        'subtitle': subtitle,\n                    })\n                if not media:\n                    continue\n                video_url = media.get('Uri')\n                if not video_url:\n                    continue\n                ext = determine_ext(video_url)\n                if ext == 'f4m':\n                    manifest_url = video_url\n                    video_url += '&' if '?' in video_url else '?'\n                    video_url += 'hdcore=3.2.0&plugin=flowplayer-3.2.0.1'\n                    formats.extend(self._extract_f4m_formats(\n                        video_url, video_id, f4m_id=concat('hds')))\n                elif ext == 'm3u8':\n                    manifest_url = video_url\n                    m3u8_formats = self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4', m3u8_id=concat('hls'),\n                        fatal=False)  # m3u8 sometimes fail\n                    if m3u8_formats:\n                        formats.extend(m3u8_formats)\n                else:\n                    qualities_basename = self._search_regex(\n                        r'/([^/]+)\\.csmil/',\n                        manifest_url, 'qualities basename', default=None)\n                    if not qualities_basename:\n                        continue\n                    QUALITIES_RE = r'((,\\d+k)+,?)'\n                    qualities = self._search_regex(\n                        QUALITIES_RE, qualities_basename,\n                        'qualities', default=None)\n                    if not qualities:\n                        continue\n                    qualities = list(map(lambda q: int(q[:-1]), qualities.strip(',').split(',')))\n                    qualities.sort()\n                    http_template = re.sub(QUALITIES_RE, r'%dk', qualities_basename)\n                    http_url_basename = url_basename(video_url)\n                    if m3u8_formats:\n                        self._sort_formats(m3u8_formats)\n                        m3u8_formats = list(filter(\n                            lambda f: f.get('vcodec') != 'none', m3u8_formats))\n                    if len(qualities) == len(m3u8_formats):\n                        for q, m3u8_format in zip(qualities, m3u8_formats):\n                            f = m3u8_format.copy()\n                            f.update({\n                                'url': video_url.replace(http_url_basename, http_template % q),\n                                'format_id': f['format_id'].replace('hls', 'http'),\n                                'protocol': 'http',\n                            })\n                            formats.append(f)\n                    else:\n                        for q in qualities:\n                            formats.append({\n                                'url': video_url.replace(http_url_basename, http_template % q),\n                                'ext': 'mp4',\n                                'format_id': 'http-%d' % q,\n                                'tbr': q,\n                            })\n\n        if not formats and not info.get('VODSettings'):\n            self.raise_geo_restricted()\n\n        self._sort_formats(formats)\n\n        synopsis = info.get('Synopsis') or {}\n        # Prefer title outside synopsis since it's less messy\n        title = (info.get('Title') or synopsis['Title']).strip()\n        description = synopsis.get('Detailed') or (info.get('Synopsis') or {}).get('Short')\n        duration = int_or_none(info.get('Duration'))\n        timestamp = parse_iso8601(info.get('ReleaseDate'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 86,
        "end_line": 217,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viidea.ViideaIE._real_extract#117",
        "src_path": "youtube_dl/extractor/viidea.py",
        "class_name": "youtube_dl.extractor.viidea.ViideaIE",
        "signature": "youtube_dl.extractor.viidea.ViideaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        lecture_slug, explicit_part_id = re.match(self._VALID_URL, url).groups()\n\n        webpage = self._download_webpage(url, lecture_slug)\n\n        cfg = self._parse_json(self._search_regex(\n            [r'cfg\\s*:\\s*({.+?})\\s*,\\s*[\\da-zA-Z_]+\\s*:\\s*\\(?\\s*function',\n             r'cfg\\s*:\\s*({[^}]+})'],\n            webpage, 'cfg'), lecture_slug, js_to_json)\n\n        lecture_id = compat_str(cfg['obj_id'])\n\n        base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n\n        lecture_data = self._download_json(\n            '%s/site/api/lecture/%s?format=json' % (base_url, lecture_id),\n            lecture_id)['lecture'][0]\n\n        lecture_info = {\n            'id': lecture_id,\n            'display_id': lecture_slug,\n            'title': lecture_data['title'],\n            'timestamp': parse_iso8601(lecture_data.get('time')),\n            'description': lecture_data.get('description_wiki'),\n            'thumbnail': lecture_data.get('thumb'),\n        }\n\n        playlist_entries = []\n        lecture_type = lecture_data.get('type')\n        parts = [compat_str(video) for video in cfg.get('videos', [])]\n        if parts:\n            multipart = len(parts) > 1\n\n            def extract_part(part_id):\n                smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n                smil = self._download_smil(smil_url, lecture_id)\n                info = self._parse_smil(smil, smil_url, lecture_id)\n                self._sort_formats(info['formats'])\n                info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n                info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n                if multipart:\n                    info['title'] += ' (Part %s)' % part_id\n                switch = smil.find('.//switch')\n                if switch is not None:\n                    info['duration'] = parse_duration(switch.attrib.get('dur'))\n                item_info = lecture_info.copy()\n                item_info.update(info)\n                return item_info\n\n            if explicit_part_id or not multipart:\n                result = extract_part(explicit_part_id or parts[0])\n            else:\n                result = {\n                    '_type': 'multi_video',\n                    'entries': [extract_part(part) for part in parts],\n                }\n                result.update(lecture_info)\n\n            # Immediately return explicitly requested part or non event item\n            if explicit_part_id or lecture_type != 'evt':\n                return result\n\n            playlist_entries.append(result)\n\n        # It's probably a playlist\n        if not parts or lecture_type == 'evt':\n            playlist_webpage = self._download_webpage(\n                '%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n            entries = [\n                self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea')\n                for _, video_url in re.findall(\n                    r'<a[^>]+href=([\"\\'])(.+?)\\1[^>]+id=[\"\\']lec=\\d+', playlist_webpage)]\n            playlist_entries.extend(entries)\n\n        playlist = self.playlist_result(playlist_entries, lecture_id)\n        playlist.update(lecture_info)\n        return playlist",
        "begin_line": 117,
        "end_line": 193,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call#41",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._prepare_call(self, path, timestamp=None, post_data=None)",
        "snippet": "    def _prepare_call(self, path, timestamp=None, post_data=None):\n        path += '?' if '?' not in path else '&'\n        if not timestamp:\n            timestamp = int(time.time())\n        query = self._API_QUERY_TEMPLATE % (path, self._APP, timestamp)\n        if self._token:\n            query += '&token=%s' % self._token\n        sig = hmac.new(\n            self._APP_SECRET.encode('ascii'),\n            query.encode('ascii'),\n            hashlib.sha1\n        ).hexdigest()\n        url = self._API_URL_TEMPLATE % (query, sig)\n        return sanitized_Request(\n            url, json.dumps(post_data).encode('utf-8')) if post_data else url",
        "begin_line": 41,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._call_api#57",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._call_api(self, path, video_id, note, timestamp=None, post_data=None)",
        "snippet": "    def _call_api(self, path, video_id, note, timestamp=None, post_data=None):\n        resp = self._download_json(\n            self._prepare_call(path, timestamp, post_data), video_id, note)\n\n        error = resp.get('error')\n        if error:\n            if error == 'invalid timestamp':\n                resp = self._download_json(\n                    self._prepare_call(path, int(resp['current_timestamp']), post_data),\n                    video_id, '%s (retry)' % note)\n                error = resp.get('error')\n            if error:\n                self._raise_error(resp['error'])\n\n        return resp",
        "begin_line": 57,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._raise_error#73",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._raise_error(self, error)",
        "snippet": "    def _raise_error(self, error):\n        raise ExtractorError(\n            '%s returned error: %s' % (self.IE_NAME, error),\n            expected=True)",
        "begin_line": 73,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._check_errors#78",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._check_errors(self, data)",
        "snippet": "    def _check_errors(self, data):\n        for reason, status in data.get('blocking', {}).items():\n            if status and reason in self._ERRORS:\n                message = self._ERRORS[reason]\n                if reason == 'geo':\n                    self.raise_geo_restricted(msg=message)\n                raise ExtractorError('%s said: %s' % (\n                    self.IE_NAME, message), expected=True)",
        "begin_line": 78,
        "end_line": 85,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize#87",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE._login#90",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'login_id': username,\n            'password': password,\n        }\n\n        login = self._call_api(\n            'sessions.json', None,\n            'Logging in as %s' % username, post_data=login_form)\n\n        self._token = login.get('token')\n        if not self._token:\n            self.report_warning('Unable to get session token, login has probably failed')",
        "begin_line": 90,
        "end_line": 106,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiBaseIE.dict_selection#109",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiBaseIE",
        "signature": "youtube_dl.extractor.viki.VikiBaseIE.dict_selection(dict_obj, preferred_key, allow_fallback=True)",
        "snippet": "    def dict_selection(dict_obj, preferred_key, allow_fallback=True):\n        if preferred_key in dict_obj:\n            return dict_obj.get(preferred_key)\n\n        if not allow_fallback:\n            return\n\n        filtered_dict = list(filter(None, [dict_obj.get(k) for k in dict_obj.keys()]))\n        return filtered_dict[0] if filtered_dict else None",
        "begin_line": 109,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._real_extract#217",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._call_api(\n            'videos/%s.json' % video_id, video_id, 'Downloading video JSON')\n\n        self._check_errors(video)\n\n        title = self.dict_selection(video.get('titles', {}), 'en', allow_fallback=False)\n        if not title:\n            title = 'Episode %d' % video.get('number') if video.get('type') == 'episode' else video.get('id') or video_id\n            container_titles = video.get('container', {}).get('titles', {})\n            container_title = self.dict_selection(container_titles, 'en')\n            title = '%s - %s' % (container_title, title)\n\n        description = self.dict_selection(video.get('descriptions', {}), 'en')\n\n        duration = int_or_none(video.get('duration'))\n        timestamp = parse_iso8601(video.get('created_at'))\n        uploader = video.get('author')\n        like_count = int_or_none(video.get('likes', {}).get('count'))\n        age_limit = parse_age_limit(video.get('rating'))\n\n        thumbnails = []\n        for thumbnail_id, thumbnail in video.get('images', {}).items():\n            thumbnails.append({\n                'id': thumbnail_id,\n                'url': thumbnail.get('url'),\n            })\n\n        subtitles = {}\n        for subtitle_lang, _ in video.get('subtitle_completions', {}).items():\n            subtitles[subtitle_lang] = [{\n                'ext': subtitles_format,\n                'url': self._prepare_call(\n                    'videos/%s/subtitles/%s.%s' % (video_id, subtitle_lang, subtitles_format)),\n            } for subtitles_format in ('srt', 'vtt')]\n\n        result = {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'like_count': like_count,\n            'age_limit': age_limit,\n            'thumbnails': thumbnails,\n            'subtitles': subtitles,\n        }\n\n        streams = self._call_api(\n            'videos/%s/streams.json' % video_id, video_id,\n            'Downloading video streams JSON')\n\n        if 'external' in streams:\n            result.update({\n                '_type': 'url_transparent',\n                'url': streams['external']['url'],\n            })\n            return result\n\n        formats = []\n        for format_id, stream_dict in streams.items():\n            height = int_or_none(self._search_regex(\n                r'^(\\d+)[pP]$', format_id, 'height', default=None))\n            for protocol, format_dict in stream_dict.items():\n                # rtmps URLs does not seem to work\n                if protocol == 'rtmps':\n                    continue\n                format_url = format_dict['url']\n                if format_id == 'm3u8':\n                    m3u8_formats = self._extract_m3u8_formats(\n                        format_url, video_id, 'mp4',\n                        entry_protocol='m3u8_native',\n                        m3u8_id='m3u8-%s' % protocol, fatal=False)\n                    # Despite CODECS metadata in m3u8 all video-only formats\n                    # are actually video+audio\n                    for f in m3u8_formats:\n                        if f.get('acodec') == 'none' and f.get('vcodec') != 'none':\n                            f['acodec'] = None\n                    formats.extend(m3u8_formats)\n                elif format_url.startswith('rtmp'):\n                    mobj = re.search(\n                        r'^(?P<url>rtmp://[^/]+/(?P<app>.+?))/(?P<playpath>mp4:.+)$',\n                        format_url)\n                    if not mobj:\n                        continue\n                    formats.append({\n                        'format_id': 'rtmp-%s' % format_id,\n                        'ext': 'flv',\n                        'url': mobj.group('url'),\n                        'play_path': mobj.group('playpath'),\n                        'app': mobj.group('app'),\n                        'page_url': url,\n                    })\n                else:\n                    formats.append({\n                        'url': format_url,\n                        'format_id': '%s-%s' % (format_id, protocol),\n                        'height': height,\n                    })\n        self._sort_formats(formats)\n\n        result['formats'] = formats\n        return result",
        "begin_line": 217,
        "end_line": 322,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viki.VikiChannelIE._real_extract#357",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiChannelIE",
        "signature": "youtube_dl.extractor.viki.VikiChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        channel = self._call_api(\n            'containers/%s.json' % channel_id, channel_id,\n            'Downloading channel JSON')\n\n        self._check_errors(channel)\n\n        title = self.dict_selection(channel['titles'], 'en')\n\n        description = self.dict_selection(channel['descriptions'], 'en')\n\n        entries = []\n        for video_type in ('episodes', 'clips', 'movies'):\n            for page_num in itertools.count(1):\n                page = self._call_api(\n                    'containers/%s/%s.json?per_page=%d&sort=number&direction=asc&with_paging=true&page=%d'\n                    % (channel_id, video_type, self._PER_PAGE, page_num), channel_id,\n                    'Downloading %s JSON page #%d' % (video_type, page_num))\n                for video in page['response']:\n                    video_id = video['id']\n                    entries.append(self.url_result(\n                        'http://www.viki.com/videos/%s' % video_id, 'Viki'))\n                if not page['pagination']['next']:\n                    break\n\n        return self.playlist_result(entries, channel_id, title, description)",
        "begin_line": 357,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login#38",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return\n        self.report_login()\n        webpage = self._download_webpage(self._LOGIN_URL, None, False)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = urlencode_postdata({\n            'action': 'login',\n            'email': username,\n            'password': password,\n            'service': 'vimeo',\n            'token': token,\n        })\n        login_request = sanitized_Request(self._LOGIN_URL, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_request.add_header('Referer', self._LOGIN_URL)\n        self._set_vimeo_cookie('vuid', vuid)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 38,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._verify_video_password#60",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._verify_video_password(self, url, video_id, webpage)",
        "snippet": "    def _verify_video_password(self, url, video_id, webpage):\n        password = self._downloader.params.get('videopassword')\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = urlencode_postdata({\n            'password': password,\n            'token': token,\n        })\n        if url.startswith('http://'):\n            # vimeo only supports https now, but the user can give an http url\n            url = url.replace('http://', 'https://')\n        password_request = sanitized_Request(url + '/password', data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Referer', url)\n        self._set_vimeo_cookie('vuid', vuid)\n        return self._download_webpage(\n            password_request, video_id,\n            'Verifying the password', 'Wrong password')",
        "begin_line": 60,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._extract_xsrft_and_vuid#80",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._extract_xsrft_and_vuid(self, webpage)",
        "snippet": "    def _extract_xsrft_and_vuid(self, webpage):\n        xsrft = self._search_regex(\n            r'(?:(?P<q1>[\"\\'])xsrft(?P=q1)\\s*:|xsrft\\s*[=:])\\s*(?P<q>[\"\\'])(?P<xsrft>.+?)(?P=q)',\n            webpage, 'login token', group='xsrft')\n        vuid = self._search_regex(\n            r'[\"\\']vuid[\"\\']\\s*:\\s*([\"\\'])(?P<vuid>.+?)\\1',\n            webpage, 'vuid', group='vuid')\n        return xsrft, vuid",
        "begin_line": 80,
        "end_line": 87,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._set_vimeo_cookie#89",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._set_vimeo_cookie(self, name, value)",
        "snippet": "    def _set_vimeo_cookie(self, name, value):\n        self._set_cookie('vimeo.com', name, value)",
        "begin_line": 89,
        "end_line": 90,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._vimeo_sort_formats#92",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._vimeo_sort_formats(self, formats)",
        "snippet": "    def _vimeo_sort_formats(self, formats):\n        # Bitrates are completely broken. Single m3u8 may contain entries in kbps and bps\n        # at the same time without actual units specified. This lead to wrong sorting.\n        self._sort_formats(formats, field_preference=('preference', 'height', 'width', 'fps', 'tbr', 'format_id'))",
        "begin_line": 92,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._parse_config#97",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._parse_config(self, config, video_id)",
        "snippet": "    def _parse_config(self, config, video_id):\n        video_data = config['video']\n        # Extract title\n        video_title = video_data['title']\n\n        # Extract uploader, uploader_url and uploader_id\n        video_uploader = video_data.get('owner', {}).get('name')\n        video_uploader_url = video_data.get('owner', {}).get('url')\n        video_uploader_id = video_uploader_url.split('/')[-1] if video_uploader_url else None\n\n        # Extract video thumbnail\n        video_thumbnail = video_data.get('thumbnail')\n        if video_thumbnail is None:\n            video_thumbs = video_data.get('thumbs')\n            if video_thumbs and isinstance(video_thumbs, dict):\n                _, video_thumbnail = sorted((int(width if width.isdigit() else 0), t_url) for (width, t_url) in video_thumbs.items())[-1]\n\n        # Extract video duration\n        video_duration = int_or_none(video_data.get('duration'))\n\n        formats = []\n        config_files = video_data.get('files') or config['request'].get('files', {})\n        for f in config_files.get('progressive', []):\n            video_url = f.get('url')\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': 'http-%s' % f.get('quality'),\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'fps': int_or_none(f.get('fps')),\n                'tbr': int_or_none(f.get('bitrate')),\n            })\n\n        for files_type in ('hls', 'dash'):\n            for cdn_name, cdn_data in config_files.get(files_type, {}).get('cdns', {}).items():\n                manifest_url = cdn_data.get('url')\n                if not manifest_url:\n                    continue\n                format_id = '%s-%s' % (files_type, cdn_name)\n                if files_type == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        manifest_url, video_id, 'mp4',\n                        'm3u8_native', m3u8_id=format_id,\n                        note='Downloading %s m3u8 information' % cdn_name,\n                        fatal=False))\n                elif files_type == 'dash':\n                    mpd_pattern = r'/%s/(?:sep/)?video/' % video_id\n                    mpd_manifest_urls = []\n                    if re.search(mpd_pattern, manifest_url):\n                        for suffix, repl in (('', 'video'), ('_sep', 'sep/video')):\n                            mpd_manifest_urls.append((format_id + suffix, re.sub(\n                                mpd_pattern, '/%s/%s/' % (video_id, repl), manifest_url)))\n                    else:\n                        mpd_manifest_urls = [(format_id, manifest_url)]\n                    for f_id, m_url in mpd_manifest_urls:\n                        mpd_formats = self._extract_mpd_formats(\n                            m_url.replace('/master.json', '/master.mpd'), video_id, f_id,\n                            'Downloading %s MPD information' % cdn_name,\n                            fatal=False)\n                        for f in mpd_formats:\n                            if f.get('vcodec') == 'none':\n                                f['preference'] = -50\n                            elif f.get('acodec') == 'none':\n                                f['preference'] = -40\n                        formats.extend(mpd_formats)\n\n        subtitles = {}\n        text_tracks = config['request'].get('text_tracks')\n        if text_tracks:\n            for tt in text_tracks:\n                subtitles[tt['lang']] = [{\n                    'ext': 'vtt',\n                    'url': 'https://vimeo.com' + tt['url'],\n                }]\n\n        return {\n            'title': video_title,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'uploader_url': video_uploader_url,\n            'thumbnail': video_thumbnail,\n            'duration': video_duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 97,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._smuggle_referrer#407",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._smuggle_referrer(url, referrer_url)",
        "snippet": "    def _smuggle_referrer(url, referrer_url):\n        return smuggle_url(url, {'http_headers': {'Referer': referrer_url}})",
        "begin_line": 407,
        "end_line": 408,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._extract_urls#411",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._extract_urls(url, webpage)",
        "snippet": "    def _extract_urls(url, webpage):\n        urls = []\n        # Look for embedded (iframe) Vimeo player\n        for mobj in re.finditer(\n                r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/.+?)\\1',\n                webpage):\n            urls.append(VimeoIE._smuggle_referrer(unescapeHTML(mobj.group('url')), url))\n        PLAIN_EMBED_RE = (\n            # Look for embedded (swf embed) Vimeo player\n            r'<embed[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\\1',\n            # Look more for non-standard embedded Vimeo player\n            r'<video[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/[0-9]+)\\1',\n        )\n        for embed_re in PLAIN_EMBED_RE:\n            for mobj in re.finditer(embed_re, webpage):\n                urls.append(mobj.group('url'))\n        return urls",
        "begin_line": 411,
        "end_line": 427,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._extract_url#430",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._extract_url(url, webpage)",
        "snippet": "    def _extract_url(url, webpage):\n        urls = VimeoIE._extract_urls(url, webpage)\n        return urls[0] if urls else None",
        "begin_line": 430,
        "end_line": 432,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password#434",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password(self, url, video_id)",
        "snippet": "    def _verify_player_video_password(self, url, video_id):\n        password = self._downloader.params.get('videopassword')\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        data = urlencode_postdata({'password': password})\n        pass_url = url + '/check-password'\n        password_request = sanitized_Request(pass_url, data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Referer', url)\n        return self._download_json(\n            password_request, video_id,\n            'Verifying the password', 'Wrong password')",
        "begin_line": 434,
        "end_line": 445,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize#447",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 447,
        "end_line": 448,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_extract#450",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url, {})\n        headers = std_headers.copy()\n        if 'http_headers' in data:\n            headers.update(data['http_headers'])\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        orig_url = url\n        if mobj.group('pro') or mobj.group('player'):\n            url = 'https://player.vimeo.com/video/' + video_id\n        elif any(p in url for p in ('play_redirect_hls', 'moogaloop.swf')):\n            url = 'https://vimeo.com/' + video_id\n\n        # Retrieve video webpage to extract further information\n        request = sanitized_Request(url, headers=headers)\n        try:\n            webpage, urlh = self._download_webpage_handle(request, video_id)\n            # Some URLs redirect to ondemand can't be extracted with\n            # this extractor right away thus should be passed through\n            # ondemand extractor (e.g. https://vimeo.com/73445910)\n            if VimeoOndemandIE.suitable(urlh.geturl()):\n                return self.url_result(urlh.geturl(), VimeoOndemandIE.ie_key())\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                errmsg = ee.cause.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call youtube-dl with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        # Now we begin extracting as much information as we can from what we\n        # retrieved. First we extract the information common to all extractors,\n        # and latter we extract those that are Vimeo specific.\n        self.report_extraction(video_id)\n\n        vimeo_config = self._search_regex(\n            r'vimeo\\.config\\s*=\\s*(?:({.+?})|_extend\\([^,]+,\\s+({.+?})\\));', webpage,\n            'vimeo config', default=None)\n        if vimeo_config:\n            seed_status = self._parse_json(vimeo_config, video_id).get('seed_status', {})\n            if seed_status.get('state') == 'failed':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, seed_status['title']),\n                    expected=True)\n\n        cc_license = None\n        timestamp = None\n\n        # Extract the config JSON\n        try:\n            try:\n                config_url = self._html_search_regex(\n                    r' data-config-url=\"(.+?)\"', webpage,\n                    'config URL', default=None)\n                if not config_url:\n                    # Sometimes new react-based page is served instead of old one that require\n                    # different config URL extraction approach (see\n                    # https://github.com/rg3/youtube-dl/pull/7209)\n                    vimeo_clip_page_config = self._search_regex(\n                        r'vimeo\\.clip_page_config\\s*=\\s*({.+?});', webpage,\n                        'vimeo clip page config')\n                    page_config = self._parse_json(vimeo_clip_page_config, video_id)\n                    config_url = page_config['player']['config_url']\n                    cc_license = page_config.get('cc_license')\n                    timestamp = try_get(\n                        page_config, lambda x: x['clip']['uploaded_on'],\n                        compat_str)\n                config_json = self._download_webpage(config_url, video_id)\n                config = json.loads(config_json)\n            except RegexNotFoundError:\n                # For pro videos or player.vimeo.com urls\n                # We try to find out to which variable is assigned the config dic\n                m_variable_name = re.search(r'(\\w)\\.video\\.id', webpage)\n                if m_variable_name is not None:\n                    config_re = r'%s=({[^}].+?});' % re.escape(m_variable_name.group(1))\n                else:\n                    config_re = [r' = {config:({.+?}),assets:', r'(?:[abc])=({.+?});']\n                config = self._search_regex(config_re, webpage, 'info section',\n                                            flags=re.DOTALL)\n                config = json.loads(config)\n        except Exception as e:\n            if re.search('The creator of this video has not given you permission to embed it on this domain.', webpage):\n                raise ExtractorError('The author has restricted the access to this video, try with the \"--referer\" option')\n\n            if re.search(r'<form[^>]+?id=\"pw_form\"', webpage) is not None:\n                if '_video_password_verified' in data:\n                    raise ExtractorError('video password verification failed!')\n                self._verify_video_password(url, video_id, webpage)\n                return self._real_extract(\n                    smuggle_url(url, {'_video_password_verified': 'verified'}))\n            else:\n                raise ExtractorError('Unable to extract info section',\n                                     cause=e)\n        else:\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(url, video_id)\n\n        def is_rented():\n            if '>You rented this title.<' in webpage:\n                return True\n            if config.get('user', {}).get('purchased'):\n                return True\n            label = try_get(\n                config, lambda x: x['video']['vod']['purchase_options'][0]['label_string'], compat_str)\n            if label and label.startswith('You rented this'):\n                return True\n            return False\n\n        if is_rented():\n            feature_id = config.get('video', {}).get('vod', {}).get('feature_id')\n            if feature_id and not data.get('force_feature_id', False):\n                return self.url_result(smuggle_url(\n                    'https://player.vimeo.com/player/%s' % feature_id,\n                    {'force_feature_id': True}), 'Vimeo')\n\n        # Extract video description\n\n        video_description = self._html_search_regex(\n            r'(?s)<div\\s+class=\"[^\"]*description[^\"]*\"[^>]*>(.*?)</div>',\n            webpage, 'description', default=None)\n        if not video_description:\n            video_description = self._html_search_meta(\n                'description', webpage, default=None)\n        if not video_description and mobj.group('pro'):\n            orig_webpage = self._download_webpage(\n                orig_url, video_id,\n                note='Downloading webpage for description',\n                fatal=False)\n            if orig_webpage:\n                video_description = self._html_search_meta(\n                    'description', orig_webpage, default=None)\n        if not video_description and not mobj.group('player'):\n            self._downloader.report_warning('Cannot find video description')\n\n        # Extract upload date\n        if not timestamp:\n            timestamp = self._search_regex(\n                r'<time[^>]+datetime=\"([^\"]+)\"', webpage,\n                'timestamp', default=None)\n\n        try:\n            view_count = int(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count'))\n            like_count = int(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count'))\n            comment_count = int(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count'))\n        except RegexNotFoundError:\n            # This info is only available in vimeo.com/{id} urls\n            view_count = None\n            like_count = None\n            comment_count = None\n\n        formats = []\n        download_request = sanitized_Request('https://vimeo.com/%s?action=load_download_config' % video_id, headers={\n            'X-Requested-With': 'XMLHttpRequest'})\n        download_data = self._download_json(download_request, video_id, fatal=False)\n        if download_data:\n            source_file = download_data.get('source_file')\n            if isinstance(source_file, dict):\n                download_url = source_file.get('download_url')\n                if download_url and not source_file.get('is_cold') and not source_file.get('is_defrosting'):\n                    source_name = source_file.get('public_name', 'Original')\n                    if self._is_valid_url(download_url, video_id, '%s video' % source_name):\n                        ext = (try_get(\n                            source_file, lambda x: x['extension'],\n                            compat_str) or determine_ext(\n                            download_url, None) or 'mp4').lower()\n                        formats.append({\n                            'url': download_url,\n                            'ext': ext,\n                            'width': int_or_none(source_file.get('width')),\n                            'height': int_or_none(source_file.get('height')),\n                            'filesize': parse_filesize(source_file.get('size')),\n                            'format_id': source_name,\n                            'preference': 1,\n                        })\n\n        info_dict = self._parse_config(config, video_id)\n        formats.extend(info_dict['formats'])\n        self._vimeo_sort_formats(formats)\n\n        if not cc_license:\n            cc_license = self._search_regex(\n                r'<link[^>]+rel=[\"\\']license[\"\\'][^>]+href=([\"\\'])(?P<license>(?:(?!\\1).)+)\\1',\n                webpage, 'license', default=None, group='license')\n\n        info_dict.update({\n            'id': video_id,\n            'formats': formats,\n            'timestamp': unified_timestamp(timestamp),\n            'description': video_description,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'license': cc_license,\n        })\n\n        return info_dict",
        "begin_line": 450,
        "end_line": 653,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoOndemandIE._real_extract#699",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoOndemandIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoOndemandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(\n            # Some videos require Referer to be passed along with og:video:url\n            # similarly to generic vimeo embeds (e.g.\n            # https://vimeo.com/ondemand/36938/126682985).\n            VimeoIE._smuggle_referrer(self._og_search_video_url(webpage), url),\n            VimeoIE.ie_key())",
        "begin_line": 699,
        "end_line": 707,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url#725",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)",
        "begin_line": 725,
        "end_line": 726,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title#728",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._TITLE or self._html_search_regex(self._TITLE_RE, webpage, 'list title')",
        "begin_line": 728,
        "end_line": 729,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._login_list_password#731",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._login_list_password(self, page_url, list_id, webpage)",
        "snippet": "    def _login_list_password(self, page_url, list_id, webpage):\n        login_form = self._search_regex(\n            r'(?s)<form[^>]+?id=\"pw_form\"(.*?)</form>',\n            webpage, 'login form', default=None)\n        if not login_form:\n            return webpage\n\n        password = self._downloader.params.get('videopassword')\n        if password is None:\n            raise ExtractorError('This album is protected by a password, use the --video-password option', expected=True)\n        fields = self._hidden_inputs(login_form)\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        fields['token'] = token\n        fields['password'] = password\n        post = urlencode_postdata(fields)\n        password_path = self._search_regex(\n            r'action=\"([^\"]+)\"', login_form, 'password URL')\n        password_url = compat_urlparse.urljoin(page_url, password_path)\n        password_request = sanitized_Request(password_url, post)\n        password_request.add_header('Content-type', 'application/x-www-form-urlencoded')\n        self._set_vimeo_cookie('vuid', vuid)\n        self._set_vimeo_cookie('xsrft', token)\n\n        return self._download_webpage(\n            password_request, list_id,\n            'Verifying the password', 'Wrong password')",
        "begin_line": 731,
        "end_line": 756,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._title_and_entries#758",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._title_and_entries(self, list_id, base_url)",
        "snippet": "    def _title_and_entries(self, list_id, base_url):\n        for pagenum in itertools.count(1):\n            page_url = self._page_url(base_url, pagenum)\n            webpage = self._download_webpage(\n                page_url, list_id,\n                'Downloading page %s' % pagenum)\n\n            if pagenum == 1:\n                webpage = self._login_list_password(page_url, list_id, webpage)\n                yield self._extract_list_title(webpage)\n\n            # Try extracting href first since not all videos are available via\n            # short https://vimeo.com/id URL (e.g. https://vimeo.com/channels/tributes/6213729)\n            clips = re.findall(\n                r'id=\"clip_(\\d+)\"[^>]*>\\s*<a[^>]+href=\"(/(?:[^/]+/)*\\1)(?:[^>]+\\btitle=\"([^\"]+)\")?', webpage)\n            if clips:\n                for video_id, video_url, video_title in clips:\n                    yield self.url_result(\n                        compat_urlparse.urljoin(base_url, video_url),\n                        VimeoIE.ie_key(), video_id=video_id, video_title=video_title)\n            # More relaxed fallback\n            else:\n                for video_id in re.findall(r'id=[\"\\']clip_(\\d+)', webpage):\n                    yield self.url_result(\n                        'https://vimeo.com/%s' % video_id,\n                        VimeoIE.ie_key(), video_id=video_id)\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break",
        "begin_line": 758,
        "end_line": 786,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos#788",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos(self, list_id, base_url)",
        "snippet": "    def _extract_videos(self, list_id, base_url):\n        title_and_entries = self._title_and_entries(list_id, base_url)\n        list_title = next(title_and_entries)\n        return self.playlist_result(title_and_entries, list_id, list_title)",
        "begin_line": 788,
        "end_line": 791,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract#793",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id, 'https://vimeo.com/channels/%s' % channel_id)",
        "begin_line": 793,
        "end_line": 796,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract#812",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/%s' % name)",
        "begin_line": 812,
        "end_line": 815,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url#849",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)",
        "begin_line": 849,
        "end_line": 850,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract#852",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n        return self._extract_videos(album_id, 'https://vimeo.com/album/%s' % album_id)",
        "begin_line": 852,
        "end_line": 854,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title#869",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._og_search_title(webpage)",
        "begin_line": 869,
        "end_line": 870,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract#872",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'https://vimeo.com/groups/%s' % name)",
        "begin_line": 872,
        "end_line": 875,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_initialize#921",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 921,
        "end_line": 922,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._get_config_url#924",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._get_config_url(self, webpage_url, video_id, video_password_verified=False)",
        "snippet": "    def _get_config_url(self, webpage_url, video_id, video_password_verified=False):\n        webpage = self._download_webpage(webpage_url, video_id)\n        config_url = self._html_search_regex(\n            r'data-config-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', webpage,\n            'config URL', default=None, group='url')\n        if not config_url:\n            data = self._parse_json(self._search_regex(\n                r'window\\s*=\\s*_extend\\(window,\\s*({.+?})\\);', webpage, 'data',\n                default=NO_DEFAULT if video_password_verified else '{}'), video_id)\n            config_url = data.get('vimeo_esi', {}).get('config', {}).get('configUrl')\n        if config_url is None:\n            self._verify_video_password(webpage_url, video_id, webpage)\n            config_url = self._get_config_url(\n                webpage_url, video_id, video_password_verified=True)\n        return config_url",
        "begin_line": 924,
        "end_line": 938,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract#940",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        config_url = self._get_config_url(url, video_id)\n        config = self._download_json(config_url, video_id)\n        info_dict = self._parse_config(config, video_id)\n        self._vimeo_sort_formats(info_dict['formats'])\n        info_dict['id'] = video_id\n        return info_dict",
        "begin_line": 940,
        "end_line": 947,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize#961",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 961,
        "end_line": 962,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url#964",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        url = '%s/page:%d/' % (base_url, pagenum)\n        request = sanitized_Request(url)\n        # Set the header to get a partial html page with the ids,\n        # the normal page doesn't contain them.\n        request.add_header('X-Requested-With', 'XMLHttpRequest')\n        return request",
        "begin_line": 964,
        "end_line": 970,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract#972",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_videos('watchlater', 'https://vimeo.com/watchlater')",
        "begin_line": 972,
        "end_line": 973,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract#990",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoLikesIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoLikesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        webpage = self._download_webpage(url, user_id)\n        page_count = self._int(\n            self._search_regex(\n                r'''(?x)<li><a\\s+href=\"[^\"]+\"\\s+data-page=\"([0-9]+)\">\n                    .*?</a></li>\\s*<li\\s+class=\"pagination_next\">\n                ''', webpage, 'page count'),\n            'page count', fatal=True)\n        PAGE_SIZE = 12\n        title = self._html_search_regex(\n            r'(?s)<h1>(.+?)</h1>', webpage, 'title', fatal=False)\n        description = self._html_search_meta('description', webpage)\n\n        def _get_page(idx):\n            page_url = 'https://vimeo.com/user%s/likes/page:%d/sort:date' % (\n                user_id, idx + 1)\n            webpage = self._download_webpage(\n                page_url, user_id,\n                note='Downloading page %d/%d' % (idx + 1, page_count))\n            video_list = self._search_regex(\n                r'(?s)<ol class=\"js-browse_list[^\"]+\"[^>]*>(.*?)</ol>',\n                webpage, 'video content')\n            paths = re.findall(\n                r'<li[^>]*>\\s*<a\\s+href=\"([^\"]+)\"', video_list)\n            for path in paths:\n                yield {\n                    '_type': 'url',\n                    'url': compat_urlparse.urljoin(page_url, path),\n                }\n\n        pl = InAdvancePagedList(_get_page, page_count, PAGE_SIZE)\n\n        return {\n            '_type': 'playlist',\n            'id': 'user%s_likes' % user_id,\n            'title': title,\n            'description': description,\n            'entries': pl,\n        }",
        "begin_line": 990,
        "end_line": 1029,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimple.SprutoBaseIE._extract_spruto#8",
        "src_path": "youtube_dl/extractor/vimple.py",
        "class_name": "youtube_dl.extractor.vimple.SprutoBaseIE",
        "signature": "youtube_dl.extractor.vimple.SprutoBaseIE._extract_spruto(self, spruto, video_id)",
        "snippet": "    def _extract_spruto(self, spruto, video_id):\n        playlist = spruto['playlist'][0]\n        title = playlist['title']\n        video_id = playlist.get('videoId') or video_id\n        thumbnail = playlist.get('posterUrl') or playlist.get('thumbnailUrl')\n        duration = int_or_none(playlist.get('duration'))\n\n        formats = [{\n            'url': f['url'],\n        } for f in playlist['video']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 8,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vimple.VimpleIE._real_extract#50",
        "src_path": "youtube_dl/extractor/vimple.py",
        "class_name": "youtube_dl.extractor.vimple.VimpleIE",
        "signature": "youtube_dl.extractor.vimple.VimpleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://player.vimple.ru/iframe/%s' % video_id, video_id)\n\n        spruto = self._parse_json(\n            self._search_regex(\n                r'sprutoData\\s*:\\s*({.+?}),\\r\\n', webpage, 'spruto data'),\n            video_id)\n\n        return self._extract_spruto(spruto, video_id)",
        "begin_line": 50,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vine.VineIE._real_extract#64",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineIE",
        "signature": "youtube_dl.extractor.vine.VineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data = self._download_json(\n            'https://archive.vine.co/posts/%s.json' % video_id, video_id)\n\n        def video_url(kind):\n            for url_suffix in ('Url', 'URL'):\n                format_url = data.get('video%s%s' % (kind, url_suffix))\n                if format_url:\n                    return format_url\n\n        formats = []\n        for quality, format_id in enumerate(('low', '', 'dash')):\n            format_url = video_url(format_id.capitalize())\n            if not format_url:\n                continue\n            # DASH link returns plain mp4\n            if format_id == 'dash' and determine_ext(format_url) == 'mpd':\n                formats.extend(self._extract_mpd_formats(\n                    format_url, video_id, mpd_id='dash', fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id or 'standard',\n                    'quality': quality,\n                })\n        self._sort_formats(formats)\n\n        username = data.get('username')\n\n        alt_title = 'Vine by %s' % username if username else None\n\n        return {\n            'id': video_id,\n            'title': data.get('description') or alt_title or 'Vine video',\n            'alt_title': alt_title,\n            'thumbnail': data.get('thumbnailUrl'),\n            'timestamp': unified_timestamp(data.get('created')),\n            'uploader': username,\n            'uploader_id': data.get('userIdStr'),\n            'view_count': int_or_none(data.get('loops')),\n            'like_count': int_or_none(data.get('likes')),\n            'comment_count': int_or_none(data.get('comments')),\n            'repost_count': int_or_none(data.get('reposts')),\n            'formats': formats,\n        }",
        "begin_line": 64,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vine.VineUserIE._real_extract#131",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineUserIE",
        "signature": "youtube_dl.extractor.vine.VineUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        u = mobj.group('u')\n\n        profile_url = '%sapi/users/profiles/%s%s' % (\n            self._VINE_BASE_URL, 'vanity/' if not u else '', user)\n        profile_data = self._download_json(\n            profile_url, user, note='Downloading user profile data')\n\n        user_id = profile_data['data']['userId']\n        timeline_data = []\n        for pagenum in itertools.count(1):\n            timeline_url = '%sapi/timelines/users/%s?page=%s&size=100' % (\n                self._VINE_BASE_URL, user_id, pagenum)\n            timeline_page = self._download_json(\n                timeline_url, user, note='Downloading page %d' % pagenum)\n            timeline_data.extend(timeline_page['data']['records'])\n            if timeline_page['data']['nextPage'] is None:\n                break\n\n        entries = [\n            self.url_result(e['permalinkUrl'], 'Vine') for e in timeline_data]\n        return self.playlist_result(entries, user)",
        "begin_line": 131,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viu.ViuBaseIE._real_initialize#18",
        "src_path": "youtube_dl/extractor/viu.py",
        "class_name": "youtube_dl.extractor.viu.ViuBaseIE",
        "signature": "youtube_dl.extractor.viu.ViuBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        viu_auth_res = self._request_webpage(\n            'https://www.viu.com/api/apps/v2/authenticate', None,\n            'Requesting Viu auth', query={\n                'acct': 'test',\n                'appid': 'viu_desktop',\n                'fmt': 'json',\n                'iid': 'guest',\n                'languageid': 'default',\n                'platform': 'desktop',\n                'userid': 'guest',\n                'useridtype': 'guest',\n                'ver': '1.0'\n            }, headers=self.geo_verification_headers())\n        self._auth_token = viu_auth_res.info()['X-VIU-AUTH']",
        "begin_line": 18,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viu.ViuBaseIE._call_api#34",
        "src_path": "youtube_dl/extractor/viu.py",
        "class_name": "youtube_dl.extractor.viu.ViuBaseIE",
        "signature": "youtube_dl.extractor.viu.ViuBaseIE._call_api(self, path, *args, **kwargs)",
        "snippet": "    def _call_api(self, path, *args, **kwargs):\n        headers = self.geo_verification_headers()\n        headers.update({\n            'X-VIU-AUTH': self._auth_token\n        })\n        headers.update(kwargs.get('headers', {}))\n        kwargs['headers'] = headers\n        response = self._download_json(\n            'https://www.viu.com/api/' + path, *args,\n            **compat_kwargs(kwargs))['response']\n        if response.get('status') != 'success':\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, response['message']), expected=True)\n        return response",
        "begin_line": 34,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viu.ViuIE._real_extract#81",
        "src_path": "youtube_dl/extractor/viu.py",
        "class_name": "youtube_dl.extractor.viu.ViuIE",
        "signature": "youtube_dl.extractor.viu.ViuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video_data = self._call_api(\n            'clip/load', video_id, 'Downloading video data', query={\n                'appid': 'viu_desktop',\n                'fmt': 'json',\n                'id': video_id\n            })['item'][0]\n\n        title = video_data['title']\n\n        m3u8_url = None\n        url_path = video_data.get('urlpathd') or video_data.get('urlpath')\n        tdirforwhole = video_data.get('tdirforwhole')\n        # #EXT-X-BYTERANGE is not supported by native hls downloader\n        # and ffmpeg (#10955)\n        # hls_file = video_data.get('hlsfile')\n        hls_file = video_data.get('jwhlsfile')\n        if url_path and tdirforwhole and hls_file:\n            m3u8_url = '%s/%s/%s' % (url_path, tdirforwhole, hls_file)\n        else:\n            # m3u8_url = re.sub(\n            #     r'(/hlsc_)[a-z]+(\\d+\\.m3u8)',\n            #     r'\\1whe\\2', video_data['href'])\n            m3u8_url = video_data['href']\n        formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for key, value in video_data.items():\n            mobj = re.match(r'^subtitle_(?P<lang>[^_]+)_(?P<ext>(vtt|srt))', key)\n            if not mobj:\n                continue\n            subtitles.setdefault(mobj.group('lang'), []).append({\n                'url': value,\n                'ext': mobj.group('ext')\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'series': video_data.get('moviealbumshowname'),\n            'episode': title,\n            'episode_number': int_or_none(video_data.get('episodeno')),\n            'duration': int_or_none(video_data.get('duration')),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 81,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viu.ViuPlaylistIE._real_extract#146",
        "src_path": "youtube_dl/extractor/viu.py",
        "class_name": "youtube_dl.extractor.viu.ViuPlaylistIE",
        "signature": "youtube_dl.extractor.viu.ViuPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        playlist_data = self._call_api(\n            'container/load', playlist_id,\n            'Downloading playlist info', query={\n                'appid': 'viu_desktop',\n                'fmt': 'json',\n                'id': 'playlist-' + playlist_id\n            })['container']\n\n        entries = []\n        for item in playlist_data.get('item', []):\n            item_id = item.get('id')\n            if not item_id:\n                continue\n            item_id = compat_str(item_id)\n            entries.append(self.url_result(\n                'viu:' + item_id, 'Viu', item_id))\n\n        return self.playlist_result(\n            entries, playlist_id, playlist_data.get('title'))",
        "begin_line": 146,
        "end_line": 166,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.viu.ViuOTTIE._real_extract#198",
        "src_path": "youtube_dl/extractor/viu.py",
        "class_name": "youtube_dl.extractor.viu.ViuOTTIE",
        "signature": "youtube_dl.extractor.viu.ViuOTTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        country_code, video_id = re.match(self._VALID_URL, url).groups()\n\n        product_data = self._download_json(\n            'http://www.viu.com/ott/%s/index.php' % country_code, video_id,\n            'Downloading video info', query={\n                'r': 'vod/ajax-detail',\n                'platform_flag_label': 'web',\n                'product_id': video_id,\n            })['data']\n\n        video_data = product_data.get('current_product')\n        if not video_data:\n            raise ExtractorError('This video is not available in your region.', expected=True)\n\n        stream_data = self._download_json(\n            'https://d1k2us671qcoau.cloudfront.net/distribute_web_%s.php' % country_code,\n            video_id, 'Downloading stream info', query={\n                'ccs_product_id': video_data['ccs_product_id'],\n            })['data']['stream']\n\n        stream_sizes = stream_data.get('size', {})\n        formats = []\n        for vid_format, stream_url in stream_data.get('url', {}).items():\n            height = int_or_none(self._search_regex(\n                r's(\\d+)p', vid_format, 'height', default=None))\n            formats.append({\n                'format_id': vid_format,\n                'url': stream_url,\n                'height': height,\n                'ext': 'mp4',\n                'filesize': int_or_none(stream_sizes.get(vid_format))\n            })\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for sub in video_data.get('subtitle', []):\n            sub_url = sub.get('url')\n            if not sub_url:\n                continue\n            subtitles.setdefault(sub.get('name'), []).append({\n                'url': sub_url,\n                'ext': 'srt',\n            })\n\n        title = video_data['synopsis'].strip()\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('description'),\n            'series': product_data.get('series', {}).get('name'),\n            'episode': title,\n            'episode_number': int_or_none(video_data.get('number')),\n            'duration': int_or_none(stream_data.get('duration')),\n            'thumbnail': video_data.get('cover_image_url'),\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 198,
        "end_line": 256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vk.VKBaseIE._login#33",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKBaseIE",
        "signature": "youtube_dl.extractor.vk.VKBaseIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_page, url_handle = self._download_webpage_handle(\n            'https://vk.com', None, 'Downloading login page')\n\n        login_form = self._hidden_inputs(login_page)\n\n        login_form.update({\n            'email': username.encode('cp1251'),\n            'pass': password.encode('cp1251'),\n        })\n\n        # https://new.vk.com/ serves two same remixlhk cookies in Set-Cookie header\n        # and expects the first one to be set rather than second (see\n        # https://github.com/rg3/youtube-dl/issues/9841#issuecomment-227871201).\n        # As of RFC6265 the newer one cookie should be set into cookie store\n        # what actually happens.\n        # We will workaround this VK issue by resetting the remixlhk cookie to\n        # the first one manually.\n        for header, cookies in url_handle.headers.items():\n            if header.lower() != 'set-cookie':\n                continue\n            if sys.version_info[0] >= 3:\n                cookies = cookies.encode('iso-8859-1')\n            cookies = cookies.decode('utf-8')\n            remixlhk = re.search(r'remixlhk=(.+?);.*?\\bdomain=(.+?)(?:[,;]|$)', cookies)\n            if remixlhk:\n                value, domain = remixlhk.groups()\n                self._set_cookie(domain, 'remixlhk', value)\n                break\n\n        login_page = self._download_webpage(\n            'https://login.vk.com/?act=login', None,\n            note='Logging in as %s' % username,\n            data=urlencode_postdata(login_form))\n\n        if re.search(r'onLoginFailed', login_page):\n            raise ExtractorError(\n                'Unable to login, incorrect username and/or password', expected=True)",
        "begin_line": 33,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vk.VKBaseIE._real_initialize#76",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKBaseIE",
        "signature": "youtube_dl.extractor.vk.VKBaseIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 76,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_extract#292",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        if video_id:\n            info_url = 'https://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id\n            # Some videos (removed?) can only be downloaded with list id specified\n            list_id = mobj.group('list_id')\n            if list_id:\n                info_url += '&list=%s' % list_id\n        else:\n            info_url = 'http://vk.com/video_ext.php?' + mobj.group('embed_query')\n            video_id = '%s_%s' % (mobj.group('oid'), mobj.group('id'))\n\n        info_page = self._download_webpage(info_url, video_id)\n\n        error_message = self._html_search_regex(\n            [r'(?s)<!><div[^>]+class=\"video_layer_message\"[^>]*>(.+?)</div>',\n                r'(?s)<div[^>]+id=\"video_ext_msg\"[^>]*>(.+?)</div>'],\n            info_page, 'error message', default=None)\n        if error_message:\n            raise ExtractorError(error_message, expected=True)\n\n        if re.search(r'<!>/login\\.php\\?.*\\bact=security_check', info_page):\n            raise ExtractorError(\n                'You are trying to log in from an unusual location. You should confirm ownership at vk.com to log in with this IP.',\n                expected=True)\n\n        ERRORS = {\n            r'>\u0412\u0438\u0434\u0435\u043e\u0437\u0430\u043f\u0438\u0441\u044c .*? \u0431\u044b\u043b\u0430 \u0438\u0437\u044a\u044f\u0442\u0430 \u0438\u0437 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u0432 \u0441\u0432\u044f\u0437\u0438 \u0441 \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u0435\u043c \u043f\u0440\u0430\u0432\u043e\u043e\u0431\u043b\u0430\u0434\u0430\u0442\u0435\u043b\u044f.<':\n            'Video %s has been removed from public access due to rightholder complaint.',\n\n            r'<!>Please log in or <':\n            'Video %s is only available for registered users, '\n            'use --username and --password options to provide account credentials.',\n\n            r'<!>Unknown error':\n            'Video %s does not exist.',\n\n            r'<!>\u0412\u0438\u0434\u0435\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e':\n            'Video %s is temporarily unavailable.',\n\n            r'<!>Access denied':\n            'Access denied to video %s.',\n\n            r'<!>\u0412\u0438\u0434\u0435\u043e\u0437\u0430\u043f\u0438\u0441\u044c \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u0430, \u0442\u0430\u043a \u043a\u0430\u043a \u0435\u0451 \u0430\u0432\u0442\u043e\u0440 \u0431\u044b\u043b \u0437\u0430\u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u0430\u043d.':\n            'Video %s is no longer available, because its author has been blocked.',\n\n            r'<!>This video is no longer available, because its author has been blocked.':\n            'Video %s is no longer available, because its author has been blocked.',\n        }\n\n        for error_re, error_msg in ERRORS.items():\n            if re.search(error_re, info_page):\n                raise ExtractorError(error_msg % video_id, expected=True)\n\n        youtube_url = self._search_regex(\n            r'<iframe[^>]+src=\"((?:https?:)?//www.youtube.com/embed/[^\"]+)\"',\n            info_page, 'youtube iframe', default=None)\n        if youtube_url:\n            return self.url_result(youtube_url, 'Youtube')\n\n        vimeo_url = VimeoIE._extract_url(url, info_page)\n        if vimeo_url is not None:\n            return self.url_result(vimeo_url)\n\n        pladform_url = PladformIE._extract_url(info_page)\n        if pladform_url:\n            return self.url_result(pladform_url)\n\n        m_rutube = re.search(\n            r'\\ssrc=\"((?:https?:)?//rutube\\.ru\\\\?/(?:video|play)\\\\?/embed(?:.*?))\\\\?\"', info_page)\n        if m_rutube is not None:\n            rutube_url = self._proto_relative_url(\n                m_rutube.group(1).replace('\\\\', ''))\n            return self.url_result(rutube_url)\n\n        dailymotion_urls = DailymotionIE._extract_urls(info_page)\n        if dailymotion_urls:\n            return self.url_result(dailymotion_urls[0], DailymotionIE.ie_key())\n\n        m_opts = re.search(r'(?s)var\\s+opts\\s*=\\s*({.+?});', info_page)\n        if m_opts:\n            m_opts_url = re.search(r\"url\\s*:\\s*'((?!/\\b)[^']+)\", m_opts.group(1))\n            if m_opts_url:\n                opts_url = m_opts_url.group(1)\n                if opts_url.startswith('//'):\n                    opts_url = 'http:' + opts_url\n                return self.url_result(opts_url)\n\n        # vars does not look to be served anymore since 24.10.2016\n        data = self._parse_json(\n            self._search_regex(\n                r'var\\s+vars\\s*=\\s*({.+?});', info_page, 'vars', default='{}'),\n            video_id, fatal=False)\n\n        # <!json> is served instead\n        if not data:\n            data = self._parse_json(\n                self._search_regex(\n                    r'<!json>\\s*({.+?})\\s*<!>', info_page, 'json', default='{}'),\n                video_id)\n            if data:\n                data = data['player']['params'][0]\n\n        if not data:\n            data = self._parse_json(\n                self._search_regex(\n                    r'var\\s+playerParams\\s*=\\s*({.+?})\\s*;\\s*\\n', info_page,\n                    'player params'),\n                video_id)['params'][0]\n\n        title = unescapeHTML(data['md_title'])\n\n        # 2 = live\n        # 3 = post live (finished live)\n        is_live = data.get('live') == 2\n        if is_live:\n            title = self._live_title(title)\n\n        timestamp = unified_timestamp(self._html_search_regex(\n            r'class=[\"\\']mv_info_date[^>]+>([^<]+)(?:<|from)', info_page,\n            'upload date', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'class=[\"\\']mv_views_count[^>]+>\\s*([\\d,.]+)',\n            info_page, 'view count', fatal=False))\n\n        formats = []\n        for format_id, format_url in data.items():\n            if not isinstance(format_url, compat_str) or not format_url.startswith(('http', '//', 'rtmp')):\n                continue\n            if (format_id.startswith(('url', 'cache')) or\n                    format_id in ('extra_data', 'live_mp4', 'postlive_mp4')):\n                height = int_or_none(self._search_regex(\n                    r'^(?:url|cache)(\\d+)', format_id, 'height', default=None))\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                    'height': height,\n                })\n            elif format_id == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', 'm3u8_native',\n                    m3u8_id=format_id, fatal=False, live=is_live))\n            elif format_id == 'rtmp':\n                formats.append({\n                    'format_id': format_id,\n                    'url': format_url,\n                    'ext': 'flv',\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(data.get('vid') or video_id),\n            'formats': formats,\n            'title': title,\n            'thumbnail': data.get('jpg'),\n            'uploader': data.get('md_author'),\n            'duration': data.get('duration'),\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'is_live': is_live,\n        }",
        "begin_line": 292,
        "end_line": 455,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract#484",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKUserVideosIE",
        "signature": "youtube_dl.extractor.vk.VKUserVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, page_id)\n\n        entries = [\n            self.url_result(\n                'http://vk.com/video' + video_id, 'VK', video_id=video_id)\n            for video_id in orderedSet(re.findall(r'href=\"/video(-?[0-9_]+)\"', webpage))]\n\n        title = unescapeHTML(self._search_regex(\n            r'<title>\\s*([^<]+?)\\s+\\|\\s+\\d+\\s+videos',\n            webpage, 'title', default=page_id))\n\n        return self.playlist_result(entries, page_id, title)",
        "begin_line": 484,
        "end_line": 498,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vk.VKWallPostIE._real_extract#564",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKWallPostIE",
        "signature": "youtube_dl.extractor.vk.VKWallPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        post_id = self._match_id(url)\n\n        wall_url = 'https://vk.com/wall%s' % post_id\n\n        post_id = remove_start(post_id, '-')\n\n        webpage = self._download_webpage(wall_url, post_id)\n\n        error = self._html_search_regex(\n            r'>Error</div>\\s*<div[^>]+class=[\"\\']body[\"\\'][^>]*>([^<]+)',\n            webpage, 'error', default=None)\n        if error:\n            raise ExtractorError('VK said: %s' % error, expected=True)\n\n        description = clean_html(get_element_by_class('wall_post_text', webpage))\n        uploader = clean_html(get_element_by_class('author', webpage))\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        entries = []\n\n        audio_ids = re.findall(r'data-full-id=[\"\\'](\\d+_\\d+)', webpage)\n        if audio_ids:\n            al_audio = self._download_webpage(\n                'https://vk.com/al_audio.php', post_id,\n                note='Downloading audio info', fatal=False,\n                data=urlencode_postdata({\n                    'act': 'reload_audio',\n                    'al': '1',\n                    'ids': ','.join(audio_ids)\n                }))\n            if al_audio:\n                Audio = collections.namedtuple(\n                    'Audio', ['id', 'user_id', 'url', 'track', 'artist', 'duration'])\n                audios = self._parse_json(\n                    self._search_regex(\n                        r'<!json>(.+?)<!>', al_audio, 'audios', default='[]'),\n                    post_id, fatal=False, transform_source=unescapeHTML)\n                if isinstance(audios, list):\n                    for audio in audios:\n                        a = Audio._make(audio[:6])\n                        entries.append({\n                            'id': '%s_%s' % (a.user_id, a.id),\n                            'url': a.url,\n                            'title': '%s - %s' % (a.artist, a.track) if a.artist and a.track else a.id,\n                            'thumbnail': thumbnail,\n                            'duration': a.duration,\n                            'uploader': uploader,\n                            'artist': a.artist,\n                            'track': a.track,\n                        })\n\n        for video in re.finditer(\n                r'<a[^>]+href=([\"\\'])(?P<url>/video(?:-?[\\d_]+).*?)\\1', webpage):\n            entries.append(self.url_result(\n                compat_urlparse.urljoin(url, video.group('url')), VKIE.ie_key()))\n\n        title = 'Wall post %s' % post_id\n\n        return self.playlist_result(\n            orderedSet(entries), post_id,\n            '%s - %s' % (uploader, title) if uploader else title,\n            description)",
        "begin_line": 564,
        "end_line": 626,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE.suitable#53",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if VLivePlaylistIE.suitable(url) else super(VLiveIE, cls).suitable(url)",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE._real_extract#56",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://www.vlive.tv/video/%s' % video_id, video_id)\n\n        VIDEO_PARAMS_RE = r'\\bvlive\\.video\\.init\\(([^)]+)'\n        VIDEO_PARAMS_FIELD = 'video params'\n\n        params = self._parse_json(self._search_regex(\n            VIDEO_PARAMS_RE, webpage, VIDEO_PARAMS_FIELD, default=''), video_id,\n            transform_source=lambda s: '[' + s + ']', fatal=False)\n\n        if not params or len(params) < 7:\n            params = self._search_regex(\n                VIDEO_PARAMS_RE, webpage, VIDEO_PARAMS_FIELD)\n            params = [p.strip(r'\"') for p in re.split(r'\\s*,\\s*', params)]\n\n        status, long_video_id, key = params[2], params[5], params[6]\n        status = remove_start(status, 'PRODUCT_')\n\n        if status in ('LIVE_ON_AIR', 'BIG_EVENT_ON_AIR'):\n            return self._live(video_id, webpage)\n        elif status in ('VOD_ON_AIR', 'BIG_EVENT_INTRO'):\n            if long_video_id and key:\n                return self._replay(video_id, webpage, long_video_id, key)\n            else:\n                status = 'COMING_SOON'\n\n        if status == 'LIVE_END':\n            raise ExtractorError('Uploading for replay. Please wait...',\n                                 expected=True)\n        elif status == 'COMING_SOON':\n            raise ExtractorError('Coming soon!', expected=True)\n        elif status == 'CANCELED':\n            raise ExtractorError('We are sorry, '\n                                 'but the live broadcast has been canceled.',\n                                 expected=True)\n        else:\n            raise ExtractorError('Unknown status %s' % status)",
        "begin_line": 56,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE._get_common_fields#97",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE._get_common_fields(self, webpage)",
        "snippet": "    def _get_common_fields(self, webpage):\n        title = self._og_search_title(webpage)\n        creator = self._html_search_regex(\n            r'<div[^>]+class=\"info_area\"[^>]*>\\s*<a\\s+[^>]*>([^<]+)',\n            webpage, 'creator', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n        return {\n            'title': title,\n            'creator': creator,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 97,
        "end_line": 107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE._live#109",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE._live(self, video_id, webpage)",
        "snippet": "    def _live(self, video_id, webpage):\n        init_page = self._download_webpage(\n            'http://www.vlive.tv/video/init/view',\n            video_id, note='Downloading live webpage',\n            data=urlencode_postdata({'videoSeq': video_id}),\n            headers={\n                'Referer': 'http://www.vlive.tv/video/%s' % video_id,\n                'Content-Type': 'application/x-www-form-urlencoded'\n            })\n\n        live_params = self._search_regex(\n            r'\"liveStreamInfo\"\\s*:\\s*(\".*\"),',\n            init_page, 'live stream info')\n        live_params = self._parse_json(live_params, video_id)\n        live_params = self._parse_json(live_params, video_id)\n\n        formats = []\n        for vid in live_params.get('resolutions', []):\n            formats.extend(self._extract_m3u8_formats(\n                vid['cdnUrl'], video_id, 'mp4',\n                m3u8_id=vid.get('name'),\n                fatal=False, live=True))\n        self._sort_formats(formats)\n\n        info = self._get_common_fields(webpage)\n        info.update({\n            'title': self._live_title(info['title']),\n            'id': video_id,\n            'formats': formats,\n            'is_live': True,\n        })\n        return info",
        "begin_line": 109,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveIE._replay#142",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveIE",
        "signature": "youtube_dl.extractor.vlive.VLiveIE._replay(self, video_id, webpage, long_video_id, key)",
        "snippet": "    def _replay(self, video_id, webpage, long_video_id, key):\n        playinfo = self._download_json(\n            'http://global.apis.naver.com/rmcnmv/rmcnmv/vod_play_videoInfo.json?%s'\n            % compat_urllib_parse_urlencode({\n                'videoId': long_video_id,\n                'key': key,\n                'ptc': 'http',\n                'doct': 'json',  # document type (xml or json)\n                'cpt': 'vtt',  # captions type (vtt or ttml)\n            }), video_id)\n\n        formats = [{\n            'url': vid['source'],\n            'format_id': vid.get('encodingOption', {}).get('name'),\n            'abr': float_or_none(vid.get('bitrate', {}).get('audio')),\n            'vbr': float_or_none(vid.get('bitrate', {}).get('video')),\n            'width': int_or_none(vid.get('encodingOption', {}).get('width')),\n            'height': int_or_none(vid.get('encodingOption', {}).get('height')),\n            'filesize': int_or_none(vid.get('size')),\n        } for vid in playinfo.get('videos', {}).get('list', []) if vid.get('source')]\n        self._sort_formats(formats)\n\n        view_count = int_or_none(playinfo.get('meta', {}).get('count'))\n\n        subtitles = {}\n        for caption in playinfo.get('captions', {}).get('list', []):\n            lang = dict_get(caption, ('locale', 'language', 'country', 'label'))\n            if lang and caption.get('source'):\n                subtitles[lang] = [{\n                    'ext': 'vtt',\n                    'url': caption['source']}]\n\n        info = self._get_common_fields(webpage)\n        info.update({\n            'id': video_id,\n            'formats': formats,\n            'view_count': view_count,\n            'subtitles': subtitles,\n        })\n        return info",
        "begin_line": 142,
        "end_line": 181,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLiveChannelIE._real_extract#197",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLiveChannelIE",
        "signature": "youtube_dl.extractor.vlive.VLiveChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_code = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'http://channels.vlive.tv/%s/video' % channel_code, channel_code)\n\n        app_id = None\n\n        app_js_url = self._search_regex(\n            r'<script[^>]+src=([\"\\'])(?P<url>http.+?/app\\.js.*?)\\1',\n            webpage, 'app js', default=None, group='url')\n\n        if app_js_url:\n            app_js = self._download_webpage(\n                app_js_url, channel_code, 'Downloading app JS', fatal=False)\n            if app_js:\n                app_id = self._search_regex(\n                    r'Global\\.VFAN_APP_ID\\s*=\\s*[\\'\"]([^\\'\"]+)[\\'\"]',\n                    app_js, 'app id', default=None)\n\n        app_id = app_id or self._APP_ID\n\n        channel_info = self._download_json(\n            'http://api.vfan.vlive.tv/vproxy/channelplus/decodeChannelCode',\n            channel_code, note='Downloading decode channel code',\n            query={\n                'app_id': app_id,\n                'channelCode': channel_code,\n                '_': int(time.time())\n            })\n\n        channel_seq = channel_info['result']['channelSeq']\n        channel_name = None\n        entries = []\n\n        for page_num in itertools.count(1):\n            video_list = self._download_json(\n                'http://api.vfan.vlive.tv/vproxy/channelplus/getChannelVideoList',\n                channel_code, note='Downloading channel list page #%d' % page_num,\n                query={\n                    'app_id': app_id,\n                    'channelSeq': channel_seq,\n                    # Large values of maxNumOfRows (~300 or above) may cause\n                    # empty responses (see [1]), e.g. this happens for [2] that\n                    # has more than 300 videos.\n                    # 1. https://github.com/rg3/youtube-dl/issues/13830\n                    # 2. http://channels.vlive.tv/EDBF.\n                    'maxNumOfRows': 100,\n                    '_': int(time.time()),\n                    'pageNo': page_num\n                }\n            )\n\n            if not channel_name:\n                channel_name = try_get(\n                    video_list,\n                    lambda x: x['result']['channelInfo']['channelName'],\n                    compat_str)\n\n            videos = try_get(\n                video_list, lambda x: x['result']['videoList'], list)\n            if not videos:\n                break\n\n            for video in videos:\n                video_id = video.get('videoSeq')\n                if not video_id:\n                    continue\n                video_id = compat_str(video_id)\n                entries.append(\n                    self.url_result(\n                        'http://www.vlive.tv/video/%s' % video_id,\n                        ie=VLiveIE.ie_key(), video_id=video_id))\n\n        return self.playlist_result(\n            entries, channel_code, channel_name)",
        "begin_line": 197,
        "end_line": 272,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vlive.VLivePlaylistIE._real_extract#287",
        "src_path": "youtube_dl/extractor/vlive.py",
        "class_name": "youtube_dl.extractor.vlive.VLivePlaylistIE",
        "signature": "youtube_dl.extractor.vlive.VLivePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id, playlist_id = mobj.group('video_id', 'id')\n\n        VIDEO_URL_TEMPLATE = 'http://www.vlive.tv/video/%s'\n        if self._downloader.params.get('noplaylist'):\n            self.to_screen(\n                'Downloading just video %s because of --no-playlist' % video_id)\n            return self.url_result(\n                VIDEO_URL_TEMPLATE % video_id,\n                ie=VLiveIE.ie_key(), video_id=video_id)\n\n        self.to_screen(\n            'Downloading playlist %s - add --no-playlist to just download video'\n            % playlist_id)\n\n        webpage = self._download_webpage(\n            'http://www.vlive.tv/video/%s/playlist/%s'\n            % (video_id, playlist_id), playlist_id)\n\n        item_ids = self._parse_json(\n            self._search_regex(\n                r'playlistVideoSeqs\\s*=\\s*(\\[[^]]+\\])', webpage,\n                'playlist video seqs'),\n            playlist_id)\n\n        entries = [\n            self.url_result(\n                VIDEO_URL_TEMPLATE % item_id, ie=VLiveIE.ie_key(),\n                video_id=compat_str(item_id))\n            for item_id in item_ids]\n\n        playlist_name = self._html_search_regex(\n            r'<div[^>]+class=\"[^\"]*multicam_playlist[^>]*>\\s*<h3[^>]+>([^<]+)',\n            webpage, 'playlist title', fatal=False)\n\n        return self.playlist_result(entries, playlist_id, playlist_name)",
        "begin_line": 287,
        "end_line": 323,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract#27",
        "src_path": "youtube_dl/extractor/vodlocker.py",
        "class_name": "youtube_dl.extractor.vodlocker.VodlockerIE",
        "signature": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        if any(p in webpage for p in (\n                '>THIS FILE WAS DELETED<',\n                '>File Not Found<',\n                'The file you were looking for could not be found, sorry for any inconvenience.<',\n                '>The file was removed')):\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        fields = self._hidden_inputs(webpage)\n\n        if fields['op'] == 'download1':\n            self._sleep(3, video_id)  # they do detect when requests happen too fast!\n            post = urlencode_postdata(fields)\n            req = sanitized_Request(url, post)\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n            webpage = self._download_webpage(\n                req, video_id, 'Downloading video page')\n\n        def extract_file_url(html, default=NO_DEFAULT):\n            return self._search_regex(\n                r'file:\\s*\"(http[^\\\"]+)\",', html, 'file url', default=default)\n\n        video_url = extract_file_url(webpage, default=None)\n\n        if not video_url:\n            embed_url = self._search_regex(\n                r'<iframe[^>]+src=([\"\\'])(?P<url>(?:https?://)?vodlocker\\.(?:com|city)/embed-.+?)\\1',\n                webpage, 'embed url', group='url')\n            embed_webpage = self._download_webpage(\n                embed_url, video_id, 'Downloading embed webpage')\n            video_url = extract_file_url(embed_webpage)\n            thumbnail_webpage = embed_webpage\n        else:\n            thumbnail_webpage = webpage\n\n        title = self._search_regex(\n            r'id=\"file_title\".*?>\\s*(.*?)\\s*<(?:br|span)', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"(http[^\\\"]+)\",', thumbnail_webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vodpl.VODPlIE._real_extract#27",
        "src_path": "youtube_dl/extractor/vodpl.py",
        "class_name": "youtube_dl.extractor.vodpl.VODPlIE",
        "signature": "youtube_dl.extractor.vodpl.VODPlIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n        info_dict = self._extract_from_id(self._search_mvp_id(webpage), webpage)\n        info_dict['id'] = video_id\n        return info_dict",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vodplatform.VODPlatformIE._real_extract#21",
        "src_path": "youtube_dl/extractor/vodplatform.py",
        "class_name": "youtube_dl.extractor.vodplatform.VODPlatformIE",
        "signature": "youtube_dl.extractor.vodplatform.VODPlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = unescapeHTML(self._og_search_title(webpage))\n        hidden_inputs = self._hidden_inputs(webpage)\n\n        formats = self._extract_wowza_formats(\n            hidden_inputs.get('HiddenmyhHlsLink') or hidden_inputs['HiddenmyDashLink'], video_id, skip_protocols=['f4m', 'smil'])\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': hidden_inputs.get('HiddenThumbnail') or self._og_search_thumbnail(webpage),\n            'formats': formats,\n        }",
        "begin_line": 21,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE._real_extract#38",
        "src_path": "youtube_dl/extractor/voicerepublic.py",
        "class_name": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE",
        "signature": "youtube_dl.extractor.voicerepublic.VoiceRepublicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n\n        req = sanitized_Request(\n            compat_urlparse.urljoin(url, '/talks/%s' % display_id))\n        # Older versions of Firefox get redirected to an \"upgrade browser\" page\n        req.add_header('User-Agent', 'youtube-dl')\n        webpage = self._download_webpage(req, display_id)\n\n        if '>Queued for processing, please stand by...<' in webpage:\n            raise ExtractorError(\n                'Audio is still queued for processing', expected=True)\n\n        config = self._search_regex(\n            r'(?s)return ({.+?});\\s*\\n', webpage,\n            'data', default=None)\n        data = self._parse_json(config, display_id, fatal=False) if config else None\n        if data:\n            title = data['title']\n            description = data.get('teaser')\n            talk_id = compat_str(data.get('talk_id') or display_id)\n            talk = data['talk']\n            duration = int_or_none(talk.get('duration'))\n            formats = [{\n                'url': compat_urlparse.urljoin(url, talk_url),\n                'format_id': format_id,\n                'ext': determine_ext(talk_url) or format_id,\n                'vcodec': 'none',\n            } for format_id, talk_url in talk['links'].items()]\n        else:\n            title = self._og_search_title(webpage)\n            description = self._html_search_regex(\n                r\"(?s)<div class='talk-teaser'[^>]*>(.+?)</div>\",\n                webpage, 'description', fatal=False)\n            talk_id = self._search_regex(\n                [r\"id='jc-(\\d+)'\", r\"data-shareable-id='(\\d+)'\"],\n                webpage, 'talk id', default=None) or display_id\n            duration = None\n            player = self._search_regex(\n                r\"class='vr-player jp-jplayer'([^>]+)>\", webpage, 'player')\n            formats = [{\n                'url': compat_urlparse.urljoin(url, talk_url),\n                'format_id': format_id,\n                'ext': determine_ext(talk_url) or format_id,\n                'vcodec': 'none',\n            } for format_id, talk_url in re.findall(r\"data-([^=]+)='([^']+)'\", player)]\n        self._sort_formats(formats)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        view_count = int_or_none(self._search_regex(\n            r\"class='play-count[^']*'>\\s*(\\d+) plays\",\n            webpage, 'play count', fatal=False))\n\n        return {\n            'id': talk_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 38,
        "end_line": 100,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.voot.VootIE._real_extract#47",
        "src_path": "youtube_dl/extractor/voot.py",
        "class_name": "youtube_dl.extractor.voot.VootIE",
        "signature": "youtube_dl.extractor.voot.VootIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        media_info = self._download_json(\n            'https://wapi.voot.com/ws/ott/getMediaInfo.json', video_id,\n            query={\n                'platform': 'Web',\n                'pId': 2,\n                'mediaId': video_id,\n            })\n\n        status_code = try_get(media_info, lambda x: x['status']['code'], int)\n        if status_code != 0:\n            raise ExtractorError(media_info['status']['message'], expected=True)\n\n        media = media_info['assets']\n\n        entry_id = media['EntryId']\n        title = media['MediaName']\n\n        description, series, season_number, episode, episode_number = [None] * 5\n\n        for meta in try_get(media, lambda x: x['Metas'], list) or []:\n            key, value = meta.get('Key'), meta.get('Value')\n            if not key or not value:\n                continue\n            if key == 'ContentSynopsis':\n                description = value\n            elif key == 'RefSeriesTitle':\n                series = value\n            elif key == 'RefSeriesSeason':\n                season_number = int_or_none(value)\n            elif key == 'EpisodeMainTitle':\n                episode = value\n            elif key == 'EpisodeNo':\n                episode_number = int_or_none(value)\n\n        return {\n            '_type': 'url_transparent',\n            'url': 'kaltura:1982551:%s' % entry_id,\n            'ie_key': KalturaIE.ie_key(),\n            'title': title,\n            'description': description,\n            'series': series,\n            'season_number': season_number,\n            'episode': episode,\n            'episode_number': episode_number,\n            'timestamp': unified_timestamp(media.get('CreationDate')),\n            'duration': int_or_none(media.get('Duration')),\n            'view_count': int_or_none(media.get('ViewCounter')),\n            'like_count': int_or_none(media.get('like_counter')),\n        }",
        "begin_line": 47,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.voxmedia.VoxMediaIE._real_extract#89",
        "src_path": "youtube_dl/extractor/voxmedia.py",
        "class_name": "youtube_dl.extractor.voxmedia.VoxMediaIE",
        "signature": "youtube_dl.extractor.voxmedia.VoxMediaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        display_id = self._match_id(url)\n        webpage = compat_urllib_parse_unquote(self._download_webpage(url, display_id))\n\n        def create_entry(provider_video_id, provider_video_type, title=None, description=None):\n            return {\n                '_type': 'url_transparent',\n                'url': provider_video_id if provider_video_type == 'youtube' else '%s:%s' % (provider_video_type, provider_video_id),\n                'title': title or self._og_search_title(webpage),\n                'description': description or self._og_search_description(webpage),\n            }\n\n        entries = []\n        entries_data = self._search_regex([\n            r'Chorus\\.VideoContext\\.addVideo\\((\\[{.+}\\])\\);',\n            r'var\\s+entry\\s*=\\s*({.+});',\n            r'SBN\\.VideoLinkset\\.entryGroup\\(\\s*(\\[.+\\])',\n        ], webpage, 'video data', default=None)\n        if entries_data:\n            entries_data = self._parse_json(entries_data, display_id)\n            if isinstance(entries_data, dict):\n                entries_data = [entries_data]\n            for video_data in entries_data:\n                provider_video_id = video_data.get('provider_video_id')\n                provider_video_type = video_data.get('provider_video_type')\n                if provider_video_id and provider_video_type:\n                    entries.append(create_entry(\n                        provider_video_id, provider_video_type,\n                        video_data.get('title'), video_data.get('description')))\n\n        provider_video_id = self._search_regex(\n            r'data-ooyala-id=\"([^\"]+)\"', webpage, 'ooyala id', default=None)\n        if provider_video_id:\n            entries.append(create_entry(provider_video_id, 'ooyala'))\n\n        volume_uuid = self._search_regex(\n            r'data-volume-uuid=\"([^\"]+)\"', webpage, 'volume uuid', default=None)\n        if volume_uuid:\n            volume_webpage = self._download_webpage(\n                'http://volume.vox-cdn.com/embed/%s' % volume_uuid, volume_uuid)\n            video_data = self._parse_json(self._search_regex(\n                r'Volume\\.createVideo\\(({.+})\\s*,\\s*{.*}\\s*,\\s*\\[.*\\]\\s*,\\s*{.*}\\);', volume_webpage, 'video data'), volume_uuid)\n            for provider_video_type in ('ooyala', 'youtube'):\n                provider_video_id = video_data.get('%s_id' % provider_video_type)\n                if provider_video_id:\n                    description = video_data.get('description_long') or video_data.get('description_short')\n                    entries.append(create_entry(\n                        provider_video_id, provider_video_type, video_data.get('title_short'), description))\n                    break\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            return self.playlist_result(entries, display_id, self._og_search_title(webpage), self._og_search_description(webpage))",
        "begin_line": 89,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vporn.VpornIE._real_extract#54",
        "src_path": "youtube_dl/extractor/vporn.py",
        "class_name": "youtube_dl.extractor.vporn.VpornIE",
        "signature": "youtube_dl.extractor.vporn.VpornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        errmsg = 'This video has been deleted due to Copyright Infringement or by the account owner!'\n        if errmsg in webpage:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, errmsg), expected=True)\n\n        title = self._html_search_regex(\n            r'videoname\\s*=\\s*\\'([^\\']+)\\'', webpage, 'title').strip()\n        description = self._html_search_regex(\n            r'class=\"(?:descr|description_txt)\">(.*?)</div>',\n            webpage, 'description', fatal=False)\n        thumbnail = urljoin('http://www.vporn.com', self._html_search_regex(\n            r'flashvars\\.imageUrl\\s*=\\s*\"([^\"]+)\"', webpage, 'description',\n            default=None))\n\n        uploader = self._html_search_regex(\n            r'(?s)Uploaded by:.*?<a href=\"/user/[^\"]+\"[^>]*>(.+?)</a>',\n            webpage, 'uploader', fatal=False)\n\n        categories = re.findall(r'<a href=\"/cat/[^\"]+\"[^>]*>([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'Runtime:\\s*</span>\\s*(\\d+ min \\d+ sec)',\n            webpage, 'duration', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'class=\"views\">([\\d,\\.]+) [Vv]iews<',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r\"'Comments \\(([\\d,\\.]+)\\)'\",\n            webpage, 'comment count', default=None))\n\n        formats = []\n\n        for video in re.findall(r'flashvars\\.videoUrl([^=]+?)\\s*=\\s*\"(https?://[^\"]+)\"', webpage):\n            video_url = video[1]\n            fmt = {\n                'url': video_url,\n                'format_id': video[0],\n            }\n            m = re.search(r'_(?P<width>\\d+)x(?P<height>\\d+)_(?P<vbr>\\d+)k\\.mp4$', video_url)\n            if m:\n                fmt.update({\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                    'vbr': int(m.group('vbr')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 54,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrak.VrakIE._real_extract#39",
        "src_path": "youtube_dl/extractor/vrak.py",
        "class_name": "youtube_dl.extractor.vrak.VrakIE",
        "signature": "youtube_dl.extractor.vrak.VrakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h\\d\\b[^>]+\\bclass=[\"\\']videoTitle[\"\\'][^>]*>([^<]+)',\n            webpage, 'title', default=None) or self._og_search_title(webpage)\n\n        content = self._parse_json(\n            self._search_regex(\n                r'data-player-options-content=([\"\\'])(?P<content>{.+?})\\1',\n                webpage, 'content', default='{}', group='content'),\n            video_id, transform_source=unescapeHTML)\n\n        ref_id = content.get('refId') or self._search_regex(\n            r'refId&quot;:&quot;([^&]+)&quot;', webpage, 'ref id')\n\n        brightcove_id = self._search_regex(\n            r'''(?x)\n                java\\.lang\\.String\\s+value\\s*=\\s*[\"']brightcove\\.article\\.\\d+\\.%s\n                [^>]*\n                java\\.lang\\.String\\s+value\\s*=\\s*[\"'](\\d+)\n            ''' % re.escape(ref_id), webpage, 'brightcove id')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': BrightcoveNewIE.ie_key(),\n            'url': smuggle_url(\n                self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,\n                {'geo_countries': ['CA']}),\n            'id': brightcove_id,\n            'description': content.get('description'),\n            'creator': content.get('brand'),\n            'age_limit': parse_age_limit(content.get('rating')),\n            'series': content.get('showName') or content.get(\n                'episodeName'),  # this is intentional\n            'season_number': int_or_none(content.get('seasonNumber')),\n            'episode': title,\n            'episode_number': int_or_none(content.get('episodeNumber')),\n            'tags': content.get('tags', []),\n        }",
        "begin_line": 39,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrt.VRTIE._real_extract#93",
        "src_path": "youtube_dl/extractor/vrt.py",
        "class_name": "youtube_dl.extractor.vrt.VRTIE",
        "signature": "youtube_dl.extractor.vrt.VRTIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_id = self._search_regex(\n            r'data-video-id=\"([^\"]+)_[^\"]+\"', webpage, 'video id', fatal=False)\n\n        src = self._search_regex(\n            r'data-video-src=\"([^\"]+)\"', webpage, 'video src', default=None)\n\n        video_type = self._search_regex(\n            r'data-video-type=\"([^\"]+)\"', webpage, 'video type', default=None)\n\n        if video_type == 'YouTubeVideo':\n            return self.url_result(src, 'Youtube')\n\n        formats = []\n\n        mobj = re.search(\n            r'data-video-iphone-server=\"(?P<server>[^\"]+)\"\\s+data-video-iphone-path=\"(?P<path>[^\"]+)\"',\n            webpage)\n        if mobj:\n            formats.extend(self._extract_m3u8_formats(\n                '%s/%s' % (mobj.group('server'), mobj.group('path')),\n                video_id, 'mp4', m3u8_id='hls', fatal=False))\n\n        if src:\n            formats = self._extract_wowza_formats(src, video_id)\n            if 'data-video-geoblocking=\"true\"' not in webpage:\n                for f in formats:\n                    if f['url'].startswith('rtsp://'):\n                        http_format = f.copy()\n                        http_format.update({\n                            'url': f['url'].replace('rtsp://', 'http://').replace('vod.', 'download.').replace('/_definst_/', '/').replace('mp4:', ''),\n                            'format_id': f['format_id'].replace('rtsp', 'http'),\n                            'protocol': 'http',\n                        })\n                        formats.append(http_format)\n\n        if not formats and 'data-video-geoblocking=\"true\"' in webpage:\n            self.raise_geo_restricted('This video is only available in Belgium')\n\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = float_or_none(self._search_regex(\n            r'data-video-sitestat-pubdate=\"(\\d+)\"', webpage, 'timestamp', fatal=False), 1000)\n        duration = float_or_none(self._search_regex(\n            r'data-video-duration=\"(\\d+)\"', webpage, 'duration', fatal=False), 1000)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 93,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVBaseIE._call_api#28",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVBaseIE",
        "signature": "youtube_dl.extractor.vrv.VRVBaseIE._call_api(self, path, video_id, note, data=None)",
        "snippet": "    def _call_api(self, path, video_id, note, data=None):\n        base_url = self._API_DOMAIN + '/core/' + path\n        encoded_query = compat_urllib_parse_urlencode({\n            'oauth_consumer_key': self._API_PARAMS['oAuthKey'],\n            'oauth_nonce': ''.join([random.choice(string.ascii_letters) for _ in range(32)]),\n            'oauth_signature_method': 'HMAC-SHA1',\n            'oauth_timestamp': int(time.time()),\n            'oauth_version': '1.0',\n        })\n        headers = self.geo_verification_headers()\n        if data:\n            data = json.dumps(data).encode()\n            headers['Content-Type'] = 'application/json'\n        method = 'POST' if data else 'GET'\n        base_string = '&'.join([method, compat_urlparse.quote(base_url, ''), compat_urlparse.quote(encoded_query, '')])\n        oauth_signature = base64.b64encode(hmac.new(\n            (self._API_PARAMS['oAuthSecret'] + '&').encode('ascii'),\n            base_string.encode(), hashlib.sha1).digest()).decode()\n        encoded_query += '&oauth_signature=' + compat_urlparse.quote(oauth_signature, '')\n        return self._download_json(\n            '?'.join([base_url, encoded_query]), video_id,\n            note='Downloading %s JSON metadata' % note, headers=headers, data=data)",
        "begin_line": 28,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVBaseIE._call_cms#51",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVBaseIE",
        "signature": "youtube_dl.extractor.vrv.VRVBaseIE._call_cms(self, path, video_id, note)",
        "snippet": "    def _call_cms(self, path, video_id, note):\n        if not self._CMS_SIGNING:\n            self._CMS_SIGNING = self._call_api('index', video_id, 'CMS Signing')['cms_signing']\n        return self._download_json(\n            self._API_DOMAIN + path, video_id, query=self._CMS_SIGNING,\n            note='Downloading %s JSON metadata' % note, headers=self.geo_verification_headers())",
        "begin_line": 51,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVBaseIE._set_api_params#58",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVBaseIE",
        "signature": "youtube_dl.extractor.vrv.VRVBaseIE._set_api_params(self, webpage, video_id)",
        "snippet": "    def _set_api_params(self, webpage, video_id):\n        if not self._API_PARAMS:\n            self._API_PARAMS = self._parse_json(self._search_regex(\n                r'window\\.__APP_CONFIG__\\s*=\\s*({.+?})</script>',\n                webpage, 'api config'), video_id)['cxApiParams']\n            self._API_DOMAIN = self._API_PARAMS.get('apiDomain', 'https://api.vrv.co')",
        "begin_line": 58,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVBaseIE._get_cms_resource#65",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVBaseIE",
        "signature": "youtube_dl.extractor.vrv.VRVBaseIE._get_cms_resource(self, resource_key, video_id)",
        "snippet": "    def _get_cms_resource(self, resource_key, video_id):\n        return self._call_api(\n            'cms_resource', video_id, 'resource path', data={\n                'resource_key': resource_key,\n            })['__links__']['cms_resource']['href']",
        "begin_line": 65,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVIE._real_extract#90",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVIE",
        "signature": "youtube_dl.extractor.vrv.VRVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, video_id,\n            headers=self.geo_verification_headers())\n        media_resource = self._parse_json(self._search_regex(\n            r'window\\.__INITIAL_STATE__\\s*=\\s*({.+?})</script>',\n            webpage, 'inital state'), video_id).get('watch', {}).get('mediaResource') or {}\n\n        video_data = media_resource.get('json')\n        if not video_data:\n            self._set_api_params(webpage, video_id)\n            episode_path = self._get_cms_resource(\n                'cms:/episodes/' + video_id, video_id)\n            video_data = self._call_cms(episode_path, video_id, 'video')\n        title = video_data['title']\n\n        streams_json = media_resource.get('streams', {}).get('json', {})\n        if not streams_json:\n            self._set_api_params(webpage, video_id)\n            streams_path = video_data['__links__']['streams']['href']\n            streams_json = self._call_cms(streams_path, video_id, 'streams')\n\n        audio_locale = streams_json.get('audio_locale')\n        formats = []\n        for stream_type, streams in streams_json.get('streams', {}).items():\n            if stream_type in ('adaptive_hls', 'adaptive_dash'):\n                for stream in streams.values():\n                    stream_url = stream.get('url')\n                    if not stream_url:\n                        continue\n                    stream_id = stream.get('hardsub_locale') or audio_locale\n                    format_id = '%s-%s' % (stream_type.split('_')[1], stream_id)\n                    if stream_type == 'adaptive_hls':\n                        adaptive_formats = self._extract_m3u8_formats(\n                            stream_url, video_id, 'mp4', m3u8_id=format_id,\n                            note='Downloading %s m3u8 information' % stream_id,\n                            fatal=False)\n                    else:\n                        adaptive_formats = self._extract_mpd_formats(\n                            stream_url, video_id, mpd_id=format_id,\n                            note='Downloading %s MPD information' % stream_id,\n                            fatal=False)\n                    if audio_locale:\n                        for f in adaptive_formats:\n                            if f.get('acodec') != 'none':\n                                f['language'] = audio_locale\n                    formats.extend(adaptive_formats)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for subtitle in streams_json.get('subtitles', {}).values():\n            subtitle_url = subtitle.get('url')\n            if not subtitle_url:\n                continue\n            subtitles.setdefault(subtitle.get('locale', 'en-US'), []).append({\n                'url': subtitle_url,\n                'ext': subtitle.get('format', 'ass'),\n            })\n\n        thumbnails = []\n        for thumbnail in video_data.get('images', {}).get('thumbnails', []):\n            thumbnail_url = thumbnail.get('source')\n            if not thumbnail_url:\n                continue\n            thumbnails.append({\n                'url': thumbnail_url,\n                'width': int_or_none(thumbnail.get('width')),\n                'height': int_or_none(thumbnail.get('height')),\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'description': video_data.get('description'),\n            'duration': float_or_none(video_data.get('duration_ms'), 1000),\n            'uploader_id': video_data.get('channel_id'),\n            'series': video_data.get('series_title'),\n            'season': video_data.get('season_title'),\n            'season_number': int_or_none(video_data.get('season_number')),\n            'season_id': video_data.get('season_id'),\n            'episode': title,\n            'episode_number': int_or_none(video_data.get('episode_number')),\n            'episode_id': video_data.get('production_episode_id'),\n        }",
        "begin_line": 90,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vrv.VRVSeriesIE._real_extract#191",
        "src_path": "youtube_dl/extractor/vrv.py",
        "class_name": "youtube_dl.extractor.vrv.VRVSeriesIE",
        "signature": "youtube_dl.extractor.vrv.VRVSeriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        series_id = self._match_id(url)\n        webpage = self._download_webpage(\n            url, series_id,\n            headers=self.geo_verification_headers())\n\n        self._set_api_params(webpage, series_id)\n        seasons_path = self._get_cms_resource(\n            'cms:/seasons?series_id=' + series_id, series_id)\n        seasons_data = self._call_cms(seasons_path, series_id, 'seasons')\n\n        entries = []\n        for season in seasons_data.get('items', []):\n            episodes_path = season['__links__']['season/episodes']['href']\n            episodes = self._call_cms(episodes_path, series_id, 'episodes')\n            for episode in episodes.get('items', []):\n                episode_id = episode['id']\n                entries.append(self.url_result(\n                    'https://vrv.co/watch/' + episode_id,\n                    'VRV', episode_id, episode.get('title')))\n\n        return self.playlist_result(entries, series_id)",
        "begin_line": 191,
        "end_line": 212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vshare.VShareIE._real_extract#22",
        "src_path": "youtube_dl/extractor/vshare.py",
        "class_name": "youtube_dl.extractor.vshare.VShareIE",
        "signature": "youtube_dl.extractor.vshare.VShareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(\n            'https://vshare.io/d/%s' % video_id, video_id)\n\n        title = self._html_search_regex(\n            r'(?s)<div id=\"root-container\">(.+?)<br/>', webpage, 'title')\n        video_url = self._search_regex(\n            r'<a[^>]+href=([\"\\'])(?P<url>(?:https?:)?//.+?)\\1[^>]*>[Cc]lick\\s+here',\n            webpage, 'video url', group='url')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 22,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vube.VubeIE._real_extract#101",
        "src_path": "youtube_dl/extractor/vube.py",
        "class_name": "youtube_dl.extractor.vube.VubeIE",
        "signature": "youtube_dl.extractor.vube.VubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://vube.com/t-api/v1/video/%s' % video_id, video_id, 'Downloading video JSON')\n\n        public_id = video['public_id']\n\n        formats = []\n\n        for media in video['media'].get('video', []) + video['media'].get('audio', []):\n            if media['transcoding_status'] != 'processed':\n                continue\n            fmt = {\n                'url': 'http://video.thestaticvube.com/video/%s/%s.mp4' % (media['media_resolution_id'], public_id),\n                'abr': int(media['audio_bitrate']),\n                'format_id': compat_str(media['media_resolution_id']),\n            }\n            vbr = int(media['video_bitrate'])\n            if vbr:\n                fmt.update({\n                    'vbr': vbr,\n                    'height': int(media['height']),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        if not formats and video.get('vst') == 'dmca':\n            raise ExtractorError(\n                'This video has been removed in response to a complaint received under the US Digital Millennium Copyright Act.',\n                expected=True)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = self._proto_relative_url(video.get('thumbnail_src'), scheme='http:')\n        uploader = video.get('user_alias') or video.get('channel')\n        timestamp = int_or_none(video.get('upload_time'))\n        duration = video['duration']\n        view_count = video.get('raw_view_count')\n        like_count = video.get('total_likes')\n        dislike_count = video.get('total_hates')\n\n        comments = video.get('comments')\n        comment_count = None\n        if comments is None:\n            comment_data = self._download_json(\n                'http://vube.com/api/video/%s/comment' % video_id,\n                video_id, 'Downloading video comment JSON', fatal=False)\n            if comment_data is not None:\n                comment_count = int_or_none(comment_data.get('total'))\n        else:\n            comment_count = len(comments)\n\n        categories = [tag['text'] for tag in video['tags']]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n        }",
        "begin_line": 101,
        "end_line": 172,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vuclip.VuClipIE._real_extract#29",
        "src_path": "youtube_dl/extractor/vuclip.py",
        "class_name": "youtube_dl.extractor.vuclip.VuClipIE",
        "signature": "youtube_dl.extractor.vuclip.VuClipIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        ad_m = re.search(\n            r'''value=\"No.*?\" onClick=\"location.href='([^\"']+)'\"''', webpage)\n        if ad_m:\n            urlr = compat_urllib_parse_urlparse(url)\n            adfree_url = urlr.scheme + '://' + urlr.netloc + ad_m.group(1)\n            webpage = self._download_webpage(\n                adfree_url, video_id, note='Download post-ad page')\n\n        error_msg = self._html_search_regex(\n            r'<p class=\"message\">(.*?)</p>', webpage, 'error message',\n            default=None)\n        if error_msg:\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, error_msg), expected=True)\n\n        # These clowns alternate between two page types\n        video_url = self._search_regex(\n            r'<a[^>]+href=\"([^\"]+)\"[^>]*><img[^>]+src=\"[^\"]*/play\\.gif',\n            webpage, 'video URL', default=None)\n        if video_url:\n            formats = [{\n                'url': video_url,\n            }]\n        else:\n            formats = self._parse_html5_media_entries(url, webpage, video_id)[0]['formats']\n\n        title = remove_end(self._html_search_regex(\n            r'<title>(.*?)-\\s*Vuclip</title>', webpage, 'title').strip(), ' - Video')\n\n        duration = parse_duration(self._html_search_regex(\n            r'[(>]([0-9]+:[0-9]+)(?:<span|\\))', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'duration': duration,\n        }",
        "begin_line": 29,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vvvvid.VVVVIDIE._real_initialize#37",
        "src_path": "youtube_dl/extractor/vvvvid.py",
        "class_name": "youtube_dl.extractor.vvvvid.VVVVIDIE",
        "signature": "youtube_dl.extractor.vvvvid.VVVVIDIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._conn_id = self._download_json(\n            'https://www.vvvvid.it/user/login',\n            None, headers=self.geo_verification_headers())['data']['conn_id']",
        "begin_line": 37,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vvvvid.VVVVIDIE._real_extract#42",
        "src_path": "youtube_dl/extractor/vvvvid.py",
        "class_name": "youtube_dl.extractor.vvvvid.VVVVIDIE",
        "signature": "youtube_dl.extractor.vvvvid.VVVVIDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id, season_id, video_id = re.match(self._VALID_URL, url).groups()\n        response = self._download_json(\n            'https://www.vvvvid.it/vvvvid/ondemand/%s/season/%s' % (show_id, season_id),\n            video_id, headers=self.geo_verification_headers(), query={\n                'conn_id': self._conn_id,\n            })\n        if response['result'] == 'error':\n            raise ExtractorError('%s said: %s' % (\n                self.IE_NAME, response['message']), expected=True)\n\n        vid = int(video_id)\n        video_data = list(filter(\n            lambda episode: episode.get('video_id') == vid, response['data']))[0]\n        formats = []\n\n        # vvvvid embed_info decryption algorithm is reverse engineered from function $ds(h) at vvvvid.js\n        def ds(h):\n            g = \"MNOPIJKL89+/4567UVWXQRSTEFGHABCDcdefYZabstuvopqr0123wxyzklmnghij\"\n\n            def f(m):\n                l = []\n                o = 0\n                b = False\n                m_len = len(m)\n                while ((not b) and o < m_len):\n                    n = m[o] << 2\n                    o += 1\n                    k = -1\n                    j = -1\n                    if o < m_len:\n                        n += m[o] >> 4\n                        o += 1\n                        if o < m_len:\n                            k = (m[o - 1] << 4) & 255\n                            k += m[o] >> 2\n                            o += 1\n                            if o < m_len:\n                                j = (m[o - 1] << 6) & 255\n                                j += m[o]\n                                o += 1\n                            else:\n                                b = True\n                        else:\n                            b = True\n                    else:\n                        b = True\n                    l.append(n)\n                    if k != -1:\n                        l.append(k)\n                    if j != -1:\n                        l.append(j)\n                return l\n\n            c = []\n            for e in h:\n                c.append(g.index(e))\n\n            c_len = len(c)\n            for e in range(c_len * 2 - 1, -1, -1):\n                a = c[e % c_len] ^ c[(e + 1) % c_len]\n                c[e % c_len] = a\n\n            c = f(c)\n            d = ''\n            for e in c:\n                d += chr(e)\n\n            return d\n\n        for quality in ('_sd', ''):\n            embed_code = video_data.get('embed_info' + quality)\n            if not embed_code:\n                continue\n            embed_code = ds(embed_code)\n            video_type = video_data.get('video_type')\n            if video_type in ('video/rcs', 'video/kenc'):\n                formats.extend(self._extract_akamai_formats(\n                    embed_code, video_id))\n            else:\n                formats.extend(self._extract_wowza_formats(\n                    'http://sb.top-ix.org/videomg/_definst_/mp4:%s/playlist.m3u8' % embed_code, video_id))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_data['title'],\n            'formats': formats,\n            'thumbnail': video_data.get('thumbnail'),\n            'duration': int_or_none(video_data.get('length')),\n            'series': video_data.get('show_title'),\n            'season_id': season_id,\n            'season_number': video_data.get('season_number'),\n            'episode_id': str_or_none(video_data.get('id')),\n            'epidode_number': int_or_none(video_data.get('number')),\n            'episode_title': video_data['title'],\n            'view_count': int_or_none(video_data.get('views')),\n            'like_count': int_or_none(video_data.get('video_likes')),\n        }",
        "begin_line": 42,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vyborymos.VyboryMosIE._real_extract#27",
        "src_path": "youtube_dl/extractor/vyborymos.py",
        "class_name": "youtube_dl.extractor.vyborymos.VyboryMosIE",
        "signature": "youtube_dl.extractor.vyborymos.VyboryMosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        station_id = self._match_id(url)\n\n        channels = self._download_json(\n            'http://vybory.mos.ru/account/channels?station_id=%s' % station_id,\n            station_id, 'Downloading channels JSON')\n\n        formats = []\n        for cam_num, (sid, hosts, name, _) in enumerate(channels, 1):\n            for num, host in enumerate(hosts, 1):\n                formats.append({\n                    'url': 'http://%s/master.m3u8?sid=%s' % (host, sid),\n                    'ext': 'mp4',\n                    'format_id': 'camera%d-host%d' % (cam_num, num),\n                    'format_note': '%s, %s' % (name, host),\n                })\n\n        info = self._download_json(\n            'http://vybory.mos.ru/json/voting_stations/%s/%s.json'\n            % (compat_str(station_id)[:3], station_id),\n            station_id, 'Downloading station JSON', fatal=False)\n\n        return {\n            'id': station_id,\n            'title': self._live_title(info['name'] if info else station_id),\n            'description': info.get('address'),\n            'is_live': True,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vzaar.VzaarIE._extract_urls#34",
        "src_path": "youtube_dl/extractor/vzaar.py",
        "class_name": "youtube_dl.extractor.vzaar.VzaarIE",
        "signature": "youtube_dl.extractor.vzaar.VzaarIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return re.findall(\n            r'<iframe[^>]+src=[\"\\']((?:https?:)?//(?:view\\.vzaar\\.com)/[0-9]+)',\n            webpage)",
        "begin_line": 34,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.vzaar.VzaarIE._real_extract#39",
        "src_path": "youtube_dl/extractor/vzaar.py",
        "class_name": "youtube_dl.extractor.vzaar.VzaarIE",
        "signature": "youtube_dl.extractor.vzaar.VzaarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'http://view.vzaar.com/v2/%s/video' % video_id, video_id)\n        source_url = video_data['sourceUrl']\n\n        info = {\n            'id': video_id,\n            'title': video_data['videoTitle'],\n            'url': source_url,\n            'thumbnail': self._proto_relative_url(video_data.get('poster')),\n            'duration': float_or_none(video_data.get('videoDuration')),\n        }\n        if 'audio' in source_url:\n            info.update({\n                'vcodec': 'none',\n                'ext': 'mp3',\n            })\n        else:\n            info.update({\n                'width': int_or_none(video_data.get('width')),\n                'height': int_or_none(video_data.get('height')),\n                'ext': 'mp4',\n            })\n        return info",
        "begin_line": 39,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.walla.WallaIE._real_extract#36",
        "src_path": "youtube_dl/extractor/walla.py",
        "class_name": "youtube_dl.extractor.walla.WallaIE",
        "signature": "youtube_dl.extractor.walla.WallaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        video = self._download_xml(\n            'http://video2.walla.co.il/?w=null/null/%s/@@/video/flv_pl' % video_id,\n            display_id)\n\n        item = video.find('./items/item')\n\n        title = xpath_text(item, './title', 'title')\n        description = xpath_text(item, './synopsis', 'description')\n        thumbnail = xpath_text(item, './preview_pic', 'thumbnail')\n        duration = int_or_none(xpath_text(item, './duration', 'duration'))\n\n        subtitles = {}\n        for subtitle in item.findall('./subtitles/subtitle'):\n            lang = xpath_text(subtitle, './title')\n            subtitles[self._SUBTITLE_LANGS.get(lang, lang)] = [{\n                'ext': 'srt',\n                'url': xpath_text(subtitle, './src'),\n            }]\n\n        formats = []\n        for quality in item.findall('./qualities/quality'):\n            format_id = xpath_text(quality, './title')\n            fmt = {\n                'url': 'rtmp://wafla.walla.co.il/vod',\n                'play_path': xpath_text(quality, './src'),\n                'player_url': 'http://isc.walla.co.il/w9/swf/video_swf/vod/WallaMediaPlayerAvod.swf',\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': xpath_text(quality, './title'),\n            }\n            m = re.search(r'^(?P<height>\\d+)[Pp]', format_id)\n            if m:\n                fmt['height'] = int(m.group('height'))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 36,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._extract_urls#32",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._extract_urls(cls, webpage)",
        "snippet": "    def _extract_urls(cls, webpage):\n        return re.findall(\n            r'<iframe[^>]+\\bsrc=[\"\\'](%s)' % cls._EMBED_URL, webpage)",
        "begin_line": 32,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract#36",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_data = self._download_json(\n            'http://www.washingtonpost.com/posttv/c/videojson/%s?resType=jsonp' % video_id,\n            video_id, transform_source=strip_jsonp)[0]['contentConfig']\n        title = video_data['title']\n\n        urls = []\n        formats = []\n        for s in video_data.get('streams', []):\n            s_url = s.get('url')\n            if not s_url or s_url in urls:\n                continue\n            urls.append(s_url)\n            video_type = s.get('type')\n            if video_type == 'smil':\n                continue\n            elif video_type in ('ts', 'hls') and ('_master.m3u8' in s_url or '_mobile.m3u8' in s_url):\n                m3u8_formats = self._extract_m3u8_formats(\n                    s_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)\n                for m3u8_format in m3u8_formats:\n                    width = m3u8_format.get('width')\n                    if not width:\n                        continue\n                    vbr = self._search_regex(\n                        r'%d_%d_(\\d+)' % (width, m3u8_format['height']), m3u8_format['url'], 'vbr', default=None)\n                    if vbr:\n                        m3u8_format.update({\n                            'vbr': int_or_none(vbr),\n                        })\n                formats.extend(m3u8_formats)\n            else:\n                width = int_or_none(s.get('width'))\n                vbr = int_or_none(s.get('bitrate'))\n                has_width = width != 0\n                formats.append({\n                    'format_id': (\n                        '%s-%d-%d' % (video_type, width, vbr)\n                        if width\n                        else video_type),\n                    'vbr': vbr if has_width else None,\n                    'width': width,\n                    'height': int_or_none(s.get('height')),\n                    'acodec': s.get('audioCodec'),\n                    'vcodec': s.get('videoCodec') if has_width else 'none',\n                    'filesize': int_or_none(s.get('fileSize')),\n                    'url': s_url,\n                    'ext': 'mp4',\n                    'protocol': 'm3u8_native' if video_type in ('ts', 'hls') else None,\n                })\n        source_media_url = video_data.get('sourceMediaURL')\n        if source_media_url:\n            formats.append({\n                'format_id': 'source_media',\n                'url': source_media_url,\n            })\n        self._sort_formats(\n            formats, ('width', 'height', 'vbr', 'filesize', 'tbr', 'format_id'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': video_data.get('blurb'),\n            'uploader': video_data.get('credits', {}).get('source'),\n            'formats': formats,\n            'duration': int_or_none(video_data.get('videoDuration'), 100),\n            'timestamp': int_or_none(\n                video_data.get('dateConfig', {}).get('dateFirstPublished'), 1000),\n        }",
        "begin_line": 36,
        "end_line": 104,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE.suitable#162",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if WashingtonPostIE.suitable(url) else super(WashingtonPostArticleIE, cls).suitable(url)",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE._real_extract#165",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n        webpage = self._download_webpage(url, page_id)\n\n        title = self._og_search_title(webpage)\n\n        uuids = re.findall(r'''(?x)\n            (?:\n                <div\\s+class=\"posttv-video-embed[^>]*?data-uuid=|\n                data-video-uuid=\n            )\"([^\"]+)\"''', webpage)\n        entries = [self.url_result('washingtonpost:%s' % uuid, 'WashingtonPost', uuid) for uuid in uuids]\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': page_id,\n            'title': title,\n        }",
        "begin_line": 165,
        "end_line": 183,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE._real_extract#54",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video_id = video_id if video_id.isdigit() and len(video_id) > 6 else compat_str(int(video_id, 36))\n\n        # 'contentv4' is used in the website, but it also returns the related\n        # videos, we don't need them\n        video_data = self._download_json(\n            'http://www.wat.tv/interface/contentv4s/' + video_id, video_id)\n        video_info = video_data['media']\n\n        error_desc = video_info.get('error_desc')\n        if error_desc:\n            self.report_warning(\n                '%s returned error: %s' % (self.IE_NAME, error_desc))\n\n        chapters = video_info['chapters']\n        if chapters:\n            first_chapter = chapters[0]\n\n            def video_id_for_chapter(chapter):\n                return chapter['tc_start'].split('-')[0]\n\n            if video_id_for_chapter(first_chapter) != video_id:\n                self.to_screen('Multipart video detected')\n                entries = [self.url_result('wat:%s' % video_id_for_chapter(chapter)) for chapter in chapters]\n                return self.playlist_result(entries, video_id, video_info['title'])\n            # Otherwise we can continue and extract just one part, we have to use\n            # the video id for getting the video url\n        else:\n            first_chapter = video_info\n\n        title = first_chapter['title']\n\n        def extract_url(path_template, url_type):\n            req_url = 'http://www.wat.tv/get/%s' % (path_template % video_id)\n            head = self._request_webpage(HEADRequest(req_url), video_id, 'Extracting %s url' % url_type, fatal=False)\n            if head:\n                red_url = head.geturl()\n                if req_url != red_url:\n                    return red_url\n            return None\n\n        def remove_bitrate_limit(manifest_url):\n            return re.sub(r'(?:max|min)_bitrate=\\d+&?', '', manifest_url)\n\n        formats = []\n        try:\n            manifest_urls = self._download_json(\n                'http://www.wat.tv/get/webhtml/' + video_id, video_id)\n            m3u8_url = manifest_urls.get('hls')\n            if m3u8_url:\n                m3u8_url = remove_bitrate_limit(m3u8_url)\n                m3u8_formats = self._extract_m3u8_formats(\n                    m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)\n                if m3u8_formats:\n                    formats.extend(m3u8_formats)\n                    formats.extend(self._extract_f4m_formats(\n                        m3u8_url.replace('ios', 'web').replace('.m3u8', '.f4m'),\n                        video_id, f4m_id='hds', fatal=False))\n                    http_url = extract_url('android5/%s.mp4', 'http')\n                    if http_url:\n                        for m3u8_format in m3u8_formats:\n                            vbr, abr = m3u8_format.get('vbr'), m3u8_format.get('abr')\n                            if not vbr or not abr:\n                                continue\n                            format_id = m3u8_format['format_id'].replace('hls', 'http')\n                            fmt_url = re.sub(r'%s-\\d+00-\\d+' % video_id, '%s-%d00-%d' % (video_id, round(vbr / 100), round(abr)), http_url)\n                            if self._is_valid_url(fmt_url, video_id, format_id):\n                                f = m3u8_format.copy()\n                                f.update({\n                                    'url': fmt_url,\n                                    'format_id': format_id,\n                                    'protocol': 'http',\n                                })\n                                formats.append(f)\n            mpd_url = manifest_urls.get('mpd')\n            if mpd_url:\n                formats.extend(self._extract_mpd_formats(remove_bitrate_limit(\n                    mpd_url), video_id, mpd_id='dash', fatal=False))\n            self._sort_formats(formats)\n        except ExtractorError:\n            abr = 64\n            for vbr, width, height in self._FORMATS:\n                tbr = vbr + abr\n                format_id = 'http-%s' % tbr\n                fmt_url = 'http://dnl.adv.tf1.fr/2/USP-0x0/%s/%s/%s/ssm/%s-%s-64k.mp4' % (video_id[-4:-2], video_id[-2:], video_id, video_id, vbr)\n                if self._is_valid_url(fmt_url, video_id, format_id):\n                    formats.append({\n                        'format_id': format_id,\n                        'url': fmt_url,\n                        'vbr': vbr,\n                        'abr': abr,\n                        'width': width,\n                        'height': height,\n                    })\n\n        date_diffusion = first_chapter.get('date_diffusion') or video_data.get('configv4', {}).get('estatS4')\n        upload_date = unified_strdate(date_diffusion) if date_diffusion else None\n        duration = None\n        files = video_info['files']\n        if files:\n            duration = int_or_none(files[0].get('duration'))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': first_chapter.get('preview'),\n            'description': first_chapter.get('description'),\n            'view_count': int_or_none(video_info.get('views')),\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 54,
        "end_line": 166,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.watchbox.WatchBoxIE._real_extract#64",
        "src_path": "youtube_dl/extractor/watchbox.py",
        "class_name": "youtube_dl.extractor.watchbox.WatchBoxIE",
        "signature": "youtube_dl.extractor.watchbox.WatchBoxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        kind, video_id = mobj.group('kind', 'id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        source = self._parse_json(\n            self._search_regex(\n                r'(?s)source\\s*:\\s*({.+?})\\s*,\\s*\\n', webpage, 'source',\n                default='{}'),\n            video_id, transform_source=js_to_json, fatal=False) or {}\n\n        video_id = compat_str(source.get('videoId') or video_id)\n\n        devapi = self._download_json(\n            'http://api.watchbox.de/devapi/id/%s' % video_id, video_id, query={\n                'format': 'json',\n                'apikey': 'hbbtv',\n            }, fatal=False)\n\n        item = try_get(devapi, lambda x: x['items'][0], dict) or {}\n\n        title = item.get('title') or try_get(\n            item, lambda x: x['movie']['headline_movie'],\n            compat_str) or source['title']\n\n        formats = []\n        hls_url = item.get('media_videourl_hls') or source.get('hls')\n        if hls_url:\n            formats.extend(self._extract_m3u8_formats(\n                hls_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                m3u8_id='hls', fatal=False))\n        dash_url = item.get('media_videourl_wv') or source.get('dash')\n        if dash_url:\n            formats.extend(self._extract_mpd_formats(\n                dash_url, video_id, mpd_id='dash', fatal=False))\n        mp4_url = item.get('media_videourl')\n        if mp4_url:\n            formats.append({\n                'url': mp4_url,\n                'format_id': 'mp4',\n                'width': int_or_none(item.get('width')),\n                'height': int_or_none(item.get('height')),\n                'tbr': int_or_none(item.get('bitrate')),\n            })\n        self._sort_formats(formats)\n\n        description = strip_or_none(item.get('descr'))\n        thumbnail = item.get('media_content_thumbnail_large') or source.get('poster') or item.get('media_thumbnail')\n        duration = int_or_none(item.get('media_length') or source.get('length'))\n        timestamp = unified_timestamp(item.get('pubDate'))\n        view_count = int_or_none(item.get('media_views'))\n        age_limit = int_or_none(try_get(item, lambda x: x['movie']['fsk']))\n        release_year = int_or_none(try_get(item, lambda x: x['movie']['rel_year']))\n\n        info = {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'age_limit': age_limit,\n            'release_year': release_year,\n            'formats': formats,\n        }\n\n        if kind.lower() == 'serien':\n            series = try_get(\n                item, lambda x: x['special']['title'],\n                compat_str) or source.get('format')\n            season_number = int_or_none(self._search_regex(\n                r'^S(\\d{1,2})\\s*E\\d{1,2}', title, 'season number',\n                default=None) or self._search_regex(\n                    r'/staffel-(\\d+)/', url, 'season number', default=None))\n            episode = source.get('title')\n            episode_number = int_or_none(self._search_regex(\n                r'^S\\d{1,2}\\s*E(\\d{1,2})', title, 'episode number',\n                default=None))\n            info.update({\n                'series': series,\n                'season_number': season_number,\n                'episode': episode,\n                'episode_number': episode_number,\n            })\n\n        return info",
        "begin_line": 64,
        "end_line": 151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.watchindianporn.WatchIndianPornIE._real_extract#29",
        "src_path": "youtube_dl/extractor/watchindianporn.py",
        "class_name": "youtube_dl.extractor.watchindianporn.WatchIndianPornIE",
        "signature": "youtube_dl.extractor.watchindianporn.WatchIndianPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]\n\n        title = self._html_search_regex((\n            r'<title>(.+?)\\s*-\\s*Indian\\s+Porn</title>',\n            r'<h4>(.+?)</h4>'\n        ), webpage, 'title')\n\n        duration = parse_duration(self._search_regex(\n            r'Time:\\s*<strong>\\s*(.+?)\\s*</strong>',\n            webpage, 'duration', fatal=False))\n\n        view_count = int(self._search_regex(\n            r'(?s)Time:\\s*<strong>.*?</strong>.*?<strong>\\s*(\\d+)\\s*</strong>',\n            webpage, 'view count', fatal=False))\n\n        categories = re.findall(\n            r'<a[^>]+class=[\\'\"]categories[\\'\"][^>]*>\\s*([^<]+)\\s*</a>',\n            webpage)\n\n        info_dict.update({\n            'id': video_id,\n            'display_id': display_id,\n            'http_headers': {\n                'Referer': url,\n            },\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'categories': categories,\n            'age_limit': 18,\n        })\n\n        return info_dict",
        "begin_line": 29,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRBaseIE._extract_wdr_video#19",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRBaseIE",
        "signature": "youtube_dl.extractor.wdr.WDRBaseIE._extract_wdr_video(self, webpage, display_id)",
        "snippet": "    def _extract_wdr_video(self, webpage, display_id):\n        # for wdr.de the data-extension is in a tag with the class \"mediaLink\"\n        # for wdr.de radio players, in a tag with the class \"wdrrPlayerPlayBtn\"\n        # for wdrmaus, in a tag with the class \"videoButton\" (previously a link\n        # to the page in a multiline \"videoLink\"-tag)\n        json_metadata = self._html_search_regex(\n            r'class=(?:\"(?:mediaLink|wdrrPlayerPlayBtn|videoButton)\\b[^\"]*\"[^>]+|\"videoLink\\b[^\"]*\"[\\s]*>\\n[^\\n]*)data-extension=\"([^\"]+)\"',\n            webpage, 'media link', default=None, flags=re.MULTILINE)\n\n        if not json_metadata:\n            return\n\n        media_link_obj = self._parse_json(json_metadata, display_id,\n                                          transform_source=js_to_json)\n        jsonp_url = media_link_obj['mediaObj']['url']\n\n        metadata = self._download_json(\n            jsonp_url, display_id, transform_source=strip_jsonp)\n\n        metadata_tracker_data = metadata['trackerData']\n        metadata_media_resource = metadata['mediaResource']\n\n        formats = []\n\n        # check if the metadata contains a direct URL to a file\n        for kind, media_resource in metadata_media_resource.items():\n            if kind not in ('dflt', 'alt'):\n                continue\n\n            for tag_name, medium_url in media_resource.items():\n                if tag_name not in ('videoURL', 'audioURL'):\n                    continue\n\n                ext = determine_ext(medium_url)\n                if ext == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        medium_url, display_id, 'mp4', 'm3u8_native',\n                        m3u8_id='hls'))\n                elif ext == 'f4m':\n                    manifest_url = update_url_query(\n                        medium_url, {'hdcore': '3.2.0', 'plugin': 'aasp-3.2.0.77.18'})\n                    formats.extend(self._extract_f4m_formats(\n                        manifest_url, display_id, f4m_id='hds', fatal=False))\n                elif ext == 'smil':\n                    formats.extend(self._extract_smil_formats(\n                        medium_url, 'stream', fatal=False))\n                else:\n                    a_format = {\n                        'url': medium_url\n                    }\n                    if ext == 'unknown_video':\n                        urlh = self._request_webpage(\n                            medium_url, display_id, note='Determining extension')\n                        ext = urlhandle_detect_ext(urlh)\n                        a_format['ext'] = ext\n                    formats.append(a_format)\n\n        self._sort_formats(formats)\n\n        subtitles = {}\n        caption_url = metadata_media_resource.get('captionURL')\n        if caption_url:\n            subtitles['de'] = [{\n                'url': caption_url,\n                'ext': 'ttml',\n            }]\n\n        title = metadata_tracker_data['trackerClipTitle']\n\n        return {\n            'id': metadata_tracker_data.get('trackerClipId', display_id),\n            'display_id': display_id,\n            'title': title,\n            'alt_title': metadata_tracker_data.get('trackerClipSubcategory'),\n            'formats': formats,\n            'subtitles': subtitles,\n            'upload_date': unified_strdate(metadata_tracker_data.get('trackerClipAirTime')),\n        }",
        "begin_line": 19,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRIE._real_extract#197",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRIE",
        "signature": "youtube_dl.extractor.wdr.WDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        url_type = mobj.group('type')\n        page_url = mobj.group('page_url')\n        display_id = mobj.group('display_id')\n        webpage = self._download_webpage(url, display_id)\n\n        info_dict = self._extract_wdr_video(webpage, display_id)\n\n        if not info_dict:\n            entries = [\n                self.url_result(page_url + href[0], 'WDR')\n                for href in re.findall(\n                    r'<a href=\"(%s)\"[^>]+data-extension=' % self._PAGE_REGEX,\n                    webpage)\n            ]\n\n            if entries:  # Playlist page\n                return self.playlist_result(entries, playlist_id=display_id)\n\n            raise ExtractorError('No downloadable streams found', expected=True)\n\n        is_live = url_type == 'live'\n\n        if is_live:\n            info_dict.update({\n                'title': self._live_title(info_dict['title']),\n                'upload_date': None,\n            })\n        elif 'upload_date' not in info_dict:\n            info_dict['upload_date'] = unified_strdate(self._html_search_meta('DC.Date', webpage, 'upload date'))\n\n        info_dict.update({\n            'description': self._html_search_meta('Description', webpage),\n            'is_live': is_live,\n        })\n\n        return info_dict",
        "begin_line": 197,
        "end_line": 234,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract#255",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRMobileIE",
        "signature": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        return {\n            'id': mobj.group('id'),\n            'title': mobj.group('title'),\n            'age_limit': int(mobj.group('age_limit')),\n            'url': url,\n            'http_headers': {\n                'User-Agent': 'mobile',\n            },\n        }",
        "begin_line": 255,
        "end_line": 265,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.webcaster.WebcasterIE._real_extract#30",
        "src_path": "youtube_dl/extractor/webcaster.py",
        "class_name": "youtube_dl.extractor.webcaster.WebcasterIE",
        "signature": "youtube_dl.extractor.webcaster.WebcasterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        video = self._download_xml(url, video_id)\n\n        title = xpath_text(video, './/event_name', 'event name', fatal=True)\n\n        def make_id(parts, separator):\n            return separator.join(filter(None, parts))\n\n        formats = []\n        for format_id in (None, 'noise'):\n            track_tag = make_id(('track', format_id), '_')\n            for track in video.findall('.//iphone/%s' % track_tag):\n                track_url = track.text\n                if not track_url:\n                    continue\n                if determine_ext(track_url) == 'm3u8':\n                    m3u8_formats = self._extract_m3u8_formats(\n                        track_url, video_id, 'mp4',\n                        entry_protocol='m3u8_native',\n                        m3u8_id=make_id(('hls', format_id), '-'), fatal=False)\n                    for f in m3u8_formats:\n                        f.update({\n                            'source_preference': 0 if format_id == 'noise' else 1,\n                            'format_note': track.get('title'),\n                        })\n                    formats.extend(m3u8_formats)\n        self._sort_formats(formats)\n\n        thumbnail = xpath_text(video, './/image', 'thumbnail')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.webcaster.WebcasterFeedIE._extract_url#78",
        "src_path": "youtube_dl/extractor/webcaster.py",
        "class_name": "youtube_dl.extractor.webcaster.WebcasterFeedIE",
        "signature": "youtube_dl.extractor.webcaster.WebcasterFeedIE._extract_url(ie, webpage)",
        "snippet": "    def _extract_url(ie, webpage):\n        mobj = re.search(\n            r'<(?:object|a[^>]+class=[\"\\']webcaster-player[\"\\'])[^>]+data(?:-config)?=([\"\\']).*?config=(?P<url>https?://bl\\.webcaster\\.pro/feed/start/free_.*?)(?:[?&]|\\1)',\n            webpage)\n        if mobj:\n            return mobj.group('url')\n        for secure in (True, False):\n            video_url = ie._og_search_video_url(\n                webpage, secure=secure, default=None)\n            if video_url:\n                mobj = re.search(\n                    r'config=(?P<url>https?://bl\\.webcaster\\.pro/feed/start/free_[^?&=]+)',\n                    video_url)\n                if mobj:\n                    return mobj.group('url')",
        "begin_line": 78,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.webcaster.WebcasterFeedIE._real_extract#94",
        "src_path": "youtube_dl/extractor/webcaster.py",
        "class_name": "youtube_dl.extractor.webcaster.WebcasterFeedIE",
        "signature": "youtube_dl.extractor.webcaster.WebcasterFeedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        feed = self._download_xml(url, video_id)\n\n        video_url = xpath_text(\n            feed, ('video_hd', 'video'), 'video url', fatal=True)\n\n        return self.url_result(video_url, WebcasterIE.ie_key())",
        "begin_line": 94,
        "end_line": 102,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.webofstories.WebOfStoriesIE._real_extract#54",
        "src_path": "youtube_dl/extractor/webofstories.py",
        "class_name": "youtube_dl.extractor.webofstories.WebOfStoriesIE",
        "signature": "youtube_dl.extractor.webofstories.WebOfStoriesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        # Sometimes og:title meta is malformed\n        title = self._og_search_title(webpage, default=None) or self._html_search_regex(\n            r'(?s)<strong>Title:\\s*</strong>(.+?)<', webpage, 'title')\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        embed_params = [s.strip(\" \\r\\n\\t'\") for s in self._search_regex(\n            r'(?s)\\$\\(\"#embedCode\"\\).html\\(getEmbedCode\\((.*?)\\)',\n            webpage, 'embed params').split(',')]\n\n        (\n            _, speaker_id, story_id, story_duration,\n            speaker_type, great_life, _thumbnail, _has_subtitles,\n            story_filename, _story_order) = embed_params\n\n        is_great_life_series = great_life == 'true'\n        duration = int_or_none(story_duration)\n\n        # URL building, see: http://www.webofstories.com/scripts/player.js\n        ms_prefix = ''\n        if speaker_type.lower() == 'ms':\n            ms_prefix = 'mini_sites/'\n\n        if is_great_life_series:\n            mp4_url = '{0:}lives/{1:}/{2:}.mp4'.format(\n                self._VIDEO_DOMAIN, speaker_id, story_filename)\n            rtmp_ext = 'flv'\n            streamer = self._GREAT_LIFE_STREAMER\n            play_path = 'stories/{0:}/{1:}'.format(\n                speaker_id, story_filename)\n        else:\n            mp4_url = '{0:}{1:}{2:}/{3:}.mp4'.format(\n                self._VIDEO_DOMAIN, ms_prefix, speaker_id, story_filename)\n            rtmp_ext = 'mp4'\n            streamer = self._USER_STREAMER\n            play_path = 'mp4:{0:}{1:}/{2}.mp4'.format(\n                ms_prefix, speaker_id, story_filename)\n\n        formats = [{\n            'format_id': 'mp4_sd',\n            'url': mp4_url,\n        }, {\n            'format_id': 'rtmp_sd',\n            'page_url': url,\n            'url': streamer,\n            'ext': rtmp_ext,\n            'play_path': play_path,\n        }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': story_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 54,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE._real_extract#130",
        "src_path": "youtube_dl/extractor/webofstories.py",
        "class_name": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE",
        "signature": "youtube_dl.extractor.webofstories.WebOfStoriesPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        entries = [\n            self.url_result('http://www.webofstories.com/play/%s' % video_number, 'WebOfStories')\n            for video_number in set(re.findall(r'href=\"/playAll/%s\\?sId=(\\d+)\"' % playlist_id, webpage))\n        ]\n\n        title = self._search_regex(\n            r'<div id=\"speakerName\">\\s*<span>([^<]+)</span>',\n            webpage, 'speaker', default=None)\n        if title:\n            field = self._search_regex(\n                r'<span id=\"primaryField\">([^<]+)</span>',\n                webpage, 'field', default=None)\n            if field:\n                title += ' (%s)' % field\n\n        if not title:\n            title = self._search_regex(\n                r'<title>Play\\s+all\\s+stories\\s*-\\s*([^<]+)\\s*-\\s*Web\\s+of\\s+Stories</title>',\n                webpage, 'title')\n\n        return self.playlist_result(entries, playlist_id, title)",
        "begin_line": 130,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.weiqitv.WeiqiTVIE._real_extract#35",
        "src_path": "youtube_dl/extractor/weiqitv.py",
        "class_name": "youtube_dl.extractor.weiqitv.WeiqiTVIE",
        "signature": "youtube_dl.extractor.weiqitv.WeiqiTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        media_id = self._match_id(url)\n        page = self._download_webpage(url, media_id)\n\n        info_json_str = self._search_regex(\n            r'var\\s+video\\s*=\\s*(.+});', page, 'info json str')\n        info_json = self._parse_json(info_json_str, media_id)\n\n        letvcloud_url = self._search_regex(\n            r'var\\s+letvurl\\s*=\\s*\"([^\"]+)', page, 'letvcloud url')\n\n        return {\n            '_type': 'url_transparent',\n            'ie_key': 'LetvCloud',\n            'url': letvcloud_url,\n            'title': info_json['name'],\n            'id': media_id,\n        }",
        "begin_line": 35,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wimp.WimpIE._real_extract#33",
        "src_path": "youtube_dl/extractor/wimp.py",
        "class_name": "youtube_dl.extractor.wimp.WimpIE",
        "signature": "youtube_dl.extractor.wimp.WimpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        youtube_id = self._search_regex(\n            r\"videoId\\s*:\\s*[\\\"']([0-9A-Za-z_-]{11})[\\\"']\",\n            webpage, 'video URL', default=None)\n        if youtube_id:\n            return {\n                '_type': 'url',\n                'url': youtube_id,\n                'ie_key': YoutubeIE.ie_key(),\n            }\n\n        info_dict = self._extract_jwplayer_data(\n            webpage, video_id, require_title=False)\n\n        info_dict.update({\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        })\n\n        return info_dict",
        "begin_line": 33,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wistia.WistiaIE._extract_url#41",
        "src_path": "youtube_dl/extractor/wistia.py",
        "class_name": "youtube_dl.extractor.wistia.WistiaIE",
        "signature": "youtube_dl.extractor.wistia.WistiaIE._extract_url(webpage)",
        "snippet": "    def _extract_url(webpage):\n        match = re.search(\n            r'<(?:meta[^>]+?content|iframe[^>]+?src)=([\"\\'])(?P<url>(?:https?:)?//(?:fast\\.)?wistia\\.net/embed/iframe/.+?)\\1', webpage)\n        if match:\n            return unescapeHTML(match.group('url'))\n\n        match = re.search(r'(?:id=[\"\\']wistia_|data-wistia-?id=[\"\\']|Wistia\\.embed\\([\"\\'])(?P<id>[^\"\\']+)', webpage)\n        if match:\n            return 'wistia:%s' % match.group('id')\n\n        match = re.search(\n            r'''(?sx)\n                <script[^>]+src=([\"'])(?:https?:)?//fast\\.wistia\\.com/assets/external/E-v1\\.js\\1[^>]*>.*?\n                <div[^>]+class=([\"']).*?\\bwistia_async_(?P<id>[a-z0-9]+)\\b.*?\\2\n            ''', webpage)\n        if match:\n            return 'wistia:%s' % match.group('id')",
        "begin_line": 41,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wistia.WistiaIE._real_extract#59",
        "src_path": "youtube_dl/extractor/wistia.py",
        "class_name": "youtube_dl.extractor.wistia.WistiaIE",
        "signature": "youtube_dl.extractor.wistia.WistiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        data_json = self._download_json(\n            self._API_URL % video_id, video_id,\n            # Some videos require this.\n            headers={\n                'Referer': url if url.startswith('http') else self._IFRAME_URL % video_id,\n            })\n\n        if data_json.get('error'):\n            raise ExtractorError(\n                'Error while getting the playlist', expected=True)\n\n        data = data_json['media']\n        title = data['name']\n\n        formats = []\n        thumbnails = []\n        for a in data['assets']:\n            aurl = a.get('url')\n            if not aurl:\n                continue\n            astatus = a.get('status')\n            atype = a.get('type')\n            if (astatus is not None and astatus != 2) or atype in ('preview', 'storyboard'):\n                continue\n            elif atype in ('still', 'still_image'):\n                thumbnails.append({\n                    'url': aurl,\n                    'width': int_or_none(a.get('width')),\n                    'height': int_or_none(a.get('height')),\n                })\n            else:\n                aext = a.get('ext')\n                is_m3u8 = a.get('container') == 'm3u8' or aext == 'm3u8'\n                formats.append({\n                    'format_id': atype,\n                    'url': aurl,\n                    'tbr': int_or_none(a.get('bitrate')),\n                    'vbr': int_or_none(a.get('opt_vbitrate')),\n                    'width': int_or_none(a.get('width')),\n                    'height': int_or_none(a.get('height')),\n                    'filesize': int_or_none(a.get('size')),\n                    'vcodec': a.get('codec'),\n                    'container': a.get('container'),\n                    'ext': 'mp4' if is_m3u8 else aext,\n                    'protocol': 'm3u8' if is_m3u8 else None,\n                    'preference': 1 if atype == 'original' else None,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': data.get('seoDescription'),\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'duration': float_or_none(data.get('duration')),\n            'timestamp': int_or_none(data.get('createdAt')),\n        }",
        "begin_line": 59,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract#21",
        "src_path": "youtube_dl/extractor/worldstarhiphop.py",
        "class_name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE",
        "signature": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        entries = self._parse_html5_media_entries(url, webpage, video_id)\n\n        if not entries:\n            return self.url_result(url, 'Generic')\n\n        title = self._html_search_regex(\n            [r'(?s)<div class=\"content-heading\">\\s*<h1>(.*?)</h1>',\n             r'<span[^>]+class=\"tc-sp-pinned-title\">(.*)</span>'],\n            webpage, 'title')\n\n        info = entries[0]\n        info.update({\n            'id': video_id,\n            'title': title,\n        })\n        return info",
        "begin_line": 21,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract#45",
        "src_path": "youtube_dl/extractor/wrzuta.py",
        "class_name": "youtube_dl.extractor.wrzuta.WrzutaIE",
        "signature": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        typ = mobj.group('typ')\n        uploader = mobj.group('uploader')\n\n        webpage, urlh = self._download_webpage_handle(url, video_id)\n\n        if urlh.geturl() == 'http://www.wrzuta.pl/':\n            raise ExtractorError('Video removed', expected=True)\n\n        quality = qualities(['SD', 'MQ', 'HQ', 'HD'])\n\n        audio_table = {'flv': 'mp3', 'webm': 'ogg', '???': 'mp3'}\n\n        embedpage = self._download_json('http://www.wrzuta.pl/npp/embed/%s/%s' % (uploader, video_id), video_id)\n\n        formats = []\n        for media in embedpage['url']:\n            fmt = media['type'].split('@')[0]\n            if typ == 'audio':\n                ext = audio_table.get(fmt, fmt)\n            else:\n                ext = fmt\n\n            formats.append({\n                'format_id': '%s_%s' % (ext, media['quality'].lower()),\n                'url': media['url'],\n                'ext': ext,\n                'quality': quality(media['quality']),\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'duration': int_or_none(embedpage['duration']),\n            'uploader_id': uploader,\n            'description': self._og_search_description(webpage),\n            'age_limit': embedpage.get('minimalAge', 0),\n        }",
        "begin_line": 45,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wrzuta.WrzutaPlaylistIE._real_extract#126",
        "src_path": "youtube_dl/extractor/wrzuta.py",
        "class_name": "youtube_dl.extractor.wrzuta.WrzutaPlaylistIE",
        "signature": "youtube_dl.extractor.wrzuta.WrzutaPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        uploader = mobj.group('uploader')\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        playlist_size = int_or_none(self._html_search_regex(\n            (r'<div[^>]+class=[\"\\']playlist-counter[\"\\'][^>]*>\\d+/(\\d+)',\n             r'<div[^>]+class=[\"\\']all-counter[\"\\'][^>]*>(.+?)</div>'),\n            webpage, 'playlist size', default=None))\n\n        playlist_title = remove_start(\n            self._og_search_title(webpage), 'Playlista: ')\n\n        entries = []\n        if playlist_size:\n            entries = [\n                self.url_result(entry_url)\n                for _, entry_url in re.findall(\n                    r'<a[^>]+href=([\"\\'])(http.+?)\\1[^>]+class=[\"\\']playlist-file-page',\n                    webpage)]\n            if playlist_size > len(entries):\n                playlist_content = self._download_json(\n                    'http://%s.wrzuta.pl/xhr/get_playlist_offset/%s' % (uploader, playlist_id),\n                    playlist_id,\n                    'Downloading playlist JSON',\n                    'Unable to download playlist JSON')\n                entries.extend([\n                    self.url_result(entry['filelink'])\n                    for entry in playlist_content.get('files', []) if entry.get('filelink')])\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 126,
        "end_line": 158,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wsj.WSJIE._real_extract#43",
        "src_path": "youtube_dl/extractor/wsj.py",
        "class_name": "youtube_dl.extractor.wsj.WSJIE",
        "signature": "youtube_dl.extractor.wsj.WSJIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://video-api.wsj.com/api-video/find_all_videos.asp', video_id,\n            query={\n                'type': 'guid',\n                'count': 1,\n                'query': video_id,\n                'fields': ','.join((\n                    'type', 'hls', 'videoMP4List', 'thumbnailList', 'author',\n                    'description', 'name', 'duration', 'videoURL', 'titletag',\n                    'formattedCreationDate', 'keywords', 'editor')),\n            })['items'][0]\n        title = info.get('name', info.get('titletag'))\n\n        formats = []\n\n        f4m_url = info.get('videoURL')\n        if f4m_url:\n            formats.extend(self._extract_f4m_formats(\n                f4m_url, video_id, f4m_id='hds', fatal=False))\n\n        m3u8_url = info.get('hls')\n        if m3u8_url:\n            formats.extend(self._extract_m3u8_formats(\n                info['hls'], video_id, ext='mp4',\n                entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n\n        for v in info.get('videoMP4List', []):\n            mp4_url = v.get('url')\n            if not mp4_url:\n                continue\n            tbr = int_or_none(v.get('bitrate'))\n            formats.append({\n                'url': mp4_url,\n                'format_id': 'http' + ('-%d' % tbr if tbr else ''),\n                'tbr': tbr,\n                'width': int_or_none(v.get('width')),\n                'height': int_or_none(v.get('height')),\n                'fps': float_or_none(v.get('fps')),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            # Thumbnails are conveniently in the correct format already\n            'thumbnails': info.get('thumbnailList'),\n            'creator': info.get('author'),\n            'uploader_id': info.get('editor'),\n            'duration': int_or_none(info.get('duration')),\n            'upload_date': unified_strdate(info.get(\n                'formattedCreationDate'), day_first=False),\n            'title': title,\n            'categories': info.get('keywords'),\n        }",
        "begin_line": 43,
        "end_line": 99,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.wsj.WSJArticleIE._real_extract#115",
        "src_path": "youtube_dl/extractor/wsj.py",
        "class_name": "youtube_dl.extractor.wsj.WSJArticleIE",
        "signature": "youtube_dl.extractor.wsj.WSJArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        article_id = self._match_id(url)\n        webpage = self._download_webpage(url, article_id)\n        video_id = self._search_regex(\n            r'data-src=[\"\\']([a-fA-F0-9-]{36})', webpage, 'video id')\n        return self.url_result('wsj:%s' % video_id, WSJIE.ie_key(), video_id)",
        "begin_line": 115,
        "end_line": 120,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xbef.XBefIE._real_extract#21",
        "src_path": "youtube_dl/extractor/xbef.py",
        "class_name": "youtube_dl.extractor.xbef.XBefIE",
        "signature": "youtube_dl.extractor.xbef.XBefIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1[^>]*>(.*?)</h1>', webpage, 'title')\n\n        config_url_enc = self._download_webpage(\n            'http://xbef.com/Main/GetVideoURLEncoded/%s' % video_id, video_id,\n            note='Retrieving config URL')\n        config_url = compat_urllib_parse_unquote(config_url_enc)\n        config = self._download_xml(\n            config_url, video_id, note='Retrieving config')\n\n        video_url = config.find('./file').text\n        thumbnail = config.find('./image').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract#27",
        "src_path": "youtube_dl/extractor/xboxclips.py",
        "class_name": "youtube_dl.extractor.xboxclips.XboxClipsIE",
        "signature": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'>(?:Link|Download): <a[^>]+href=\"([^\"]+)\"', webpage, 'video URL')\n        title = self._html_search_regex(\n            r'<title>XboxClips \\| ([^<]+)</title>', webpage, 'title')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'>Recorded: ([^<]+)<', webpage, 'upload date', fatal=False))\n        filesize = parse_filesize(self._html_search_regex(\n            r'>Size: ([^<]+)<', webpage, 'file size', fatal=False))\n        duration = int_or_none(self._html_search_regex(\n            r'>Duration: (\\d+) Seconds<', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'>Views: (\\d+)<', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'upload_date': upload_date,\n            'filesize_approx': filesize,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 27,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xfileshare.XFileShareIE._real_extract#121",
        "src_path": "youtube_dl/extractor/xfileshare.py",
        "class_name": "youtube_dl.extractor.xfileshare.XFileShareIE",
        "signature": "youtube_dl.extractor.xfileshare.XFileShareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'http://%s/%s' % (mobj.group('host'), video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        if any(re.search(p, webpage) for p in self._FILE_NOT_FOUND_REGEXES):\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        fields = self._hidden_inputs(webpage)\n\n        if fields['op'] == 'download1':\n            countdown = int_or_none(self._search_regex(\n                r'<span id=\"countdown_str\">(?:[Ww]ait)?\\s*<span id=\"cxc\">(\\d+)</span>\\s*(?:seconds?)?</span>',\n                webpage, 'countdown', default=None))\n            if countdown:\n                self._sleep(countdown, video_id)\n\n            webpage = self._download_webpage(\n                url, video_id, 'Downloading video page',\n                data=urlencode_postdata(fields), headers={\n                    'Referer': url,\n                    'Content-type': 'application/x-www-form-urlencoded',\n                })\n\n        title = (self._search_regex(\n            (r'style=\"z-index: [0-9]+;\">([^<]+)</span>',\n             r'<td nowrap>([^<]+)</td>',\n             r'h4-fine[^>]*>([^<]+)<',\n             r'>Watch (.+) ',\n             r'<h2 class=\"video-page-head\">([^<]+)</h2>',\n             r'<h2 style=\"[^\"]*color:#403f3d[^\"]*\"[^>]*>([^<]+)<'),  # streamin.to\n            webpage, 'title', default=None) or self._og_search_title(\n            webpage, default=None) or video_id).strip()\n\n        def extract_formats(default=NO_DEFAULT):\n            urls = []\n            for regex in (\n                    r'(?:file|src)\\s*:\\s*([\"\\'])(?P<url>http(?:(?!\\1).)+\\.(?:m3u8|mp4|flv)(?:(?!\\1).)*)\\1',\n                    r'file_link\\s*=\\s*([\"\\'])(?P<url>http(?:(?!\\1).)+)\\1',\n                    r'addVariable\\((\\\\?[\"\\'])file\\1\\s*,\\s*(\\\\?[\"\\'])(?P<url>http(?:(?!\\2).)+)\\2\\)',\n                    r'<embed[^>]+src=([\"\\'])(?P<url>http(?:(?!\\1).)+\\.(?:m3u8|mp4|flv)(?:(?!\\1).)*)\\1'):\n                for mobj in re.finditer(regex, webpage):\n                    video_url = mobj.group('url')\n                    if video_url not in urls:\n                        urls.append(video_url)\n            formats = []\n            for video_url in urls:\n                if determine_ext(video_url) == 'm3u8':\n                    formats.extend(self._extract_m3u8_formats(\n                        video_url, video_id, 'mp4',\n                        entry_protocol='m3u8_native', m3u8_id='hls',\n                        fatal=False))\n                else:\n                    formats.append({\n                        'url': video_url,\n                        'format_id': 'sd',\n                    })\n            if not formats and default is not NO_DEFAULT:\n                return default\n            self._sort_formats(formats)\n            return formats\n\n        formats = extract_formats(default=None)\n\n        if not formats:\n            webpage = decode_packed_codes(self._search_regex(\n                r\"(}\\('(.+)',(\\d+),(\\d+),'[^']*\\b(?:file|embed)\\b[^']*'\\.split\\('\\|'\\))\",\n                webpage, 'packed code'))\n            formats = extract_formats()\n\n        thumbnail = self._search_regex(\n            r'image\\s*:\\s*[\"\\'](http[^\"\\']+)[\"\\'],', webpage, 'thumbnail', default=None)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 121,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract#86",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('id_2')\n        display_id = mobj.group('display_id') or mobj.group('display_id_2')\n\n        webpage = self._download_webpage(url, video_id)\n\n        error = self._html_search_regex(\n            r'<div[^>]+id=[\"\\']videoClosed[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'error', default=None)\n        if error:\n            raise ExtractorError(error, expected=True)\n\n        title = self._html_search_regex(\n            [r'<h1[^>]*>([^<]+)</h1>',\n             r'<meta[^>]+itemprop=\".*?caption.*?\"[^>]+content=\"(.+?)\"',\n             r'<title[^>]*>(.+?)(?:,\\s*[^,]*?\\s*Porn\\s*[^,]*?:\\s*xHamster[^<]*| - xHamster\\.com)</title>'],\n            webpage, 'title')\n\n        formats = []\n        format_urls = set()\n\n        sources = self._parse_json(\n            self._search_regex(\n                r'sources\\s*:\\s*({.+?})\\s*,?\\s*\\n', webpage, 'sources',\n                default='{}'),\n            video_id, fatal=False)\n        for format_id, format_url in sources.items():\n            if not isinstance(format_url, compat_str):\n                continue\n            if format_url in format_urls:\n                continue\n            format_urls.add(format_url)\n            formats.append({\n                'format_id': format_id,\n                'url': format_url,\n                'height': int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]', format_id, 'height', default=None))\n            })\n\n        video_url = self._search_regex(\n            [r'''file\\s*:\\s*(?P<q>[\"'])(?P<mp4>.+?)(?P=q)''',\n             r'''<a\\s+href=(?P<q>[\"'])(?P<mp4>.+?)(?P=q)\\s+class=[\"']mp4Thumb''',\n             r'''<video[^>]+file=(?P<q>[\"'])(?P<mp4>.+?)(?P=q)[^>]*>'''],\n            webpage, 'video url', group='mp4', default=None)\n        if video_url and video_url not in format_urls:\n            formats.append({\n                'url': video_url,\n            })\n\n        self._sort_formats(formats)\n\n        # Only a few videos have an description\n        mobj = re.search(r'<span>Description: </span>([^<]+)', webpage)\n        description = mobj.group(1) if mobj else None\n\n        upload_date = unified_strdate(self._search_regex(\n            r'hint=[\"\\'](\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2} [A-Z]{3,4}',\n            webpage, 'upload date', fatal=False))\n\n        uploader = self._html_search_regex(\n            r'<span[^>]+itemprop=[\"\\']author[^>]+><a[^>]+><span[^>]+>([^<]+)',\n            webpage, 'uploader', default='anonymous')\n\n        thumbnail = self._search_regex(\n            [r'''thumb\\s*:\\s*(?P<q>[\"'])(?P<thumbnail>.+?)(?P=q)''',\n             r'''<video[^>]+poster=(?P<q>[\"'])(?P<thumbnail>.+?)(?P=q)[^>]*>'''],\n            webpage, 'thumbnail', fatal=False, group='thumbnail')\n\n        duration = parse_duration(self._search_regex(\n            [r'<[^<]+\\bitemprop=[\"\\']duration[\"\\'][^<]+\\bcontent=[\"\\'](.+?)[\"\\']',\n             r'Runtime:\\s*</span>\\s*([\\d:]+)'], webpage,\n            'duration', fatal=False))\n\n        view_count = int_or_none(self._search_regex(\n            r'content=[\"\\']User(?:View|Play)s:(\\d+)',\n            webpage, 'view count', fatal=False))\n\n        mobj = re.search(r'hint=[\\'\"](?P<likecount>\\d+) Likes / (?P<dislikecount>\\d+) Dislikes', webpage)\n        (like_count, dislike_count) = (mobj.group('likecount'), mobj.group('dislikecount')) if mobj else (None, None)\n\n        mobj = re.search(r'</label>Comments \\((?P<commentcount>\\d+)\\)</div>', webpage)\n        comment_count = mobj.group('commentcount') if mobj else 0\n\n        age_limit = self._rta_search(webpage)\n\n        categories_html = self._search_regex(\n            r'(?s)<table.+?(<span>Categories:.+?)</table>', webpage,\n            'categories', default=None)\n        categories = [clean_html(category) for category in re.findall(\n            r'<a[^>]+>(.+?)</a>', categories_html)] if categories_html else None\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': age_limit,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 86,
        "end_line": 194,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls#213",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._extract_urls(webpage)",
        "snippet": "    def _extract_urls(webpage):\n        return [url for _, url in re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?xhamster\\.com/xembed\\.php\\?video=\\d+)\\1',\n            webpage)]",
        "begin_line": 213,
        "end_line": 216,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._real_extract#218",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterEmbedIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'href=\"(https?://xhamster\\.com/movies/%s/[^\"]*\\.html[^\"]*)\"' % video_id,\n            webpage, 'xhamster url', default=None)\n\n        if not video_url:\n            vars = self._parse_json(\n                self._search_regex(r'vars\\s*:\\s*({.+?})\\s*,\\s*\\n', webpage, 'vars'),\n                video_id)\n            video_url = dict_get(vars, ('downloadLink', 'homepageLink', 'commentsLink', 'shareUrl'))\n\n        return self.url_result(video_url, 'XHamster')",
        "begin_line": 218,
        "end_line": 233,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiBaseIE._download_webpage#12",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiBaseIE",
        "signature": "youtube_dl.extractor.xiami.XiamiBaseIE._download_webpage(self, *args, **kwargs)",
        "snippet": "    def _download_webpage(self, *args, **kwargs):\n        webpage = super(XiamiBaseIE, self)._download_webpage(*args, **kwargs)\n        if '>Xiami is currently not available in your country.<' in webpage:\n            self.raise_geo_restricted('Xiami is currently not available in your country')\n        return webpage",
        "begin_line": 12,
        "end_line": 16,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiBaseIE._extract_track#18",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiBaseIE",
        "signature": "youtube_dl.extractor.xiami.XiamiBaseIE._extract_track(self, track, track_id=None)",
        "snippet": "    def _extract_track(self, track, track_id=None):\n        track_name = track.get('songName') or track.get('name') or track['subName']\n        artist = track.get('artist') or track.get('artist_name') or track.get('singers')\n        title = '%s - %s' % (artist, track_name) if artist else track_name\n        track_url = self._decrypt(track['location'])\n\n        subtitles = {}\n        lyrics_url = track.get('lyric_url') or track.get('lyric')\n        if lyrics_url and lyrics_url.startswith('http'):\n            subtitles['origin'] = [{'url': lyrics_url}]\n\n        return {\n            'id': track.get('song_id') or track_id,\n            'url': track_url,\n            'title': title,\n            'thumbnail': track.get('pic') or track.get('album_pic'),\n            'duration': int_or_none(track.get('length')),\n            'creator': track.get('artist', '').split(';')[0],\n            'track': track_name,\n            'track_number': int_or_none(track.get('track')),\n            'album': track.get('album_name') or track.get('title'),\n            'artist': artist,\n            'subtitles': subtitles,\n        }",
        "begin_line": 18,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiBaseIE._extract_tracks#43",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiBaseIE",
        "signature": "youtube_dl.extractor.xiami.XiamiBaseIE._extract_tracks(self, item_id, typ=None)",
        "snippet": "    def _extract_tracks(self, item_id, typ=None):\n        playlist = self._download_json(\n            '%s/%s%s' % (self._API_BASE_URL, item_id, '/type/%s' % typ if typ else ''), item_id)\n        return [\n            self._extract_track(track, item_id)\n            for track in playlist['data']['trackList']]",
        "begin_line": 43,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiBaseIE._decrypt#51",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiBaseIE",
        "signature": "youtube_dl.extractor.xiami.XiamiBaseIE._decrypt(origin)",
        "snippet": "    def _decrypt(origin):\n        n = int(origin[0])\n        origin = origin[1:]\n        short_lenth = len(origin) // n\n        long_num = len(origin) - short_lenth * n\n        l = tuple()\n        for i in range(0, n):\n            length = short_lenth\n            if i < long_num:\n                length += 1\n            l += (origin[0:length], )\n            origin = origin[length:]\n        ans = ''\n        for i in range(0, short_lenth + 1):\n            for j in range(0, n):\n                if len(l[j]) > i:\n                    ans += l[j][i]\n        return compat_urllib_parse_unquote(ans).replace('^', '0')",
        "begin_line": 51,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiSongIE._real_extract#137",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiSongIE",
        "signature": "youtube_dl.extractor.xiami.XiamiSongIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_tracks(self._match_id(url))[0]",
        "begin_line": 137,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xiami.XiamiPlaylistBaseIE._real_extract#142",
        "src_path": "youtube_dl/extractor/xiami.py",
        "class_name": "youtube_dl.extractor.xiami.XiamiPlaylistBaseIE",
        "signature": "youtube_dl.extractor.xiami.XiamiPlaylistBaseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        item_id = self._match_id(url)\n        return self.playlist_result(self._extract_tracks(item_id, self._TYPE), item_id)",
        "begin_line": 142,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xminus.XMinusIE._real_extract#34",
        "src_path": "youtube_dl/extractor/xminus.py",
        "class_name": "youtube_dl.extractor.xminus.XMinusIE",
        "signature": "youtube_dl.extractor.xminus.XMinusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        artist = self._html_search_regex(\n            r'<a[^>]+href=\"/artist/\\d+\">([^<]+)</a>', webpage, 'artist')\n        title = artist + '-' + self._html_search_regex(\n            r'<span[^>]+class=\"minustrack-full-title(?:\\s+[^\"]+)?\"[^>]*>([^<]+)', webpage, 'title')\n        duration = parse_duration(self._html_search_regex(\n            r'<span[^>]+class=\"player-duration(?:\\s+[^\"]+)?\"[^>]*>([^<]+)',\n            webpage, 'duration', fatal=False))\n        mobj = re.search(\n            r'<div[^>]+class=\"dw-info(?:\\s+[^\"]+)?\"[^>]*>(?P<tbr>\\d+)\\s*\u043a\u0431\u0438\u0442/c\\s+(?P<filesize>[0-9.]+)\\s*\u043c\u0431</div>',\n            webpage)\n        tbr = filesize_approx = None\n        if mobj:\n            filesize_approx = float(mobj.group('filesize')) * 1000000\n            tbr = float(mobj.group('tbr'))\n        view_count = int_or_none(self._html_search_regex(\n            r'<span><[^>]+class=\"icon-chart-bar\".*?>(\\d+)</span>',\n            webpage, 'view count', fatal=False))\n        description = self._html_search_regex(\n            r'(?s)<pre[^>]+id=\"lyrics-original\"[^>]*>(.*?)</pre>',\n            webpage, 'song lyrics', fatal=False)\n        if description:\n            description = re.sub(' *\\r *', '\\n', description)\n\n        k = self._search_regex(\n            r'<div[^>]+id=\"player-bottom\"[^>]+data-k=\"([^\"]+)\">', webpage,\n            'encoded data')\n        h = time.time() / 3600\n        a = sum(map(int, [compat_ord(c) for c in k])) + int(video_id) + h\n        video_url = 'http://x-minus.me/dl/minus?id=%s&tkn2=%df%d' % (video_id, a, h)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            # The extension is unknown until actual downloading\n            'ext': 'mp3',\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n            'tbr': tbr,\n            'view_count': view_count,\n            'description': description,\n        }",
        "begin_line": 34,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xnxx.XNXXIE._real_extract#27",
        "src_path": "youtube_dl/extractor/xnxx.py",
        "class_name": "youtube_dl.extractor.xnxx.XNXXIE",
        "signature": "youtube_dl.extractor.xnxx.XNXXIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(r'flv_url=(.*?)&amp;',\n                                       webpage, 'video URL')\n        video_url = compat_urllib_parse_unquote(video_url)\n\n        video_title = self._html_search_regex(r'<title>(.*?)\\s+-\\s+XNXX.COM',\n                                              webpage, 'title')\n\n        video_thumbnail = self._search_regex(r'url_bigthumb=(.*?)&amp;',\n                                             webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xstream.XstreamIE._extract_video_info#45",
        "src_path": "youtube_dl/extractor/xstream.py",
        "class_name": "youtube_dl.extractor.xstream.XstreamIE",
        "signature": "youtube_dl.extractor.xstream.XstreamIE._extract_video_info(self, partner_id, video_id)",
        "snippet": "    def _extract_video_info(self, partner_id, video_id):\n        data = self._download_xml(\n            'http://frontend.xstream.dk/%s/feed/video/?platform=web&id=%s'\n            % (partner_id, video_id),\n            video_id)\n\n        NS_MAP = {\n            'atom': 'http://www.w3.org/2005/Atom',\n            'xt': 'http://xstream.dk/',\n            'media': 'http://search.yahoo.com/mrss/',\n        }\n\n        entry = data.find(xpath_with_ns('./atom:entry', NS_MAP))\n\n        title = xpath_text(\n            entry, xpath_with_ns('./atom:title', NS_MAP), 'title')\n        description = xpath_text(\n            entry, xpath_with_ns('./atom:summary', NS_MAP), 'description')\n        timestamp = parse_iso8601(xpath_text(\n            entry, xpath_with_ns('./atom:published', NS_MAP), 'upload date'))\n\n        formats = []\n        media_group = entry.find(xpath_with_ns('./media:group', NS_MAP))\n        for media_content in media_group.findall(xpath_with_ns('./media:content', NS_MAP)):\n            media_url = media_content.get('url')\n            if not media_url:\n                continue\n            tbr = int_or_none(media_content.get('bitrate'))\n            mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', media_url)\n            if mobj:\n                formats.append({\n                    'url': mobj.group('url'),\n                    'play_path': 'mp4:%s' % mobj.group('playpath'),\n                    'app': mobj.group('app'),\n                    'ext': 'flv',\n                    'tbr': tbr,\n                    'format_id': 'rtmp-%d' % tbr,\n                })\n            else:\n                formats.append({\n                    'url': media_url,\n                    'tbr': tbr,\n                })\n        self._sort_formats(formats)\n\n        link = find_xpath_attr(\n            entry, xpath_with_ns('./atom:link', NS_MAP), 'rel', 'original')\n        if link is not None:\n            formats.append({\n                'url': link.get('href'),\n                'format_id': link.get('rel'),\n                'preference': 1,\n            })\n\n        thumbnails = [{\n            'url': splash.get('url'),\n            'width': int_or_none(splash.get('width')),\n            'height': int_or_none(splash.get('height')),\n        } for splash in media_group.findall(xpath_with_ns('./xt:splash', NS_MAP))]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 45,
        "end_line": 112,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xstream.XstreamIE._real_extract#114",
        "src_path": "youtube_dl/extractor/xstream.py",
        "class_name": "youtube_dl.extractor.xstream.XstreamIE",
        "signature": "youtube_dl.extractor.xstream.XstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        partner_id = mobj.group('partner_id')\n        video_id = mobj.group('id')\n\n        return self._extract_video_info(partner_id, video_id)",
        "begin_line": 114,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeIE._real_extract#69",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeIE",
        "signature": "youtube_dl.extractor.xtube.XTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        if not display_id:\n            display_id = video_id\n\n        if video_id.isdigit() and len(video_id) < 11:\n            url_pattern = 'http://www.xtube.com/video-watch/-%s'\n        else:\n            url_pattern = 'http://www.xtube.com/watch.php?v=%s'\n\n        webpage = self._download_webpage(\n            url_pattern % video_id, display_id, headers={\n                'Cookie': 'age_verified=1; cookiesAccepted=1',\n            })\n\n        sources = self._parse_json(self._search_regex(\n            r'([\"\\'])?sources\\1?\\s*:\\s*(?P<sources>{.+?}),',\n            webpage, 'sources', group='sources'), video_id,\n            transform_source=js_to_json)\n\n        formats = []\n        for format_id, format_url in sources.items():\n            formats.append({\n                'url': format_url,\n                'format_id': format_id,\n                'height': int_or_none(format_id),\n            })\n        self._remove_duplicate_formats(formats)\n        self._sort_formats(formats)\n\n        title = self._search_regex(\n            (r'<h1>\\s*(?P<title>[^<]+?)\\s*</h1>', r'videoTitle\\s*:\\s*([\"\\'])(?P<title>.+?)\\1'),\n            webpage, 'title', group='title')\n        description = self._search_regex(\n            r'</h1>\\s*<p>([^<]+)', webpage, 'description', fatal=False)\n        uploader = self._search_regex(\n            (r'<input[^>]+name=\"contentOwnerId\"[^>]+value=\"([^\"]+)\"',\n             r'<span[^>]+class=\"nickname\"[^>]*>([^<]+)'),\n            webpage, 'uploader', fatal=False)\n        duration = parse_duration(self._search_regex(\n            r'<dt>Runtime:?</dt>\\s*<dd>([^<]+)</dd>',\n            webpage, 'duration', fatal=False))\n        view_count = str_to_int(self._search_regex(\n            r'<dt>Views:?</dt>\\s*<dd>([\\d,\\.]+)</dd>',\n            webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'>Comments? \\(([\\d,\\.]+)\\)<',\n            webpage, 'comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'uploader': uploader,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 69,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract#147",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeUserIE",
        "signature": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        user_id = self._match_id(url)\n\n        entries = []\n        for pagenum in itertools.count(1):\n            request = sanitized_Request(\n                'http://www.xtube.com/profile/%s/videos/%d' % (user_id, pagenum),\n                headers={\n                    'Cookie': 'popunder=4',\n                    'X-Requested-With': 'XMLHttpRequest',\n                    'Referer': url,\n                })\n\n            page = self._download_json(\n                request, user_id, 'Downloading videos JSON page %d' % pagenum)\n\n            html = page.get('html')\n            if not html:\n                break\n\n            for video_id in orderedSet([video_id for _, video_id in re.findall(\n                    r'data-plid=([\"\\'])(.+?)\\1', html)]):\n                entries.append(self.url_result('xtube:%s' % video_id, XTubeIE.ie_key()))\n\n            page_count = int_or_none(page.get('pageCount'))\n            if not page_count or pagenum == page_count:\n                break\n\n        playlist = self.playlist_result(entries, user_id)\n        playlist['age_limit'] = 18\n        return playlist",
        "begin_line": 147,
        "end_line": 177,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xuite.XuiteIE._real_extract#89",
        "src_path": "youtube_dl/extractor/xuite.py",
        "class_name": "youtube_dl.extractor.xuite.XuiteIE",
        "signature": "youtube_dl.extractor.xuite.XuiteIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # /play/ URLs provide embedded video URL and more metadata\n        url = url.replace('/embed/', '/play/')\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        error_msg = self._search_regex(\n            r'<div id=\"error-message-content\">([^<]+)',\n            webpage, 'error message', default=None)\n        if error_msg:\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_msg),\n                expected=True)\n\n        media_info = self._parse_json(self._search_regex(\n            r'var\\s+mediaInfo\\s*=\\s*({.*});', webpage, 'media info'), video_id)\n\n        video_id = media_info['MEDIA_ID']\n\n        formats = []\n        for key in ('html5Url', 'html5HQUrl'):\n            video_url = media_info.get(key)\n            if not video_url:\n                continue\n            format_id = self._search_regex(\n                r'\\bq=(.+?)\\b', video_url, 'format id', default=None)\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4' if format_id.isnumeric() else format_id,\n                'format_id': format_id,\n                'height': int(format_id) if format_id.isnumeric() else None,\n            })\n        self._sort_formats(formats)\n\n        timestamp = media_info.get('PUBLISH_DATETIME')\n        if timestamp:\n            timestamp = parse_iso8601(timestamp + ' +0800', ' ')\n\n        category = media_info.get('catName')\n        categories = [category] if category else []\n\n        uploader = media_info.get('NICKNAME')\n        uploader_url = None\n\n        author_div = get_element_by_attribute('itemprop', 'author', webpage)\n        if author_div:\n            uploader = uploader or self._html_search_meta('name', author_div)\n            uploader_url = self._html_search_regex(\n                r'<link[^>]+itemprop=\"url\"[^>]+href=\"([^\"]+)\"', author_div,\n                'uploader URL', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': media_info['TITLE'],\n            'description': remove_end(media_info.get('metaDesc'), ' (Xuite \u5f71\u97f3)'),\n            'thumbnail': media_info.get('ogImageUrl'),\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': media_info.get('MEMBER_ID'),\n            'uploader_url': uploader_url,\n            'duration': float_or_none(media_info.get('MEDIA_DURATION'), 1000000),\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 89,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xvideos.XVideosIE._real_extract#30",
        "src_path": "youtube_dl/extractor/xvideos.py",
        "class_name": "youtube_dl.extractor.xvideos.XVideosIE",
        "signature": "youtube_dl.extractor.xvideos.XVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        mobj = re.search(r'<h1 class=\"inlineError\">(.+?)</h1>', webpage)\n        if mobj:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, clean_html(mobj.group(1))), expected=True)\n\n        video_title = self._html_search_regex(\n            r'<title>(.*?)\\s+-\\s+XVID', webpage, 'title')\n        video_thumbnail = self._search_regex(\n            r'url_bigthumb=(.+?)&amp', webpage, 'thumbnail', fatal=False)\n        video_duration = int_or_none(self._og_search_property(\n            'duration', webpage, default=None)) or parse_duration(\n            self._search_regex(\n                r'<span[^>]+class=[\"\\']duration[\"\\'][^>]*>.*?(\\d[^<]+)',\n                webpage, 'duration', fatal=False))\n\n        formats = []\n\n        video_url = compat_urllib_parse_unquote(self._search_regex(\n            r'flv_url=(.+?)&', webpage, 'video URL', default=''))\n        if video_url:\n            formats.append({\n                'url': video_url,\n                'format_id': 'flv',\n            })\n\n        for kind, _, format_url in re.findall(\n                r'setVideo([^(]+)\\(([\"\\'])(http.+?)\\2\\)', webpage):\n            format_id = kind.lower()\n            if format_id == 'hls':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4',\n                    entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))\n            elif format_id in ('urllow', 'urlhigh'):\n                formats.append({\n                    'url': format_url,\n                    'format_id': '%s-%s' % (determine_ext(format_url, 'mp4'), format_id[3:]),\n                    'quality': -2 if format_id.endswith('low') else None,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'duration': video_duration,\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE._real_extract#31",
        "src_path": "youtube_dl/extractor/xxxymovies.py",
        "class_name": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE",
        "signature": "youtube_dl.extractor.xxxymovies.XXXYMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._search_regex(\n            r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video URL')\n\n        title = self._html_search_regex(\n            [r'<div[^>]+\\bclass=\"block_header\"[^>]*>\\s*<h1>([^<]+)<',\n             r'<title>(.*?)\\s*-\\s*(?:XXXYMovies\\.com|XXX\\s+Movies)</title>'],\n            webpage, 'title')\n\n        thumbnail = self._search_regex(\n            r\"preview_url\\s*:\\s*'([^']+)'\",\n            webpage, 'thumbnail', fatal=False)\n\n        categories = self._html_search_meta(\n            'keywords', webpage, 'categories', default='').split(',')\n\n        duration = parse_duration(self._search_regex(\n            r'<span>Duration:</span>\\s*(\\d+:\\d+)',\n            webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<div class=\"video_views\">\\s*(\\d+)',\n            webpage, 'view count', fatal=False))\n        like_count = int_or_none(self._search_regex(\n            r'>\\s*Likes? <b>\\((\\d+)\\)',\n            webpage, 'like count', fatal=False))\n        dislike_count = int_or_none(self._search_regex(\n            r'>\\s*Dislike <b>\\((\\d+)\\)</b>',\n            webpage, 'dislike count', fatal=False))\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'age_limit': age_limit,\n        }",
        "begin_line": 31,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._real_extract#232",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id') or self._match_id(url)\n        page_id = mobj.group('id')\n        url = mobj.group('url')\n        host = mobj.group('host')\n        webpage, urlh = self._download_webpage_handle(url, display_id)\n        if 'err=404' in urlh.geturl():\n            raise ExtractorError('Video gone', expected=True)\n\n        # Look for iframed media first\n        entries = []\n        iframe_urls = re.findall(r'<iframe[^>]+src=\"(/video/.+?-\\d+\\.html\\?format=embed.*?)\"', webpage)\n        for idx, iframe_url in enumerate(iframe_urls):\n            entries.append(self.url_result(host + iframe_url, 'Yahoo'))\n        if entries:\n            return self.playlist_result(entries, page_id)\n\n        # Look for NBCSports iframes\n        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)\n        if nbc_sports_url:\n            return self.url_result(nbc_sports_url, NBCSportsVPlayerIE.ie_key())\n\n        # Look for Brightcove Legacy Studio embeds\n        bc_url = BrightcoveLegacyIE._extract_brightcove_url(webpage)\n        if bc_url:\n            return self.url_result(bc_url, BrightcoveLegacyIE.ie_key())\n\n        # Look for Brightcove New Studio embeds\n        bc_url = BrightcoveNewIE._extract_url(self, webpage)\n        if bc_url:\n            return self.url_result(bc_url, BrightcoveNewIE.ie_key())\n\n        # Query result is often embedded in webpage as JSON. Sometimes explicit requests\n        # to video API results in a failure with geo restriction reason therefore using\n        # embedded query result when present sounds reasonable.\n        config_json = self._search_regex(\n            r'window\\.Af\\.bootstrap\\[[^\\]]+\\]\\s*=\\s*({.*?\"applet_type\"\\s*:\\s*\"td-applet-videoplayer\".*?});(?:</script>|$)',\n            webpage, 'videoplayer applet', default=None)\n        if config_json:\n            config = self._parse_json(config_json, display_id, fatal=False)\n            if config:\n                sapi = config.get('models', {}).get('applet_model', {}).get('data', {}).get('sapi')\n                if sapi and 'query' in sapi:\n                    info = self._extract_info(display_id, sapi, webpage)\n                    self._sort_formats(info['formats'])\n                    return info\n\n        items_json = self._search_regex(\n            r'mediaItems: ({.*?})$', webpage, 'items', flags=re.MULTILINE,\n            default=None)\n        if items_json is None:\n            alias = self._search_regex(\n                r'\"aliases\":{\"video\":\"(.*?)\"', webpage, 'alias', default=None)\n            if alias is not None:\n                alias_info = self._download_json(\n                    'https://www.yahoo.com/_td/api/resource/VideoService.videos;video_aliases=[\"%s\"]' % alias,\n                    display_id, 'Downloading alias info')\n                video_id = alias_info[0]['id']\n            else:\n                CONTENT_ID_REGEXES = [\n                    r'YUI\\.namespace\\(\"Media\"\\)\\.CONTENT_ID\\s*=\\s*\"([^\"]+)\"',\n                    r'root\\.App\\.Cache\\.context\\.videoCache\\.curVideo = \\{\"([^\"]+)\"',\n                    r'\"first_videoid\"\\s*:\\s*\"([^\"]+)\"',\n                    r'%s[^}]*\"ccm_id\"\\s*:\\s*\"([^\"]+)\"' % re.escape(page_id),\n                    r'<article[^>]data-uuid=[\"\\']([^\"\\']+)',\n                    r'<meta[^<>]+yahoo://article/view\\?.*\\buuid=([^&\"\\']+)',\n                    r'<meta[^<>]+[\"\\']ytwnews://cavideo/(?:[^/]+/)+([\\da-fA-F-]+)[&\"\\']',\n                ]\n                video_id = self._search_regex(\n                    CONTENT_ID_REGEXES, webpage, 'content ID')\n        else:\n            items = json.loads(items_json)\n            info = items['mediaItems']['query']['results']['mediaObj'][0]\n            # The 'meta' field is not always in the video webpage, we request it\n            # from another page\n            video_id = info['id']\n        return self._get_info(video_id, display_id, webpage)",
        "begin_line": 232,
        "end_line": 309,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._extract_info#311",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._extract_info(self, display_id, query, webpage)",
        "snippet": "    def _extract_info(self, display_id, query, webpage):\n        info = query['query']['results']['mediaObj'][0]\n        meta = info.get('meta')\n        video_id = info.get('id')\n\n        if not meta:\n            msg = info['status'].get('msg')\n            if msg:\n                raise ExtractorError(\n                    '%s returned error: %s' % (self.IE_NAME, msg), expected=True)\n            raise ExtractorError('Unable to extract media object meta')\n\n        formats = []\n        for s in info['streams']:\n            tbr = int_or_none(s.get('bitrate'))\n            format_info = {\n                'width': int_or_none(s.get('width')),\n                'height': int_or_none(s.get('height')),\n                'tbr': tbr,\n            }\n\n            host = s['host']\n            path = s['path']\n            if host.startswith('rtmp'):\n                fmt = 'rtmp'\n                format_info.update({\n                    'url': host,\n                    'play_path': path,\n                    'ext': 'flv',\n                })\n            else:\n                if s.get('format') == 'm3u8_playlist':\n                    fmt = 'hls'\n                    format_info.update({\n                        'protocol': 'm3u8_native',\n                        'ext': 'mp4',\n                    })\n                else:\n                    fmt = format_info['ext'] = determine_ext(path)\n                format_url = compat_urlparse.urljoin(host, path)\n                format_info['url'] = format_url\n            format_info['format_id'] = fmt + ('-%d' % tbr if tbr else '')\n            formats.append(format_info)\n\n        closed_captions = self._html_search_regex(\n            r'\"closedcaptions\":(\\[[^\\]]+\\])', webpage, 'closed captions',\n            default='[]')\n\n        cc_json = self._parse_json(closed_captions, video_id, fatal=False)\n        subtitles = {}\n        if cc_json:\n            for closed_caption in cc_json:\n                lang = closed_caption['lang']\n                if lang not in subtitles:\n                    subtitles[lang] = []\n                subtitles[lang].append({\n                    'url': closed_caption['url'],\n                    'ext': mimetype2ext(closed_caption['content_type']),\n                })\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': unescapeHTML(meta['title']),\n            'formats': formats,\n            'description': clean_html(meta['description']),\n            'thumbnail': meta['thumbnail'] if meta.get('thumbnail') else self._og_search_thumbnail(webpage),\n            'duration': int_or_none(meta.get('duration')),\n            'subtitles': subtitles,\n        }",
        "begin_line": 311,
        "end_line": 380,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._get_info#382",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._get_info(self, video_id, display_id, webpage)",
        "snippet": "    def _get_info(self, video_id, display_id, webpage):\n        region = self._search_regex(\n            r'\\\\?\"region\\\\?\"\\s*:\\s*\\\\?\"([^\"]+?)\\\\?\"',\n            webpage, 'region', fatal=False, default='US').upper()\n        formats = []\n        info = {}\n        for fmt in ('webm', 'mp4'):\n            query_result = self._download_json(\n                'https://video.media.yql.yahoo.com/v1/video/sapi/streams/' + video_id,\n                display_id, 'Downloading %s video info' % fmt, query={\n                    'protocol': 'http',\n                    'region': region,\n                    'format': fmt,\n                })\n            info = self._extract_info(display_id, query_result, webpage)\n            formats.extend(info['formats'])\n        formats.extend(self._extract_m3u8_formats(\n            'http://video.media.yql.yahoo.com/v1/hls/%s?region=%s' % (video_id, region),\n            video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))\n        self._sort_formats(formats)\n        info['formats'] = formats\n        return info",
        "begin_line": 382,
        "end_line": 403,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results#412",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooSearchIE",
        "signature": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        entries = []\n        for pagenum in itertools.count(0):\n            result_url = 'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)\n            info = self._download_json(result_url, query,\n                                       note='Downloading results page ' + str(pagenum + 1))\n            m = info['m']\n            results = info['results']\n\n            for (i, r) in enumerate(results):\n                if (pagenum * 30) + i >= n:\n                    break\n                mobj = re.search(r'(?P<url>screen\\.yahoo\\.com/.*?-\\d*?\\.html)\"', r)\n                e = self.url_result('http://' + mobj.group('url'), 'Yahoo')\n                entries.append(e)\n            if (pagenum * 30 + i >= n) or (m['last'] >= (m['total'] - 1)):\n                break\n\n        return {\n            '_type': 'playlist',\n            'id': query,\n            'entries': entries,\n        }",
        "begin_line": 412,
        "end_line": 435,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexdisk.YandexDiskIE._real_extract#35",
        "src_path": "youtube_dl/extractor/yandexdisk.py",
        "class_name": "youtube_dl.extractor.yandexdisk.YandexDiskIE",
        "signature": "youtube_dl.extractor.yandexdisk.YandexDiskIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        status = self._download_webpage(\n            'https://disk.yandex.com/auth/status', video_id, query={\n                'urlOrigin': url,\n                'source': 'public',\n                'md5': 'false',\n            })\n\n        sk = self._search_regex(\n            r'([\"\\'])sk(?:External)?\\1\\s*:\\s*([\"\\'])(?P<value>(?:(?!\\2).)+)\\2',\n            status, 'sk', group='value')\n\n        webpage = self._download_webpage(url, video_id)\n\n        models = self._parse_json(\n            self._search_regex(\n                r'<script[^>]+id=[\"\\']models-client[^>]+>\\s*(\\[.+?\\])\\s*</script',\n                webpage, 'video JSON'),\n            video_id)\n\n        data = next(\n            model['data'] for model in models\n            if model.get('model') == 'resource')\n\n        video_hash = data['id']\n        title = data['name']\n\n        models = self._download_json(\n            'https://disk.yandex.com/models/', video_id,\n            data=urlencode_postdata({\n                '_model.0': 'videoInfo',\n                'id.0': video_hash,\n                '_model.1': 'do-get-resource-url',\n                'id.1': video_hash,\n                'version': '13.6',\n                'sk': sk,\n            }), query={'_m': 'videoInfo'})['models']\n\n        videos = try_get(models, lambda x: x[0]['data']['videos'], list) or []\n        source_url = try_get(\n            models, lambda x: x[1]['data']['file'], compat_str)\n\n        formats = []\n        if source_url:\n            formats.append({\n                'url': source_url,\n                'format_id': 'source',\n                'ext': determine_ext(title, 'mp4'),\n                'quality': 1,\n            })\n        for video in videos:\n            format_url = video.get('url')\n            if not format_url:\n                continue\n            if determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                formats.append({\n                    'url': format_url,\n                })\n        self._sort_formats(formats)\n\n        duration = float_or_none(try_get(\n            models, lambda x: x[0]['data']['duration']), 1000)\n        uploader = try_get(\n            data, lambda x: x['user']['display_name'], compat_str)\n        uploader_id = try_get(\n            data, lambda x: x['user']['uid'], compat_str)\n        view_count = int_or_none(try_get(\n            data, lambda x: x['meta']['views_counter']))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 35,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._handle_error#18",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._handle_error(response)",
        "snippet": "    def _handle_error(response):\n        if isinstance(response, dict):\n            error = response.get('error')\n            if error:\n                raise ExtractorError(error, expected=True)\n            if response.get('type') == 'captcha' or 'captcha' in response:\n                YandexMusicBaseIE._raise_captcha()",
        "begin_line": 18,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._raise_captcha#27",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._raise_captcha()",
        "snippet": "    def _raise_captcha():\n        raise ExtractorError(\n            'YandexMusic has considered youtube-dl requests automated and '\n            'asks you to solve a CAPTCHA. You can either wait for some '\n            'time until unblocked and optionally use --sleep-interval '\n            'in future or alternatively you can go to https://music.yandex.ru/ '\n            'solve CAPTCHA, then export cookies and pass cookie file to '\n            'youtube-dl with --cookies',\n            expected=True)",
        "begin_line": 27,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._download_webpage#37",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._download_webpage(self, *args, **kwargs)",
        "snippet": "    def _download_webpage(self, *args, **kwargs):\n        webpage = super(YandexMusicBaseIE, self)._download_webpage(*args, **kwargs)\n        if '\u041d\u0430\u043c \u043e\u0447\u0435\u043d\u044c \u0436\u0430\u043b\u044c, \u043d\u043e&nbsp;\u0437\u0430\u043f\u0440\u043e\u0441\u044b, \u043f\u043e\u0441\u0442\u0443\u043f\u0438\u0432\u0448\u0438\u0435 \u0441&nbsp;\u0432\u0430\u0448\u0435\u0433\u043e IP-\u0430\u0434\u0440\u0435\u0441\u0430, \u043f\u043e\u0445\u043e\u0436\u0438 \u043d\u0430&nbsp;\u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435.' in webpage:\n            self._raise_captcha()\n        return webpage",
        "begin_line": 37,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._download_json#43",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicBaseIE._download_json(self, *args, **kwargs)",
        "snippet": "    def _download_json(self, *args, **kwargs):\n        response = super(YandexMusicBaseIE, self)._download_json(*args, **kwargs)\n        self._handle_error(response)\n        return response",
        "begin_line": 43,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_url#72",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_url(self, storage_dir, track_id)",
        "snippet": "    def _get_track_url(self, storage_dir, track_id):\n        data = self._download_json(\n            'http://music.yandex.ru/api/v1.5/handlers/api-jsonp.jsx?action=getTrackSrc&p=download-info/%s'\n            % storage_dir,\n            track_id, 'Downloading track location JSON')\n\n        # Each string is now wrapped in a list, this is probably only temporarily thus\n        # supporting both scenarios (see https://github.com/rg3/youtube-dl/issues/10193)\n        for k, v in data.items():\n            if v and isinstance(v, list):\n                data[k] = v[0]\n\n        key = hashlib.md5(('XGRlBW9FXlekgbPrRHuSiA' + data['path'][1:] + data['s']).encode('utf-8')).hexdigest()\n        storage = storage_dir.split('.')\n\n        return ('http://%s/get-mp3/%s/%s?track-id=%s&from=service-10-track&similarities-experiment=default'\n                % (data['host'], key, data['ts'] + data['path'], storage[1]))",
        "begin_line": 72,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_info#90",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._get_track_info(self, track)",
        "snippet": "    def _get_track_info(self, track):\n        thumbnail = None\n        cover_uri = track.get('albums', [{}])[0].get('coverUri')\n        if cover_uri:\n            thumbnail = cover_uri.replace('%%', 'orig')\n            if not thumbnail.startswith('http'):\n                thumbnail = 'http://' + thumbnail\n\n        track_title = track['title']\n        track_info = {\n            'id': track['id'],\n            'ext': 'mp3',\n            'url': self._get_track_url(track['storageDir'], track['id']),\n            'filesize': int_or_none(track.get('fileSize')),\n            'duration': float_or_none(track.get('durationMs'), 1000),\n            'thumbnail': thumbnail,\n            'track': track_title,\n        }\n\n        def extract_artist(artist_list):\n            if artist_list and isinstance(artist_list, list):\n                artists_names = [a['name'] for a in artist_list if a.get('name')]\n                if artists_names:\n                    return ', '.join(artists_names)\n\n        albums = track.get('albums')\n        if albums and isinstance(albums, list):\n            album = albums[0]\n            if isinstance(album, dict):\n                year = album.get('year')\n                track_info.update({\n                    'album': album.get('title'),\n                    'album_artist': extract_artist(album.get('artists')),\n                    'release_year': compat_str(year) if year else None,\n                })\n\n        track_artist = extract_artist(track.get('artists'))\n        if track_artist:\n            track_info.update({\n                'artist': track_artist,\n                'title': '%s - %s' % (track_artist, track_title),\n            })\n        else:\n            track_info['title'] = track_title\n        return track_info",
        "begin_line": 90,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._real_extract#136",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicTrackIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        album_id, track_id = mobj.group('album_id'), mobj.group('id')\n\n        track = self._download_json(\n            'http://music.yandex.ru/handlers/track.jsx?track=%s:%s' % (track_id, album_id),\n            track_id, 'Downloading track JSON')['track']\n\n        return self._get_track_info(track)",
        "begin_line": 136,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE._build_playlist#148",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistBaseIE._build_playlist(self, tracks)",
        "snippet": "    def _build_playlist(self, tracks):\n        return [\n            self.url_result(\n                'http://music.yandex.ru/album/%s/track/%s' % (track['albums'][0]['id'], track['id']))\n            for track in tracks if track.get('albums') and isinstance(track.get('albums'), list)]",
        "begin_line": 148,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE._real_extract#170",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        album_id = self._match_id(url)\n\n        album = self._download_json(\n            'http://music.yandex.ru/handlers/album.jsx?album=%s' % album_id,\n            album_id, 'Downloading album JSON')\n\n        entries = self._build_playlist(album['volumes'][0])\n\n        title = '%s - %s' % (album['artists'][0]['name'], album['title'])\n        year = album.get('year')\n        if year:\n            title += ' (%s)' % year\n\n        return self.playlist_result(entries, compat_str(album['id']), title)",
        "begin_line": 170,
        "end_line": 184,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE._real_extract#213",
        "src_path": "youtube_dl/extractor/yandexmusic.py",
        "class_name": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE",
        "signature": "youtube_dl.extractor.yandexmusic.YandexMusicPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        tld = mobj.group('tld')\n        user = mobj.group('user')\n        playlist_id = mobj.group('id')\n\n        playlist = self._download_json(\n            'https://music.yandex.%s/handlers/playlist.jsx' % tld,\n            playlist_id, 'Downloading missing tracks JSON',\n            fatal=False,\n            headers={\n                'Referer': url,\n                'X-Requested-With': 'XMLHttpRequest',\n                'X-Retpath-Y': url,\n            },\n            query={\n                'owner': user,\n                'kinds': playlist_id,\n                'light': 'true',\n                'lang': tld,\n                'external-domain': 'music.yandex.%s' % tld,\n                'overembed': 'false',\n            })['playlist']\n\n        tracks = playlist['tracks']\n        track_ids = [compat_str(track_id) for track_id in playlist['trackIds']]\n\n        # tracks dictionary shipped with playlist.jsx API is limited to 150 tracks,\n        # missing tracks should be retrieved manually.\n        if len(tracks) < len(track_ids):\n            present_track_ids = set([\n                compat_str(track['id'])\n                for track in tracks if track.get('id')])\n            missing_track_ids = [\n                track_id for track_id in track_ids\n                if track_id not in present_track_ids]\n            missing_tracks = self._download_json(\n                'https://music.yandex.%s/handlers/track-entries.jsx' % tld,\n                playlist_id, 'Downloading missing tracks JSON',\n                fatal=False,\n                headers={\n                    'Referer': url,\n                    'X-Requested-With': 'XMLHttpRequest',\n                },\n                query={\n                    'entries': ','.join(missing_track_ids),\n                    'lang': tld,\n                    'external-domain': 'music.yandex.%s' % tld,\n                    'overembed': 'false',\n                    'strict': 'true',\n                })\n            if missing_tracks:\n                tracks.extend(missing_tracks)\n\n        return self.playlist_result(\n            self._build_playlist(tracks),\n            compat_str(playlist_id),\n            playlist.get('title'), playlist.get('description'))",
        "begin_line": 213,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yesjapan.YesJapanIE._real_extract#28",
        "src_path": "youtube_dl/extractor/yesjapan.py",
        "class_name": "youtube_dl.extractor.yesjapan.YesJapanIE",
        "signature": "youtube_dl.extractor.yesjapan.YesJapanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        video_url = self._og_search_video_url(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        timestamp = None\n        submit_info = get_element_by_attribute('class', 'pm-submit-data', webpage)\n        if submit_info:\n            timestamp = parse_iso8601(self._search_regex(\n                r'datetime=\"([^\"]+)\"', submit_info, 'upload date', fatal=False, default=None))\n\n        # attempt to resolve the final URL in order to get a proper extension\n        redirect_req = HEADRequest(video_url)\n        req = self._request_webpage(\n            redirect_req, video_id, note='Resolving final URL', errnote='Could not resolve final URL', fatal=False)\n        if req:\n            video_url = req.geturl()\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'timestamp': timestamp,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yinyuetai.YinYueTaiIE._real_extract#28",
        "src_path": "youtube_dl/extractor/yinyuetai.py",
        "class_name": "youtube_dl.extractor.yinyuetai.YinYueTaiIE",
        "signature": "youtube_dl.extractor.yinyuetai.YinYueTaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        info = self._download_json(\n            'http://ext.yinyuetai.com/main/get-h-mv-info?json=true&videoId=%s' % video_id, video_id,\n            'Downloading mv info')['videoInfo']['coreVideoInfo']\n\n        if info['error']:\n            raise ExtractorError(info['errorMsg'], expected=True)\n\n        formats = [{\n            'url': format_info['videoUrl'],\n            'format_id': format_info['qualityLevel'],\n            'format': format_info.get('qualityLevelName'),\n            'filesize': format_info.get('fileSize'),\n            # though URLs ends with .flv, the downloaded files are in fact mp4\n            'ext': 'mp4',\n            'tbr': format_info.get('bitrate'),\n        } for format_info in info['videoUrlModels']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['videoName'],\n            'thumbnail': info.get('bigHeadImage'),\n            'creator': info.get('artistNames'),\n            'duration': info.get('duration'),\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.ynet.YnetIE._real_extract#33",
        "src_path": "youtube_dl/extractor/ynet.py",
        "class_name": "youtube_dl.extractor.ynet.YnetIE",
        "signature": "youtube_dl.extractor.ynet.YnetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(url, video_id)\n\n        content = compat_urllib_parse_unquote_plus(self._og_search_video_url(webpage))\n        config = json.loads(self._search_regex(r'config=({.+?})$', content, 'video config'))\n        f4m_url = config['clip']['url']\n        title = self._og_search_title(webpage)\n        m = re.search(r'ynet - HOT -- ([\"\\']+)(?P<title>.+?)\\1', title)\n        if m:\n            title = m.group('title')\n        formats = self._extract_f4m_formats(f4m_url, video_id)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 33,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract#34",
        "src_path": "youtube_dl/extractor/youjizz.py",
        "class_name": "youtube_dl.extractor.youjizz.YouJizzIE",
        "signature": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id') or mobj.group('embed_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+?)</title>', webpage, 'title')\n\n        formats = []\n\n        encodings = self._parse_json(\n            self._search_regex(\n                r'encodings\\s*=\\s*(\\[.+?\\]);\\n', webpage, 'encodings',\n                default='[]'),\n            video_id, fatal=False)\n        for encoding in encodings:\n            if not isinstance(encoding, dict):\n                continue\n            format_url = encoding.get('filename')\n            if not isinstance(format_url, compat_str):\n                continue\n            if determine_ext(format_url) == 'm3u8':\n                formats.extend(self._extract_m3u8_formats(\n                    format_url, video_id, 'mp4', entry_protocol='m3u8_native',\n                    m3u8_id='hls', fatal=False))\n            else:\n                format_id = encoding.get('name') or encoding.get('quality')\n                height = int_or_none(self._search_regex(\n                    r'^(\\d+)[pP]', format_id, 'height', default=None))\n                formats.append({\n                    'url': format_url,\n                    'format_id': format_id,\n                    'height': height,\n                })\n\n        if formats:\n            info_dict = {\n                'formats': formats,\n            }\n        else:\n            # YouJizz's HTML5 player has invalid HTML\n            webpage = webpage.replace('\"controls', '\" controls')\n            info_dict = self._parse_html5_media_entries(\n                url, webpage, video_id)[0]\n\n        duration = parse_duration(self._search_regex(\n            r'<strong>Runtime:</strong>([^<]+)', webpage, 'duration',\n            default=None))\n        uploader = self._search_regex(\n            r'<strong>Uploaded By:.*?<a[^>]*>([^<]+)', webpage, 'uploader',\n            default=None)\n\n        info_dict.update({\n            'id': video_id,\n            'title': title,\n            'age_limit': self._rta_search(webpage),\n            'duration': duration,\n            'uploader': uploader,\n        })\n\n        return info_dict",
        "begin_line": 34,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.get_ysuid#124",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.get_ysuid()",
        "snippet": "    def get_ysuid():\n        return '%d%s' % (int(time.time()), ''.join([\n            random.choice(string.ascii_letters) for i in range(3)]))",
        "begin_line": 124,
        "end_line": 126,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE.get_format_name#128",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE.get_format_name(self, fm)",
        "snippet": "    def get_format_name(self, fm):\n        _dict = {\n            '3gp': 'h6',\n            '3gphd': 'h5',\n            'flv': 'h4',\n            'flvhd': 'h4',\n            'mp4': 'h3',\n            'mp4hd': 'h3',\n            'mp4hd2': 'h4',\n            'mp4hd3': 'h4',\n            'hd2': 'h2',\n            'hd3': 'h1',\n        }\n        return _dict.get(fm)",
        "begin_line": 128,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._real_extract#143",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        self._set_cookie('youku.com', '__ysuid', self.get_ysuid())\n        self._set_cookie('youku.com', 'xreferrer', 'http://www.youku.com')\n\n        _, urlh = self._download_webpage_handle(\n            'https://log.mmstat.com/eg.js', video_id, 'Retrieving cna info')\n        # The etag header is '\"foobar\"'; let's remove the double quotes\n        cna = urlh.headers['etag'][1:-1]\n\n        # request basic data\n        basic_data_params = {\n            'vid': video_id,\n            'ccode': '0402' if 'tudou.com' in url else '0401',\n            'client_ip': '192.168.1.1',\n            'utid': cna,\n            'client_ts': time.time() / 1000,\n        }\n\n        video_password = self._downloader.params.get('videopassword')\n        if video_password:\n            basic_data_params['password'] = video_password\n\n        headers = {\n            'Referer': url,\n        }\n        headers.update(self.geo_verification_headers())\n        data = self._download_json(\n            'https://ups.youku.com/ups/get.json', video_id,\n            'Downloading JSON metadata',\n            query=basic_data_params, headers=headers)['data']\n\n        error = data.get('error')\n        if error:\n            error_note = error.get('note')\n            if error_note is not None and '\u56e0\u7248\u6743\u539f\u56e0\u65e0\u6cd5\u89c2\u770b\u6b64\u89c6\u9891' in error_note:\n                raise ExtractorError(\n                    'Youku said: Sorry, this video is available in China only', expected=True)\n            elif error_note and '\u8be5\u89c6\u9891\u88ab\u8bbe\u4e3a\u79c1\u5bc6' in error_note:\n                raise ExtractorError(\n                    'Youku said: Sorry, this video is private', expected=True)\n            else:\n                msg = 'Youku server reported error %i' % error.get('code')\n                if error_note is not None:\n                    msg += ': ' + error_note\n                raise ExtractorError(msg)\n\n        # get video title\n        video_data = data['video']\n        title = video_data['title']\n\n        formats = [{\n            'url': stream['m3u8_url'],\n            'format_id': self.get_format_name(stream.get('stream_type')),\n            'ext': 'mp4',\n            'protocol': 'm3u8_native',\n            'filesize': int(stream.get('size')),\n            'width': stream.get('width'),\n            'height': stream.get('height'),\n        } for stream in data['stream'] if stream.get('channel_type') != 'tail']\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'duration': video_data.get('seconds'),\n            'thumbnail': video_data.get('logo'),\n            'uploader': video_data.get('username'),\n            'uploader_id': str_or_none(video_data.get('userid')),\n            'uploader_url': data.get('uploader', {}).get('homepage'),\n            'tags': video_data.get('tags'),\n        }",
        "begin_line": 143,
        "end_line": 216,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuShowIE._extract_entries#246",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuShowIE",
        "signature": "youtube_dl.extractor.youku.YoukuShowIE._extract_entries(self, playlist_data_url, show_id, note, query)",
        "snippet": "    def _extract_entries(self, playlist_data_url, show_id, note, query):\n        query['callback'] = 'cb'\n        playlist_data = self._download_json(\n            playlist_data_url, show_id, query=query, note=note,\n            transform_source=lambda s: js_to_json(strip_jsonp(s)))['html']\n        drama_list = (get_element_by_class('p-drama-grid', playlist_data) or\n                      get_element_by_class('p-drama-half-row', playlist_data))\n        if drama_list is None:\n            raise ExtractorError('No episodes found')\n        video_urls = re.findall(r'<a[^>]+href=\"([^\"]+)\"', drama_list)\n        return playlist_data, [\n            self.url_result(self._proto_relative_url(video_url, 'http:'), YoukuIE.ie_key())\n            for video_url in video_urls]",
        "begin_line": 246,
        "end_line": 258,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuShowIE._real_extract#260",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuShowIE",
        "signature": "youtube_dl.extractor.youku.YoukuShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        show_id = self._match_id(url)\n        webpage = self._download_webpage(url, show_id)\n\n        entries = []\n        page_config = self._parse_json(self._search_regex(\n            r'var\\s+PageConfig\\s*=\\s*({.+});', webpage, 'page config'),\n            show_id, transform_source=js_to_json)\n        first_page, initial_entries = self._extract_entries(\n            'http://list.youku.com/show/module', show_id,\n            note='Downloading initial playlist data page',\n            query={\n                'id': page_config['showid'],\n                'tab': 'showInfo',\n            })\n        first_page_reload_id = self._html_search_regex(\n            r'<div[^>]+id=\"(reload_\\d+)', first_page, 'first page reload id')\n        # The first reload_id has the same items as first_page\n        reload_ids = re.findall('<li[^>]+data-id=\"([^\"]+)\">', first_page)\n        for idx, reload_id in enumerate(reload_ids):\n            if reload_id == first_page_reload_id:\n                entries.extend(initial_entries)\n                continue\n            _, new_entries = self._extract_entries(\n                'http://list.youku.com/show/episode', show_id,\n                note='Downloading playlist data page %d' % (idx + 1),\n                query={\n                    'id': page_config['showid'],\n                    'stage': reload_id,\n                })\n            entries.extend(new_entries)\n\n        desc = self._html_search_meta('description', webpage, fatal=False)\n        playlist_title = desc.split(',')[0] if desc else None\n        detail_li = get_element_by_class('p-intro', webpage)\n        playlist_description = get_element_by_class(\n            'intro-more', detail_li) if detail_li else None\n\n        return self.playlist_result(\n            entries, show_id, playlist_title, playlist_description)",
        "begin_line": 260,
        "end_line": 299,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youporn.YouPornIE._real_extract#62",
        "src_path": "youtube_dl/extractor/youporn.py",
        "class_name": "youtube_dl.extractor.youporn.YouPornIE",
        "signature": "youtube_dl.extractor.youporn.YouPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        request = sanitized_Request(url)\n        request.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(request, display_id)\n\n        title = self._search_regex(\n            [r'(?:video_titles|videoTitle)\\s*[:=]\\s*([\"\\'])(?P<title>(?:(?!\\1).)+)\\1',\n             r'<h1[^>]+class=[\"\\']heading\\d?[\"\\'][^>]*>(?P<title>[^<]+)<'],\n            webpage, 'title', group='title',\n            default=None) or self._og_search_title(\n            webpage, default=None) or self._html_search_meta(\n            'title', webpage, fatal=True)\n\n        links = []\n\n        # Main source\n        definitions = self._parse_json(\n            self._search_regex(\n                r'mediaDefinition\\s*=\\s*(\\[.+?\\]);', webpage,\n                'media definitions', default='[]'),\n            video_id, fatal=False)\n        if definitions:\n            for definition in definitions:\n                if not isinstance(definition, dict):\n                    continue\n                video_url = definition.get('videoUrl')\n                if isinstance(video_url, compat_str) and video_url:\n                    links.append(video_url)\n\n        # Fallback #1, this also contains extra low quality 180p format\n        for _, link in re.findall(r'<a[^>]+href=([\"\\'])(http.+?)\\1[^>]+title=[\"\\']Download [Vv]ideo', webpage):\n            links.append(link)\n\n        # Fallback #2 (unavailable as at 22.06.2017)\n        sources = self._search_regex(\n            r'(?s)sources\\s*:\\s*({.+?})', webpage, 'sources', default=None)\n        if sources:\n            for _, link in re.findall(r'[^:]+\\s*:\\s*([\"\\'])(http.+?)\\1', sources):\n                links.append(link)\n\n        # Fallback #3 (unavailable as at 22.06.2017)\n        for _, link in re.findall(\n                r'(?:videoSrc|videoIpadUrl|html5PlayerSrc)\\s*[:=]\\s*([\"\\'])(http.+?)\\1', webpage):\n            links.append(link)\n\n        # Fallback #4, encrypted links (unavailable as at 22.06.2017)\n        for _, encrypted_link in re.findall(\n                r'encryptedQuality\\d{3,4}URL\\s*=\\s*([\"\\'])([\\da-zA-Z+/=]+)\\1', webpage):\n            links.append(aes_decrypt_text(encrypted_link, title, 32).decode('utf-8'))\n\n        formats = []\n        for video_url in set(unescapeHTML(link) for link in links):\n            f = {\n                'url': video_url,\n            }\n            # Video URL's path looks like this:\n            #  /201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4\n            #  /201012/17/505835/vl_240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4\n            # We will benefit from it by extracting some metadata\n            mobj = re.search(r'(?P<height>\\d{3,4})[pP]_(?P<bitrate>\\d+)[kK]_\\d+/', video_url)\n            if mobj:\n                height = int(mobj.group('height'))\n                bitrate = int(mobj.group('bitrate'))\n                f.update({\n                    'format_id': '%dp-%dk' % (height, bitrate),\n                    'height': height,\n                    'tbr': bitrate,\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = self._search_regex(\n            r'(?:imageurl\\s*=|poster\\s*:)\\s*([\"\\'])(?P<thumbnail>.+?)\\1',\n            webpage, 'thumbnail', fatal=False, group='thumbnail')\n\n        uploader = self._html_search_regex(\n            r'(?s)<div[^>]+class=[\"\\']submitByLink[\"\\'][^>]*>(.+?)</div>',\n            webpage, 'uploader', fatal=False)\n        upload_date = unified_strdate(self._html_search_regex(\n            [r'Date\\s+[Aa]dded:\\s*<span>([^<]+)',\n             r'(?s)<div[^>]+class=[\"\\']videoInfo(?:Date|Time)[\"\\'][^>]*>(.+?)</div>'],\n            webpage, 'upload date', fatal=False))\n\n        age_limit = self._rta_search(webpage)\n\n        average_rating = int_or_none(self._search_regex(\n            r'<div[^>]+class=[\"\\']videoRatingPercentage[\"\\'][^>]*>(\\d+)%</div>',\n            webpage, 'average rating', fatal=False))\n\n        view_count = str_to_int(self._search_regex(\n            r'(?s)<div[^>]+class=([\"\\']).*?\\bvideoInfoViews\\b.*?\\1[^>]*>.*?(?P<count>[\\d,.]+)<',\n            webpage, 'view count', fatal=False, group='count'))\n        comment_count = str_to_int(self._search_regex(\n            r'>All [Cc]omments? \\(([\\d,.]+)\\)',\n            webpage, 'comment count', fatal=False))\n\n        def extract_tag_box(regex, title):\n            tag_box = self._search_regex(regex, webpage, title, default=None)\n            if not tag_box:\n                return []\n            return re.findall(r'<a[^>]+href=[^>]+>([^<]+)', tag_box)\n\n        categories = extract_tag_box(\n            r'(?s)Categories:.*?</[^>]+>(.+?)</div>', 'categories')\n        tags = extract_tag_box(\n            r'(?s)Tags:.*?</div>\\s*<div[^>]+class=[\"\\']tagBoxContent[\"\\'][^>]*>(.+?)</div>',\n            'tags')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'average_rating': average_rating,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'tags': tags,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 62,
        "end_line": 190,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.yourupload.YourUploadIE._real_extract#27",
        "src_path": "youtube_dl/extractor/yourupload.py",
        "class_name": "youtube_dl.extractor.yourupload.YourUploadIE",
        "signature": "youtube_dl.extractor.yourupload.YourUploadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        embed_url = 'http://www.yourupload.com/embed/%s' % video_id\n\n        webpage = self._download_webpage(embed_url, video_id)\n\n        title = self._og_search_title(webpage)\n        video_url = urljoin(embed_url, self._og_search_video_url(webpage))\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'http_headers': {\n                'Referer': embed_url,\n            },\n        }",
        "begin_line": 27,
        "end_line": 46,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language#67",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language(self)",
        "snippet": "    def _set_language(self):\n        self._set_cookie(\n            '.youtube.com', 'PREF', 'f1=50000000&hl=en',\n            # YouTube sets the expire time to about two months\n            expire_time=time.time() + 2 * 30 * 24 * 3600)",
        "begin_line": 67,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._ids_to_results#73",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._ids_to_results(self, ids)",
        "snippet": "    def _ids_to_results(self, ids):\n        return [\n            self.url_result(vid_id, 'Youtube', video_id=vid_id)\n            for vid_id in ids]",
        "begin_line": 73,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login#78",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        login_form = self._hidden_inputs(login_page)\n\n        def req(url, f_req, note, errnote):\n            data = login_form.copy()\n            data.update({\n                'pstMsg': 1,\n                'checkConnection': 'youtube',\n                'checkedDomains': 'youtube',\n                'hl': 'en',\n                'deviceinfo': '[null,null,null,[],null,\"US\",null,null,[],\"GlifWebSignIn\",null,[null,null,[]]]',\n                'f.req': json.dumps(f_req),\n                'flowName': 'GlifWebSignIn',\n                'flowEntry': 'ServiceLogin',\n            })\n            return self._download_json(\n                url, None, note=note, errnote=errnote,\n                transform_source=lambda s: re.sub(r'^[^[]*', '', s),\n                fatal=False,\n                data=urlencode_postdata(data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',\n                    'Google-Accounts-XSRF': 1,\n                })\n\n        def warn(message):\n            self._downloader.report_warning(message)\n\n        lookup_req = [\n            username,\n            None, [], None, 'US', None, None, 2, False, True,\n            [\n                None, None,\n                [2, 1, None, 1,\n                 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn',\n                 None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ],\n            username,\n        ]\n\n        lookup_results = req(\n            self._LOOKUP_URL, lookup_req,\n            'Looking up account info', 'Unable to look up account info')\n\n        if lookup_results is False:\n            return False\n\n        user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)\n        if not user_hash:\n            warn('Unable to extract user hash')\n            return False\n\n        challenge_req = [\n            user_hash,\n            None, 1, None, [1, None, None, None, [password, None, True]],\n            [\n                None, None, [2, 1, None, 1, 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn', None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ]]\n\n        challenge_results = req(\n            self._CHALLENGE_URL, challenge_req,\n            'Logging in', 'Unable to log in')\n\n        if challenge_results is False:\n            return\n\n        login_res = try_get(challenge_results, lambda x: x[0][5], list)\n        if login_res:\n            login_msg = try_get(login_res, lambda x: x[5], compat_str)\n            warn(\n                'Unable to login: %s' % 'Invalid password'\n                if login_msg == 'INCORRECT_ANSWER_ENTERED' else login_msg)\n            return False\n\n        res = try_get(challenge_results, lambda x: x[0][-1], list)\n        if not res:\n            warn('Unable to extract result entry')\n            return False\n\n        tfa = try_get(res, lambda x: x[0][0], list)\n        if tfa:\n            tfa_str = try_get(tfa, lambda x: x[2], compat_str)\n            if tfa_str == 'TWO_STEP_VERIFICATION':\n                # SEND_SUCCESS - TFA code has been successfully sent to phone\n                # QUOTA_EXCEEDED - reached the limit of TFA codes\n                status = try_get(tfa, lambda x: x[5], compat_str)\n                if status == 'QUOTA_EXCEEDED':\n                    warn('Exceeded the limit of TFA codes, try later')\n                    return False\n\n                tl = try_get(challenge_results, lambda x: x[1][2], compat_str)\n                if not tl:\n                    warn('Unable to extract TL')\n                    return False\n\n                tfa_code = self._get_tfa_info('2-step verification code')\n\n                if not tfa_code:\n                    warn(\n                        'Two-factor authentication required. Provide it either interactively or with --twofactor <code>'\n                        '(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                    return False\n\n                tfa_code = remove_start(tfa_code, 'G-')\n\n                tfa_req = [\n                    user_hash, None, 2, None,\n                    [\n                        9, None, None, None, None, None, None, None,\n                        [None, tfa_code, True, 2]\n                    ]]\n\n                tfa_results = req(\n                    self._TFA_URL.format(tl), tfa_req,\n                    'Submitting TFA code', 'Unable to submit TFA code')\n\n                if tfa_results is False:\n                    return False\n\n                tfa_res = try_get(tfa_results, lambda x: x[0][5], list)\n                if tfa_res:\n                    tfa_msg = try_get(tfa_res, lambda x: x[5], compat_str)\n                    warn(\n                        'Unable to finish TFA: %s' % 'Invalid TFA code'\n                        if tfa_msg == 'INCORRECT_ANSWER_ENTERED' else tfa_msg)\n                    return False\n\n                check_cookie_url = try_get(\n                    tfa_results, lambda x: x[0][-1][2], compat_str)\n        else:\n            check_cookie_url = try_get(res, lambda x: x[2], compat_str)\n\n        if not check_cookie_url:\n            warn('Unable to extract CheckCookie URL')\n            return False\n\n        check_cookie_results = self._download_webpage(\n            check_cookie_url, None, 'Checking cookie', fatal=False)\n\n        if check_cookie_results is False:\n            return False\n\n        if 'https://myaccount.google.com/' not in check_cookie_results:\n            warn('Unable to log in')\n            return False\n\n        return True",
        "begin_line": 78,
        "end_line": 246,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize#248",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        self._set_language()\n        if not self._login():\n            return",
        "begin_line": 248,
        "end_line": 253,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeEntryListBaseInfoExtractor._entries#258",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeEntryListBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeEntryListBaseInfoExtractor._entries(self, page, playlist_id)",
        "snippet": "    def _entries(self, page, playlist_id):\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            for entry in self._process_page(content_html):\n                yield entry\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            if not content_html.strip():\n                # Some webpages show a \"Load more\" button but they don't\n                # have more videos\n                break\n            more_widget_html = more['load_more_widget_html']",
        "begin_line": 258,
        "end_line": 277,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor._process_page#281",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor._process_page(self, content)",
        "snippet": "    def _process_page(self, content):\n        for video_id, video_title in self.extract_videos_from_page(content):\n            yield self.url_result(video_id, 'Youtube', video_id, video_title)",
        "begin_line": 281,
        "end_line": 283,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor.extract_videos_from_page#285",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistBaseInfoExtractor.extract_videos_from_page(self, page)",
        "snippet": "    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        titles_in_page = []\n        for mobj in re.finditer(self._VIDEO_RE, page):\n            # The link with index 0 is not the first video of the playlist (not sure if still actual)\n            if 'index' in mobj.groupdict() and mobj.group('id') == '0':\n                continue\n            video_id = mobj.group('id')\n            video_title = unescapeHTML(mobj.group('title'))\n            if video_title:\n                video_title = video_title.strip()\n            try:\n                idx = ids_in_page.index(video_id)\n                if video_title and not titles_in_page[idx]:\n                    titles_in_page[idx] = video_title\n            except ValueError:\n                ids_in_page.append(video_id)\n                titles_in_page.append(video_title)\n        return zip(ids_in_page, titles_in_page)",
        "begin_line": 285,
        "end_line": 303,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor._process_page#307",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor._process_page(self, content)",
        "snippet": "    def _process_page(self, content):\n        for playlist_id in orderedSet(re.findall(\n                r'<h3[^>]+class=\"[^\"]*yt-lockup-title[^\"]*\"[^>]*><a[^>]+href=\"/?playlist\\?list=([0-9A-Za-z-_]{10,})\"',\n                content)):\n            yield self.url_result(\n                'https://www.youtube.com/playlist?list=%s' % playlist_id, 'YoutubePlaylist')",
        "begin_line": 307,
        "end_line": 312,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor._real_extract#314",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistsBaseInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._og_search_title(webpage, fatal=False)\n        return self.playlist_result(self._entries(webpage, playlist_id), playlist_id, title)",
        "begin_line": 314,
        "end_line": 318,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.__init__#1022",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}",
        "begin_line": 1022,
        "end_line": 1024,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download#1026",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download(self, video_id)",
        "snippet": "    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen('%s: Downloading video info webpage' % video_id)",
        "begin_line": 1026,
        "end_line": 1028,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction#1030",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction(self, video_id)",
        "snippet": "    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen('%s: Extracting video information' % video_id)",
        "begin_line": 1030,
        "end_line": 1032,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format#1034",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format(self, video_id, format)",
        "snippet": "    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen('%s: Format %s not available' % (video_id, format))",
        "begin_line": 1034,
        "end_line": 1036,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download#1038",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download(self)",
        "snippet": "    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen('RTMP download detected')",
        "begin_line": 1038,
        "end_line": 1040,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id#1042",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id(self, example_sig)",
        "snippet": "    def _signature_cache_id(self, example_sig):\n        \"\"\" Return a string representation of a signature \"\"\"\n        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))",
        "begin_line": 1042,
        "end_line": 1044,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function#1046",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function(self, video_id, player_url, example_sig)",
        "snippet": "    def _extract_signature_function(self, video_id, player_url, example_sig):\n        id_m = re.match(\n            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|(?:/[a-z]{2}_[A-Z]{2})?/base)?\\.(?P<ext>[a-z]+)$',\n            player_url)\n        if not id_m:\n            raise ExtractorError('Cannot identify player %r' % player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%s' % (\n            player_type, player_id, self._signature_cache_id(example_sig))\n        assert os.path.basename(func_id) == func_id\n\n        cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)\n        if cache_spec is not None:\n            return lambda s: ''.join(s[i] for i in cache_spec)\n\n        download_note = (\n            'Downloading player %s' % player_url\n            if self._downloader.params.get('verbose') else\n            'Downloading %s player %s' % (player_type, player_id)\n        )\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = res(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n\n        self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)\n        return res",
        "begin_line": 1046,
        "end_line": 1090,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code#1092",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code(self, func, example_sig)",
        "snippet": "    def _print_sig_code(self, func, example_sig):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = '' if start == 0 else str(start)\n                ends = (':%d' % (end + step)) if end + step >= 0 else ':'\n                steps = '' if step == 1 else (':%d' % step)\n                return 's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            # Quelch pyflakes warnings - start will be set when step is set\n            start = '(Never used)'\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield 's[%d]' % prev\n            if step is None:\n                yield 's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = ' + '.join(gen_sig_code(cache_spec))\n        signature_id_tuple = '(%s)' % (\n            ', '.join(compat_str(len(p)) for p in example_sig.split('.')))\n        code = ('if tuple(len(p) for p in s.split(\\'.\\')) == %s:\\n'\n                '    return %s\\n') % (signature_id_tuple, expr_code)\n        self.to_screen('Extracted signature function:\\n' + code)",
        "begin_line": 1092,
        "end_line": 1129,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js#1131",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js(self, jscode)",
        "snippet": "    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            (r'([\"\\'])signature\\1\\s*,\\s*(?P<sig>[a-zA-Z0-9$]+)\\(',\n             r'\\.sig\\|\\|(?P<sig>[a-zA-Z0-9$]+)\\('),\n            jscode, 'Initial JS player signature function name', group='sig')\n\n        jsi = JSInterpreter(jscode)\n        initial_function = jsi.extract_function(funcname)\n        return lambda s: initial_function([s])",
        "begin_line": 1131,
        "end_line": 1139,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf#1141",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf(self, file_contents)",
        "snippet": "    def _parse_sig_swf(self, file_contents):\n        swfi = SWFInterpreter(file_contents)\n        TARGET_CLASSNAME = 'SignatureDecipher'\n        searched_class = swfi.extract_class(TARGET_CLASSNAME)\n        initial_function = swfi.extract_function(searched_class, 'decipher')\n        return lambda s: initial_function([s])",
        "begin_line": 1141,
        "end_line": 1146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature#1148",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature(self, s, video_id, player_url, age_gate=False)",
        "snippet": "    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is None:\n            raise ExtractorError('Cannot decrypt signature without player_url')\n\n        if player_url.startswith('//'):\n            player_url = 'https:' + player_url\n        elif not re.match(r'https?://', player_url):\n            player_url = compat_urlparse.urljoin(\n                'https://www.youtube.com', player_url)\n        try:\n            player_id = (player_url, self._signature_cache_id(s))\n            if player_id not in self._player_cache:\n                func = self._extract_signature_function(\n                    video_id, player_url, s\n                )\n                self._player_cache[player_id] = func\n            func = self._player_cache[player_id]\n            if self._downloader.params.get('youtube_print_sig_code'):\n                self._print_sig_code(func, s)\n            return func(s)\n        except Exception as e:\n            tb = traceback.format_exc()\n            raise ExtractorError(\n                'Signature extraction failed: ' + tb, cause=e)",
        "begin_line": 1148,
        "end_line": 1173,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_subtitles#1175",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_subtitles(self, video_id, webpage):\n        try:\n            subs_doc = self._download_xml(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))\n            return {}\n\n        sub_lang_list = {}\n        for track in subs_doc.findall('track'):\n            lang = track.attrib['lang_code']\n            if lang in sub_lang_list:\n                continue\n            sub_formats = []\n            for ext in self._SUBTITLE_FORMATS:\n                params = compat_urllib_parse_urlencode({\n                    'lang': lang,\n                    'v': video_id,\n                    'fmt': ext,\n                    'name': track.attrib['name'].encode('utf-8'),\n                })\n                sub_formats.append({\n                    'url': 'https://www.youtube.com/api/timedtext?' + params,\n                    'ext': ext,\n                })\n            sub_lang_list[lang] = sub_formats\n        if not sub_lang_list:\n            self._downloader.report_warning('video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list",
        "begin_line": 1175,
        "end_line": 1205,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_ytplayer_config#1207",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_ytplayer_config(self, video_id, webpage)",
        "snippet": "    def _get_ytplayer_config(self, video_id, webpage):\n        patterns = (\n            # User data may contain arbitrary character sequences that may affect\n            # JSON extraction with regex, e.g. when '};' is contained the second\n            # regex won't capture the whole JSON. Yet working around by trying more\n            # concrete regex first keeping in mind proper quoted string handling\n            # to be implemented in future that will replace this workaround (see\n            # https://github.com/rg3/youtube-dl/issues/7468,\n            # https://github.com/rg3/youtube-dl/pull/7599)\n            r';ytplayer\\.config\\s*=\\s*({.+?});ytplayer',\n            r';ytplayer\\.config\\s*=\\s*({.+?});',\n        )\n        config = self._search_regex(\n            patterns, webpage, 'ytplayer.config', default=None)\n        if config:\n            return self._parse_json(\n                uppercase_escape(config), video_id, fatal=False)",
        "begin_line": 1207,
        "end_line": 1223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_automatic_captions#1225",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_automatic_captions(self, video_id, webpage)",
        "snippet": "    def _get_automatic_captions(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        self.to_screen('%s: Looking for automatic captions' % video_id)\n        player_config = self._get_ytplayer_config(video_id, webpage)\n        err_msg = 'Couldn\\'t find automatic captions for %s' % video_id\n        if not player_config:\n            self._downloader.report_warning(err_msg)\n            return {}\n        try:\n            args = player_config['args']\n            caption_url = args.get('ttsurl')\n            if caption_url:\n                timestamp = args['timestamp']\n                # We get the available subtitles\n                list_params = compat_urllib_parse_urlencode({\n                    'type': 'list',\n                    'tlangs': 1,\n                    'asrs': 1,\n                })\n                list_url = caption_url + '&' + list_params\n                caption_list = self._download_xml(list_url, video_id)\n                original_lang_node = caption_list.find('track')\n                if original_lang_node is None:\n                    self._downloader.report_warning('Video doesn\\'t have automatic captions')\n                    return {}\n                original_lang = original_lang_node.attrib['lang_code']\n                caption_kind = original_lang_node.attrib.get('kind', '')\n\n                sub_lang_list = {}\n                for lang_node in caption_list.findall('target'):\n                    sub_lang = lang_node.attrib['lang_code']\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        params = compat_urllib_parse_urlencode({\n                            'lang': original_lang,\n                            'tlang': sub_lang,\n                            'fmt': ext,\n                            'ts': timestamp,\n                            'kind': caption_kind,\n                        })\n                        sub_formats.append({\n                            'url': caption_url + '&' + params,\n                            'ext': ext,\n                        })\n                    sub_lang_list[sub_lang] = sub_formats\n                return sub_lang_list\n\n            def make_captions(sub_url, sub_langs):\n                parsed_sub_url = compat_urllib_parse_urlparse(sub_url)\n                caption_qs = compat_parse_qs(parsed_sub_url.query)\n                captions = {}\n                for sub_lang in sub_langs:\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        caption_qs.update({\n                            'tlang': [sub_lang],\n                            'fmt': [ext],\n                        })\n                        sub_url = compat_urlparse.urlunparse(parsed_sub_url._replace(\n                            query=compat_urllib_parse_urlencode(caption_qs, True)))\n                        sub_formats.append({\n                            'url': sub_url,\n                            'ext': ext,\n                        })\n                    captions[sub_lang] = sub_formats\n                return captions\n\n            # New captions format as of 22.06.2017\n            player_response = args.get('player_response')\n            if player_response and isinstance(player_response, compat_str):\n                player_response = self._parse_json(\n                    player_response, video_id, fatal=False)\n                if player_response:\n                    renderer = player_response['captions']['playerCaptionsTracklistRenderer']\n                    base_url = renderer['captionTracks'][0]['baseUrl']\n                    sub_lang_list = []\n                    for lang in renderer['translationLanguages']:\n                        lang_code = lang.get('languageCode')\n                        if lang_code:\n                            sub_lang_list.append(lang_code)\n                    return make_captions(base_url, sub_lang_list)\n\n            # Some videos don't provide ttsurl but rather caption_tracks and\n            # caption_translation_languages (e.g. 20LmZk1hakA)\n            # Does not used anymore as of 22.06.2017\n            caption_tracks = args['caption_tracks']\n            caption_translation_languages = args['caption_translation_languages']\n            caption_url = compat_parse_qs(caption_tracks.split(',')[0])['u'][0]\n            sub_lang_list = []\n            for lang in caption_translation_languages.split(','):\n                lang_qs = compat_parse_qs(compat_urllib_parse_unquote_plus(lang))\n                sub_lang = lang_qs.get('lc', [None])[0]\n                if sub_lang:\n                    sub_lang_list.append(sub_lang)\n            return make_captions(caption_url, sub_lang_list)\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, IndexError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}",
        "begin_line": 1225,
        "end_line": 1325,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._mark_watched#1327",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._mark_watched(self, video_id, video_info)",
        "snippet": "    def _mark_watched(self, video_id, video_info):\n        playback_url = video_info.get('videostats_playback_base_url', [None])[0]\n        if not playback_url:\n            return\n        parsed_playback_url = compat_urlparse.urlparse(playback_url)\n        qs = compat_urlparse.parse_qs(parsed_playback_url.query)\n\n        # cpn generation algorithm is reverse engineered from base.js.\n        # In fact it works even with dummy cpn.\n        CPN_ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'\n        cpn = ''.join((CPN_ALPHABET[random.randint(0, 256) & 63] for _ in range(0, 16)))\n\n        qs.update({\n            'ver': ['2'],\n            'cpn': [cpn],\n        })\n        playback_url = compat_urlparse.urlunparse(\n            parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))\n\n        self._download_webpage(\n            playback_url, video_id, 'Marking watched',\n            'Unable to mark watched', fatal=False)",
        "begin_line": 1327,
        "end_line": 1348,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_id#1351",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_id(cls, url)",
        "snippet": "    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id",
        "begin_line": 1351,
        "end_line": 1356,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations#1358",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations(self, video_id)",
        "snippet": "    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note='Searching for annotations.', errnote='Unable to download video annotations.')",
        "begin_line": 1358,
        "end_line": 1360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_chapters#1363",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_chapters(description, duration)",
        "snippet": "    def _extract_chapters(description, duration):\n        if not description:\n            return None\n        chapter_lines = re.findall(\n            r'(?:^|<br\\s*/>)([^<]*<a[^>]+onclick=[\"\\']yt\\.www\\.watch\\.player\\.seekTo[^>]+>(\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)</a>[^>]*)(?=$|<br\\s*/>)',\n            description)\n        if not chapter_lines:\n            return None\n        chapters = []\n        for next_num, (chapter_line, time_point) in enumerate(\n                chapter_lines, start=1):\n            start_time = parse_duration(time_point)\n            if start_time is None:\n                continue\n            if start_time > duration:\n                break\n            end_time = (duration if next_num == len(chapter_lines)\n                        else parse_duration(chapter_lines[next_num][1]))\n            if end_time is None:\n                continue\n            if end_time > duration:\n                end_time = duration\n            if start_time > end_time:\n                break\n            chapter_title = re.sub(\n                r'<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \\t-')\n            chapter_title = re.sub(r'\\s+', ' ', chapter_title)\n            chapters.append({\n                'start_time': start_time,\n                'end_time': end_time,\n                'title': chapter_title,\n            })\n        return chapters",
        "begin_line": 1363,
        "end_line": 1395,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._real_extract#1397",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        start_time = None\n        end_time = None\n        parsed_url = compat_urllib_parse_urlparse(url)\n        for component in [parsed_url.fragment, parsed_url.query]:\n            query = compat_parse_qs(component)\n            if start_time is None and 't' in query:\n                start_time = parse_duration(query['t'][0])\n            if start_time is None and 'start' in query:\n                start_time = parse_duration(query['start'][0])\n            if end_time is None and 'end' in query:\n                end_time = parse_duration(query['end'][0])\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse_unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        dash_mpds = []\n\n        def add_dash_mpd(video_info):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd and dash_mpd[0] not in dash_mpds:\n                dash_mpds.append(dash_mpd[0])\n\n        # Get video info\n        embed_webpage = None\n        is_live = None\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            url = proto + '://www.youtube.com/embed/%s' % video_id\n            embed_webpage = self._download_webpage(url, video_id, 'Downloading embed webpage')\n            data = compat_urllib_parse_urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', embed_webpage, 'sts', default=''),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(\n                video_info_url, video_id,\n                note='Refetching age-gated info webpage',\n                errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n            add_dash_mpd(video_info)\n        else:\n            age_gate = False\n            video_info = None\n            sts = None\n            # Try looking directly into the video webpage\n            ytplayer_config = self._get_ytplayer_config(video_id, video_webpage)\n            if ytplayer_config:\n                args = ytplayer_config['args']\n                if args.get('url_encoded_fmt_stream_map'):\n                    # Convert to the same format returned by compat_parse_qs\n                    video_info = dict((k, [v]) for k, v in args.items())\n                    add_dash_mpd(video_info)\n                # Rental video is not rented but preview is available (e.g.\n                # https://www.youtube.com/watch?v=yYr8q0y5Jfg,\n                # https://github.com/rg3/youtube-dl/issues/10532)\n                if not video_info and args.get('ypc_vid'):\n                    return self.url_result(\n                        args['ypc_vid'], YoutubeIE.ie_key(), video_id=args['ypc_vid'])\n                if args.get('livestream') == '1' or args.get('live_playback') == 1:\n                    is_live = True\n                sts = ytplayer_config.get('sts')\n            if not video_info or self._downloader.params.get('youtube_include_dash_manifest', True):\n                # We also try looking in get_video_info since it may contain different dashmpd\n                # URL that points to a DASH manifest with possibly different itag set (some itags\n                # are missing from DASH manifest pointed by webpage's dashmpd, some - from DASH\n                # manifest pointed by get_video_info's dashmpd).\n                # The general idea is to take a union of itags of both DASH manifests (for example\n                # video with such 'manifest behavior' see https://github.com/rg3/youtube-dl/issues/6093)\n                self.report_video_info_webpage_download(video_id)\n                for el in ('info', 'embedded', 'detailpage', 'vevo', ''):\n                    query = {\n                        'video_id': video_id,\n                        'ps': 'default',\n                        'eurl': '',\n                        'gl': 'US',\n                        'hl': 'en',\n                    }\n                    if el:\n                        query['el'] = el\n                    if sts:\n                        query['sts'] = sts\n                    video_info_webpage = self._download_webpage(\n                        '%s://www.youtube.com/get_video_info' % proto,\n                        video_id, note=False,\n                        errnote='unable to download video info webpage',\n                        fatal=False, query=query)\n                    if not video_info_webpage:\n                        continue\n                    get_video_info = compat_parse_qs(video_info_webpage)\n                    add_dash_mpd(get_video_info)\n                    if not video_info:\n                        video_info = get_video_info\n                    if 'token' in get_video_info:\n                        # Different get_video_info requests may report different results, e.g.\n                        # some may report video unavailability, but some may serve it without\n                        # any complaint (see https://github.com/rg3/youtube-dl/issues/7362,\n                        # the original webpage as well as el=info and el=embedded get_video_info\n                        # requests report video unavailability due to geo restriction while\n                        # el=detailpage succeeds and returns valid data). This is probably\n                        # due to YouTube measures against IP ranges of hosting providers.\n                        # Working around by preferring the first succeeded video_info containing\n                        # the token if no such video_info yet was found.\n                        if 'token' not in video_info:\n                            video_info = get_video_info\n                        break\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                if 'The uploader has not made this video available in your country.' in video_info['reason']:\n                    regions_allowed = self._html_search_meta(\n                        'regionsAllowed', video_webpage, default=None)\n                    countries = regions_allowed.split(',') if regions_allowed else None\n                    self.raise_geo_restricted(\n                        msg=video_info['reason'][0], countries=countries)\n                raise ExtractorError(\n                    'YouTube said: %s' % video_info['reason'][0],\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning('Unable to extract video title')\n            video_title = '_'\n\n        # description\n        description_original = video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n            description_original = video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    (?:title|href)=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    class=\"[^\"]*\"[^>]*>\n                [^<]+\\.{3}\\s*\n                </a>\n            ''', r'\\1', video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        if 'multifeed_metadata_list' in video_info and not smuggled_data.get('force_singlefeed', False):\n            if not self._downloader.params.get('noplaylist'):\n                entries = []\n                feed_ids = []\n                multifeed_metadata_list = video_info['multifeed_metadata_list'][0]\n                for feed in multifeed_metadata_list.split(','):\n                    # Unquote should take place before split on comma (,) since textual\n                    # fields may contain comma as well (see\n                    # https://github.com/rg3/youtube-dl/issues/8536)\n                    feed_data = compat_parse_qs(compat_urllib_parse_unquote_plus(feed))\n                    entries.append({\n                        '_type': 'url_transparent',\n                        'ie_key': 'Youtube',\n                        'url': smuggle_url(\n                            '%s://www.youtube.com/watch?v=%s' % (proto, feed_data['id'][0]),\n                            {'force_singlefeed': True}),\n                        'title': '%s (%s)' % (video_title, feed_data['title'][0]),\n                    })\n                    feed_ids.append(feed_data['id'][0])\n                self.to_screen(\n                    'Downloading multifeed video (%s) - add --no-playlist to just download video %s'\n                    % (', '.join(feed_ids), video_id))\n                return self.playlist_result(entries, video_id, video_title, video_description)\n            self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n\n        if 'view_count' in video_info:\n            view_count = int(video_info['view_count'][0])\n        else:\n            view_count = None\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError('\"rental\" videos not supported. See https://github.com/rg3/youtube-dl/issues/359 for more information.', expected=True)\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError('Unable to extract uploader name')\n        video_uploader = compat_urllib_parse_unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        video_uploader_url = None\n        mobj = re.search(\n            r'<link itemprop=\"url\" href=\"(?P<uploader_url>https?://www.youtube.com/(?:user|channel)/(?P<uploader_id>[^\"]+))\">',\n            video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group('uploader_id')\n            video_uploader_url = mobj.group('uploader_url')\n        else:\n            self._downloader.report_warning('unable to extract uploader nickname')\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning('unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse_unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = self._html_search_meta(\n            'datePublished', video_webpage, 'upload date', default=None)\n        if not upload_date:\n            upload_date = self._search_regex(\n                [r'(?s)id=\"eow-date.*?>(.*?)</span>',\n                 r'id=\"watch-uploader-info\".*?>.*?(?:Published|Uploaded|Streamed live|Started) on (.+?)</strong>'],\n                video_webpage, 'upload date', default=None)\n            if upload_date:\n                upload_date = ' '.join(re.sub(r'[/,-]', r' ', mobj.group(1)).split())\n        upload_date = unified_strdate(upload_date)\n\n        video_license = self._html_search_regex(\n            r'<h4[^>]+class=\"title\"[^>]*>\\s*License\\s*</h4>\\s*<ul[^>]*>\\s*<li>(.+?)</li',\n            video_webpage, 'license', default=None)\n\n        m_music = re.search(\n            r'''(?x)\n                <h4[^>]+class=\"title\"[^>]*>\\s*Music\\s*</h4>\\s*\n                <ul[^>]*>\\s*\n                <li>(?P<title>.+?)\n                by (?P<creator>.+?)\n                (?:\n                    \\(.+?\\)|\n                    <a[^>]*\n                        (?:\n                            \\bhref=[\"\\']/red[^>]*>|             # drop possible\n                            >\\s*Listen ad-free with YouTube Red # YouTube Red ad\n                        )\n                    .*?\n                )?</li\n            ''',\n            video_webpage)\n        if m_music:\n            video_alt_title = remove_quotes(unescapeHTML(m_music.group('title')))\n            video_creator = clean_html(m_music.group('creator'))\n        else:\n            video_alt_title = video_creator = None\n\n        m_episode = re.search(\n            r'<div[^>]+id=\"watch7-headline\"[^>]*>\\s*<span[^>]*>.*?>(?P<series>[^<]+)</a></b>\\s*S(?P<season>\\d+)\\s*\u2022\\s*E(?P<episode>\\d+)</span>',\n            video_webpage)\n        if m_episode:\n            series = m_episode.group('series')\n            season_number = int(m_episode.group('season'))\n            episode_number = int(m_episode.group('episode'))\n        else:\n            series = season_number = episode_number = None\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', default=None)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        video_tags = [\n            unescapeHTML(m.group('content'))\n            for m in re.finditer(self._meta_regex('og:video:tag'), video_webpage)]\n\n        def _extract_count(count_name):\n            return str_to_int(self._search_regex(\n                r'-%s-button[^>]+><span[^>]+class=\"yt-uix-button-content\"[^>]*>([\\d,]+)</span>'\n                % re.escape(count_name),\n                video_webpage, count_name, default=None))\n\n        like_count = _extract_count('like')\n        dislike_count = _extract_count('dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)\n\n        video_duration = try_get(\n            video_info, lambda x: int_or_none(x['length_seconds'][0]))\n        if not video_duration:\n            video_duration = parse_duration(self._html_search_meta(\n                'duration', video_webpage, 'video duration'))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n            video_annotations = self._extract_annotations(video_id)\n\n        chapters = self._extract_chapters(description_original, video_duration)\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1:\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            formats_spec = {}\n            fmt_list = video_info.get('fmt_list', [''])[0]\n            if fmt_list:\n                for fmt in fmt_list.split(','):\n                    spec = fmt.split('/')\n                    if len(spec) > 1:\n                        width_height = spec[1].split('x')\n                        if len(width_height) == 2:\n                            formats_spec[spec[0]] = {\n                                'resolution': spec[1],\n                                'width': int_or_none(width_height[0]),\n                                'height': int_or_none(width_height[1]),\n                            }\n            formats = []\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 's' in url_data or self._downloader.params.get('youtube_include_dash_manifest', True):\n                    ASSETS_RE = r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")'\n                    jsplayer_url_json = self._search_regex(\n                        ASSETS_RE,\n                        embed_webpage if age_gate else video_webpage,\n                        'JS player URL (1)', default=None)\n                    if not jsplayer_url_json and not age_gate:\n                        # We need the embed website after all\n                        if embed_webpage is None:\n                            embed_url = proto + '://www.youtube.com/embed/%s' % video_id\n                            embed_webpage = self._download_webpage(\n                                embed_url, video_id, 'Downloading embed webpage')\n                        jsplayer_url_json = self._search_regex(\n                            ASSETS_RE, embed_webpage, 'JS player URL')\n\n                    player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\\.js',\n                                     r'(?:www|player)-([^/]+)(?:/[a-z]{2}_[A-Z]{2})?/base\\.js'],\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen('{%s} signature length %s, %s' %\n                                       (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n\n                dct = {\n                    'format_id': format_id,\n                    'url': url,\n                    'player_url': player_url,\n                }\n                if format_id in self._formats:\n                    dct.update(self._formats[format_id])\n                if format_id in formats_spec:\n                    dct.update(formats_spec[format_id])\n\n                # Some itags are not included in DASH manifest thus corresponding formats will\n                # lack metadata (see https://github.com/rg3/youtube-dl/pull/5993).\n                # Trying to extract metadata from url_encoded_fmt_stream_map entry.\n                mobj = re.search(r'^(?P<width>\\d+)[xX](?P<height>\\d+)$', url_data.get('size', [''])[0])\n                width, height = (int(mobj.group('width')), int(mobj.group('height'))) if mobj else (None, None)\n\n                more_fields = {\n                    'filesize': int_or_none(url_data.get('clen', [None])[0]),\n                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], 1000),\n                    'width': width,\n                    'height': height,\n                    'fps': int_or_none(url_data.get('fps', [None])[0]),\n                    'format_note': url_data.get('quality_label', [None])[0] or url_data.get('quality', [None])[0],\n                }\n                for key, value in more_fields.items():\n                    if value:\n                        dct[key] = value\n                type_ = url_data.get('type', [None])[0]\n                if type_:\n                    type_split = type_.split(';')\n                    kind_ext = type_split[0].split('/')\n                    if len(kind_ext) == 2:\n                        kind, _ = kind_ext\n                        dct['ext'] = mimetype2ext(type_split[0])\n                        if kind in ('audio', 'video'):\n                            codecs = None\n                            for mobj in re.finditer(\n                                    r'(?P<key>[a-zA-Z_-]+)=(?P<quote>[\"\\']?)(?P<val>.+?)(?P=quote)(?:;|$)', type_):\n                                if mobj.group('key') == 'codecs':\n                                    codecs = mobj.group('val')\n                                    break\n                            if codecs:\n                                dct.update(parse_codecs(codecs))\n                formats.append(dct)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            formats = []\n            m3u8_formats = self._extract_m3u8_formats(\n                manifest_url, video_id, 'mp4', fatal=False)\n            for a_format in m3u8_formats:\n                itag = self._search_regex(\n                    r'/itag/(\\d+)/', a_format['url'], 'itag', default=None)\n                if itag:\n                    a_format['format_id'] = itag\n                    if itag in self._formats:\n                        dct = self._formats[itag].copy()\n                        dct.update(a_format)\n                        a_format = dct\n                a_format['player_url'] = player_url\n                # Accept-Encoding header causes failures in live streams on Youtube and Youtube Gaming\n                a_format.setdefault('http_headers', {})['Youtubedl-no-compression'] = 'True'\n                formats.append(a_format)\n        else:\n            unavailable_message = self._html_search_regex(\n                r'(?s)<h1[^>]+id=\"unavailable-message\"[^>]*>(.+?)</h1>',\n                video_webpage, 'unavailable message', default=None)\n            if unavailable_message:\n                raise ExtractorError(unavailable_message, expected=True)\n            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if self._downloader.params.get('youtube_include_dash_manifest', True):\n            dash_mpd_fatal = True\n            for mpd_url in dash_mpds:\n                dash_formats = {}\n                try:\n                    def decrypt_sig(mobj):\n                        s = mobj.group(1)\n                        dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n                        return '/signature/%s' % dec_s\n\n                    mpd_url = re.sub(r'/s/([a-fA-F0-9\\.]+)', decrypt_sig, mpd_url)\n\n                    for df in self._extract_mpd_formats(\n                            mpd_url, video_id, fatal=dash_mpd_fatal,\n                            formats_dict=self._formats):\n                        # Do not overwrite DASH format found in some previous DASH manifest\n                        if df['format_id'] not in dash_formats:\n                            dash_formats[df['format_id']] = df\n                        # Additional DASH manifests may end up in HTTP Error 403 therefore\n                        # allow them to fail without bug report message if we already have\n                        # some DASH manifest succeeded. This is temporary workaround to reduce\n                        # burst of bug reports until we figure out the reason and whether it\n                        # can be fixed at all.\n                        dash_mpd_fatal = False\n                except (ExtractorError, KeyError) as e:\n                    self.report_warning(\n                        'Skipping DASH manifest: %r' % e, video_id)\n                if dash_formats:\n                    # Remove the formats we found through non-DASH, they\n                    # contain less info and it can be wrong, because we use\n                    # fixed values (for example the resolution). See\n                    # https://github.com/rg3/youtube-dl/issues/5774 for an\n                    # example.\n                    formats = [f for f in formats if f['format_id'] not in dash_formats.keys()]\n                    formats.extend(dash_formats.values())\n\n        # Check for malformed aspect ratio\n        stretched_m = re.search(\n            r'<meta\\s+property=\"og:video:tag\".*?content=\"yt:stretch=(?P<w>[0-9]+):(?P<h>[0-9]+)\">',\n            video_webpage)\n        if stretched_m:\n            w = float(stretched_m.group('w'))\n            h = float(stretched_m.group('h'))\n            # yt:stretch may hold invalid ratio data (e.g. for Q39EVAstoRM ratio is 17:0).\n            # We will only process correct ratios.\n            if w > 0 and h > 0:\n                ratio = w / h\n                for f in formats:\n                    if f.get('vcodec') != 'none':\n                        f['stretched_ratio'] = ratio\n\n        self._sort_formats(formats)\n\n        self.mark_watched(video_id, video_info)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'uploader_url': video_uploader_url,\n            'upload_date': upload_date,\n            'license': video_license,\n            'creator': video_creator,\n            'title': video_title,\n            'alt_title': video_alt_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'categories': video_categories,\n            'tags': video_tags,\n            'subtitles': video_subtitles,\n            'automatic_captions': automatic_captions,\n            'duration': video_duration,\n            'age_limit': 18 if age_gate else 0,\n            'annotations': video_annotations,\n            'chapters': chapters,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'average_rating': float_or_none(video_info.get('avg_rating', [None])[0]),\n            'formats': formats,\n            'is_live': is_live,\n            'start_time': start_time,\n            'end_time': end_time,\n            'series': series,\n            'season_number': season_number,\n            'episode_number': episode_number,\n        }",
        "begin_line": 1397,
        "end_line": 1972,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSharedVideoIE._real_extract#1997",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSharedVideoIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSharedVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        real_video_id = self._html_search_meta(\n            'videoId', webpage, 'YouTube video id', fatal=True)\n\n        return self.url_result(real_video_id, YoutubeIE.ie_key())",
        "begin_line": 1997,
        "end_line": 2005,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize#2163",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 2163,
        "end_line": 2164,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix#2166",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix(self, playlist_id)",
        "snippet": "    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a single video\n        # the id of the playlist is just 'RD' + video_id\n        ids = []\n        last_id = playlist_id[-11:]\n        for n in itertools.count(1):\n            url = 'https://youtube.com/watch?v=%s&list=%s' % (last_id, playlist_id)\n            webpage = self._download_webpage(\n                url, playlist_id, 'Downloading page {0} of Youtube mix'.format(n))\n            new_ids = orderedSet(re.findall(\n                r'''(?xs)data-video-username=\".*?\".*?\n                           href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n                webpage))\n            # Fetch new pages until all the videos are repeated, it seems that\n            # there are always 51 unique videos.\n            new_ids = [_id for _id in new_ids if _id not in ids]\n            if not new_ids:\n                break\n            ids.extend(new_ids)\n            last_id = ids[-1]\n\n        url_results = self._ids_to_results(ids)\n\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n\n        return self.playlist_result(url_results, playlist_id, title)",
        "begin_line": 2166,
        "end_line": 2196,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist#2198",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_playlist(self, playlist_id)",
        "snippet": "    def _extract_playlist(self, playlist_id):\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n\n        # the yt-alert-message now has tabindex attribute (see https://github.com/rg3/youtube-dl/issues/11604)\n        for match in re.findall(r'<div class=\"yt-alert-message\"[^>]*>([^<]+)</div>', page):\n            match = match.strip()\n            # Check if the playlist exists or is private\n            mobj = re.match(r'[^<]*(?:The|This) playlist (?P<reason>does not exist|is private)[^<]*', match)\n            if mobj:\n                reason = mobj.group('reason')\n                message = 'This playlist %s' % reason\n                if 'private' in reason:\n                    message += ', use --username or --netrc to access it'\n                message += '.'\n                raise ExtractorError(message, expected=True)\n            elif re.match(r'[^<]*Invalid parameters[^<]*', match):\n                raise ExtractorError(\n                    'Invalid parameters. Maybe URL is incorrect.',\n                    expected=True)\n            elif re.match(r'[^<]*Choose your language[^<]*', match):\n                continue\n            else:\n                self.report_warning('Youtube gives an alert message: ' + match)\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\"[^>]*>\\s*(.*?)\\s*</h1>',\n            page, 'title', default=None)\n\n        has_videos = True\n\n        if not playlist_title:\n            try:\n                # Some playlist URLs don't actually serve a playlist (e.g.\n                # https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4)\n                next(self._entries(page, playlist_id))\n            except StopIteration:\n                has_videos = False\n\n        return has_videos, self.playlist_result(\n            self._entries(page, playlist_id), playlist_id, playlist_title)",
        "begin_line": 2198,
        "end_line": 2238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._check_download_just_video#2240",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._check_download_just_video(self, url, playlist_id)",
        "snippet": "    def _check_download_just_video(self, url, playlist_id):\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        video_id = query_dict.get('v', [None])[0] or self._search_regex(\n            r'(?:(?:^|//)youtu\\.be/|youtube\\.com/embed/(?!videoseries))([0-9A-Za-z_-]{11})', url,\n            'video id', default=None)\n        if video_id:\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n                return video_id, self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n                return video_id, None\n        return None, None",
        "begin_line": 2240,
        "end_line": 2253,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract#2255",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        video_id, video = self._check_download_just_video(url, playlist_id)\n        if video:\n            return video\n\n        if playlist_id.startswith(('RD', 'UL', 'PU')):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n\n        has_videos, playlist = self._extract_playlist(playlist_id)\n        if has_videos or not video_id:\n            return playlist\n\n        # Some playlist URLs don't actually serve a playlist (see\n        # https://github.com/rg3/youtube-dl/issues/10537).\n        # Fallback to plain video extraction if there is a video id\n        # along with playlist id.\n        return self.url_result(video_id, 'Youtube', video_id=video_id)",
        "begin_line": 2255,
        "end_line": 2278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE.suitable#2307",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return (False if YoutubePlaylistsIE.suitable(url) or YoutubeLiveIE.suitable(url)\n                else super(YoutubeChannelIE, cls).suitable(url))",
        "begin_line": 2307,
        "end_line": 2309,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._build_template_url#2311",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._build_template_url(self, url, channel_id)",
        "snippet": "    def _build_template_url(self, url, channel_id):\n        return self._TEMPLATE_URL % channel_id",
        "begin_line": 2311,
        "end_line": 2312,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract#2314",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        url = self._build_template_url(url, channel_id)\n\n        # Channel by page listing is restricted to 35 pages of 30 items, i.e. 1050 videos total (see #5778)\n        # Workaround by extracting as a playlist if managed to obtain channel playlist URL\n        # otherwise fallback on channel by page extraction\n        channel_page = self._download_webpage(\n            url + '?view=57', channel_id,\n            'Downloading channel page', fatal=False)\n        if channel_page is False:\n            channel_playlist_id = False\n        else:\n            channel_playlist_id = self._html_search_meta(\n                'channelId', channel_page, 'channel id', default=None)\n            if not channel_playlist_id:\n                channel_url = self._html_search_meta(\n                    ('al:ios:url', 'twitter:app:url:iphone', 'twitter:app:url:ipad'),\n                    channel_page, 'channel url', default=None)\n                if channel_url:\n                    channel_playlist_id = self._search_regex(\n                        r'vnd\\.youtube://user/([0-9A-Za-z_-]+)',\n                        channel_url, 'channel id', default=None)\n        if channel_playlist_id and channel_playlist_id.startswith('UC'):\n            playlist_id = 'UU' + channel_playlist_id[2:]\n            return self.url_result(\n                compat_urlparse.urljoin(url, '/playlist?list=%s' % playlist_id), 'YoutubePlaylist')\n\n        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            entries = [\n                self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n                for video_id, video_title in self.extract_videos_from_page(channel_page)]\n            return self.playlist_result(entries, channel_id)\n\n        try:\n            next(self._entries(channel_page, channel_id))\n        except StopIteration:\n            alert_message = self._html_search_regex(\n                r'(?s)<div[^>]+class=([\"\\']).*?\\byt-alert-message\\b.*?\\1[^>]*>(?P<alert>[^<]+)</div>',\n                channel_page, 'alert', default=None, group='alert')\n            if alert_message:\n                raise ExtractorError('Youtube said: %s' % alert_message, expected=True)\n\n        return self.playlist_result(self._entries(channel_page, channel_id), channel_id)",
        "begin_line": 2314,
        "end_line": 2369,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable#2410",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_yt_ies = iter(klass for (name, klass) in globals().items() if name.startswith('Youtube') and name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_yt_ies):\n            return False\n        else:\n            return super(YoutubeUserIE, cls).suitable(url)",
        "begin_line": 2410,
        "end_line": 2417,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE._build_template_url#2419",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE._build_template_url(self, url, channel_id)",
        "snippet": "    def _build_template_url(self, url, channel_id):\n        mobj = re.match(self._VALID_URL, url)\n        return self._TEMPLATE_URL % (mobj.group('user') or 'user', mobj.group('id'))",
        "begin_line": 2419,
        "end_line": 2421,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeLiveIE._real_extract#2460",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeLiveIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeLiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        base_url = mobj.group('base_url')\n        webpage = self._download_webpage(url, channel_id, fatal=False)\n        if webpage:\n            page_type = self._og_search_property(\n                'type', webpage, 'page type', default=None)\n            video_id = self._html_search_meta(\n                'videoId', webpage, 'video id', default=None)\n            if page_type == 'video' and video_id and re.match(r'^[0-9A-Za-z_-]{11}$', video_id):\n                return self.url_result(video_id, YoutubeIE.ie_key())\n        return self.url_result(base_url)",
        "begin_line": 2460,
        "end_line": 2472,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results#2515",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        videos = []\n        limit = n\n\n        url_query = {\n            'search_query': query.encode('utf-8'),\n        }\n        url_query.update(self._EXTRA_QUERY_ARGS)\n        result_url = 'https://www.youtube.com/results?' + compat_urllib_parse_urlencode(url_query)\n\n        for pagenum in itertools.count(1):\n            data = self._download_json(\n                result_url, video_id='query \"%s\"' % query,\n                note='Downloading page %s' % pagenum,\n                errnote='Unable to download API page',\n                query={'spf': 'navigate'})\n            html_content = data[1]['body']['content']\n\n            if 'class=\"search-message' in html_content:\n                raise ExtractorError(\n                    '[youtube] No video results', expected=True)\n\n            new_videos = self._ids_to_results(orderedSet(re.findall(\n                r'href=\"/watch\\?v=(.{11})', html_content)))\n            videos += new_videos\n            if not new_videos or len(videos) > limit:\n                break\n            next_link = self._html_search_regex(\n                r'href=\"(/results\\?[^\"]*\\bsp=[^\"]+)\"[^>]*>\\s*<span[^>]+class=\"[^\"]*\\byt-uix-button-content\\b[^\"]*\"[^>]*>Next',\n                html_content, 'next link', default=None)\n            if next_link is None:\n                break\n            result_url = compat_urlparse.urljoin('https://www.youtube.com/', next_link)\n\n        if len(videos) > n:\n            videos = videos[:n]\n        return self.playlist_result(videos, query)",
        "begin_line": 2515,
        "end_line": 2553,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract#2579",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse_unquote_plus(mobj.group('query'))\n        webpage = self._download_webpage(url, query)\n        return self.playlist_result(self._process_page(webpage), playlist_title=query)",
        "begin_line": 2579,
        "end_line": 2583,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract#2599",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeShowIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        return super(YoutubeShowIE, self)._real_extract(\n            'https://www.youtube.com/show/%s/playlists' % playlist_id)",
        "begin_line": 2599,
        "end_line": 2602,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME#2613",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME",
        "begin_line": 2613,
        "end_line": 2614,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize#2616",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 2616,
        "end_line": 2617,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract#2619",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page = self._download_webpage(\n            'https://www.youtube.com/feed/%s' % self._FEED_NAME, self._PLAYLIST_TITLE)\n\n        # The extraction process is the same as for playlists, but the regex\n        # for the video ids doesn't contain an index\n        ids = []\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n\n            # 'recommended' feed has infinite 'load more' and each new portion spins\n            # the same videos in (sometimes) slightly different order, so we'll check\n            # for unicity and break when portion has no new videos\n            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))\n            if not new_ids:\n                break\n\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(\n            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)",
        "begin_line": 2619,
        "end_line": 2651,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract#2667",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        _, video = self._check_download_just_video(url, 'WL')\n        if video:\n            return video\n        _, playlist = self._extract_playlist('WL')\n        return playlist",
        "begin_line": 2667,
        "end_line": 2672,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract#2681",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')",
        "begin_line": 2681,
        "end_line": 2684,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract#2747",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"https://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)",
        "begin_line": 2747,
        "end_line": 2754,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract#2767",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedIDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raise ExtractorError(\n            'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),\n            expected=True)",
        "begin_line": 2767,
        "end_line": 2771,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zapiks.ZapiksIE._real_extract#49",
        "src_path": "youtube_dl/extractor/zapiks.py",
        "class_name": "youtube_dl.extractor.zapiks.ZapiksIE",
        "signature": "youtube_dl.extractor.zapiks.ZapiksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        if not video_id:\n            video_id = self._search_regex(\n                r'data-media-id=\"(\\d+)\"', webpage, 'video id')\n\n        playlist = self._download_xml(\n            'http://www.zapiks.fr/view/index.php?action=playlist&media_id=%s&lang=en' % video_id,\n            display_id)\n\n        NS_MAP = {\n            'jwplayer': 'http://rss.jwpcdn.com/'\n        }\n\n        def ns(path):\n            return xpath_with_ns(path, NS_MAP)\n\n        item = playlist.find('./channel/item')\n\n        title = xpath_text(item, 'title', 'title') or self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default=None)\n        thumbnail = xpath_text(\n            item, ns('./jwplayer:image'), 'thumbnail') or self._og_search_thumbnail(webpage, default=None)\n        duration = parse_duration(self._html_search_meta(\n            'duration', webpage, 'duration', default=None))\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date', default=None), ' ')\n\n        view_count = int_or_none(self._search_regex(\n            r'UserPlays:(\\d+)', webpage, 'view count', default=None))\n        comment_count = int_or_none(self._search_regex(\n            r'UserComments:(\\d+)', webpage, 'comment count', default=None))\n\n        formats = []\n        for source in item.findall(ns('./jwplayer:source')):\n            format_id = source.attrib['label']\n            f = {\n                'url': source.attrib['file'],\n                'format_id': format_id,\n            }\n            m = re.search(r'^(?P<height>\\d+)[pP]', format_id)\n            if m:\n                f['height'] = int(m.group('height'))\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 49,
        "end_line": 110,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zaq1.Zaq1IE._real_extract#46",
        "src_path": "youtube_dl/extractor/zaq1.py",
        "class_name": "youtube_dl.extractor.zaq1.Zaq1IE",
        "signature": "youtube_dl.extractor.zaq1.Zaq1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            r'data-video-url=([\"\\'])(?P<url>(?:(?!\\1).)+)\\1', webpage,\n            'video url', group='url')\n\n        info = self._search_json_ld(webpage, video_id, fatal=False)\n\n        def extract_data(field, name, fatal=False):\n            return self._search_regex(\n                r'data-%s=([\"\\'])(?P<field>(?:(?!\\1).)+)\\1' % field,\n                webpage, field, fatal=fatal, group='field')\n\n        if not info.get('title'):\n            info['title'] = extract_data('file-name', 'title', fatal=True)\n\n        if not info.get('duration'):\n            info['duration'] = int_or_none(extract_data('duration', 'duration'))\n\n        if not info.get('thumbnail'):\n            info['thumbnail'] = extract_data('photo-url', 'thumbnail')\n\n        if not info.get('timestamp'):\n            info['timestamp'] = unified_timestamp(self._html_search_meta(\n                'uploadDate', webpage, 'timestamp'))\n\n        if not info.get('interactionCount'):\n            info['view_count'] = int_or_none(self._html_search_meta(\n                'interactionCount', webpage, 'view count'))\n\n        uploader = self._html_search_regex(\n            r'Wideo doda\u0142:\\s*<a[^>]*>([^<]+)</a>', webpage, 'uploader',\n            fatal=False)\n\n        width = int_or_none(self._html_search_meta(\n            'width', webpage, fatal=False))\n        height = int_or_none(self._html_search_meta(\n            'height', webpage, fatal=False))\n\n        info.update({\n            'id': video_id,\n            'formats': [{\n                'url': video_url,\n                'width': width,\n                'height': height,\n                'http_headers': {\n                    'Referer': url,\n                },\n            }],\n            'uploader': uploader,\n        })\n\n        return info",
        "begin_line": 46,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFBaseIE._call_api#23",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFBaseIE",
        "signature": "youtube_dl.extractor.zdf.ZDFBaseIE._call_api(self, url, player, referrer, video_id, item)",
        "snippet": "    def _call_api(self, url, player, referrer, video_id, item):\n        return self._download_json(\n            url, video_id, 'Downloading JSON %s' % item,\n            headers={\n                'Referer': referrer,\n                'Api-Auth': 'Bearer %s' % player['apiToken'],\n            })",
        "begin_line": 23,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFBaseIE._extract_player#31",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFBaseIE",
        "signature": "youtube_dl.extractor.zdf.ZDFBaseIE._extract_player(self, webpage, video_id, fatal=True)",
        "snippet": "    def _extract_player(self, webpage, video_id, fatal=True):\n        return self._parse_json(\n            self._search_regex(\n                r'(?s)data-zdfplayer-jsb=([\"\\'])(?P<json>{.+?})\\1', webpage,\n                'player JSON', default='{}' if not fatal else NO_DEFAULT,\n                group='json'),\n            video_id)",
        "begin_line": 31,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._extract_subtitles#64",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._extract_subtitles(src)",
        "snippet": "    def _extract_subtitles(src):\n        subtitles = {}\n        for caption in try_get(src, lambda x: x['captions'], list) or []:\n            subtitle_url = caption.get('uri')\n            if subtitle_url and isinstance(subtitle_url, compat_str):\n                lang = caption.get('language', 'deu')\n                subtitles.setdefault(lang, []).append({\n                    'url': subtitle_url,\n                })\n        return subtitles",
        "begin_line": 64,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._extract_format#75",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._extract_format(self, video_id, formats, format_urls, meta)",
        "snippet": "    def _extract_format(self, video_id, formats, format_urls, meta):\n        format_url = meta.get('url')\n        if not format_url or not isinstance(format_url, compat_str):\n            return\n        if format_url in format_urls:\n            return\n        format_urls.add(format_url)\n        mime_type = meta.get('mimeType')\n        ext = determine_ext(format_url)\n        if mime_type == 'application/x-mpegURL' or ext == 'm3u8':\n            formats.extend(self._extract_m3u8_formats(\n                format_url, video_id, 'mp4', m3u8_id='hls',\n                entry_protocol='m3u8_native', fatal=False))\n        elif mime_type == 'application/f4m+xml' or ext == 'f4m':\n            formats.extend(self._extract_f4m_formats(\n                update_url_query(format_url, {'hdcore': '3.7.0'}), video_id, f4m_id='hds', fatal=False))\n        else:\n            f = parse_codecs(meta.get('mimeCodec'))\n            format_id = ['http']\n            for p in (meta.get('type'), meta.get('quality')):\n                if p and isinstance(p, compat_str):\n                    format_id.append(p)\n            f.update({\n                'url': format_url,\n                'format_id': '-'.join(format_id),\n                'format_note': meta.get('quality'),\n                'language': meta.get('language'),\n                'quality': qualities(self._QUALITIES)(meta.get('quality')),\n                'preference': -10,\n            })\n            formats.append(f)",
        "begin_line": 75,
        "end_line": 105,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._extract_entry#107",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._extract_entry(self, url, player, content, video_id)",
        "snippet": "    def _extract_entry(self, url, player, content, video_id):\n        title = content.get('title') or content['teaserHeadline']\n\n        t = content['mainVideoContent']['http://zdf.de/rels/target']\n\n        ptmd_path = t.get('http://zdf.de/rels/streams/ptmd')\n\n        if not ptmd_path:\n            ptmd_path = t[\n                'http://zdf.de/rels/streams/ptmd-template'].replace(\n                '{playerId}', 'portal')\n\n        ptmd = self._call_api(\n            urljoin(url, ptmd_path), player, url, video_id, 'metadata')\n\n        formats = []\n        track_uris = set()\n        for p in ptmd['priorityList']:\n            formitaeten = p.get('formitaeten')\n            if not isinstance(formitaeten, list):\n                continue\n            for f in formitaeten:\n                f_qualities = f.get('qualities')\n                if not isinstance(f_qualities, list):\n                    continue\n                for quality in f_qualities:\n                    tracks = try_get(quality, lambda x: x['audio']['tracks'], list)\n                    if not tracks:\n                        continue\n                    for track in tracks:\n                        self._extract_format(\n                            video_id, formats, track_uris, {\n                                'url': track.get('uri'),\n                                'type': f.get('type'),\n                                'mimeType': f.get('mimeType'),\n                                'quality': quality.get('quality'),\n                                'language': track.get('language'),\n                            })\n        self._sort_formats(formats)\n\n        thumbnails = []\n        layouts = try_get(\n            content, lambda x: x['teaserImageRef']['layouts'], dict)\n        if layouts:\n            for layout_key, layout_url in layouts.items():\n                if not isinstance(layout_url, compat_str):\n                    continue\n                thumbnail = {\n                    'url': layout_url,\n                    'format_id': layout_key,\n                }\n                mobj = re.search(r'(?P<width>\\d+)x(?P<height>\\d+)', layout_key)\n                if mobj:\n                    thumbnail.update({\n                        'width': int(mobj.group('width')),\n                        'height': int(mobj.group('height')),\n                    })\n                thumbnails.append(thumbnail)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': content.get('leadParagraph') or content.get('teasertext'),\n            'duration': int_or_none(t.get('duration')),\n            'timestamp': unified_timestamp(content.get('editorialDate')),\n            'thumbnails': thumbnails,\n            'subtitles': self._extract_subtitles(ptmd),\n            'formats': formats,\n        }",
        "begin_line": 107,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._extract_regular#177",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._extract_regular(self, url, player, video_id)",
        "snippet": "    def _extract_regular(self, url, player, video_id):\n        content = self._call_api(\n            player['content'], player, url, video_id, 'content')\n        return self._extract_entry(player['content'], player, content, video_id)",
        "begin_line": 177,
        "end_line": 180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._extract_mobile#182",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._extract_mobile(self, video_id)",
        "snippet": "    def _extract_mobile(self, video_id):\n        document = self._download_json(\n            'https://zdf-cdn.live.cellular.de/mediathekV2/document/%s' % video_id,\n            video_id)['document']\n\n        title = document['titel']\n\n        formats = []\n        format_urls = set()\n        for f in document['formitaeten']:\n            self._extract_format(video_id, formats, format_urls, f)\n        self._sort_formats(formats)\n\n        thumbnails = []\n        teaser_bild = document.get('teaserBild')\n        if isinstance(teaser_bild, dict):\n            for thumbnail_key, thumbnail in teaser_bild.items():\n                thumbnail_url = try_get(\n                    thumbnail, lambda x: x['url'], compat_str)\n                if thumbnail_url:\n                    thumbnails.append({\n                        'url': thumbnail_url,\n                        'id': thumbnail_key,\n                        'width': int_or_none(thumbnail.get('width')),\n                        'height': int_or_none(thumbnail.get('height')),\n                    })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': document.get('beschreibung'),\n            'duration': int_or_none(document.get('length')),\n            'timestamp': unified_timestamp(try_get(\n                document, lambda x: x['meta']['editorialDate'], compat_str)),\n            'thumbnails': thumbnails,\n            'subtitles': self._extract_subtitles(document),\n            'formats': formats,\n        }",
        "begin_line": 182,
        "end_line": 219,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._real_extract#221",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, video_id, fatal=False)\n        if webpage:\n            player = self._extract_player(webpage, url, fatal=False)\n            if player:\n                return self._extract_regular(url, player, video_id)\n\n        return self._extract_mobile(video_id)",
        "begin_line": 221,
        "end_line": 230,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFChannelIE.suitable#255",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFChannelIE",
        "signature": "youtube_dl.extractor.zdf.ZDFChannelIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if ZDFIE.suitable(url) else super(ZDFChannelIE, cls).suitable(url)",
        "begin_line": 255,
        "end_line": 256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFChannelIE._real_extract#258",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFChannelIE",
        "signature": "youtube_dl.extractor.zdf.ZDFChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, channel_id)\n\n        entries = [\n            self.url_result(item_url, ie=ZDFIE.ie_key())\n            for item_url in orderedSet(re.findall(\n                r'data-plusbar-url=[\"\\'](http.+?\\.html)', webpage))]\n\n        return self.playlist_result(\n            entries, channel_id, self._og_search_title(webpage, fatal=False))\n\n        r\"\"\"\n        player = self._extract_player(webpage, channel_id)\n\n        channel_id = self._search_regex(\n            r'docId\\s*:\\s*([\"\\'])(?P<id>(?!\\1).+?)\\1', webpage,\n            'channel id', group='id')\n\n        channel = self._call_api(\n            'https://api.zdf.de/content/documents/%s.json' % channel_id,\n            player, url, channel_id)\n\n        items = []\n        for module in channel['module']:\n            for teaser in try_get(module, lambda x: x['teaser'], list) or []:\n                t = try_get(\n                    teaser, lambda x: x['http://zdf.de/rels/target'], dict)\n                if not t:\n                    continue\n                items.extend(try_get(\n                    t,\n                    lambda x: x['resultsWithVideo']['http://zdf.de/rels/search/results'],\n                    list) or [])\n            items.extend(try_get(\n                module,\n                lambda x: x['filterRef']['resultsWithVideo']['http://zdf.de/rels/search/results'],\n                list) or [])\n\n        entries = []\n        entry_urls = set()\n        for item in items:\n            t = try_get(item, lambda x: x['http://zdf.de/rels/target'], dict)\n            if not t:\n                continue\n            sharing_url = t.get('http://zdf.de/rels/sharing-url')\n            if not sharing_url or not isinstance(sharing_url, compat_str):\n                continue\n            if sharing_url in entry_urls:\n                continue\n            entry_urls.add(sharing_url)\n            entries.append(self.url_result(\n                sharing_url, ie=ZDFIE.ie_key(), video_id=t.get('id')))\n\n        return self.playlist_result(entries, channel_id, channel.get('title'))\n        \"\"\"",
        "begin_line": 258,
        "end_line": 314,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_item#16",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_item(self, item, page_type, fatal=True)",
        "snippet": "    def _extract_item(self, item, page_type, fatal=True):\n        error_message = item.get('msg')\n        if error_message:\n            if not fatal:\n                return\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, error_message),\n                expected=True)\n\n        formats = []\n        for quality, source_url in zip(item.get('qualities') or item.get('quality', []), item.get('source_list') or item.get('source', [])):\n            if not source_url or source_url == 'require vip':\n                continue\n            if not re.match(r'https?://', source_url):\n                source_url = '//' + source_url\n            source_url = self._proto_relative_url(source_url, 'http:')\n            quality_num = int_or_none(quality)\n            f = {\n                'format_id': quality,\n                'url': source_url,\n            }\n            if page_type == 'video':\n                f.update({\n                    'height': quality_num,\n                    'ext': 'mp4',\n                })\n            else:\n                f.update({\n                    'abr': quality_num,\n                    'ext': 'mp3',\n                })\n            formats.append(f)\n\n        cover = item.get('cover')\n\n        return {\n            'title': (item.get('name') or item.get('title')).strip(),\n            'formats': formats,\n            'thumbnail': 'http:/' + cover if cover else None,\n            'artist': item.get('artist'),\n        }",
        "begin_line": 16,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_player_json#58",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3BaseInfoExtractor._extract_player_json(self, player_json_url, id, page_type, playlist_title=None)",
        "snippet": "    def _extract_player_json(self, player_json_url, id, page_type, playlist_title=None):\n        player_json = self._download_json(player_json_url, id, 'Downloading Player JSON')\n        items = player_json['data']\n        if 'item' in items:\n            items = items['item']\n\n        if len(items) == 1:\n            # one single song\n            data = self._extract_item(items[0], page_type)\n            data['id'] = id\n\n            return data\n        else:\n            # playlist of songs\n            entries = []\n\n            for i, item in enumerate(items, 1):\n                entry = self._extract_item(item, page_type, fatal=False)\n                if not entry:\n                    continue\n                entry['id'] = '%s-%d' % (id, i)\n                entries.append(entry)\n\n            return {\n                '_type': 'playlist',\n                'id': id,\n                'title': playlist_title,\n                'entries': entries,\n            }",
        "begin_line": 58,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.extractor.zingmp3.ZingMp3IE._real_extract#124",
        "src_path": "youtube_dl/extractor/zingmp3.py",
        "class_name": "youtube_dl.extractor.zingmp3.ZingMp3IE",
        "signature": "youtube_dl.extractor.zingmp3.ZingMp3IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        page_id = self._match_id(url)\n\n        webpage = self._download_webpage(url, page_id)\n\n        player_json_url = self._search_regex([\n            r'data-xml=\"([^\"]+)',\n            r'&amp;xmlURL=([^&]+)&'\n        ], webpage, 'player xml url')\n\n        playlist_title = None\n        page_type = self._search_regex(r'/(?:html5)?xml/([^/-]+)', player_json_url, 'page type')\n        if page_type == 'video':\n            player_json_url = update_url_query(player_json_url, {'format': 'json'})\n        else:\n            player_json_url = player_json_url.replace('/xml/', '/html5xml/')\n            if page_type == 'album':\n                playlist_title = self._og_search_title(webpage)\n\n        return self._extract_player_json(player_json_url, page_id, page_type, playlist_title)",
        "begin_line": 124,
        "end_line": 143,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.__init__#31",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.__init__(self, code, objects=None)",
        "snippet": "    def __init__(self, code, objects=None):\n        if objects is None:\n            objects = {}\n        self.code = code\n        self._functions = {}\n        self._objects = objects",
        "begin_line": 31,
        "end_line": 36,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_statement#38",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_statement(self, stmt, local_vars, allow_recursion=100)",
        "snippet": "    def interpret_statement(self, stmt, local_vars, allow_recursion=100):\n        if allow_recursion < 0:\n            raise ExtractorError('Recursion limit reached')\n\n        should_abort = False\n        stmt = stmt.lstrip()\n        stmt_m = re.match(r'var\\s', stmt)\n        if stmt_m:\n            expr = stmt[len(stmt_m.group(0)):]\n        else:\n            return_m = re.match(r'return(?:\\s+|$)', stmt)\n            if return_m:\n                expr = stmt[len(return_m.group(0)):]\n                should_abort = True\n            else:\n                # Try interpreting it as an expression\n                expr = stmt\n\n        v = self.interpret_expression(expr, local_vars, allow_recursion)\n        return v, should_abort",
        "begin_line": 38,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_expression#59",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_expression(self, expr, local_vars, allow_recursion)",
        "snippet": "    def interpret_expression(self, expr, local_vars, allow_recursion):\n        expr = expr.strip()\n        if expr == '':  # Empty expression\n            return None\n\n        if expr.startswith('('):\n            parens_count = 0\n            for m in re.finditer(r'[()]', expr):\n                if m.group(0) == '(':\n                    parens_count += 1\n                else:\n                    parens_count -= 1\n                    if parens_count == 0:\n                        sub_expr = expr[1:m.start()]\n                        sub_result = self.interpret_expression(\n                            sub_expr, local_vars, allow_recursion)\n                        remaining_expr = expr[m.end():].strip()\n                        if not remaining_expr:\n                            return sub_result\n                        else:\n                            expr = json.dumps(sub_result) + remaining_expr\n                        break\n            else:\n                raise ExtractorError('Premature end of parens in %r' % expr)\n\n        for op, opfunc in _ASSIGN_OPERATORS:\n            m = re.match(r'''(?x)\n                (?P<out>%s)(?:\\[(?P<index>[^\\]]+?)\\])?\n                \\s*%s\n                (?P<expr>.*)$''' % (_NAME_RE, re.escape(op)), expr)\n            if not m:\n                continue\n            right_val = self.interpret_expression(\n                m.group('expr'), local_vars, allow_recursion - 1)\n\n            if m.groupdict().get('index'):\n                lvar = local_vars[m.group('out')]\n                idx = self.interpret_expression(\n                    m.group('index'), local_vars, allow_recursion)\n                assert isinstance(idx, int)\n                cur = lvar[idx]\n                val = opfunc(cur, right_val)\n                lvar[idx] = val\n                return val\n            else:\n                cur = local_vars.get(m.group('out'))\n                val = opfunc(cur, right_val)\n                local_vars[m.group('out')] = val\n                return val\n\n        if expr.isdigit():\n            return int(expr)\n\n        var_m = re.match(\n            r'(?!if|return|true|false)(?P<name>%s)$' % _NAME_RE,\n            expr)\n        if var_m:\n            return local_vars[var_m.group('name')]\n\n        try:\n            return json.loads(expr)\n        except ValueError:\n            pass\n\n        m = re.match(\n            r'(?P<in>%s)\\[(?P<idx>.+)\\]$' % _NAME_RE, expr)\n        if m:\n            val = local_vars[m.group('in')]\n            idx = self.interpret_expression(\n                m.group('idx'), local_vars, allow_recursion - 1)\n            return val[idx]\n\n        m = re.match(\n            r'(?P<var>%s)(?:\\.(?P<member>[^(]+)|\\[(?P<member2>[^]]+)\\])\\s*(?:\\(+(?P<args>[^()]*)\\))?$' % _NAME_RE,\n            expr)\n        if m:\n            variable = m.group('var')\n            member = remove_quotes(m.group('member') or m.group('member2'))\n            arg_str = m.group('args')\n\n            if variable in local_vars:\n                obj = local_vars[variable]\n            else:\n                if variable not in self._objects:\n                    self._objects[variable] = self.extract_object(variable)\n                obj = self._objects[variable]\n\n            if arg_str is None:\n                # Member access\n                if member == 'length':\n                    return len(obj)\n                return obj[member]\n\n            assert expr.endswith(')')\n            # Function call\n            if arg_str == '':\n                argvals = tuple()\n            else:\n                argvals = tuple([\n                    self.interpret_expression(v, local_vars, allow_recursion)\n                    for v in arg_str.split(',')])\n\n            if member == 'split':\n                assert argvals == ('',)\n                return list(obj)\n            if member == 'join':\n                assert len(argvals) == 1\n                return argvals[0].join(obj)\n            if member == 'reverse':\n                assert len(argvals) == 0\n                obj.reverse()\n                return obj\n            if member == 'slice':\n                assert len(argvals) == 1\n                return obj[argvals[0]:]\n            if member == 'splice':\n                assert isinstance(obj, list)\n                index, howMany = argvals\n                res = []\n                for i in range(index, min(index + howMany, len(obj))):\n                    res.append(obj.pop(index))\n                return res\n\n            return obj[member](argvals)\n\n        for op, opfunc in _OPERATORS:\n            m = re.match(r'(?P<x>.+?)%s(?P<y>.+)' % re.escape(op), expr)\n            if not m:\n                continue\n            x, abort = self.interpret_statement(\n                m.group('x'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature left-side return of %s in %r' % (op, expr))\n            y, abort = self.interpret_statement(\n                m.group('y'), local_vars, allow_recursion - 1)\n            if abort:\n                raise ExtractorError(\n                    'Premature right-side return of %s in %r' % (op, expr))\n            return opfunc(x, y)\n\n        m = re.match(\n            r'^(?P<func>%s)\\((?P<args>[a-zA-Z0-9_$,]*)\\)$' % _NAME_RE, expr)\n        if m:\n            fname = m.group('func')\n            argvals = tuple([\n                int(v) if v.isdigit() else local_vars[v]\n                for v in m.group('args').split(',')]) if len(m.group('args')) > 0 else tuple()\n            if fname not in self._functions:\n                self._functions[fname] = self.extract_function(fname)\n            return self._functions[fname](argvals)\n\n        raise ExtractorError('Unsupported JS expression %r' % expr)",
        "begin_line": 59,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_object#213",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_object(self, objname)",
        "snippet": "    def extract_object(self, objname):\n        _FUNC_NAME_RE = r'''(?:[a-zA-Z$0-9]+|\"[a-zA-Z$0-9]+\"|'[a-zA-Z$0-9]+')'''\n        obj = {}\n        obj_m = re.search(\n            r'''(?x)\n                (?<!this\\.)%s\\s*=\\s*{\\s*\n                    (?P<fields>(%s\\s*:\\s*function\\s*\\(.*?\\)\\s*{.*?}(?:,\\s*)?)*)\n                }\\s*;\n            ''' % (re.escape(objname), _FUNC_NAME_RE),\n            self.code)\n        fields = obj_m.group('fields')\n        # Currently, it only supports function definitions\n        fields_m = re.finditer(\n            r'''(?x)\n                (?P<key>%s)\\s*:\\s*function\\s*\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}\n            ''' % _FUNC_NAME_RE,\n            fields)\n        for f in fields_m:\n            argnames = f.group('args').split(',')\n            obj[remove_quotes(f.group('key'))] = self.build_function(argnames, f.group('code'))\n\n        return obj",
        "begin_line": 213,
        "end_line": 234,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_function#236",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_function(self, funcname)",
        "snippet": "    def extract_function(self, funcname):\n        func_m = re.search(\n            r'''(?x)\n                (?:function\\s+%s|[{;,]\\s*%s\\s*=\\s*function|var\\s+%s\\s*=\\s*function)\\s*\n                \\((?P<args>[^)]*)\\)\\s*\n                \\{(?P<code>[^}]+)\\}''' % (\n                re.escape(funcname), re.escape(funcname), re.escape(funcname)),\n            self.code)\n        if func_m is None:\n            raise ExtractorError('Could not find JS function %r' % funcname)\n        argnames = func_m.group('args').split(',')\n\n        return self.build_function(argnames, func_m.group('code'))",
        "begin_line": 236,
        "end_line": 248,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.call_function#250",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.call_function(self, funcname, *args)",
        "snippet": "    def call_function(self, funcname, *args):\n        f = self.extract_function(funcname)\n        return f(args)",
        "begin_line": 250,
        "end_line": 252,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.build_function#254",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.build_function(self, argnames, code)",
        "snippet": "    def build_function(self, argnames, code):\n        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res, abort = self.interpret_statement(stmt, local_vars)\n                if abort:\n                    break\n            return res\n        return resf",
        "begin_line": 254,
        "end_line": 262,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.options._hide_login_info#23",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._hide_login_info(opts)",
        "snippet": "def _hide_login_info(opts):\n    PRIVATE_OPTS = set(['-p', '--password', '-u', '--username', '--video-password', '--ap-password', '--ap-username'])\n    eqre = re.compile('^(?P<key>' + ('|'.join(re.escape(po) for po in PRIVATE_OPTS)) + ')=.+$')\n\n    def _scrub_eq(o):\n        m = eqre.match(o)\n        if m:\n            return m.group('key') + '=PRIVATE'\n        else:\n            return o\n\n    opts = list(map(_scrub_eq, opts))\n    for idx, opt in enumerate(opts):\n        if opt in PRIVATE_OPTS and idx + 1 < len(opts):\n            opts[idx + 1] = 'PRIVATE'\n    return opts",
        "begin_line": 23,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.options.parseOpts#41",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options.parseOpts(overrideArguments=None)",
        "snippet": "def parseOpts(overrideArguments=None):\n    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            # FIXME: https://github.com/rg3/youtube-dl/commit/dfe5fa49aed02cf36ba9f743b11b0903554b5e56\n            contents = optionf.read()\n            if sys.version_info < (3,):\n                contents = contents.decode(preferredencoding())\n            res = compat_shlex_split(contents, comments=True)\n        finally:\n            optionf.close()\n        return res\n\n    def _readUserConf():\n        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = compat_getenv('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf\n\n    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value():\n            opts.append(' %s' % option.metavar)\n\n        return ''.join(opts)\n\n    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))\n\n    # No need to wrap help messages if we're on a wide console\n    columns = compat_get_terminal_size().columns\n    max_width = columns if columns else 80\n    max_help_position = 80\n\n    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)\n    fmt.format_option_strings = _format_option_string\n\n    kw = {\n        'version': __version__,\n        'formatter': fmt,\n        'usage': '%prog [OPTIONS] URL [URL...]',\n        'conflict_handler': 'resolve',\n    }\n\n    parser = optparse.OptionParser(**compat_kwargs(kw))\n\n    general = optparse.OptionGroup(parser, 'General Options')\n    general.add_option(\n        '-h', '--help',\n        action='help',\n        help='Print this help text and exit')\n    general.add_option(\n        '-v', '--version',\n        action='version',\n        help='Print program version and exit')\n    general.add_option(\n        '-U', '--update',\n        action='store_true', dest='update_self',\n        help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')\n    general.add_option(\n        '-i', '--ignore-errors',\n        action='store_true', dest='ignoreerrors', default=False,\n        help='Continue on download errors, for example to skip unavailable videos in a playlist')\n    general.add_option(\n        '--abort-on-error',\n        action='store_false', dest='ignoreerrors',\n        help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')\n    general.add_option(\n        '--dump-user-agent',\n        action='store_true', dest='dump_user_agent', default=False,\n        help='Display the current browser identification')\n    general.add_option(\n        '--list-extractors',\n        action='store_true', dest='list_extractors', default=False,\n        help='List all supported extractors')\n    general.add_option(\n        '--extractor-descriptions',\n        action='store_true', dest='list_extractor_descriptions', default=False,\n        help='Output descriptions of all supported extractors')\n    general.add_option(\n        '--force-generic-extractor',\n        action='store_true', dest='force_generic_extractor', default=False,\n        help='Force extraction to use the generic extractor')\n    general.add_option(\n        '--default-search',\n        dest='default_search', metavar='PREFIX',\n        help='Use this prefix for unqualified URLs. For example \"gvsearch2:\" downloads two videos from google videos for youtube-dl \"large apple\". Use the value \"auto\" to let youtube-dl guess (\"auto_warning\" to emit a warning when guessing). \"error\" just throws an error. The default value \"fixup_error\" repairs broken URLs, but emits an error if this is not possible instead of searching.')\n    general.add_option(\n        '--ignore-config',\n        action='store_true',\n        help='Do not read configuration files. '\n        'When given in the global configuration file /etc/youtube-dl.conf: '\n        'Do not read the user configuration in ~/.config/youtube-dl/config '\n        '(%APPDATA%/youtube-dl/config.txt on Windows)')\n    general.add_option(\n        '--config-location',\n        dest='config_location', metavar='PATH',\n        help='Location of the configuration file; either the path to the config or its containing directory.')\n    general.add_option(\n        '--flat-playlist',\n        action='store_const', dest='extract_flat', const='in_playlist',\n        default=False,\n        help='Do not extract the videos of a playlist, only list them.')\n    general.add_option(\n        '--mark-watched',\n        action='store_true', dest='mark_watched', default=False,\n        help='Mark videos watched (YouTube only)')\n    general.add_option(\n        '--no-mark-watched',\n        action='store_false', dest='mark_watched', default=False,\n        help='Do not mark videos watched (YouTube only)')\n    general.add_option(\n        '--no-color', '--no-colors',\n        action='store_true', dest='no_color',\n        default=False,\n        help='Do not emit color codes in output')\n\n    network = optparse.OptionGroup(parser, 'Network Options')\n    network.add_option(\n        '--proxy', dest='proxy',\n        default=None, metavar='URL',\n        help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable experimental '\n             'SOCKS proxy, specify a proper scheme. For example '\n             'socks5://127.0.0.1:1080/. Pass in an empty string (--proxy \"\") '\n             'for direct connection')\n    network.add_option(\n        '--socket-timeout',\n        dest='socket_timeout', type=float, default=None, metavar='SECONDS',\n        help='Time to wait before giving up, in seconds')\n    network.add_option(\n        '--source-address',\n        metavar='IP', dest='source_address', default=None,\n        help='Client-side IP address to bind to',\n    )\n    network.add_option(\n        '-4', '--force-ipv4',\n        action='store_const', const='0.0.0.0', dest='source_address',\n        help='Make all connections via IPv4',\n    )\n    network.add_option(\n        '-6', '--force-ipv6',\n        action='store_const', const='::', dest='source_address',\n        help='Make all connections via IPv6',\n    )\n\n    geo = optparse.OptionGroup(parser, 'Geo Restriction')\n    geo.add_option(\n        '--geo-verification-proxy',\n        dest='geo_verification_proxy', default=None, metavar='URL',\n        help='Use this proxy to verify the IP address for some geo-restricted sites. '\n        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading.')\n    geo.add_option(\n        '--cn-verification-proxy',\n        dest='cn_verification_proxy', default=None, metavar='URL',\n        help=optparse.SUPPRESS_HELP)\n    geo.add_option(\n        '--geo-bypass',\n        action='store_true', dest='geo_bypass', default=True,\n        help='Bypass geographic restriction via faking X-Forwarded-For HTTP header (experimental)')\n    geo.add_option(\n        '--no-geo-bypass',\n        action='store_false', dest='geo_bypass', default=True,\n        help='Do not bypass geographic restriction via faking X-Forwarded-For HTTP header (experimental)')\n    geo.add_option(\n        '--geo-bypass-country', metavar='CODE',\n        dest='geo_bypass_country', default=None,\n        help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code (experimental)')\n\n    selection = optparse.OptionGroup(parser, 'Video Selection')\n    selection.add_option(\n        '--playlist-start',\n        dest='playliststart', metavar='NUMBER', default=1, type=int,\n        help='Playlist video to start at (default is %default)')\n    selection.add_option(\n        '--playlist-end',\n        dest='playlistend', metavar='NUMBER', default=None, type=int,\n        help='Playlist video to end at (default is last)')\n    selection.add_option(\n        '--playlist-items',\n        dest='playlist_items', metavar='ITEM_SPEC', default=None,\n        help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: \"--playlist-items 1,2,5,8\" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: \"--playlist-items 1-3,7,10-13\", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')\n    selection.add_option(\n        '--match-title',\n        dest='matchtitle', metavar='REGEX',\n        help='Download only matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--reject-title',\n        dest='rejecttitle', metavar='REGEX',\n        help='Skip download for matching titles (regex or caseless sub-string)')\n    selection.add_option(\n        '--max-downloads',\n        dest='max_downloads', metavar='NUMBER', type=int, default=None,\n        help='Abort after downloading NUMBER files')\n    selection.add_option(\n        '--min-filesize',\n        metavar='SIZE', dest='min_filesize', default=None,\n        help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--max-filesize',\n        metavar='SIZE', dest='max_filesize', default=None,\n        help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')\n    selection.add_option(\n        '--date',\n        metavar='DATE', dest='date', default=None,\n        help='Download only videos uploaded in this date')\n    selection.add_option(\n        '--datebefore',\n        metavar='DATE', dest='datebefore', default=None,\n        help='Download only videos uploaded on or before this date (i.e. inclusive)')\n    selection.add_option(\n        '--dateafter',\n        metavar='DATE', dest='dateafter', default=None,\n        help='Download only videos uploaded on or after this date (i.e. inclusive)')\n    selection.add_option(\n        '--min-views',\n        metavar='COUNT', dest='min_views', default=None, type=int,\n        help='Do not download any videos with less than COUNT views')\n    selection.add_option(\n        '--max-views',\n        metavar='COUNT', dest='max_views', default=None, type=int,\n        help='Do not download any videos with more than COUNT views')\n    selection.add_option(\n        '--match-filter',\n        metavar='FILTER', dest='match_filter', default=None,\n        help=(\n            'Generic video filter. '\n            'Specify any key (see the \"OUTPUT TEMPLATE\" for a list of available keys) to '\n            'match if the key is present, '\n            '!key to check if the key is not present, '\n            'key > NUMBER (like \"comment_count > 12\", also works with '\n            '>=, <, <=, !=, =) to compare against a number, '\n            'key = \\'LITERAL\\' (like \"uploader = \\'Mike Smith\\'\", also works with !=) '\n            'to match against a string literal '\n            'and & to require multiple matches. '\n            'Values which are not known are excluded unless you '\n            'put a question mark (?) after the operator. '\n            'For example, to only match videos that have been liked more than '\n            '100 times and disliked less than 50 times (or the dislike '\n            'functionality is not available at the given service), but who '\n            'also have a description, use --match-filter '\n            '\"like_count > 100 & dislike_count <? 50 & description\" .'\n        ))\n    selection.add_option(\n        '--no-playlist',\n        action='store_true', dest='noplaylist', default=False,\n        help='Download only the video, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--yes-playlist',\n        action='store_false', dest='noplaylist', default=False,\n        help='Download the playlist, if the URL refers to a video and a playlist.')\n    selection.add_option(\n        '--age-limit',\n        metavar='YEARS', dest='age_limit', default=None, type=int,\n        help='Download only videos suitable for the given age')\n    selection.add_option(\n        '--download-archive', metavar='FILE',\n        dest='download_archive',\n        help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')\n    selection.add_option(\n        '--include-ads',\n        dest='include_ads', action='store_true',\n        help='Download advertisements as well (experimental)')\n\n    authentication = optparse.OptionGroup(parser, 'Authentication Options')\n    authentication.add_option(\n        '-u', '--username',\n        dest='username', metavar='USERNAME',\n        help='Login with this account ID')\n    authentication.add_option(\n        '-p', '--password',\n        dest='password', metavar='PASSWORD',\n        help='Account password. If this option is left out, youtube-dl will ask interactively.')\n    authentication.add_option(\n        '-2', '--twofactor',\n        dest='twofactor', metavar='TWOFACTOR',\n        help='Two-factor authentication code')\n    authentication.add_option(\n        '-n', '--netrc',\n        action='store_true', dest='usenetrc', default=False,\n        help='Use .netrc authentication data')\n    authentication.add_option(\n        '--video-password',\n        dest='videopassword', metavar='PASSWORD',\n        help='Video password (vimeo, smotri, youku)')\n\n    adobe_pass = optparse.OptionGroup(parser, 'Adobe Pass Options')\n    adobe_pass.add_option(\n        '--ap-mso',\n        dest='ap_mso', metavar='MSO',\n        help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')\n    adobe_pass.add_option(\n        '--ap-username',\n        dest='ap_username', metavar='USERNAME',\n        help='Multiple-system operator account login')\n    adobe_pass.add_option(\n        '--ap-password',\n        dest='ap_password', metavar='PASSWORD',\n        help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')\n    adobe_pass.add_option(\n        '--ap-list-mso',\n        action='store_true', dest='ap_list_mso', default=False,\n        help='List all supported multiple-system operators')\n\n    video_format = optparse.OptionGroup(parser, 'Video Format Options')\n    video_format.add_option(\n        '-f', '--format',\n        action='store', dest='format', metavar='FORMAT', default=None,\n        help='Video format code, see the \"FORMAT SELECTION\" for all the info')\n    video_format.add_option(\n        '--all-formats',\n        action='store_const', dest='format', const='all',\n        help='Download all available video formats')\n    video_format.add_option(\n        '--prefer-free-formats',\n        action='store_true', dest='prefer_free_formats', default=False,\n        help='Prefer free video formats unless a specific one is requested')\n    video_format.add_option(\n        '-F', '--list-formats',\n        action='store_true', dest='listformats',\n        help='List all available formats of requested videos')\n    video_format.add_option(\n        '--youtube-include-dash-manifest',\n        action='store_true', dest='youtube_include_dash_manifest', default=True,\n        help=optparse.SUPPRESS_HELP)\n    video_format.add_option(\n        '--youtube-skip-dash-manifest',\n        action='store_false', dest='youtube_include_dash_manifest',\n        help='Do not download the DASH manifests and related data on YouTube videos')\n    video_format.add_option(\n        '--merge-output-format',\n        action='store', dest='merge_output_format', metavar='FORMAT', default=None,\n        help=(\n            'If a merge is required (e.g. bestvideo+bestaudio), '\n            'output to given container format. One of mkv, mp4, ogg, webm, flv. '\n            'Ignored if no merge is required'))\n\n    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')\n    subtitles.add_option(\n        '--write-sub', '--write-srt',\n        action='store_true', dest='writesubtitles', default=False,\n        help='Write subtitle file')\n    subtitles.add_option(\n        '--write-auto-sub', '--write-automatic-sub',\n        action='store_true', dest='writeautomaticsub', default=False,\n        help='Write automatically generated subtitle file (YouTube only)')\n    subtitles.add_option(\n        '--all-subs',\n        action='store_true', dest='allsubtitles', default=False,\n        help='Download all the available subtitles of the video')\n    subtitles.add_option(\n        '--list-subs',\n        action='store_true', dest='listsubtitles', default=False,\n        help='List all available subtitles for the video')\n    subtitles.add_option(\n        '--sub-format',\n        action='store', dest='subtitlesformat', metavar='FORMAT', default='best',\n        help='Subtitle format, accepts formats preference, for example: \"srt\" or \"ass/srt/best\"')\n    subtitles.add_option(\n        '--sub-lang', '--sub-langs', '--srt-lang',\n        action='callback', dest='subtitleslangs', metavar='LANGS', type='str',\n        default=[], callback=_comma_separated_values_options_callback,\n        help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')\n\n    downloader = optparse.OptionGroup(parser, 'Download Options')\n    downloader.add_option(\n        '-r', '--limit-rate', '--rate-limit',\n        dest='ratelimit', metavar='RATE',\n        help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')\n    downloader.add_option(\n        '-R', '--retries',\n        dest='retries', metavar='RETRIES', default=10,\n        help='Number of retries (default is %default), or \"infinite\".')\n    downloader.add_option(\n        '--fragment-retries',\n        dest='fragment_retries', metavar='RETRIES', default=10,\n        help='Number of retries for a fragment (default is %default), or \"infinite\" (DASH, hlsnative and ISM)')\n    downloader.add_option(\n        '--skip-unavailable-fragments',\n        action='store_true', dest='skip_unavailable_fragments', default=True,\n        help='Skip unavailable fragments (DASH, hlsnative and ISM)')\n    downloader.add_option(\n        '--abort-on-unavailable-fragment',\n        action='store_false', dest='skip_unavailable_fragments',\n        help='Abort downloading when some fragment is not available')\n    downloader.add_option(\n        '--keep-fragments',\n        action='store_true', dest='keep_fragments', default=False,\n        help='Keep downloaded fragments on disk after downloading is finished; fragments are erased by default')\n    downloader.add_option(\n        '--buffer-size',\n        dest='buffersize', metavar='SIZE', default='1024',\n        help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')\n    downloader.add_option(\n        '--no-resize-buffer',\n        action='store_true', dest='noresizebuffer', default=False,\n        help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')\n    downloader.add_option(\n        '--test',\n        action='store_true', dest='test', default=False,\n        help=optparse.SUPPRESS_HELP)\n    downloader.add_option(\n        '--playlist-reverse',\n        action='store_true',\n        help='Download playlist videos in reverse order')\n    downloader.add_option(\n        '--playlist-random',\n        action='store_true',\n        help='Download playlist videos in random order')\n    downloader.add_option(\n        '--xattr-set-filesize',\n        dest='xattr_set_filesize', action='store_true',\n        help='Set file xattribute ytdl.filesize with expected file size (experimental)')\n    downloader.add_option(\n        '--hls-prefer-native',\n        dest='hls_prefer_native', action='store_true', default=None,\n        help='Use the native HLS downloader instead of ffmpeg')\n    downloader.add_option(\n        '--hls-prefer-ffmpeg',\n        dest='hls_prefer_native', action='store_false', default=None,\n        help='Use ffmpeg instead of the native HLS downloader')\n    downloader.add_option(\n        '--hls-use-mpegts',\n        dest='hls_use_mpegts', action='store_true',\n        help='Use the mpegts container for HLS videos, allowing to play the '\n             'video while downloading (some players may not be able to play it)')\n    downloader.add_option(\n        '--external-downloader',\n        dest='external_downloader', metavar='COMMAND',\n        help='Use the specified external downloader. '\n             'Currently supports %s' % ','.join(list_external_downloaders()))\n    downloader.add_option(\n        '--external-downloader-args',\n        dest='external_downloader_args', metavar='ARGS',\n        help='Give these arguments to the external downloader')\n\n    workarounds = optparse.OptionGroup(parser, 'Workarounds')\n    workarounds.add_option(\n        '--encoding',\n        dest='encoding', metavar='ENCODING',\n        help='Force the specified encoding (experimental)')\n    workarounds.add_option(\n        '--no-check-certificate',\n        action='store_true', dest='no_check_certificate', default=False,\n        help='Suppress HTTPS certificate validation')\n    workarounds.add_option(\n        '--prefer-insecure',\n        '--prefer-unsecure', action='store_true', dest='prefer_insecure',\n        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')\n    workarounds.add_option(\n        '--user-agent',\n        metavar='UA', dest='user_agent',\n        help='Specify a custom user agent')\n    workarounds.add_option(\n        '--referer',\n        metavar='URL', dest='referer', default=None,\n        help='Specify a custom referer, use if the video access is restricted to one domain',\n    )\n    workarounds.add_option(\n        '--add-header',\n        metavar='FIELD:VALUE', dest='headers', action='append',\n        help='Specify a custom HTTP header and its value, separated by a colon \\':\\'. You can use this option multiple times',\n    )\n    workarounds.add_option(\n        '--bidi-workaround',\n        dest='bidi_workaround', action='store_true',\n        help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')\n    workarounds.add_option(\n        '--sleep-interval', '--min-sleep-interval', metavar='SECONDS',\n        dest='sleep_interval', type=float,\n        help=(\n            'Number of seconds to sleep before each download when used alone '\n            'or a lower bound of a range for randomized sleep before each download '\n            '(minimum possible number of seconds to sleep) when used along with '\n            '--max-sleep-interval.'))\n    workarounds.add_option(\n        '--max-sleep-interval', metavar='SECONDS',\n        dest='max_sleep_interval', type=float,\n        help=(\n            'Upper bound of a range for randomized sleep before each download '\n            '(maximum possible number of seconds to sleep). Must only be used '\n            'along with --min-sleep-interval.'))\n\n    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')\n    verbosity.add_option(\n        '-q', '--quiet',\n        action='store_true', dest='quiet', default=False,\n        help='Activate quiet mode')\n    verbosity.add_option(\n        '--no-warnings',\n        dest='no_warnings', action='store_true', default=False,\n        help='Ignore warnings')\n    verbosity.add_option(\n        '-s', '--simulate',\n        action='store_true', dest='simulate', default=False,\n        help='Do not download the video and do not write anything to disk')\n    verbosity.add_option(\n        '--skip-download',\n        action='store_true', dest='skip_download', default=False,\n        help='Do not download the video')\n    verbosity.add_option(\n        '-g', '--get-url',\n        action='store_true', dest='geturl', default=False,\n        help='Simulate, quiet but print URL')\n    verbosity.add_option(\n        '-e', '--get-title',\n        action='store_true', dest='gettitle', default=False,\n        help='Simulate, quiet but print title')\n    verbosity.add_option(\n        '--get-id',\n        action='store_true', dest='getid', default=False,\n        help='Simulate, quiet but print id')\n    verbosity.add_option(\n        '--get-thumbnail',\n        action='store_true', dest='getthumbnail', default=False,\n        help='Simulate, quiet but print thumbnail URL')\n    verbosity.add_option(\n        '--get-description',\n        action='store_true', dest='getdescription', default=False,\n        help='Simulate, quiet but print video description')\n    verbosity.add_option(\n        '--get-duration',\n        action='store_true', dest='getduration', default=False,\n        help='Simulate, quiet but print video length')\n    verbosity.add_option(\n        '--get-filename',\n        action='store_true', dest='getfilename', default=False,\n        help='Simulate, quiet but print output filename')\n    verbosity.add_option(\n        '--get-format',\n        action='store_true', dest='getformat', default=False,\n        help='Simulate, quiet but print output format')\n    verbosity.add_option(\n        '-j', '--dump-json',\n        action='store_true', dest='dumpjson', default=False,\n        help='Simulate, quiet but print JSON information. See the \"OUTPUT TEMPLATE\" for a description of available keys.')\n    verbosity.add_option(\n        '-J', '--dump-single-json',\n        action='store_true', dest='dump_single_json', default=False,\n        help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')\n    verbosity.add_option(\n        '--print-json',\n        action='store_true', dest='print_json', default=False,\n        help='Be quiet and print the video information as JSON (video is still being downloaded).',\n    )\n    verbosity.add_option(\n        '--newline',\n        action='store_true', dest='progress_with_newline', default=False,\n        help='Output progress bar as new lines')\n    verbosity.add_option(\n        '--no-progress',\n        action='store_true', dest='noprogress', default=False,\n        help='Do not print progress bar')\n    verbosity.add_option(\n        '--console-title',\n        action='store_true', dest='consoletitle', default=False,\n        help='Display progress in console titlebar')\n    verbosity.add_option(\n        '-v', '--verbose',\n        action='store_true', dest='verbose', default=False,\n        help='Print various debugging information')\n    verbosity.add_option(\n        '--dump-pages', '--dump-intermediate-pages',\n        action='store_true', dest='dump_intermediate_pages', default=False,\n        help='Print downloaded pages encoded using base64 to debug problems (very verbose)')\n    verbosity.add_option(\n        '--write-pages',\n        action='store_true', dest='write_pages', default=False,\n        help='Write downloaded intermediary pages to files in the current directory to debug problems')\n    verbosity.add_option(\n        '--youtube-print-sig-code',\n        action='store_true', dest='youtube_print_sig_code', default=False,\n        help=optparse.SUPPRESS_HELP)\n    verbosity.add_option(\n        '--print-traffic', '--dump-headers',\n        dest='debug_printtraffic', action='store_true', default=False,\n        help='Display sent and read HTTP traffic')\n    verbosity.add_option(\n        '-C', '--call-home',\n        dest='call_home', action='store_true', default=False,\n        help='Contact the youtube-dl server for debugging')\n    verbosity.add_option(\n        '--no-call-home',\n        dest='call_home', action='store_false', default=False,\n        help='Do NOT contact the youtube-dl server for debugging')\n\n    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')\n    filesystem.add_option(\n        '-a', '--batch-file',\n        dest='batchfile', metavar='FILE',\n        help='File containing URLs to download (\\'-\\' for stdin)')\n    filesystem.add_option(\n        '--id', default=False,\n        action='store_true', dest='useid', help='Use only video ID in file name')\n    filesystem.add_option(\n        '-o', '--output',\n        dest='outtmpl', metavar='TEMPLATE',\n        help=('Output filename template, see the \"OUTPUT TEMPLATE\" for all the info'))\n    filesystem.add_option(\n        '--autonumber-size',\n        dest='autonumber_size', metavar='NUMBER', type=int,\n        help=optparse.SUPPRESS_HELP)\n    filesystem.add_option(\n        '--autonumber-start',\n        dest='autonumber_start', metavar='NUMBER', default=1, type=int,\n        help='Specify the start value for %(autonumber)s (default is %default)')\n    filesystem.add_option(\n        '--restrict-filenames',\n        action='store_true', dest='restrictfilenames', default=False,\n        help='Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames')\n    filesystem.add_option(\n        '-A', '--auto-number',\n        action='store_true', dest='autonumber', default=False,\n        help=optparse.SUPPRESS_HELP)\n    filesystem.add_option(\n        '-t', '--title',\n        action='store_true', dest='usetitle', default=False,\n        help=optparse.SUPPRESS_HELP)\n    filesystem.add_option(\n        '-l', '--literal', default=False,\n        action='store_true', dest='usetitle',\n        help=optparse.SUPPRESS_HELP)\n    filesystem.add_option(\n        '-w', '--no-overwrites',\n        action='store_true', dest='nooverwrites', default=False,\n        help='Do not overwrite files')\n    filesystem.add_option(\n        '-c', '--continue',\n        action='store_true', dest='continue_dl', default=True,\n        help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')\n    filesystem.add_option(\n        '--no-continue',\n        action='store_false', dest='continue_dl',\n        help='Do not resume partially downloaded files (restart from beginning)')\n    filesystem.add_option(\n        '--no-part',\n        action='store_true', dest='nopart', default=False,\n        help='Do not use .part files - write directly into output file')\n    filesystem.add_option(\n        '--no-mtime',\n        action='store_false', dest='updatetime', default=True,\n        help='Do not use the Last-modified header to set the file modification time')\n    filesystem.add_option(\n        '--write-description',\n        action='store_true', dest='writedescription', default=False,\n        help='Write video description to a .description file')\n    filesystem.add_option(\n        '--write-info-json',\n        action='store_true', dest='writeinfojson', default=False,\n        help='Write video metadata to a .info.json file')\n    filesystem.add_option(\n        '--write-annotations',\n        action='store_true', dest='writeannotations', default=False,\n        help='Write video annotations to a .annotations.xml file')\n    filesystem.add_option(\n        '--load-info-json', '--load-info',\n        dest='load_info_filename', metavar='FILE',\n        help='JSON file containing the video information (created with the \"--write-info-json\" option)')\n    filesystem.add_option(\n        '--cookies',\n        dest='cookiefile', metavar='FILE',\n        help='File to read cookies from and dump cookie jar in')\n    filesystem.add_option(\n        '--cache-dir', dest='cachedir', default=None, metavar='DIR',\n        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')\n    filesystem.add_option(\n        '--no-cache-dir', action='store_const', const=False, dest='cachedir',\n        help='Disable filesystem caching')\n    filesystem.add_option(\n        '--rm-cache-dir',\n        action='store_true', dest='rm_cachedir',\n        help='Delete all filesystem cache files')\n\n    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')\n    thumbnail.add_option(\n        '--write-thumbnail',\n        action='store_true', dest='writethumbnail', default=False,\n        help='Write thumbnail image to disk')\n    thumbnail.add_option(\n        '--write-all-thumbnails',\n        action='store_true', dest='write_all_thumbnails', default=False,\n        help='Write all thumbnail image formats to disk')\n    thumbnail.add_option(\n        '--list-thumbnails',\n        action='store_true', dest='list_thumbnails', default=False,\n        help='Simulate and list all available thumbnail formats')\n\n    postproc = optparse.OptionGroup(parser, 'Post-processing Options')\n    postproc.add_option(\n        '-x', '--extract-audio',\n        action='store_true', dest='extractaudio', default=False,\n        help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')\n    postproc.add_option(\n        '--audio-format', metavar='FORMAT', dest='audioformat', default='best',\n        help='Specify audio format: \"best\", \"aac\", \"flac\", \"mp3\", \"m4a\", \"opus\", \"vorbis\", or \"wav\"; \"%default\" by default; No effect without -x')\n    postproc.add_option(\n        '--audio-quality', metavar='QUALITY',\n        dest='audioquality', default='5',\n        help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')\n    postproc.add_option(\n        '--recode-video',\n        metavar='FORMAT', dest='recodevideo', default=None,\n        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')\n    postproc.add_option(\n        '--postprocessor-args',\n        dest='postprocessor_args', metavar='ARGS',\n        help='Give these arguments to the postprocessor')\n    postproc.add_option(\n        '-k', '--keep-video',\n        action='store_true', dest='keepvideo', default=False,\n        help='Keep the video file on disk after the post-processing; the video is erased by default')\n    postproc.add_option(\n        '--no-post-overwrites',\n        action='store_true', dest='nopostoverwrites', default=False,\n        help='Do not overwrite post-processed files; the post-processed files are overwritten by default')\n    postproc.add_option(\n        '--embed-subs',\n        action='store_true', dest='embedsubtitles', default=False,\n        help='Embed subtitles in the video (only for mp4, webm and mkv videos)')\n    postproc.add_option(\n        '--embed-thumbnail',\n        action='store_true', dest='embedthumbnail', default=False,\n        help='Embed thumbnail in the audio as cover art')\n    postproc.add_option(\n        '--add-metadata',\n        action='store_true', dest='addmetadata', default=False,\n        help='Write metadata to the video file')\n    postproc.add_option(\n        '--metadata-from-title',\n        metavar='FORMAT', dest='metafromtitle',\n        help='Parse additional metadata like song title / artist from the video title. '\n             'The format syntax is the same as --output. Regular expression with '\n             'named capture groups may also be used. '\n             'The parsed parameters replace existing values. '\n             'Example: --metadata-from-title \"%(artist)s - %(title)s\" matches a title like '\n             '\"Coldplay - Paradise\". '\n             'Example (regex): --metadata-from-title \"(?P<artist>.+?) - (?P<title>.+)\"')\n    postproc.add_option(\n        '--xattrs',\n        action='store_true', dest='xattrs', default=False,\n        help='Write metadata to the video file\\'s xattrs (using dublin core and xdg standards)')\n    postproc.add_option(\n        '--fixup',\n        metavar='POLICY', dest='fixup', default='detect_or_warn',\n        help='Automatically correct known faults of the file. '\n             'One of never (do nothing), warn (only emit a warning), '\n             'detect_or_warn (the default; fix file if we can, warn otherwise)')\n    postproc.add_option(\n        '--prefer-avconv',\n        action='store_false', dest='prefer_ffmpeg',\n        help='Prefer avconv over ffmpeg for running the postprocessors (default)')\n    postproc.add_option(\n        '--prefer-ffmpeg',\n        action='store_true', dest='prefer_ffmpeg',\n        help='Prefer ffmpeg over avconv for running the postprocessors')\n    postproc.add_option(\n        '--ffmpeg-location', '--avconv-location', metavar='PATH',\n        dest='ffmpeg_location',\n        help='Location of the ffmpeg/avconv binary; either the path to the binary or its containing directory.')\n    postproc.add_option(\n        '--exec',\n        metavar='CMD', dest='exec_cmd',\n        help='Execute a command on the file after downloading, similar to find\\'s -exec syntax. Example: --exec \\'adb push {} /sdcard/Music/ && rm {}\\'')\n    postproc.add_option(\n        '--convert-subs', '--convert-subtitles',\n        metavar='FORMAT', dest='convertsubtitles', default=None,\n        help='Convert the subtitles to other format (currently supported: srt|ass|vtt)')\n\n    parser.add_option_group(general)\n    parser.add_option_group(network)\n    parser.add_option_group(geo)\n    parser.add_option_group(selection)\n    parser.add_option_group(downloader)\n    parser.add_option_group(filesystem)\n    parser.add_option_group(thumbnail)\n    parser.add_option_group(verbosity)\n    parser.add_option_group(workarounds)\n    parser.add_option_group(video_format)\n    parser.add_option_group(subtitles)\n    parser.add_option_group(authentication)\n    parser.add_option_group(adobe_pass)\n    parser.add_option_group(postproc)\n\n    if overrideArguments is not None:\n        opts, args = parser.parse_args(overrideArguments)\n        if opts.verbose:\n            write_string('[debug] Override config: ' + repr(overrideArguments) + '\\n')\n    else:\n        def compat_conf(conf):\n            if sys.version_info < (3,):\n                return [a.decode(preferredencoding(), 'replace') for a in conf]\n            return conf\n\n        command_line_conf = compat_conf(sys.argv[1:])\n        opts, args = parser.parse_args(command_line_conf)\n\n        system_conf = user_conf = custom_conf = []\n\n        if '--config-location' in command_line_conf:\n            location = compat_expanduser(opts.config_location)\n            if os.path.isdir(location):\n                location = os.path.join(location, 'youtube-dl.conf')\n            if not os.path.exists(location):\n                parser.error('config-location %s does not exist.' % location)\n            custom_conf = _readOptions(location)\n        elif '--ignore-config' in command_line_conf:\n            pass\n        else:\n            system_conf = _readOptions('/etc/youtube-dl.conf')\n            if '--ignore-config' not in system_conf:\n                user_conf = _readUserConf()\n\n        argv = system_conf + user_conf + custom_conf + command_line_conf\n        opts, args = parser.parse_args(argv)\n        if opts.verbose:\n            for conf_label, conf in (\n                    ('System config', system_conf),\n                    ('User config', user_conf),\n                    ('Custom config', custom_conf),\n                    ('Command-line args', command_line_conf)):\n                write_string('[debug] %s: %s\\n' % (conf_label, repr(_hide_login_info(conf))))\n\n    return parser, opts, args",
        "begin_line": 41,
        "end_line": 906,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.__init__.get_postprocessor#21",
        "src_path": "youtube_dl/postprocessor/__init__.py",
        "class_name": "youtube_dl.postprocessor.__init__",
        "signature": "youtube_dl.postprocessor.__init__.get_postprocessor(key)",
        "snippet": "def get_postprocessor(key):\n    return globals()[key + 'PP']",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.__init__#34",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        self._downloader = downloader",
        "begin_line": 34,
        "end_line": 35,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.set_downloader#37",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this PP.\"\"\"\n        self._downloader = downloader",
        "begin_line": 37,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.run#41",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.run(self, information)",
        "snippet": "    def run(self, information):\n        \"\"\"Run the PostProcessor.\n\n        The \"information\" argument is a dictionary like the ones\n        composed by InfoExtractors. The only difference is that this\n        one has an extra field called \"filepath\" that points to the\n        downloaded file.\n\n        This method returns a tuple, the first element is a list of the files\n        that can be deleted, and the second of which is the updated\n        information.\n\n        In addition, this method may raise a PostProcessingError\n        exception if post processing fails.\n        \"\"\"\n        return [], information  # by default, keep file and do nothing",
        "begin_line": 41,
        "end_line": 56,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.try_utime#58",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.try_utime(self, path, atime, mtime, errnote='Cannot update utime of file')",
        "snippet": "    def try_utime(self, path, atime, mtime, errnote='Cannot update utime of file'):\n        try:\n            os.utime(encodeFilename(path), (atime, mtime))\n        except Exception:\n            self._downloader.report_warning(errnote)",
        "begin_line": 58,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor._configuration_args#64",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor._configuration_args(self, default=[])",
        "snippet": "    def _configuration_args(self, default=[]):\n        return cli_configuration_args(self._downloader.params, 'postprocessor_args', default)",
        "begin_line": 64,
        "end_line": 65,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.__init__#25",
        "src_path": "youtube_dl/postprocessor/embedthumbnail.py",
        "class_name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP",
        "signature": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.__init__(self, downloader=None, already_have_thumbnail=False)",
        "snippet": "    def __init__(self, downloader=None, already_have_thumbnail=False):\n        super(EmbedThumbnailPP, self).__init__(downloader)\n        self._already_have_thumbnail = already_have_thumbnail",
        "begin_line": 25,
        "end_line": 27,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.run#29",
        "src_path": "youtube_dl/postprocessor/embedthumbnail.py",
        "class_name": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP",
        "signature": "youtube_dl.postprocessor.embedthumbnail.EmbedThumbnailPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        if not info.get('thumbnails'):\n            raise EmbedThumbnailPPError('Thumbnail was not found. Nothing to do.')\n\n        thumbnail_filename = info['thumbnails'][-1]['filename']\n\n        if not os.path.exists(encodeFilename(thumbnail_filename)):\n            self._downloader.report_warning(\n                'Skipping embedding the thumbnail because the file is missing.')\n            return [], info\n\n        if info['ext'] == 'mp3':\n            options = [\n                '-c', 'copy', '-map', '0', '-map', '1',\n                '-metadata:s:v', 'title=\"Album cover\"', '-metadata:s:v', 'comment=\"Cover (Front)\"']\n\n            self._downloader.to_screen('[ffmpeg] Adding thumbnail to \"%s\"' % filename)\n\n            self.run_ffmpeg_multiple_files([filename, thumbnail_filename], temp_filename, options)\n\n            if not self._already_have_thumbnail:\n                os.remove(encodeFilename(thumbnail_filename))\n            os.remove(encodeFilename(filename))\n            os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        elif info['ext'] in ['m4a', 'mp4']:\n            if not check_executable('AtomicParsley', ['-v']):\n                raise EmbedThumbnailPPError('AtomicParsley was not found. Please install.')\n\n            cmd = [encodeFilename('AtomicParsley', True),\n                   encodeFilename(filename, True),\n                   encodeArgument('--artwork'),\n                   encodeFilename(thumbnail_filename, True),\n                   encodeArgument('-o'),\n                   encodeFilename(temp_filename, True)]\n\n            self._downloader.to_screen('[atomicparsley] Adding thumbnail to \"%s\"' % filename)\n\n            if self._downloader.params.get('verbose', False):\n                self._downloader.to_screen('[debug] AtomicParsley command line: %s' % shell_quote(cmd))\n\n            p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            stdout, stderr = p.communicate()\n\n            if p.returncode != 0:\n                msg = stderr.decode('utf-8', 'replace').strip()\n                raise EmbedThumbnailPPError(msg)\n\n            if not self._already_have_thumbnail:\n                os.remove(encodeFilename(thumbnail_filename))\n            # for formats that don't support thumbnails (like 3gp) AtomicParsley\n            # won't create to the temporary file\n            if b'No changes' in stdout:\n                self._downloader.report_warning('The file format doesn\\'t support embedding a thumbnail')\n            else:\n                os.remove(encodeFilename(filename))\n                os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        else:\n            raise EmbedThumbnailPPError('Only mp3 and m4a/mp4 are supported for thumbnail embedding for now.')\n\n        return [], info",
        "begin_line": 29,
        "end_line": 92,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__#14",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__(self, downloader, exec_cmd)",
        "snippet": "    def __init__(self, downloader, exec_cmd):\n        super(ExecAfterDownloadPP, self).__init__(downloader)\n        self.exec_cmd = exec_cmd",
        "begin_line": 14,
        "end_line": 16,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run#18",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run(self, information)",
        "snippet": "    def run(self, information):\n        cmd = self.exec_cmd\n        if '{}' not in cmd:\n            cmd += ' {}'\n\n        cmd = cmd.replace('{}', compat_shlex_quote(information['filepath']))\n\n        self._downloader.to_screen('[exec] Executing command: %s' % cmd)\n        retCode = subprocess.call(encodeArgument(cmd), shell=True)\n        if retCode != 0:\n            raise PostProcessingError(\n                'Command returned error code %d' % retCode)\n\n        return [], information",
        "begin_line": 18,
        "end_line": 31,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__#58",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        PostProcessor.__init__(self, downloader)\n        self._determine_executables()",
        "begin_line": 58,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.check_version#62",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.check_version(self)",
        "snippet": "    def check_version(self):\n        if not self.available:\n            raise FFmpegPostProcessorError('ffmpeg or avconv not found. Please install one.')\n\n        required_version = '10-0' if self.basename == 'avconv' else '1.0'\n        if is_outdated_version(\n                self._versions[self.basename], required_version):\n            warning = 'Your copy of %s is outdated, update %s to version %s or newer if you encounter any errors.' % (\n                self.basename, self.basename, required_version)\n            if self._downloader:\n                self._downloader.report_warning(warning)",
        "begin_line": 62,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions#75",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_versions(downloader=None)",
        "snippet": "    def get_versions(downloader=None):\n        return FFmpegPostProcessor(downloader)._versions",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables#78",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._determine_executables(self)",
        "snippet": "    def _determine_executables(self):\n        programs = ['avprobe', 'avconv', 'ffmpeg', 'ffprobe']\n        prefer_ffmpeg = False\n\n        self.basename = None\n        self.probe_basename = None\n\n        self._paths = None\n        self._versions = None\n        if self._downloader:\n            prefer_ffmpeg = self._downloader.params.get('prefer_ffmpeg', False)\n            location = self._downloader.params.get('ffmpeg_location')\n            if location is not None:\n                if not os.path.exists(location):\n                    self._downloader.report_warning(\n                        'ffmpeg-location %s does not exist! '\n                        'Continuing without avconv/ffmpeg.' % (location))\n                    self._versions = {}\n                    return\n                elif not os.path.isdir(location):\n                    basename = os.path.splitext(os.path.basename(location))[0]\n                    if basename not in programs:\n                        self._downloader.report_warning(\n                            'Cannot identify executable %s, its basename should be one of %s. '\n                            'Continuing without avconv/ffmpeg.' %\n                            (location, ', '.join(programs)))\n                        self._versions = {}\n                        return None\n                    location = os.path.dirname(os.path.abspath(location))\n                    if basename in ('ffmpeg', 'ffprobe'):\n                        prefer_ffmpeg = True\n\n                self._paths = dict(\n                    (p, os.path.join(location, p)) for p in programs)\n                self._versions = dict(\n                    (p, get_exe_version(self._paths[p], args=['-version']))\n                    for p in programs)\n        if self._versions is None:\n            self._versions = dict(\n                (p, get_exe_version(p, args=['-version'])) for p in programs)\n            self._paths = dict((p, p) for p in programs)\n\n        if prefer_ffmpeg:\n            prefs = ('ffmpeg', 'avconv')\n        else:\n            prefs = ('avconv', 'ffmpeg')\n        for p in prefs:\n            if self._versions[p]:\n                self.basename = p\n                break\n\n        if prefer_ffmpeg:\n            prefs = ('ffprobe', 'avprobe')\n        else:\n            prefs = ('avprobe', 'ffprobe')\n        for p in prefs:\n            if self._versions[p]:\n                self.probe_basename = p\n                break",
        "begin_line": 78,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.available#139",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.available(self)",
        "snippet": "    def available(self):\n        return self.basename is not None",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.executable#143",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.executable(self)",
        "snippet": "    def executable(self):\n        return self._paths[self.basename]",
        "begin_line": 143,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_available#147",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_available(self)",
        "snippet": "    def probe_available(self):\n        return self.probe_basename is not None",
        "begin_line": 147,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_executable#151",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.probe_executable(self)",
        "snippet": "    def probe_executable(self):\n        return self._paths[self.probe_basename]",
        "begin_line": 151,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_audio_codec#154",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.get_audio_codec(self, path)",
        "snippet": "    def get_audio_codec(self, path):\n        if not self.probe_available:\n            raise PostProcessingError('ffprobe or avprobe not found. Please install one.')\n        try:\n            cmd = [\n                encodeFilename(self.probe_executable, True),\n                encodeArgument('-show_streams'),\n                encodeFilename(self._ffmpeg_filename_argument(path), True)]\n            if self._downloader.params.get('verbose', False):\n                self._downloader.to_screen('[debug] %s command line: %s' % (self.basename, shell_quote(cmd)))\n            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n            output = handle.communicate()[0]\n            if handle.wait() != 0:\n                return None\n        except (IOError, OSError):\n            return None\n        audio_codec = None\n        for line in output.decode('ascii', 'ignore').split('\\n'):\n            if line.startswith('codec_name='):\n                audio_codec = line.split('=')[1].strip()\n            elif line.strip() == 'codec_type=audio' and audio_codec is not None:\n                return audio_codec\n        return None",
        "begin_line": 154,
        "end_line": 176,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files#178",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files(self, input_paths, out_path, opts)",
        "snippet": "    def run_ffmpeg_multiple_files(self, input_paths, out_path, opts):\n        self.check_version()\n\n        oldest_mtime = min(\n            os.stat(encodeFilename(path)).st_mtime for path in input_paths)\n\n        opts += self._configuration_args()\n\n        files_cmd = []\n        for path in input_paths:\n            files_cmd.extend([\n                encodeArgument('-i'),\n                encodeFilename(self._ffmpeg_filename_argument(path), True)\n            ])\n        cmd = ([encodeFilename(self.executable, True), encodeArgument('-y')] +\n               files_cmd +\n               [encodeArgument(o) for o in opts] +\n               [encodeFilename(self._ffmpeg_filename_argument(out_path), True)])\n\n        if self._downloader.params.get('verbose', False):\n            self._downloader.to_screen('[debug] ffmpeg command line: %s' % shell_quote(cmd))\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n        if p.returncode != 0:\n            stderr = stderr.decode('utf-8', 'replace')\n            msg = stderr.strip().split('\\n')[-1]\n            raise FFmpegPostProcessorError(msg)\n        self.try_utime(out_path, oldest_mtime, oldest_mtime)",
        "begin_line": 178,
        "end_line": 205,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg#207",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, opts):\n        self.run_ffmpeg_multiple_files([path], out_path, opts)",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument#210",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument(self, fn)",
        "snippet": "    def _ffmpeg_filename_argument(self, fn):\n        # Always use 'file:' because the filename may contain ':' (ffmpeg\n        # interprets that as a protocol) or can start with '-' (-- is broken in\n        # ffmpeg, see https://ffmpeg.org/trac/ffmpeg/ticket/2127 for details)\n        # Also leave '-' intact in order not to break streaming to stdout.\n        return 'file:' + fn if fn != '-' else fn",
        "begin_line": 210,
        "end_line": 215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__#219",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False)",
        "snippet": "    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):\n        FFmpegPostProcessor.__init__(self, downloader)\n        if preferredcodec is None:\n            preferredcodec = 'best'\n        self._preferredcodec = preferredcodec\n        self._preferredquality = preferredquality\n        self._nopostoverwrites = nopostoverwrites",
        "begin_line": 219,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg#227",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg(self, path, out_path, codec, more_opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, codec, more_opts):\n        if codec is None:\n            acodec_opts = []\n        else:\n            acodec_opts = ['-acodec', codec]\n        opts = ['-vn'] + acodec_opts + more_opts\n        try:\n            FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)\n        except FFmpegPostProcessorError as err:\n            raise AudioConversionError(err.msg)",
        "begin_line": 227,
        "end_line": 236,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run#238",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n\n        filecodec = self.get_audio_codec(path)\n        if filecodec is None:\n            raise PostProcessingError('WARNING: unable to obtain file audio codec with ffprobe')\n\n        more_opts = []\n        if self._preferredcodec == 'best' or self._preferredcodec == filecodec or (self._preferredcodec == 'm4a' and filecodec == 'aac'):\n            if filecodec == 'aac' and self._preferredcodec in ['m4a', 'best']:\n                # Lossless, but in another container\n                acodec = 'copy'\n                extension = 'm4a'\n                more_opts = ['-bsf:a', 'aac_adtstoasc']\n            elif filecodec in ['aac', 'flac', 'mp3', 'vorbis', 'opus']:\n                # Lossless if possible\n                acodec = 'copy'\n                extension = filecodec\n                if filecodec == 'aac':\n                    more_opts = ['-f', 'adts']\n                if filecodec == 'vorbis':\n                    extension = 'ogg'\n            else:\n                # MP3 otherwise.\n                acodec = 'libmp3lame'\n                extension = 'mp3'\n                more_opts = []\n                if self._preferredquality is not None:\n                    if int(self._preferredquality) < 10:\n                        more_opts += ['-q:a', self._preferredquality]\n                    else:\n                        more_opts += ['-b:a', self._preferredquality + 'k']\n        else:\n            # We convert the audio (lossy if codec is lossy)\n            acodec = ACODECS[self._preferredcodec]\n            extension = self._preferredcodec\n            more_opts = []\n            if self._preferredquality is not None:\n                # The opus codec doesn't support the -aq option\n                if int(self._preferredquality) < 10 and extension != 'opus':\n                    more_opts += ['-q:a', self._preferredquality]\n                else:\n                    more_opts += ['-b:a', self._preferredquality + 'k']\n            if self._preferredcodec == 'aac':\n                more_opts += ['-f', 'adts']\n            if self._preferredcodec == 'm4a':\n                more_opts += ['-bsf:a', 'aac_adtstoasc']\n            if self._preferredcodec == 'vorbis':\n                extension = 'ogg'\n            if self._preferredcodec == 'wav':\n                extension = 'wav'\n                more_opts += ['-f', 'wav']\n\n        prefix, sep, ext = path.rpartition('.')  # not os.path.splitext, since the latter does not work on unicode in all setups\n        new_path = prefix + sep + extension\n\n        information['filepath'] = new_path\n        information['ext'] = extension\n\n        # If we download foo.mp3 and convert it to... foo.mp3, then don't delete foo.mp3, silly.\n        if (new_path == path or\n                (self._nopostoverwrites and os.path.exists(encodeFilename(new_path)))):\n            self._downloader.to_screen('[ffmpeg] Post-process file %s exists, skipping' % new_path)\n            return [], information\n\n        try:\n            self._downloader.to_screen('[ffmpeg] Destination: ' + new_path)\n            self.run_ffmpeg(path, new_path, acodec, more_opts)\n        except AudioConversionError as e:\n            raise PostProcessingError(\n                'audio conversion failed: ' + e.msg)\n        except Exception:\n            raise PostProcessingError('error running ' + self.basename)\n\n        # Try to update the date time for extracted audio file.\n        if information.get('filetime') is not None:\n            self.try_utime(\n                new_path, time.time(), information['filetime'],\n                errnote='Cannot update utime of audio file')\n\n        return [path], information",
        "begin_line": 238,
        "end_line": 318,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.__init__#322",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.__init__(self, downloader=None, preferedformat=None)",
        "snippet": "    def __init__(self, downloader=None, preferedformat=None):\n        super(FFmpegVideoConvertorPP, self).__init__(downloader)\n        self._preferedformat = preferedformat",
        "begin_line": 322,
        "end_line": 324,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run#326",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertorPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n        if information['ext'] == self._preferedformat:\n            self._downloader.to_screen('[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))\n            return [], information\n        options = []\n        if self._preferedformat == 'avi':\n            options.extend(['-c:v', 'libxvid', '-vtag', 'XVID'])\n        prefix, sep, ext = path.rpartition('.')\n        outpath = prefix + sep + self._preferedformat\n        self._downloader.to_screen('[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)\n        self.run_ffmpeg(path, outpath, options)\n        information['filepath'] = outpath\n        information['format'] = self._preferedformat\n        information['ext'] = self._preferedformat\n        return [path], information",
        "begin_line": 326,
        "end_line": 341,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run#345",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run(self, information)",
        "snippet": "    def run(self, information):\n        if information['ext'] not in ('mp4', 'webm', 'mkv'):\n            self._downloader.to_screen('[ffmpeg] Subtitles can only be embedded in mp4, webm or mkv files')\n            return [], information\n        subtitles = information.get('requested_subtitles')\n        if not subtitles:\n            self._downloader.to_screen('[ffmpeg] There aren\\'t any subtitles to embed')\n            return [], information\n\n        filename = information['filepath']\n\n        ext = information['ext']\n        sub_langs = []\n        sub_filenames = []\n        webm_vtt_warn = False\n\n        for lang, sub_info in subtitles.items():\n            sub_ext = sub_info['ext']\n            if ext != 'webm' or ext == 'webm' and sub_ext == 'vtt':\n                sub_langs.append(lang)\n                sub_filenames.append(subtitles_filename(filename, lang, sub_ext))\n            else:\n                if not webm_vtt_warn and ext == 'webm' and sub_ext != 'vtt':\n                    webm_vtt_warn = True\n                    self._downloader.to_screen('[ffmpeg] Only WebVTT subtitles can be embedded in webm files')\n\n        if not sub_langs:\n            return [], information\n\n        input_files = [filename] + sub_filenames\n\n        opts = [\n            '-map', '0',\n            '-c', 'copy',\n            # Don't copy the existing subtitles, we may be running the\n            # postprocessor a second time\n            '-map', '-0:s',\n        ]\n        if information['ext'] == 'mp4':\n            opts += ['-c:s', 'mov_text']\n        for (i, lang) in enumerate(sub_langs):\n            opts.extend(['-map', '%d:0' % (i + 1)])\n            lang_code = ISO639Utils.short2long(lang)\n            if lang_code is not None:\n                opts.extend(['-metadata:s:s:%d' % i, 'language=%s' % lang_code])\n\n        temp_filename = prepend_extension(filename, 'temp')\n        self._downloader.to_screen('[ffmpeg] Embedding subtitles in \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(input_files, temp_filename, opts)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return sub_filenames, information",
        "begin_line": 345,
        "end_line": 397,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run#401",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        metadata = {}\n\n        def add(meta_list, info_list=None):\n            if not info_list:\n                info_list = meta_list\n            if not isinstance(meta_list, (list, tuple)):\n                meta_list = (meta_list,)\n            if not isinstance(info_list, (list, tuple)):\n                info_list = (info_list,)\n            for info_f in info_list:\n                if info.get(info_f) is not None:\n                    for meta_f in meta_list:\n                        metadata[meta_f] = info[info_f]\n                    break\n\n        add('title', ('track', 'title'))\n        add('date', 'upload_date')\n        add(('description', 'comment'), 'description')\n        add('purl', 'webpage_url')\n        add('track', 'track_number')\n        add('artist', ('artist', 'creator', 'uploader', 'uploader_id'))\n        add('genre')\n        add('album')\n        add('album_artist')\n        add('disc', 'disc_number')\n\n        if not metadata:\n            self._downloader.to_screen('[ffmpeg] There isn\\'t any metadata to add')\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n        in_filenames = [filename]\n        options = []\n\n        if info['ext'] == 'm4a':\n            options.extend(['-vn', '-acodec', 'copy'])\n        else:\n            options.extend(['-c', 'copy'])\n\n        for (name, value) in metadata.items():\n            options.extend(['-metadata', '%s=%s' % (name, value)])\n\n        chapters = info.get('chapters', [])\n        if chapters:\n            metadata_filename = replace_extension(filename, 'meta')\n            with io.open(metadata_filename, 'wt', encoding='utf-8') as f:\n                def ffmpeg_escape(text):\n                    return re.sub(r'(=|;|#|\\\\|\\n)', r'\\\\\\1', text)\n\n                metadata_file_content = ';FFMETADATA1\\n'\n                for chapter in chapters:\n                    metadata_file_content += '[CHAPTER]\\nTIMEBASE=1/1000\\n'\n                    metadata_file_content += 'START=%d\\n' % (chapter['start_time'] * 1000)\n                    metadata_file_content += 'END=%d\\n' % (chapter['end_time'] * 1000)\n                    chapter_title = chapter.get('title')\n                    if chapter_title:\n                        metadata_file_content += 'title=%s\\n' % ffmpeg_escape(chapter_title)\n                f.write(metadata_file_content)\n                in_filenames.append(metadata_filename)\n                options.extend(['-map_metadata', '1'])\n\n        self._downloader.to_screen('[ffmpeg] Adding metadata to \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(in_filenames, temp_filename, options)\n        if chapters:\n            os.remove(metadata_filename)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return [], info",
        "begin_line": 401,
        "end_line": 470,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run#474",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n        args = ['-c', 'copy', '-map', '0:v:0', '-map', '1:a:0']\n        self._downloader.to_screen('[ffmpeg] Merging formats into \"%s\"' % filename)\n        self.run_ffmpeg_multiple_files(info['__files_to_merge'], temp_filename, args)\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return info['__files_to_merge'], info",
        "begin_line": 474,
        "end_line": 481,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.can_merge#483",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.can_merge(self)",
        "snippet": "    def can_merge(self):\n        # TODO: figure out merge-capable ffmpeg version\n        if self.basename != 'avconv':\n            return True\n\n        required_version = '10-0'\n        if is_outdated_version(\n                self._versions[self.basename], required_version):\n            warning = ('Your copy of %s is outdated and unable to properly mux separate video and audio files, '\n                       'youtube-dl will download single file media. '\n                       'Update %s to version %s or newer to fix this.') % (\n                           self.basename, self.basename, required_version)\n            if self._downloader:\n                self._downloader.report_warning(warning)\n            return False\n        return True",
        "begin_line": 483,
        "end_line": 498,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run#502",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupStretchedPP.run(self, info)",
        "snippet": "    def run(self, info):\n        stretched_ratio = info.get('stretched_ratio')\n        if stretched_ratio is None or stretched_ratio == 1:\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy', '-aspect', '%f' % stretched_ratio]\n        self._downloader.to_screen('[ffmpeg] Fixing aspect ratio in \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return [], info",
        "begin_line": 502,
        "end_line": 517,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP.run#521",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM4aPP.run(self, info)",
        "snippet": "    def run(self, info):\n        if info.get('container') != 'm4a_dash':\n            return [], info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy', '-f', 'mp4']\n        self._downloader.to_screen('[ffmpeg] Correcting container in \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return [], info",
        "begin_line": 521,
        "end_line": 535,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM3u8PP.run#539",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM3u8PP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegFixupM3u8PP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        if self.get_audio_codec(filename) == 'aac':\n            temp_filename = prepend_extension(filename, 'temp')\n\n            options = ['-c', 'copy', '-f', 'mp4', '-bsf:a', 'aac_adtstoasc']\n            self._downloader.to_screen('[ffmpeg] Fixing malformed AAC bitstream in \"%s\"' % filename)\n            self.run_ffmpeg(filename, temp_filename, options)\n\n            os.remove(encodeFilename(filename))\n            os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return [], info",
        "begin_line": 539,
        "end_line": 550,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.__init__#554",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.__init__(self, downloader=None, format=None)",
        "snippet": "    def __init__(self, downloader=None, format=None):\n        super(FFmpegSubtitlesConvertorPP, self).__init__(downloader)\n        self.format = format",
        "begin_line": 554,
        "end_line": 556,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.run#558",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegSubtitlesConvertorPP.run(self, info)",
        "snippet": "    def run(self, info):\n        subs = info.get('requested_subtitles')\n        filename = info['filepath']\n        new_ext = self.format\n        new_format = new_ext\n        if new_format == 'vtt':\n            new_format = 'webvtt'\n        if subs is None:\n            self._downloader.to_screen('[ffmpeg] There aren\\'t any subtitles to convert')\n            return [], info\n        self._downloader.to_screen('[ffmpeg] Converting subtitles')\n        sub_filenames = []\n        for lang, sub in subs.items():\n            ext = sub['ext']\n            if ext == new_ext:\n                self._downloader.to_screen(\n                    '[ffmpeg] Subtitle file for %s is already in the requested format' % new_ext)\n                continue\n            old_file = subtitles_filename(filename, lang, ext)\n            sub_filenames.append(old_file)\n            new_file = subtitles_filename(filename, lang, new_ext)\n\n            if ext in ('dfxp', 'ttml', 'tt'):\n                self._downloader.report_warning(\n                    'You have requested to convert dfxp (TTML) subtitles into another format, '\n                    'which results in style information loss')\n\n                dfxp_file = old_file\n                srt_file = subtitles_filename(filename, lang, 'srt')\n\n                with io.open(dfxp_file, 'rt', encoding='utf-8') as f:\n                    srt_data = dfxp2srt(f.read())\n\n                with io.open(srt_file, 'wt', encoding='utf-8') as f:\n                    f.write(srt_data)\n                old_file = srt_file\n\n                subs[lang] = {\n                    'ext': 'srt',\n                    'data': srt_data\n                }\n\n                if new_ext == 'srt':\n                    continue\n                else:\n                    sub_filenames.append(srt_file)\n\n            self.run_ffmpeg(old_file, new_file, ['-f', new_format])\n\n            with io.open(new_file, 'rt', encoding='utf-8') as f:\n                subs[lang] = {\n                    'ext': new_ext,\n                    'data': f.read(),\n                }\n\n        return sub_filenames, info",
        "begin_line": 558,
        "end_line": 613,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__#9",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.__init__(self, downloader, titleformat)",
        "snippet": "    def __init__(self, downloader, titleformat):\n        super(MetadataFromTitlePP, self).__init__(downloader)\n        self._titleformat = titleformat\n        self._titleregex = (self.format_to_regex(titleformat)\n                            if re.search(r'%\\(\\w+\\)s', titleformat)\n                            else titleformat)",
        "begin_line": 9,
        "end_line": 14,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex#16",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.format_to_regex(self, fmt)",
        "snippet": "    def format_to_regex(self, fmt):\n        r\"\"\"\n        Converts a string like\n           '%(title)s - %(artist)s'\n        to a regex like\n           '(?P<title>.+)\\ \\-\\ (?P<artist>.+)'\n        \"\"\"\n        lastpos = 0\n        regex = ''\n        # replace %(..)s with regex group and escape other string parts\n        for match in re.finditer(r'%\\((\\w+)\\)s', fmt):\n            regex += re.escape(fmt[lastpos:match.start()])\n            regex += r'(?P<' + match.group(1) + '>.+)'\n            lastpos = match.end()\n        if lastpos < len(fmt):\n            regex += re.escape(fmt[lastpos:])\n        return regex",
        "begin_line": 16,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.run#34",
        "src_path": "youtube_dl/postprocessor/metadatafromtitle.py",
        "class_name": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP",
        "signature": "youtube_dl.postprocessor.metadatafromtitle.MetadataFromTitlePP.run(self, info)",
        "snippet": "    def run(self, info):\n        title = info['title']\n        match = re.match(self._titleregex, title)\n        if match is None:\n            self._downloader.to_screen(\n                '[fromtitle] Could not interpret title of video as \"%s\"'\n                % self._titleformat)\n            return [], info\n        for attribute, value in match.groupdict().items():\n            info[attribute] = value\n            self._downloader.to_screen(\n                '[fromtitle] parsed %s: %s'\n                % (attribute, value if value is not None else 'NA'))\n\n        return [], info",
        "begin_line": 34,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run#26",
        "src_path": "youtube_dl/postprocessor/xattrpp.py",
        "class_name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP",
        "signature": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        \"\"\" Set extended attributes on downloaded file (if xattr support is found). \"\"\"\n\n        # Write the metadata to the file's xattrs\n        self._downloader.to_screen('[metadata] Writing metadata to file\\'s xattrs')\n\n        filename = info['filepath']\n\n        try:\n            xattr_mapping = {\n                'user.xdg.referrer.url': 'webpage_url',\n                # 'user.xdg.comment':            'description',\n                'user.dublincore.title': 'title',\n                'user.dublincore.date': 'upload_date',\n                'user.dublincore.description': 'description',\n                'user.dublincore.contributor': 'uploader',\n                'user.dublincore.format': 'format',\n            }\n\n            for xattrname, infoname in xattr_mapping.items():\n\n                value = info.get(infoname)\n\n                if value:\n                    if infoname == 'upload_date':\n                        value = hyphenate_date(value)\n\n                    byte_value = value.encode('utf-8')\n                    write_xattr(filename, xattrname, byte_value)\n\n            return [], info\n\n        except XAttrUnavailableError as e:\n            self._downloader.report_error(str(e))\n            return [], info\n\n        except XAttrMetadataError as e:\n            if e.reason == 'NO_SPACE':\n                self._downloader.report_warning(\n                    'There\\'s no disk space left or disk quota exceeded. ' +\n                    'Extended attributes are not written.')\n            elif e.reason == 'VALUE_TOO_LONG':\n                self._downloader.report_warning(\n                    'Unable to write extended attributes due to too long values.')\n            else:\n                msg = 'This filesystem doesn\\'t support extended attributes. '\n                if compat_os_name == 'nt':\n                    msg += 'You need to use NTFS.'\n                else:\n                    msg += '(You may have to enable them in your /etc/fstab)'\n                self._downloader.report_error(msg)\n            return [], info",
        "begin_line": 26,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.ProxyError.__init__#61",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.ProxyError",
        "signature": "youtube_dl.socks.ProxyError.__init__(self, code=None, msg=None)",
        "snippet": "    def __init__(self, code=None, msg=None):\n        if code is not None and msg is None:\n            msg = self.CODES.get(code) or 'unknown error'\n        super(ProxyError, self).__init__(code, msg)",
        "begin_line": 61,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.InvalidVersionError.__init__#68",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.InvalidVersionError",
        "signature": "youtube_dl.socks.InvalidVersionError.__init__(self, expected_version, got_version)",
        "snippet": "    def __init__(self, expected_version, got_version):\n        msg = ('Invalid response version from server. Expected {0:02x} got '\n               '{1:02x}'.format(expected_version, got_version))\n        super(InvalidVersionError, self).__init__(0, msg)",
        "begin_line": 68,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket.__init__#112",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        self._proxy = None\n        super(sockssocket, self).__init__(*args, **kwargs)",
        "begin_line": 112,
        "end_line": 114,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket.setproxy#116",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket.setproxy(self, proxytype, addr, port, rdns=True, username=None, password=None)",
        "snippet": "    def setproxy(self, proxytype, addr, port, rdns=True, username=None, password=None):\n        assert proxytype in (ProxyType.SOCKS4, ProxyType.SOCKS4A, ProxyType.SOCKS5)\n\n        self._proxy = Proxy(proxytype, addr, port, username, password, rdns)",
        "begin_line": 116,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket.recvall#121",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket.recvall(self, cnt)",
        "snippet": "    def recvall(self, cnt):\n        data = b''\n        while len(data) < cnt:\n            cur = self.recv(cnt - len(data))\n            if not cur:\n                raise EOFError('{0} bytes missing'.format(cnt - len(data)))\n            data += cur\n        return data",
        "begin_line": 121,
        "end_line": 128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._recv_bytes#130",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._recv_bytes(self, cnt)",
        "snippet": "    def _recv_bytes(self, cnt):\n        data = self.recvall(cnt)\n        return compat_struct_unpack('!{0}B'.format(cnt), data)",
        "begin_line": 130,
        "end_line": 132,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._len_and_data#135",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._len_and_data(data)",
        "snippet": "    def _len_and_data(data):\n        return compat_struct_pack('!B', len(data)) + data",
        "begin_line": 135,
        "end_line": 136,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._check_response_version#138",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._check_response_version(self, expected_version, got_version)",
        "snippet": "    def _check_response_version(self, expected_version, got_version):\n        if got_version != expected_version:\n            self.close()\n            raise InvalidVersionError(expected_version, got_version)",
        "begin_line": 138,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._resolve_address#143",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._resolve_address(self, destaddr, default, use_remote_dns)",
        "snippet": "    def _resolve_address(self, destaddr, default, use_remote_dns):\n        try:\n            return socket.inet_aton(destaddr)\n        except socket.error:\n            if use_remote_dns and self._proxy.remote_dns:\n                return default\n            else:\n                return socket.inet_aton(socket.gethostbyname(destaddr))",
        "begin_line": 143,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._setup_socks4#152",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._setup_socks4(self, address, is_4a=False)",
        "snippet": "    def _setup_socks4(self, address, is_4a=False):\n        destaddr, port = address\n\n        ipaddr = self._resolve_address(destaddr, SOCKS4_DEFAULT_DSTIP, use_remote_dns=is_4a)\n\n        packet = compat_struct_pack('!BBH', SOCKS4_VERSION, Socks4Command.CMD_CONNECT, port) + ipaddr\n\n        username = (self._proxy.username or '').encode('utf-8')\n        packet += username + b'\\x00'\n\n        if is_4a and self._proxy.remote_dns:\n            packet += destaddr.encode('utf-8') + b'\\x00'\n\n        self.sendall(packet)\n\n        version, resp_code, dstport, dsthost = compat_struct_unpack('!BBHI', self.recvall(8))\n\n        self._check_response_version(SOCKS4_REPLY_VERSION, version)\n\n        if resp_code != Socks4Error.ERR_SUCCESS:\n            self.close()\n            raise Socks4Error(resp_code)\n\n        return (dsthost, dstport)",
        "begin_line": 152,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._setup_socks4a#177",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._setup_socks4a(self, address)",
        "snippet": "    def _setup_socks4a(self, address):\n        self._setup_socks4(address, is_4a=True)",
        "begin_line": 177,
        "end_line": 178,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._socks5_auth#180",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._socks5_auth(self)",
        "snippet": "    def _socks5_auth(self):\n        packet = compat_struct_pack('!B', SOCKS5_VERSION)\n\n        auth_methods = [Socks5Auth.AUTH_NONE]\n        if self._proxy.username and self._proxy.password:\n            auth_methods.append(Socks5Auth.AUTH_USER_PASS)\n\n        packet += compat_struct_pack('!B', len(auth_methods))\n        packet += compat_struct_pack('!{0}B'.format(len(auth_methods)), *auth_methods)\n\n        self.sendall(packet)\n\n        version, method = self._recv_bytes(2)\n\n        self._check_response_version(SOCKS5_VERSION, version)\n\n        if method == Socks5Auth.AUTH_NO_ACCEPTABLE or (\n                method == Socks5Auth.AUTH_USER_PASS and (not self._proxy.username or not self._proxy.password)):\n            self.close()\n            raise Socks5Error(Socks5Auth.AUTH_NO_ACCEPTABLE)\n\n        if method == Socks5Auth.AUTH_USER_PASS:\n            username = self._proxy.username.encode('utf-8')\n            password = self._proxy.password.encode('utf-8')\n            packet = compat_struct_pack('!B', SOCKS5_USER_AUTH_VERSION)\n            packet += self._len_and_data(username) + self._len_and_data(password)\n            self.sendall(packet)\n\n            version, status = self._recv_bytes(2)\n\n            self._check_response_version(SOCKS5_USER_AUTH_VERSION, version)\n\n            if status != SOCKS5_USER_AUTH_SUCCESS:\n                self.close()\n                raise Socks5Error(Socks5Error.ERR_GENERAL_FAILURE)",
        "begin_line": 180,
        "end_line": 214,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._setup_socks5#216",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._setup_socks5(self, address)",
        "snippet": "    def _setup_socks5(self, address):\n        destaddr, port = address\n\n        ipaddr = self._resolve_address(destaddr, None, use_remote_dns=True)\n\n        self._socks5_auth()\n\n        reserved = 0\n        packet = compat_struct_pack('!BBB', SOCKS5_VERSION, Socks5Command.CMD_CONNECT, reserved)\n        if ipaddr is None:\n            destaddr = destaddr.encode('utf-8')\n            packet += compat_struct_pack('!B', Socks5AddressType.ATYP_DOMAINNAME)\n            packet += self._len_and_data(destaddr)\n        else:\n            packet += compat_struct_pack('!B', Socks5AddressType.ATYP_IPV4) + ipaddr\n        packet += compat_struct_pack('!H', port)\n\n        self.sendall(packet)\n\n        version, status, reserved, atype = self._recv_bytes(4)\n\n        self._check_response_version(SOCKS5_VERSION, version)\n\n        if status != Socks5Error.ERR_SUCCESS:\n            self.close()\n            raise Socks5Error(status)\n\n        if atype == Socks5AddressType.ATYP_IPV4:\n            destaddr = self.recvall(4)\n        elif atype == Socks5AddressType.ATYP_DOMAINNAME:\n            alen = compat_ord(self.recv(1))\n            destaddr = self.recvall(alen)\n        elif atype == Socks5AddressType.ATYP_IPV6:\n            destaddr = self.recvall(16)\n        destport = compat_struct_unpack('!H', self.recvall(2))[0]\n\n        return (destaddr, destport)",
        "begin_line": 216,
        "end_line": 252,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket._make_proxy#254",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket._make_proxy(self, connect_func, address)",
        "snippet": "    def _make_proxy(self, connect_func, address):\n        if not self._proxy:\n            return connect_func(self, address)\n\n        result = connect_func(self, (self._proxy.host, self._proxy.port))\n        if result != 0 and result is not None:\n            return result\n        setup_funcs = {\n            ProxyType.SOCKS4: self._setup_socks4,\n            ProxyType.SOCKS4A: self._setup_socks4a,\n            ProxyType.SOCKS5: self._setup_socks5,\n        }\n        setup_funcs[self._proxy.type](address)\n        return result",
        "begin_line": 254,
        "end_line": 267,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket.connect#269",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket.connect(self, address)",
        "snippet": "    def connect(self, address):\n        self._make_proxy(socket.socket.connect, address)",
        "begin_line": 269,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.socks.sockssocket.connect_ex#272",
        "src_path": "youtube_dl/socks.py",
        "class_name": "youtube_dl.socks.sockssocket",
        "signature": "youtube_dl.socks.sockssocket.connect_ex(self, address)",
        "snippet": "    def connect_ex(self, address):\n        return self._make_proxy(socket.socket.connect_ex, address)",
        "begin_line": 272,
        "end_line": 273,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._extract_tags#16",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._extract_tags(file_contents)",
        "snippet": "def _extract_tags(file_contents):\n    if file_contents[1:3] != b'WS':\n        raise ExtractorError(\n            'Not an SWF file; header is %r' % file_contents[:3])\n    if file_contents[:1] == b'C':\n        content = zlib.decompress(file_contents[8:])\n    else:\n        raise NotImplementedError(\n            'Unsupported compression format %r' %\n            file_contents[:1])\n\n    # Determine number of bits in framesize rectangle\n    framesize_nbits = compat_struct_unpack('!B', content[:1])[0] >> 3\n    framesize_len = (5 + 4 * framesize_nbits + 7) // 8\n\n    pos = framesize_len + 2 + 2\n    while pos < len(content):\n        header16 = compat_struct_unpack('<H', content[pos:pos + 2])[0]\n        pos += 2\n        tag_code = header16 >> 6\n        tag_len = header16 & 0x3f\n        if tag_len == 0x3f:\n            tag_len = compat_struct_unpack('<I', content[pos:pos + 4])[0]\n            pos += 4\n        assert pos + tag_len <= len(content), \\\n            ('Tag %d ends at %d+%d - that\\'s longer than the file (%d)'\n                % (tag_code, pos, tag_len, len(content)))\n        yield (tag_code, content[pos:pos + tag_len])\n        pos += tag_len",
        "begin_line": 16,
        "end_line": 44,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__init__#48",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        self.avm_class = avm_class",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__repr__#51",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s#%x' % (self.avm_class.name, id(self))",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__init__#56",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        super(_ScopeDict, self).__init__()\n        self.avm_class = avm_class",
        "begin_line": 56,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__repr__#60",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s__Scope(%s)' % (\n            self.avm_class.name,\n            super(_ScopeDict, self).__repr__())",
        "begin_line": 60,
        "end_line": 63,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__init__#67",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__init__(self, name_idx, name, static_properties=None)",
        "snippet": "    def __init__(self, name_idx, name, static_properties=None):\n        self.name_idx = name_idx\n        self.name = name\n        self.method_names = {}\n        self.method_idxs = {}\n        self.methods = {}\n        self.method_pyfunctions = {}\n        self.static_properties = static_properties if static_properties else {}\n\n        self.variables = _ScopeDict(self)\n        self.constants = {}",
        "begin_line": 67,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.make_object#79",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.make_object(self)",
        "snippet": "    def make_object(self):\n        return _AVMClass_Object(self)",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__repr__#82",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '_AVMClass(%s)' % (self.name)",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.register_methods#85",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.register_methods(self, methods)",
        "snippet": "    def register_methods(self, methods):\n        self.method_names.update(methods.items())\n        self.method_idxs.update(dict(\n            (idx, name)\n            for name, idx in methods.items()))",
        "begin_line": 85,
        "end_line": 89,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__init__#93",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__init__(self, kind)",
        "snippet": "    def __init__(self, kind):\n        self.kind = kind",
        "begin_line": 93,
        "end_line": 94,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__repr__#96",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '[MULTINAME kind: 0x%x]' % self.kind",
        "begin_line": 96,
        "end_line": 97,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._read_int#100",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_int(reader)",
        "snippet": "def _read_int(reader):\n    res = 0\n    shift = 0\n    for _ in range(5):\n        buf = reader.read(1)\n        assert len(buf) == 1\n        b = compat_struct_unpack('<B', buf)[0]\n        res = res | ((b & 0x7f) << shift)\n        if b & 0x80 == 0:\n            break\n        shift += 7\n    return res",
        "begin_line": 100,
        "end_line": 111,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._u30#114",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._u30(reader)",
        "snippet": "def _u30(reader):\n    res = _read_int(reader)\n    assert res & 0xf0000000 == 0\n    return res",
        "begin_line": 114,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._s32#123",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s32(reader)",
        "snippet": "def _s32(reader):\n    v = _read_int(reader)\n    if v & 0x80000000 != 0:\n        v = - ((v ^ 0xffffffff) + 1)\n    return v",
        "begin_line": 123,
        "end_line": 127,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._s24#130",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s24(reader)",
        "snippet": "def _s24(reader):\n    bs = reader.read(3)\n    assert len(bs) == 3\n    last_byte = b'\\xff' if (ord(bs[2:3]) >= 0x80) else b'\\x00'\n    return compat_struct_unpack('<i', bs + last_byte)[0]",
        "begin_line": 130,
        "end_line": 134,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._read_string#137",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_string(reader)",
        "snippet": "def _read_string(reader):\n    slen = _u30(reader)\n    resb = reader.read(slen)\n    assert len(resb) == slen\n    return resb.decode('utf-8')",
        "begin_line": 137,
        "end_line": 141,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._read_bytes#144",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_bytes(count, reader)",
        "snippet": "def _read_bytes(count, reader):\n    assert count >= 0\n    resb = reader.read(count)\n    assert len(resb) == count\n    return resb",
        "begin_line": 144,
        "end_line": 148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._read_byte#151",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_byte(reader)",
        "snippet": "def _read_byte(reader):\n    resb = _read_bytes(1, reader=reader)\n    res = compat_struct_unpack('<B', resb)[0]\n    return res",
        "begin_line": 151,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__bool__#170",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__bool__(self)",
        "snippet": "    def __bool__(self):\n        return False",
        "begin_line": 170,
        "end_line": 171,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__hash__#174",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__hash__(self)",
        "snippet": "    def __hash__(self):\n        return 0",
        "begin_line": 174,
        "end_line": 175,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp._Undefined.__str__#177",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Undefined",
        "signature": "youtube_dl.swfinterp._Undefined.__str__(self)",
        "snippet": "    def __str__(self):\n        return 'undefined'",
        "begin_line": 177,
        "end_line": 178,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.__init__#186",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.__init__(self, file_contents)",
        "snippet": "    def __init__(self, file_contents):\n        self._patched_functions = {\n            (TimerClass, 'addEventListener'): lambda params: undefined,\n        }\n        code_tag = next(tag\n                        for tag_code, tag in _extract_tags(file_contents)\n                        if tag_code == 82)\n        p = code_tag.index(b'\\0', 4) + 1\n        code_reader = io.BytesIO(code_tag[p:])\n\n        # Parse ABC (AVM2 ByteCode)\n\n        # Define a couple convenience methods\n        u30 = lambda *args: _u30(*args, reader=code_reader)\n        s32 = lambda *args: _s32(*args, reader=code_reader)\n        u32 = lambda *args: _u32(*args, reader=code_reader)\n        read_bytes = lambda *args: _read_bytes(*args, reader=code_reader)\n        read_byte = lambda *args: _read_byte(*args, reader=code_reader)\n\n        # minor_version + major_version\n        read_bytes(2 + 2)\n\n        # Constant pool\n        int_count = u30()\n        self.constant_ints = [0]\n        for _c in range(1, int_count):\n            self.constant_ints.append(s32())\n        self.constant_uints = [0]\n        uint_count = u30()\n        for _c in range(1, uint_count):\n            self.constant_uints.append(u32())\n        double_count = u30()\n        read_bytes(max(0, (double_count - 1)) * 8)\n        string_count = u30()\n        self.constant_strings = ['']\n        for _c in range(1, string_count):\n            s = _read_string(code_reader)\n            self.constant_strings.append(s)\n        namespace_count = u30()\n        for _c in range(1, namespace_count):\n            read_bytes(1)  # kind\n            u30()  # name\n        ns_set_count = u30()\n        for _c in range(1, ns_set_count):\n            count = u30()\n            for _c2 in range(count):\n                u30()\n        multiname_count = u30()\n        MULTINAME_SIZES = {\n            0x07: 2,  # QName\n            0x0d: 2,  # QNameA\n            0x0f: 1,  # RTQName\n            0x10: 1,  # RTQNameA\n            0x11: 0,  # RTQNameL\n            0x12: 0,  # RTQNameLA\n            0x09: 2,  # Multiname\n            0x0e: 2,  # MultinameA\n            0x1b: 1,  # MultinameL\n            0x1c: 1,  # MultinameLA\n        }\n        self.multinames = ['']\n        for _c in range(1, multiname_count):\n            kind = u30()\n            assert kind in MULTINAME_SIZES, 'Invalid multiname kind %r' % kind\n            if kind == 0x07:\n                u30()  # namespace_idx\n                name_idx = u30()\n                self.multinames.append(self.constant_strings[name_idx])\n            elif kind == 0x09:\n                name_idx = u30()\n                u30()\n                self.multinames.append(self.constant_strings[name_idx])\n            else:\n                self.multinames.append(_Multiname(kind))\n                for _c2 in range(MULTINAME_SIZES[kind]):\n                    u30()\n\n        # Methods\n        method_count = u30()\n        MethodInfo = collections.namedtuple(\n            'MethodInfo',\n            ['NEED_ARGUMENTS', 'NEED_REST'])\n        method_infos = []\n        for method_id in range(method_count):\n            param_count = u30()\n            u30()  # return type\n            for _ in range(param_count):\n                u30()  # param type\n            u30()  # name index (always 0 for youtube)\n            flags = read_byte()\n            if flags & 0x08 != 0:\n                # Options present\n                option_count = u30()\n                for c in range(option_count):\n                    u30()  # val\n                    read_bytes(1)  # kind\n            if flags & 0x80 != 0:\n                # Param names present\n                for _ in range(param_count):\n                    u30()  # param name\n            mi = MethodInfo(flags & 0x01 != 0, flags & 0x04 != 0)\n            method_infos.append(mi)\n\n        # Metadata\n        metadata_count = u30()\n        for _c in range(metadata_count):\n            u30()  # name\n            item_count = u30()\n            for _c2 in range(item_count):\n                u30()  # key\n                u30()  # value\n\n        def parse_traits_info():\n            trait_name_idx = u30()\n            kind_full = read_byte()\n            kind = kind_full & 0x0f\n            attrs = kind_full >> 4\n            methods = {}\n            constants = None\n            if kind == 0x00:  # Slot\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                if vindex != 0:\n                    read_byte()  # vkind\n            elif kind == 0x06:  # Const\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                vkind = 'any'\n                if vindex != 0:\n                    vkind = read_byte()\n                if vkind == 0x03:  # Constant_Int\n                    value = self.constant_ints[vindex]\n                elif vkind == 0x04:  # Constant_UInt\n                    value = self.constant_uints[vindex]\n                else:\n                    return {}, None  # Ignore silently for now\n                constants = {self.multinames[trait_name_idx]: value}\n            elif kind in (0x01, 0x02, 0x03):  # Method / Getter / Setter\n                u30()  # disp_id\n                method_idx = u30()\n                methods[self.multinames[trait_name_idx]] = method_idx\n            elif kind == 0x04:  # Class\n                u30()  # slot_id\n                u30()  # classi\n            elif kind == 0x05:  # Function\n                u30()  # slot_id\n                function_idx = u30()\n                methods[function_idx] = self.multinames[trait_name_idx]\n            else:\n                raise ExtractorError('Unsupported trait kind %d' % kind)\n\n            if attrs & 0x4 != 0:  # Metadata present\n                metadata_count = u30()\n                for _c3 in range(metadata_count):\n                    u30()  # metadata index\n\n            return methods, constants\n\n        # Classes\n        class_count = u30()\n        classes = []\n        for class_id in range(class_count):\n            name_idx = u30()\n\n            cname = self.multinames[name_idx]\n            avm_class = _AVMClass(name_idx, cname)\n            classes.append(avm_class)\n\n            u30()  # super_name idx\n            flags = read_byte()\n            if flags & 0x08 != 0:  # Protected namespace is present\n                u30()  # protected_ns_idx\n            intrf_count = u30()\n            for _c2 in range(intrf_count):\n                u30()\n            u30()  # iinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods, trait_constants = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n                if trait_constants:\n                    avm_class.constants.update(trait_constants)\n\n        assert len(classes) == class_count\n        self._classes_by_name = dict((c.name, c) for c in classes)\n\n        for avm_class in classes:\n            avm_class.cinit_idx = u30()\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods, trait_constants = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n                if trait_constants:\n                    avm_class.constants.update(trait_constants)\n\n        # Scripts\n        script_count = u30()\n        for _c in range(script_count):\n            u30()  # init\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        # Method bodies\n        method_body_count = u30()\n        Method = collections.namedtuple('Method', ['code', 'local_count'])\n        self._all_methods = []\n        for _c in range(method_body_count):\n            method_idx = u30()\n            u30()  # max_stack\n            local_count = u30()\n            u30()  # init_scope_depth\n            u30()  # max_scope_depth\n            code_length = u30()\n            code = read_bytes(code_length)\n            m = Method(code, local_count)\n            self._all_methods.append(m)\n            for avm_class in classes:\n                if method_idx in avm_class.method_idxs:\n                    avm_class.methods[avm_class.method_idxs[method_idx]] = m\n            exception_count = u30()\n            for _c2 in range(exception_count):\n                u30()  # from\n                u30()  # to\n                u30()  # target\n                u30()  # exc_type\n                u30()  # var_name\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        assert p + code_reader.tell() == len(code_tag)",
        "begin_line": 186,
        "end_line": 419,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.patch_function#421",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.patch_function(self, avm_class, func_name, f)",
        "snippet": "    def patch_function(self, avm_class, func_name, f):\n        self._patched_functions[(avm_class, func_name)] = f",
        "begin_line": 421,
        "end_line": 422,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_class#424",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_class(self, class_name, call_cinit=True)",
        "snippet": "    def extract_class(self, class_name, call_cinit=True):\n        try:\n            res = self._classes_by_name[class_name]\n        except KeyError:\n            raise ExtractorError('Class %r not found' % class_name)\n\n        if call_cinit and hasattr(res, 'cinit_idx'):\n            res.register_methods({'$cinit': res.cinit_idx})\n            res.methods['$cinit'] = self._all_methods[res.cinit_idx]\n            cinit = self.extract_function(res, '$cinit')\n            cinit([])\n\n        return res",
        "begin_line": 424,
        "end_line": 436,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_function#438",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_function(self, avm_class, func_name)",
        "snippet": "    def extract_function(self, avm_class, func_name):\n        p = self._patched_functions.get((avm_class, func_name))\n        if p:\n            return p\n        if func_name in avm_class.method_pyfunctions:\n            return avm_class.method_pyfunctions[func_name]\n        if func_name in self._classes_by_name:\n            return self._classes_by_name[func_name].make_object()\n        if func_name not in avm_class.methods:\n            raise ExtractorError('Cannot find function %s.%s' % (\n                avm_class.name, func_name))\n        m = avm_class.methods[func_name]\n\n        def resfunc(args):\n            # Helper functions\n            coder = io.BytesIO(m.code)\n            s24 = lambda: _s24(coder)\n            u30 = lambda: _u30(coder)\n\n            registers = [avm_class.variables] + list(args) + [None] * m.local_count\n            stack = []\n            scopes = collections.deque([\n                self._classes_by_name, avm_class.constants, avm_class.variables])\n            while True:\n                opcode = _read_byte(coder)\n                if opcode == 9:  # label\n                    pass  # Spec says: \"Do nothing.\"\n                elif opcode == 16:  # jump\n                    offset = s24()\n                    coder.seek(coder.tell() + offset)\n                elif opcode == 17:  # iftrue\n                    offset = s24()\n                    value = stack.pop()\n                    if value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 18:  # iffalse\n                    offset = s24()\n                    value = stack.pop()\n                    if not value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 19:  # ifeq\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value2 == value1:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 20:  # ifne\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value2 != value1:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 21:  # iflt\n                    offset = s24()\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    if value1 < value2:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 32:  # pushnull\n                    stack.append(None)\n                elif opcode == 33:  # pushundefined\n                    stack.append(undefined)\n                elif opcode == 36:  # pushbyte\n                    v = _read_byte(coder)\n                    stack.append(v)\n                elif opcode == 37:  # pushshort\n                    v = u30()\n                    stack.append(v)\n                elif opcode == 38:  # pushtrue\n                    stack.append(True)\n                elif opcode == 39:  # pushfalse\n                    stack.append(False)\n                elif opcode == 40:  # pushnan\n                    stack.append(float('NaN'))\n                elif opcode == 42:  # dup\n                    value = stack[-1]\n                    stack.append(value)\n                elif opcode == 44:  # pushstring\n                    idx = u30()\n                    stack.append(self.constant_strings[idx])\n                elif opcode == 48:  # pushscope\n                    new_scope = stack.pop()\n                    scopes.append(new_scope)\n                elif opcode == 66:  # construct\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    res = obj.avm_class.make_object()\n                    stack.append(res)\n                elif opcode == 70:  # callproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    if obj == StringClass:\n                        if mname == 'String':\n                            assert len(args) == 1\n                            assert isinstance(args[0], (\n                                int, compat_str, _Undefined))\n                            if args[0] == undefined:\n                                res = 'undefined'\n                            else:\n                                res = compat_str(args[0])\n                            stack.append(res)\n                            continue\n                        else:\n                            raise NotImplementedError(\n                                'Function String.%s is not yet implemented'\n                                % mname)\n                    elif isinstance(obj, _AVMClass_Object):\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, _AVMClass):\n                        func = self.extract_function(obj, mname)\n                        res = func(args)\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, _ScopeDict):\n                        if mname in obj.avm_class.method_names:\n                            func = self.extract_function(obj.avm_class, mname)\n                            res = func(args)\n                        else:\n                            res = obj[mname]\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, compat_str):\n                        if mname == 'split':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            if args[0] == '':\n                                res = list(obj)\n                            else:\n                                res = obj.split(args[0])\n                            stack.append(res)\n                            continue\n                        elif mname == 'charCodeAt':\n                            assert len(args) <= 1\n                            idx = 0 if len(args) == 0 else args[0]\n                            assert isinstance(idx, int)\n                            res = ord(obj[idx])\n                            stack.append(res)\n                            continue\n                    elif isinstance(obj, list):\n                        if mname == 'slice':\n                            assert len(args) == 1\n                            assert isinstance(args[0], int)\n                            res = obj[args[0]:]\n                            stack.append(res)\n                            continue\n                        elif mname == 'join':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            res = args[0].join(obj)\n                            stack.append(res)\n                            continue\n                    raise NotImplementedError(\n                        'Unsupported property %r on %r'\n                        % (mname, obj))\n                elif opcode == 71:  # returnvoid\n                    res = undefined\n                    return res\n                elif opcode == 72:  # returnvalue\n                    res = stack.pop()\n                    return res\n                elif opcode == 73:  # constructsuper\n                    # Not yet implemented, just hope it works without it\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                elif opcode == 74:  # constructproperty\n                    index = u30()\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    mname = self.multinames[index]\n                    assert isinstance(obj, _AVMClass)\n\n                    # We do not actually call the constructor for now;\n                    # we just pretend it does nothing\n                    stack.append(obj.make_object())\n                elif opcode == 79:  # callpropvoid\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    if isinstance(obj, _AVMClass_Object):\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        assert res is undefined\n                        continue\n                    if isinstance(obj, _ScopeDict):\n                        assert mname in obj.avm_class.method_names\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        assert res is undefined\n                        continue\n                    if mname == 'reverse':\n                        assert isinstance(obj, list)\n                        obj.reverse()\n                    else:\n                        raise NotImplementedError(\n                            'Unsupported (void) property %r on %r'\n                            % (mname, obj))\n                elif opcode == 86:  # newarray\n                    arg_count = u30()\n                    arr = []\n                    for i in range(arg_count):\n                        arr.append(stack.pop())\n                    arr = arr[::-1]\n                    stack.append(arr)\n                elif opcode == 93:  # findpropstrict\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = scopes[0]\n                    if mname not in res and mname in _builtin_classes:\n                        stack.append(_builtin_classes[mname])\n                    else:\n                        stack.append(res[mname])\n                elif opcode == 94:  # findproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = avm_class.variables\n                    stack.append(res)\n                elif opcode == 96:  # getlex\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            scope = s\n                            break\n                    else:\n                        scope = avm_class.variables\n\n                    if mname in scope:\n                        res = scope[mname]\n                    elif mname in _builtin_classes:\n                        res = _builtin_classes[mname]\n                    else:\n                        # Assume uninitialized\n                        # TODO warn here\n                        res = undefined\n                    stack.append(res)\n                elif opcode == 97:  # setproperty\n                    index = u30()\n                    value = stack.pop()\n                    idx = self.multinames[index]\n                    if isinstance(idx, _Multiname):\n                        idx = stack.pop()\n                    obj = stack.pop()\n                    obj[idx] = value\n                elif opcode == 98:  # getlocal\n                    index = u30()\n                    stack.append(registers[index])\n                elif opcode == 99:  # setlocal\n                    index = u30()\n                    value = stack.pop()\n                    registers[index] = value\n                elif opcode == 102:  # getproperty\n                    index = u30()\n                    pname = self.multinames[index]\n                    if pname == 'length':\n                        obj = stack.pop()\n                        assert isinstance(obj, (compat_str, list))\n                        stack.append(len(obj))\n                    elif isinstance(pname, compat_str):  # Member access\n                        obj = stack.pop()\n                        if isinstance(obj, _AVMClass):\n                            res = obj.static_properties[pname]\n                            stack.append(res)\n                            continue\n\n                        assert isinstance(obj, (dict, _ScopeDict)),\\\n                            'Accessing member %r on %r' % (pname, obj)\n                        res = obj.get(pname, undefined)\n                        stack.append(res)\n                    else:  # Assume attribute access\n                        idx = stack.pop()\n                        assert isinstance(idx, int)\n                        obj = stack.pop()\n                        assert isinstance(obj, list)\n                        stack.append(obj[idx])\n                elif opcode == 104:  # initproperty\n                    index = u30()\n                    value = stack.pop()\n                    idx = self.multinames[index]\n                    if isinstance(idx, _Multiname):\n                        idx = stack.pop()\n                    obj = stack.pop()\n                    obj[idx] = value\n                elif opcode == 115:  # convert_\n                    value = stack.pop()\n                    intvalue = int(value)\n                    stack.append(intvalue)\n                elif opcode == 128:  # coerce\n                    u30()\n                elif opcode == 130:  # coerce_a\n                    value = stack.pop()\n                    # um, yes, it's any value\n                    stack.append(value)\n                elif opcode == 133:  # coerce_s\n                    assert isinstance(stack[-1], (type(None), compat_str))\n                elif opcode == 147:  # decrement\n                    value = stack.pop()\n                    assert isinstance(value, int)\n                    stack.append(value - 1)\n                elif opcode == 149:  # typeof\n                    value = stack.pop()\n                    return {\n                        _Undefined: 'undefined',\n                        compat_str: 'String',\n                        int: 'Number',\n                        float: 'Number',\n                    }[type(value)]\n                elif opcode == 160:  # add\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 + value2\n                    stack.append(res)\n                elif opcode == 161:  # subtract\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 - value2\n                    stack.append(res)\n                elif opcode == 162:  # multiply\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 * value2\n                    stack.append(res)\n                elif opcode == 164:  # modulo\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 % value2\n                    stack.append(res)\n                elif opcode == 168:  # bitand\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    assert isinstance(value1, int)\n                    assert isinstance(value2, int)\n                    res = value1 & value2\n                    stack.append(res)\n                elif opcode == 171:  # equals\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    result = value1 == value2\n                    stack.append(result)\n                elif opcode == 175:  # greaterequals\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    result = value1 >= value2\n                    stack.append(result)\n                elif opcode == 192:  # increment_i\n                    value = stack.pop()\n                    assert isinstance(value, int)\n                    stack.append(value + 1)\n                elif opcode == 208:  # getlocal_0\n                    stack.append(registers[0])\n                elif opcode == 209:  # getlocal_1\n                    stack.append(registers[1])\n                elif opcode == 210:  # getlocal_2\n                    stack.append(registers[2])\n                elif opcode == 211:  # getlocal_3\n                    stack.append(registers[3])\n                elif opcode == 212:  # setlocal_0\n                    registers[0] = stack.pop()\n                elif opcode == 213:  # setlocal_1\n                    registers[1] = stack.pop()\n                elif opcode == 214:  # setlocal_2\n                    registers[2] = stack.pop()\n                elif opcode == 215:  # setlocal_3\n                    registers[3] = stack.pop()\n                else:\n                    raise NotImplementedError(\n                        'Unsupported opcode %d' % opcode)\n\n        avm_class.method_pyfunctions[func_name] = resfunc\n        return resfunc",
        "begin_line": 438,
        "end_line": 834,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.update.rsa_verify#17",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.rsa_verify(message, signature, key)",
        "snippet": "def rsa_verify(message, signature, key):\n    from hashlib import sha256\n    assert isinstance(message, bytes)\n    byte_size = (len(bin(key[0])) - 2 + 8 - 1) // 8\n    signature = ('%x' % pow(int(signature, 16), key[1], key[0])).encode()\n    signature = (byte_size * 2 - len(signature)) * b'0' + signature\n    asn1 = b'3031300d060960864801650304020105000420'\n    asn1 += sha256(message).hexdigest().encode()\n    if byte_size < len(asn1) // 2 + 11:\n        return False\n    expected = b'0001' + (byte_size - len(asn1) // 2 - 3) * b'ff' + b'00' + asn1\n    return expected == signature",
        "begin_line": 17,
        "end_line": 28,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.update.update_self#31",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.update_self(to_screen, verbose, opener)",
        "snippet": "def update_self(to_screen, verbose, opener):\n    \"\"\"Update the program file with the latest version from the repository\"\"\"\n\n    UPDATE_URL = 'https://rg3.github.io/youtube-dl/update/'\n    VERSION_URL = UPDATE_URL + 'LATEST_VERSION'\n    JSON_URL = UPDATE_URL + 'versions.json'\n    UPDATES_RSA_KEY = (0x9d60ee4d8f805312fdb15a62f87b95bd66177b91df176765d13514a0f1754bcd2057295c5b6f1d35daa6742c3ffc9a82d3e118861c207995a8031e151d863c9927e304576bc80692bc8e094896fcf11b66f3e29e04e3a71e9a11558558acea1840aec37fc396fb6b65dc81a1c4144e03bd1c011de62e3f1357b327d08426fe93, 65537)\n\n    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, 'frozen'):\n        to_screen('It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')\n        return\n\n    # Check if there is a new version\n    try:\n        newversion = opener.open(VERSION_URL).read().decode('utf-8').strip()\n    except Exception:\n        if verbose:\n            to_screen(encode_compat_str(traceback.format_exc()))\n        to_screen('ERROR: can\\'t find the current version. Please try again later.')\n        return\n    if newversion == __version__:\n        to_screen('youtube-dl is up-to-date (' + __version__ + ')')\n        return\n\n    # Download and check versions info\n    try:\n        versions_info = opener.open(JSON_URL).read().decode('utf-8')\n        versions_info = json.loads(versions_info)\n    except Exception:\n        if verbose:\n            to_screen(encode_compat_str(traceback.format_exc()))\n        to_screen('ERROR: can\\'t obtain versions info. Please try again later.')\n        return\n    if 'signature' not in versions_info:\n        to_screen('ERROR: the versions file is not signed or corrupted. Aborting.')\n        return\n    signature = versions_info['signature']\n    del versions_info['signature']\n    if not rsa_verify(json.dumps(versions_info, sort_keys=True).encode('utf-8'), signature, UPDATES_RSA_KEY):\n        to_screen('ERROR: the versions file signature is invalid. Aborting.')\n        return\n\n    version_id = versions_info['latest']\n\n    def version_tuple(version_str):\n        return tuple(map(int, version_str.split('.')))\n    if version_tuple(__version__) >= version_tuple(version_id):\n        to_screen('youtube-dl is up to date (%s)' % __version__)\n        return\n\n    to_screen('Updating to version ' + version_id + ' ...')\n    version = versions_info['versions'][version_id]\n\n    print_notes(to_screen, versions_info['versions'])\n\n    # sys.executable is set to the full pathname of the exe-file for py2exe\n    filename = sys.executable if hasattr(sys, 'frozen') else sys.argv[0]\n\n    if not os.access(filename, os.W_OK):\n        to_screen('ERROR: no write permissions on %s' % filename)\n        return\n\n    # Py2EXE\n    if hasattr(sys, 'frozen'):\n        exe = filename\n        directory = os.path.dirname(exe)\n        if not os.access(directory, os.W_OK):\n            to_screen('ERROR: no write permissions on %s' % directory)\n            return\n\n        try:\n            urlh = opener.open(version['exe'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose:\n                to_screen(encode_compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['exe'][1]:\n            to_screen('ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(exe + '.new', 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose:\n                to_screen(encode_compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to write the new version')\n            return\n\n        try:\n            bat = os.path.join(directory, 'youtube-dl-updater.bat')\n            with io.open(bat, 'w') as batfile:\n                batfile.write('''\n@echo off\necho Waiting for file handle to be closed ...\nping 127.0.0.1 -n 5 -w 1000 > NUL\nmove /Y \"%s.new\" \"%s\" > NUL\necho Updated youtube-dl to version %s.\nstart /b \"\" cmd /c del \"%%~f0\"&exit /b\"\n                \\n''' % (exe, exe, version_id))\n\n            subprocess.Popen([bat])  # Continues to run in the background\n            return  # Do not show premature success messages\n        except (IOError, OSError):\n            if verbose:\n                to_screen(encode_compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to overwrite current version')\n            return\n\n    # Zip unix package\n    elif isinstance(globals().get('__loader__'), zipimporter):\n        try:\n            urlh = opener.open(version['bin'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose:\n                to_screen(encode_compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['bin'][1]:\n            to_screen('ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(filename, 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose:\n                to_screen(encode_compat_str(traceback.format_exc()))\n            to_screen('ERROR: unable to overwrite current version')\n            return\n\n    to_screen('Updated youtube-dl. Restart youtube-dl to use the new version.')",
        "begin_line": 31,
        "end_line": 171,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.update.get_notes#174",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.get_notes(versions, fromVersion)",
        "snippet": "def get_notes(versions, fromVersion):\n    notes = []\n    for v, vdata in sorted(versions.items()):\n        if v > fromVersion:\n            notes.extend(vdata.get('notes', []))\n    return notes",
        "begin_line": 174,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.update.print_notes#182",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.print_notes(to_screen, versions, fromVersion=__version__)",
        "snippet": "def print_notes(to_screen, versions, fromVersion=__version__):\n    notes = get_notes(versions, fromVersion)\n    if notes:\n        to_screen('PLEASE NOTE:')\n        for note in notes:\n            to_screen(note)",
        "begin_line": 182,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.register_socks_protocols#71",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.register_socks_protocols()",
        "snippet": "def register_socks_protocols():\n    # \"Register\" SOCKS protocols\n    # In Python < 2.6.5, urlsplit() suffers from bug https://bugs.python.org/issue7904\n    # URLs with protocols not in urlparse.uses_netloc are not handled correctly\n    for scheme in ('socks', 'socks4', 'socks4a', 'socks5'):\n        if scheme not in compat_urlparse.uses_netloc:\n            compat_urlparse.uses_netloc.append(scheme)",
        "begin_line": 71,
        "end_line": 77,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.preferredencoding#186",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.preferredencoding()",
        "snippet": "def preferredencoding():\n    \"\"\"Get preferred encoding.\n\n    Returns the best encoding scheme for the system, based on\n    locale.getpreferredencoding() and some further tweaks.\n    \"\"\"\n    try:\n        pref = locale.getpreferredencoding()\n        'TEST'.encode(pref)\n    except Exception:\n        pref = 'UTF-8'\n\n    return pref",
        "begin_line": 186,
        "end_line": 198,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.write_json_file#201",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_json_file(obj, fn)",
        "snippet": "def write_json_file(obj, fn):\n    \"\"\" Encode obj as JSON and write it to fn, atomically if possible \"\"\"\n\n    fn = encodeFilename(fn)\n    if sys.version_info < (3, 0) and sys.platform != 'win32':\n        encoding = get_filesystem_encoding()\n        # os.path.basename returns a bytes object, but NamedTemporaryFile\n        # will fail if the filename contains non ascii characters unless we\n        # use a unicode object\n        path_basename = lambda f: os.path.basename(fn).decode(encoding)\n        # the same for os.path.dirname\n        path_dirname = lambda f: os.path.dirname(fn).decode(encoding)\n    else:\n        path_basename = os.path.basename\n        path_dirname = os.path.dirname\n\n    args = {\n        'suffix': '.tmp',\n        'prefix': path_basename(fn) + '.',\n        'dir': path_dirname(fn),\n        'delete': False,\n    }\n\n    # In Python 2.x, json.dump expects a bytestream.\n    # In Python 3.x, it writes to a character stream\n    if sys.version_info < (3, 0):\n        args['mode'] = 'wb'\n    else:\n        args.update({\n            'mode': 'w',\n            'encoding': 'utf-8',\n        })\n\n    tf = tempfile.NamedTemporaryFile(**compat_kwargs(args))\n\n    try:\n        with tf:\n            json.dump(obj, tf)\n        if sys.platform == 'win32':\n            # Need to remove existing file on Windows, else os.rename raises\n            # WindowsError or FileExistsError.\n            try:\n                os.unlink(fn)\n            except OSError:\n                pass\n        os.rename(tf.name, fn)\n    except Exception:\n        try:\n            os.remove(tf.name)\n        except OSError:\n            pass\n        raise",
        "begin_line": 201,
        "end_line": 252,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.find_xpath_attr#256",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.find_xpath_attr(node, xpath, key, val=None)",
        "snippet": "    def find_xpath_attr(node, xpath, key, val=None):\n        \"\"\" Find the xpath xpath[@key=val] \"\"\"\n        assert re.match(r'^[a-zA-Z_-]+$', key)\n        expr = xpath + ('[@%s]' % key if val is None else \"[@%s='%s']\" % (key, val))\n        return node.find(expr)",
        "begin_line": 256,
        "end_line": 260,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.xpath_with_ns#274",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_with_ns(path, ns_map)",
        "snippet": "def xpath_with_ns(path, ns_map):\n    components = [c.split(':') for c in path.split('/')]\n    replaced = []\n    for c in components:\n        if len(c) == 1:\n            replaced.append(c[0])\n        else:\n            ns, tag = c\n            replaced.append('{%s}%s' % (ns_map[ns], tag))\n    return '/'.join(replaced)",
        "begin_line": 274,
        "end_line": 283,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.xpath_element#286",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT):\n    def _find_xpath(xpath):\n        return node.find(compat_xpath(xpath))\n\n    if isinstance(xpath, (str, compat_str)):\n        n = _find_xpath(xpath)\n    else:\n        for xp in xpath:\n            n = _find_xpath(xp)\n            if n is not None:\n                break\n\n    if n is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element %s' % name)\n        else:\n            return None\n    return n",
        "begin_line": 286,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.xpath_text#309",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT):\n    n = xpath_element(node, xpath, name, fatal=fatal, default=default)\n    if n is None or n == default:\n        return n\n    if n.text is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element\\'s text %s' % name)\n        else:\n            return None\n    return n.text",
        "begin_line": 309,
        "end_line": 321,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.xpath_attr#324",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_attr(node, xpath, key, name=None, fatal=False, default=NO_DEFAULT)",
        "snippet": "def xpath_attr(node, xpath, key, name=None, fatal=False, default=NO_DEFAULT):\n    n = find_xpath_attr(node, xpath, key)\n    if n is None:\n        if default is not NO_DEFAULT:\n            return default\n        elif fatal:\n            name = '%s[@%s]' % (xpath, key) if name is None else name\n            raise ExtractorError('Could not find XML attribute %s' % name)\n        else:\n            return None\n    return n.attrib[key]",
        "begin_line": 324,
        "end_line": 334,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_element_by_id#337",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_id(id, html)",
        "snippet": "def get_element_by_id(id, html):\n    \"\"\"Return the content of the tag with the specified ID in the passed HTML document\"\"\"\n    return get_element_by_attribute('id', id, html)",
        "begin_line": 337,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_element_by_class#342",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_class(class_name, html)",
        "snippet": "def get_element_by_class(class_name, html):\n    \"\"\"Return the content of the first tag with the specified class in the passed HTML document\"\"\"\n    retval = get_elements_by_class(class_name, html)\n    return retval[0] if retval else None",
        "begin_line": 342,
        "end_line": 345,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_element_by_attribute#348",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_attribute(attribute, value, html, escape_value=True)",
        "snippet": "def get_element_by_attribute(attribute, value, html, escape_value=True):\n    retval = get_elements_by_attribute(attribute, value, html, escape_value)\n    return retval[0] if retval else None",
        "begin_line": 348,
        "end_line": 350,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_elements_by_class#353",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_elements_by_class(class_name, html)",
        "snippet": "def get_elements_by_class(class_name, html):\n    \"\"\"Return the content of all tags with the specified class in the passed HTML document as a list\"\"\"\n    return get_elements_by_attribute(\n        'class', r'[^\\'\"]*\\b%s\\b[^\\'\"]*' % re.escape(class_name),\n        html, escape_value=False)",
        "begin_line": 353,
        "end_line": 357,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_elements_by_attribute#360",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_elements_by_attribute(attribute, value, html, escape_value=True)",
        "snippet": "def get_elements_by_attribute(attribute, value, html, escape_value=True):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n\n    value = re.escape(value) if escape_value else value\n\n    retlist = []\n    for m in re.finditer(r'''(?xs)\n        <([a-zA-Z0-9:._-]+)\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n         \\s+%s=['\"]?%s['\"]?\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n        \\s*>\n        (?P<content>.*?)\n        </\\1>\n    ''' % (re.escape(attribute), value), html):\n        res = m.group('content')\n\n        if res.startswith('\"') or res.startswith(\"'\"):\n            res = res[1:-1]\n\n        retlist.append(unescapeHTML(res))\n\n    return retlist",
        "begin_line": 360,
        "end_line": 382,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.HTMLAttributeParser.__init__#387",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HTMLAttributeParser",
        "signature": "youtube_dl.utils.HTMLAttributeParser.__init__(self)",
        "snippet": "    def __init__(self):\n        self.attrs = {}\n        compat_HTMLParser.__init__(self)",
        "begin_line": 387,
        "end_line": 389,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.HTMLAttributeParser.handle_starttag#391",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HTMLAttributeParser",
        "signature": "youtube_dl.utils.HTMLAttributeParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        self.attrs = dict(attrs)",
        "begin_line": 391,
        "end_line": 392,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.extract_attributes#395",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.extract_attributes(html_element)",
        "snippet": "def extract_attributes(html_element):\n    \"\"\"Given a string for an HTML element such as\n    <el\n         a=\"foo\" B=\"bar\" c=\"&98;az\" d=boz\n         empty= noval entity=\"&amp;\"\n         sq='\"' dq=\"'\"\n    >\n    Decode and return a dictionary of attributes.\n    {\n        'a': 'foo', 'b': 'bar', c: 'baz', d: 'boz',\n        'empty': '', 'noval': None, 'entity': '&',\n        'sq': '\"', 'dq': '\\''\n    }.\n    NB HTMLParser is stricter in Python 2.6 & 3.2 than in later versions,\n    but the cases in the unit test will work for all of 2.6, 2.7, 3.2-3.5.\n    \"\"\"\n    parser = HTMLAttributeParser()\n    try:\n        parser.feed(html_element)\n        parser.close()\n    # Older Python may throw HTMLParseError in case of malformed HTML\n    except compat_HTMLParseError:\n        pass\n    return parser.attrs",
        "begin_line": 395,
        "end_line": 418,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.clean_html#421",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.clean_html(html)",
        "snippet": "def clean_html(html):\n    \"\"\"Clean an HTML snippet into a readable string\"\"\"\n\n    if html is None:  # Convenience for sanitizing descriptions etc.\n        return html\n\n    # Newline vs <br />\n    html = html.replace('\\n', ' ')\n    html = re.sub(r'(?u)\\s*<\\s*br\\s*/?\\s*>\\s*', '\\n', html)\n    html = re.sub(r'(?u)<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\\n', html)\n    # Strip html tags\n    html = re.sub('<.*?>', '', html)\n    # Replace html entities\n    html = unescapeHTML(html)\n    return html.strip()",
        "begin_line": 421,
        "end_line": 435,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.sanitize_open#438",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_open(filename, open_mode)",
        "snippet": "def sanitize_open(filename, open_mode):\n    \"\"\"Try to open the given filename, and slightly tweak it if this fails.\n\n    Attempts to open the given filename. If this fails, it tries to change\n    the filename slightly, step by step, until it's either able to open it\n    or it fails and raises a final exception, like the standard open()\n    function.\n\n    It returns the tuple (stream, definitive_file_name).\n    \"\"\"\n    try:\n        if filename == '-':\n            if sys.platform == 'win32':\n                import msvcrt\n                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\n            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)\n        stream = open(encodeFilename(filename), open_mode)\n        return (stream, filename)\n    except (IOError, OSError) as err:\n        if err.errno in (errno.EACCES,):\n            raise\n\n        # In case of error, try to remove win32 forbidden chars\n        alt_filename = sanitize_path(filename)\n        if alt_filename == filename:\n            raise\n        else:\n            # An exception here should be caught in the caller\n            stream = open(encodeFilename(alt_filename), open_mode)\n            return (stream, alt_filename)",
        "begin_line": 438,
        "end_line": 467,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.timeconvert#470",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.timeconvert(timestr)",
        "snippet": "def timeconvert(timestr):\n    \"\"\"Convert RFC 2822 defined time string into system timestamp\"\"\"\n    timestamp = None\n    timetuple = email.utils.parsedate_tz(timestr)\n    if timetuple is not None:\n        timestamp = email.utils.mktime_tz(timetuple)\n    return timestamp",
        "begin_line": 470,
        "end_line": 476,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.sanitize_filename#479",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_filename(s, restricted=False, is_id=False)",
        "snippet": "def sanitize_filename(s, restricted=False, is_id=False):\n    \"\"\"Sanitizes a string so it could be used as part of a filename.\n    If restricted is set, use a stricter subset of allowed characters.\n    Set is_id if this is not an arbitrary string, but an ID that should be kept\n    if possible.\n    \"\"\"\n    def replace_insane(char):\n        if restricted and char in ACCENT_CHARS:\n            return ACCENT_CHARS[char]\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char\n\n    # Handle timestamps\n    s = re.sub(r'[0-9]+(?::[0-9]+)+', lambda m: m.group(0).replace(':', '_'), s)\n    result = ''.join(map(replace_insane, s))\n    if not is_id:\n        while '__' in result:\n            result = result.replace('__', '_')\n        result = result.strip('_')\n        # Common case of \"Foreign band name - English song title\"\n        if restricted and result.startswith('-_'):\n            result = result[2:]\n        if result.startswith('-'):\n            result = '_' + result[len('-'):]\n        result = result.lstrip('.')\n        if not result:\n            result = '_'\n    return result",
        "begin_line": 479,
        "end_line": 517,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.sanitize_path#520",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_path(s)",
        "snippet": "def sanitize_path(s):\n    \"\"\"Sanitizes and normalizes path on Windows\"\"\"\n    if sys.platform != 'win32':\n        return s\n    drive_or_unc, _ = os.path.splitdrive(s)\n    if sys.version_info < (2, 7) and not drive_or_unc:\n        drive_or_unc, _ = os.path.splitunc(s)\n    norm_path = os.path.normpath(remove_start(s, drive_or_unc)).split(os.path.sep)\n    if drive_or_unc:\n        norm_path.pop(0)\n    sanitized_path = [\n        path_part if path_part in ['.', '..'] else re.sub(r'(?:[/<>:\"\\|\\\\?\\*]|[\\s.]$)', '#', path_part)\n        for path_part in norm_path]\n    if drive_or_unc:\n        sanitized_path.insert(0, drive_or_unc + os.path.sep)\n    return os.path.join(*sanitized_path)",
        "begin_line": 520,
        "end_line": 535,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.sanitize_url#540",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_url(url)",
        "snippet": "def sanitize_url(url):\n    return 'http:%s' % url if url.startswith('//') else url",
        "begin_line": 540,
        "end_line": 541,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.sanitized_Request#544",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitized_Request(url, *args, **kwargs)",
        "snippet": "def sanitized_Request(url, *args, **kwargs):\n    return compat_urllib_request.Request(sanitize_url(url), *args, **kwargs)",
        "begin_line": 544,
        "end_line": 545,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.expand_path#548",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.expand_path(s)",
        "snippet": "def expand_path(s):\n    \"\"\"Expand shell variables and ~\"\"\"\n    return os.path.expandvars(compat_expanduser(s))",
        "begin_line": 548,
        "end_line": 550,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.orderedSet#553",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.orderedSet(iterable)",
        "snippet": "def orderedSet(iterable):\n    \"\"\" Remove all duplicates from the input iterable \"\"\"\n    res = []\n    for el in iterable:\n        if el not in res:\n            res.append(el)\n    return res",
        "begin_line": 553,
        "end_line": 559,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._htmlentity_transform#562",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._htmlentity_transform(entity_with_semicolon)",
        "snippet": "def _htmlentity_transform(entity_with_semicolon):\n    \"\"\"Transforms an HTML entity to a character.\"\"\"\n    entity = entity_with_semicolon[:-1]\n\n    # Known non-numeric HTML entity\n    if entity in compat_html_entities.name2codepoint:\n        return compat_chr(compat_html_entities.name2codepoint[entity])\n\n    # TODO: HTML5 allows entities without a semicolon. For example,\n    # '&Eacuteric' should be decoded as '\u00c9ric'.\n    if entity_with_semicolon in compat_html_entities_html5:\n        return compat_html_entities_html5[entity_with_semicolon]\n\n    mobj = re.match(r'#(x[0-9a-fA-F]+|[0-9]+)', entity)\n    if mobj is not None:\n        numstr = mobj.group(1)\n        if numstr.startswith('x'):\n            base = 16\n            numstr = '0%s' % numstr\n        else:\n            base = 10\n        # See https://github.com/rg3/youtube-dl/issues/7518\n        try:\n            return compat_chr(int(numstr, base))\n        except ValueError:\n            pass\n\n    # Unknown entity in name, return its literal representation\n    return '&%s;' % entity",
        "begin_line": 562,
        "end_line": 590,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.unescapeHTML#593",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unescapeHTML(s)",
        "snippet": "def unescapeHTML(s):\n    if s is None:\n        return None\n    assert type(s) == compat_str\n\n    return re.sub(\n        r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)",
        "begin_line": 593,
        "end_line": 599,
        "comment": "",
        "is_bug": true
    },
    {
        "name": "youtube_dl.utils.get_subprocess_encoding#602",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_subprocess_encoding()",
        "snippet": "def get_subprocess_encoding():\n    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        # For subprocess calls, encode with locale encoding\n        # Refer to http://stackoverflow.com/a/9951851/35070\n        encoding = preferredencoding()\n    else:\n        encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    return encoding",
        "begin_line": 602,
        "end_line": 611,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.encodeFilename#614",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeFilename(s, for_subprocess=False)",
        "snippet": "def encodeFilename(s, for_subprocess=False):\n    \"\"\"\n    @param s The name of the file\n    \"\"\"\n\n    assert type(s) == compat_str\n\n    # Python 3 has a Unicode API\n    if sys.version_info >= (3, 0):\n        return s\n\n    # Pass '' directly to use Unicode APIs on Windows 2000 and up\n    # (Detecting Windows NT 4 is tricky because 'major >= 4' would\n    # match Windows 9x series as well. Besides, NT 4 is obsolete.)\n    if not for_subprocess and sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        return s\n\n    # Jython assumes filenames are Unicode strings though reported as Python 2.x compatible\n    if sys.platform.startswith('java'):\n        return s\n\n    return s.encode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 614,
        "end_line": 635,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.decodeFilename#638",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeFilename(b, for_subprocess=False)",
        "snippet": "def decodeFilename(b, for_subprocess=False):\n\n    if sys.version_info >= (3, 0):\n        return b\n\n    if not isinstance(b, bytes):\n        return b\n\n    return b.decode(get_subprocess_encoding(), 'ignore')",
        "begin_line": 638,
        "end_line": 646,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.encodeArgument#649",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeArgument(s)",
        "snippet": "def encodeArgument(s):\n    if not isinstance(s, compat_str):\n        # Legacy code that uses byte strings\n        # Uncomment the following line after fixing all post processors\n        # assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))\n        s = s.decode('ascii')\n    return encodeFilename(s, True)",
        "begin_line": 649,
        "end_line": 655,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.decodeArgument#658",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeArgument(b)",
        "snippet": "def decodeArgument(b):\n    return decodeFilename(b, True)",
        "begin_line": 658,
        "end_line": 659,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.decodeOption#662",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeOption(optval)",
        "snippet": "def decodeOption(optval):\n    if optval is None:\n        return optval\n    if isinstance(optval, bytes):\n        optval = optval.decode(preferredencoding())\n\n    assert isinstance(optval, compat_str)\n    return optval",
        "begin_line": 662,
        "end_line": 669,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.formatSeconds#672",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.formatSeconds(secs)",
        "snippet": "def formatSeconds(secs):\n    if secs > 3600:\n        return '%d:%02d:%02d' % (secs // 3600, (secs % 3600) // 60, secs % 60)\n    elif secs > 60:\n        return '%d:%02d' % (secs // 60, secs % 60)\n    else:\n        return '%d' % secs",
        "begin_line": 672,
        "end_line": 678,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.make_HTTPS_handler#681",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_HTTPS_handler(params, **kwargs)",
        "snippet": "def make_HTTPS_handler(params, **kwargs):\n    opts_no_check_certificate = params.get('nocheckcertificate', False)\n    if hasattr(ssl, 'create_default_context'):  # Python >= 3.4 or 2.7.9\n        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        if opts_no_check_certificate:\n            context.check_hostname = False\n            context.verify_mode = ssl.CERT_NONE\n        try:\n            return YoutubeDLHTTPSHandler(params, context=context, **kwargs)\n        except TypeError:\n            # Python 2.7.8\n            # (create_default_context present but HTTPSHandler has no context=)\n            pass\n\n    if sys.version_info < (3, 2):\n        return YoutubeDLHTTPSHandler(params, **kwargs)\n    else:  # Python < 3.4\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n        context.verify_mode = (ssl.CERT_NONE\n                               if opts_no_check_certificate\n                               else ssl.CERT_REQUIRED)\n        context.set_default_verify_paths()\n        return YoutubeDLHTTPSHandler(params, context=context, **kwargs)",
        "begin_line": 681,
        "end_line": 703,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.bug_reports_message#706",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bug_reports_message()",
        "snippet": "def bug_reports_message():\n    if ytdl_is_updateable():\n        update_cmd = 'type  youtube-dl -U  to update'\n    else:\n        update_cmd = 'see  https://yt-dl.org/update  on how to update'\n    msg = '; please report this issue on https://yt-dl.org/bug .'\n    msg += ' Make sure you are using the latest version; %s.' % update_cmd\n    msg += ' Be sure to call youtube-dl with the --verbose flag and include its complete output.'\n    return msg",
        "begin_line": 706,
        "end_line": 714,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ExtractorError.__init__#725",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.__init__(self, msg, tb=None, expected=False, cause=None, video_id=None)",
        "snippet": "    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):\n        \"\"\" tb, if given, is the original traceback (so that it can be printed out).\n        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.\n        \"\"\"\n\n        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):\n            expected = True\n        if video_id is not None:\n            msg = video_id + ': ' + msg\n        if cause:\n            msg += ' (caused by %r)' % cause\n        if not expected:\n            msg += bug_reports_message()\n        super(ExtractorError, self).__init__(msg)\n\n        self.traceback = tb\n        self.exc_info = sys.exc_info()  # preserve original exception\n        self.cause = cause\n        self.video_id = video_id",
        "begin_line": 725,
        "end_line": 743,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ExtractorError.format_traceback#745",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.format_traceback(self)",
        "snippet": "    def format_traceback(self):\n        if self.traceback is None:\n            return None\n        return ''.join(traceback.format_tb(self.traceback))",
        "begin_line": 745,
        "end_line": 748,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.UnsupportedError.__init__#752",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.UnsupportedError",
        "signature": "youtube_dl.utils.UnsupportedError.__init__(self, url)",
        "snippet": "    def __init__(self, url):\n        super(UnsupportedError, self).__init__(\n            'Unsupported URL: %s' % url, expected=True)\n        self.url = url",
        "begin_line": 752,
        "end_line": 755,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.GeoRestrictedError.__init__#769",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.GeoRestrictedError",
        "signature": "youtube_dl.utils.GeoRestrictedError.__init__(self, msg, countries=None)",
        "snippet": "    def __init__(self, msg, countries=None):\n        super(GeoRestrictedError, self).__init__(msg, expected=True)\n        self.msg = msg\n        self.countries = countries",
        "begin_line": 769,
        "end_line": 772,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.DownloadError.__init__#783",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DownloadError",
        "signature": "youtube_dl.utils.DownloadError.__init__(self, msg, exc_info=None)",
        "snippet": "    def __init__(self, msg, exc_info=None):\n        \"\"\" exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). \"\"\"\n        super(DownloadError, self).__init__(msg)\n        self.exc_info = exc_info",
        "begin_line": 783,
        "end_line": 786,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.PostProcessingError.__init__#805",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PostProcessingError",
        "signature": "youtube_dl.utils.PostProcessingError.__init__(self, msg)",
        "snippet": "    def __init__(self, msg):\n        super(PostProcessingError, self).__init__(msg)\n        self.msg = msg",
        "begin_line": 805,
        "end_line": 807,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ContentTooShortError.__init__#832",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ContentTooShortError",
        "signature": "youtube_dl.utils.ContentTooShortError.__init__(self, downloaded, expected)",
        "snippet": "    def __init__(self, downloaded, expected):\n        super(ContentTooShortError, self).__init__(\n            'Downloaded {0} bytes, expected {1} bytes'.format(downloaded, expected)\n        )\n        # Both in bytes\n        self.downloaded = downloaded\n        self.expected = expected",
        "begin_line": 832,
        "end_line": 838,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.XAttrMetadataError.__init__#842",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.XAttrMetadataError",
        "signature": "youtube_dl.utils.XAttrMetadataError.__init__(self, code=None, msg='Unknown error')",
        "snippet": "    def __init__(self, code=None, msg='Unknown error'):\n        super(XAttrMetadataError, self).__init__(msg)\n        self.code = code\n        self.msg = msg\n\n        # Parsing code and msg\n        if (self.code in (errno.ENOSPC, errno.EDQUOT) or\n                'No space left' in self.msg or 'Disk quota excedded' in self.msg):\n            self.reason = 'NO_SPACE'\n        elif self.code == errno.E2BIG or 'Argument list too long' in self.msg:\n            self.reason = 'VALUE_TOO_LONG'\n        else:\n            self.reason = 'NOT_SUPPORTED'",
        "begin_line": 842,
        "end_line": 854,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._create_http_connection#861",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs)",
        "snippet": "def _create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs):\n    # Working around python 2 bug (see http://bugs.python.org/issue17849) by limiting\n    # expected HTTP responses to meet HTTP/1.0 or later (see also\n    # https://github.com/rg3/youtube-dl/issues/6727)\n    if sys.version_info < (3, 0):\n        kwargs[b'strict'] = True\n    hc = http_class(*args, **kwargs)\n    source_address = ydl_handler._params.get('source_address')\n    if source_address is not None:\n        sa = (source_address, 0)\n        if hasattr(hc, 'source_address'):  # Python 2.7+\n            hc.source_address = sa\n        else:  # Python 2.6\n            def _hc_connect(self, *args, **kwargs):\n                sock = compat_socket_create_connection(\n                    (self.host, self.port), self.timeout, sa)\n                if is_https:\n                    self.sock = ssl.wrap_socket(\n                        sock, self.key_file, self.cert_file,\n                        ssl_version=ssl.PROTOCOL_TLSv1)\n                else:\n                    self.sock = sock\n            hc.connect = functools.partial(_hc_connect, hc)\n\n    return hc",
        "begin_line": 861,
        "end_line": 885,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.handle_youtubedl_headers#888",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.handle_youtubedl_headers(headers)",
        "snippet": "def handle_youtubedl_headers(headers):\n    filtered_headers = headers\n\n    if 'Youtubedl-no-compression' in filtered_headers:\n        filtered_headers = dict((k, v) for k, v in filtered_headers.items() if k.lower() != 'accept-encoding')\n        del filtered_headers['Youtubedl-no-compression']\n\n    return filtered_headers",
        "begin_line": 888,
        "end_line": 895,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.__init__#916",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.__init__(self, params, *args, **kwargs)",
        "snippet": "    def __init__(self, params, *args, **kwargs):\n        compat_urllib_request.HTTPHandler.__init__(self, *args, **kwargs)\n        self._params = params",
        "begin_line": 916,
        "end_line": 918,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_open#920",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_open(self, req)",
        "snippet": "    def http_open(self, req):\n        conn_class = compat_http_client.HTTPConnection\n\n        socks_proxy = req.headers.get('Ytdl-socks-proxy')\n        if socks_proxy:\n            conn_class = make_socks_conn_class(conn_class, socks_proxy)\n            del req.headers['Ytdl-socks-proxy']\n\n        return self.do_open(functools.partial(\n            _create_http_connection, self, conn_class, False),\n            req)",
        "begin_line": 920,
        "end_line": 930,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.deflate#933",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.deflate(data)",
        "snippet": "    def deflate(data):\n        try:\n            return zlib.decompress(data, -zlib.MAX_WBITS)\n        except zlib.error:\n            return zlib.decompress(data)",
        "begin_line": 933,
        "end_line": 937,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_request#939",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_request(self, req)",
        "snippet": "    def http_request(self, req):\n        # According to RFC 3986, URLs can not contain non-ASCII characters, however this is not\n        # always respected by websites, some tend to give out URLs with non percent-encoded\n        # non-ASCII characters (see telemb.py, ard.py [#3412])\n        # urllib chokes on URLs with non-ASCII characters (see http://bugs.python.org/issue3991)\n        # To work around aforementioned issue we will replace request's original URL with\n        # percent-encoded one\n        # Since redirects are also affected (e.g. http://www.southpark.de/alle-episoden/s18e09)\n        # the code of this workaround has been moved here from YoutubeDL.urlopen()\n        url = req.get_full_url()\n        url_escaped = escape_url(url)\n\n        # Substitute URL if any change after escaping\n        if url != url_escaped:\n            req = update_Request(req, url=url_escaped)\n\n        for h, v in std_headers.items():\n            # Capitalize is needed because of Python bug 2275: http://bugs.python.org/issue2275\n            # The dict keys are capitalized because of this bug by urllib\n            if h.capitalize() not in req.headers:\n                req.add_header(h, v)\n\n        req.headers = handle_youtubedl_headers(req.headers)\n\n        if sys.version_info < (2, 7) and '#' in req.get_full_url():\n            # Python 2.6 is brain-dead when it comes to fragments\n            req._Request__original = req._Request__original.partition('#')[0]\n            req._Request__r_type = req._Request__r_type.partition('#')[0]\n\n        return req",
        "begin_line": 939,
        "end_line": 968,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_response#970",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_response(self, req, resp)",
        "snippet": "    def http_response(self, req, resp):\n        old_resp = resp\n        # gzip\n        if resp.headers.get('Content-encoding', '') == 'gzip':\n            content = resp.read()\n            gz = gzip.GzipFile(fileobj=io.BytesIO(content), mode='rb')\n            try:\n                uncompressed = io.BytesIO(gz.read())\n            except IOError as original_ioerror:\n                # There may be junk add the end of the file\n                # See http://stackoverflow.com/q/4928560/35070 for details\n                for i in range(1, 1024):\n                    try:\n                        gz = gzip.GzipFile(fileobj=io.BytesIO(content[:-i]), mode='rb')\n                        uncompressed = io.BytesIO(gz.read())\n                    except IOError:\n                        continue\n                    break\n                else:\n                    raise original_ioerror\n            resp = compat_urllib_request.addinfourl(uncompressed, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n            del resp.headers['Content-encoding']\n        # deflate\n        if resp.headers.get('Content-encoding', '') == 'deflate':\n            gz = io.BytesIO(self.deflate(resp.read()))\n            resp = compat_urllib_request.addinfourl(gz, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n            del resp.headers['Content-encoding']\n        # Percent-encode redirect URL of Location HTTP header to satisfy RFC 3986 (see\n        # https://github.com/rg3/youtube-dl/issues/6457).\n        if 300 <= resp.code < 400:\n            location = resp.headers.get('Location')\n            if location:\n                # As of RFC 2616 default charset is iso-8859-1 that is respected by python 3\n                if sys.version_info >= (3, 0):\n                    location = location.encode('iso-8859-1').decode('utf-8')\n                else:\n                    location = location.decode('utf-8')\n                location_escaped = escape_url(location)\n                if location != location_escaped:\n                    del resp.headers['Location']\n                    if sys.version_info < (3, 0):\n                        location_escaped = location_escaped.encode('utf-8')\n                    resp.headers['Location'] = location_escaped\n        return resp",
        "begin_line": 970,
        "end_line": 1015,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.make_socks_conn_class#1021",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_socks_conn_class(base_class, socks_proxy)",
        "snippet": "def make_socks_conn_class(base_class, socks_proxy):\n    assert issubclass(base_class, (\n        compat_http_client.HTTPConnection, compat_http_client.HTTPSConnection))\n\n    url_components = compat_urlparse.urlparse(socks_proxy)\n    if url_components.scheme.lower() == 'socks5':\n        socks_type = ProxyType.SOCKS5\n    elif url_components.scheme.lower() in ('socks', 'socks4'):\n        socks_type = ProxyType.SOCKS4\n    elif url_components.scheme.lower() == 'socks4a':\n        socks_type = ProxyType.SOCKS4A\n\n    def unquote_if_non_empty(s):\n        if not s:\n            return s\n        return compat_urllib_parse_unquote_plus(s)\n\n    proxy_args = (\n        socks_type,\n        url_components.hostname, url_components.port or 1080,\n        True,  # Remote DNS\n        unquote_if_non_empty(url_components.username),\n        unquote_if_non_empty(url_components.password),\n    )\n\n    class SocksConnection(base_class):\n        def connect(self):\n            self.sock = sockssocket()\n            self.sock.setproxy(*proxy_args)\n            if type(self.timeout) in (int, float):\n                self.sock.settimeout(self.timeout)\n            self.sock.connect((self.host, self.port))\n\n            if isinstance(self, compat_http_client.HTTPSConnection):\n                if hasattr(self, '_context'):  # Python > 2.6\n                    self.sock = self._context.wrap_socket(\n                        self.sock, server_hostname=self.host)\n                else:\n                    self.sock = ssl.wrap_socket(self.sock)\n\n    return SocksConnection",
        "begin_line": 1021,
        "end_line": 1061,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__#1065",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.__init__(self, params, https_conn_class=None, *args, **kwargs)",
        "snippet": "    def __init__(self, params, https_conn_class=None, *args, **kwargs):\n        compat_urllib_request.HTTPSHandler.__init__(self, *args, **kwargs)\n        self._https_conn_class = https_conn_class or compat_http_client.HTTPSConnection\n        self._params = params",
        "begin_line": 1065,
        "end_line": 1068,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open#1070",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHTTPSHandler",
        "signature": "youtube_dl.utils.YoutubeDLHTTPSHandler.https_open(self, req)",
        "snippet": "    def https_open(self, req):\n        kwargs = {}\n        conn_class = self._https_conn_class\n\n        if hasattr(self, '_context'):  # python > 2.6\n            kwargs['context'] = self._context\n        if hasattr(self, '_check_hostname'):  # python 3.x\n            kwargs['check_hostname'] = self._check_hostname\n\n        socks_proxy = req.headers.get('Ytdl-socks-proxy')\n        if socks_proxy:\n            conn_class = make_socks_conn_class(conn_class, socks_proxy)\n            del req.headers['Ytdl-socks-proxy']\n\n        return self.do_open(functools.partial(\n            _create_http_connection, self, conn_class, True),\n            req, **kwargs)",
        "begin_line": 1070,
        "end_line": 1086,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLCookieProcessor.__init__#1090",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLCookieProcessor",
        "signature": "youtube_dl.utils.YoutubeDLCookieProcessor.__init__(self, cookiejar=None)",
        "snippet": "    def __init__(self, cookiejar=None):\n        compat_urllib_request.HTTPCookieProcessor.__init__(self, cookiejar)",
        "begin_line": 1090,
        "end_line": 1091,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.YoutubeDLCookieProcessor.http_response#1093",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLCookieProcessor",
        "signature": "youtube_dl.utils.YoutubeDLCookieProcessor.http_response(self, request, response)",
        "snippet": "    def http_response(self, request, response):\n        # Python 2 will choke on next HTTP request in row if there are non-ASCII\n        # characters in Set-Cookie HTTP header of last response (see\n        # https://github.com/rg3/youtube-dl/issues/6769).\n        # In order to at least prevent crashing we will percent encode Set-Cookie\n        # header before HTTPCookieProcessor starts processing it.\n        # if sys.version_info < (3, 0) and response.headers:\n        #     for set_cookie_header in ('Set-Cookie', 'Set-Cookie2'):\n        #         set_cookie = response.headers.get(set_cookie_header)\n        #         if set_cookie:\n        #             set_cookie_escaped = compat_urllib_parse.quote(set_cookie, b\"%/;:@&=+$,!~*'()?#[] \")\n        #             if set_cookie != set_cookie_escaped:\n        #                 del response.headers[set_cookie_header]\n        #                 response.headers[set_cookie_header] = set_cookie_escaped\n        return compat_urllib_request.HTTPCookieProcessor.http_response(self, request, response)",
        "begin_line": 1093,
        "end_line": 1107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.extract_timezone#1113",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.extract_timezone(date_str)",
        "snippet": "def extract_timezone(date_str):\n    m = re.search(\n        r'^.{8,}?(?P<tz>Z$| ?(?P<sign>\\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',\n        date_str)\n    if not m:\n        timezone = datetime.timedelta()\n    else:\n        date_str = date_str[:-len(m.group('tz'))]\n        if not m.group('sign'):\n            timezone = datetime.timedelta()\n        else:\n            sign = 1 if m.group('sign') == '+' else -1\n            timezone = datetime.timedelta(\n                hours=sign * int(m.group('hours')),\n                minutes=sign * int(m.group('minutes')))\n    return timezone, date_str",
        "begin_line": 1113,
        "end_line": 1128,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_iso8601#1131",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_iso8601(date_str, delimiter='T', timezone=None)",
        "snippet": "def parse_iso8601(date_str, delimiter='T', timezone=None):\n    \"\"\" Return a UNIX timestamp from the given date \"\"\"\n\n    if date_str is None:\n        return None\n\n    date_str = re.sub(r'\\.[0-9]+', '', date_str)\n\n    if timezone is None:\n        timezone, date_str = extract_timezone(date_str)\n\n    try:\n        date_format = '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)\n        dt = datetime.datetime.strptime(date_str, date_format) - timezone\n        return calendar.timegm(dt.timetuple())\n    except ValueError:\n        pass",
        "begin_line": 1131,
        "end_line": 1147,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.date_formats#1150",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_formats(day_first=True)",
        "snippet": "def date_formats(day_first=True):\n    return DATE_FORMATS_DAY_FIRST if day_first else DATE_FORMATS_MONTH_FIRST",
        "begin_line": 1150,
        "end_line": 1151,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.unified_strdate#1154",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_strdate(date_str, day_first=True)",
        "snippet": "def unified_strdate(date_str, day_first=True):\n    \"\"\"Return a string with the date in the format YYYYMMDD\"\"\"\n\n    if date_str is None:\n        return None\n    upload_date = None\n    # Replace commas\n    date_str = date_str.replace(',', ' ')\n    # Remove AM/PM + timezone\n    date_str = re.sub(r'(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)\n    _, date_str = extract_timezone(date_str)\n\n    for expression in date_formats(day_first):\n        try:\n            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')\n        except ValueError:\n            pass\n    if upload_date is None:\n        timetuple = email.utils.parsedate_tz(date_str)\n        if timetuple:\n            try:\n                upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')\n            except ValueError:\n                pass\n    if upload_date is not None:\n        return compat_str(upload_date)",
        "begin_line": 1154,
        "end_line": 1179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.unified_timestamp#1182",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_timestamp(date_str, day_first=True)",
        "snippet": "def unified_timestamp(date_str, day_first=True):\n    if date_str is None:\n        return None\n\n    date_str = re.sub(r'[,|]', '', date_str)\n\n    pm_delta = 12 if re.search(r'(?i)PM', date_str) else 0\n    timezone, date_str = extract_timezone(date_str)\n\n    # Remove AM/PM + timezone\n    date_str = re.sub(r'(?i)\\s*(?:AM|PM)(?:\\s+[A-Z]+)?', '', date_str)\n\n    # Remove unrecognized timezones from ISO 8601 alike timestamps\n    m = re.search(r'\\d{1,2}:\\d{1,2}(?:\\.\\d+)?(?P<tz>\\s*[A-Z]+)$', date_str)\n    if m:\n        date_str = date_str[:-len(m.group('tz'))]\n\n    for expression in date_formats(day_first):\n        try:\n            dt = datetime.datetime.strptime(date_str, expression) - timezone + datetime.timedelta(hours=pm_delta)\n            return calendar.timegm(dt.timetuple())\n        except ValueError:\n            pass\n    timetuple = email.utils.parsedate_tz(date_str)\n    if timetuple:\n        return calendar.timegm(timetuple) + pm_delta * 3600",
        "begin_line": 1182,
        "end_line": 1207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.determine_ext#1210",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_ext(url, default_ext='unknown_video')",
        "snippet": "def determine_ext(url, default_ext='unknown_video'):\n    if url is None:\n        return default_ext\n    guess = url.partition('?')[0].rpartition('.')[2]\n    if re.match(r'^[A-Za-z0-9]+$', guess):\n        return guess\n    # Try extract ext from URLs like http://example.com/foo/bar.mp4/?download\n    elif guess.rstrip('/') in KNOWN_EXTENSIONS:\n        return guess.rstrip('/')\n    else:\n        return default_ext",
        "begin_line": 1210,
        "end_line": 1220,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.subtitles_filename#1223",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.subtitles_filename(filename, sub_lang, sub_format)",
        "snippet": "def subtitles_filename(filename, sub_lang, sub_format):\n    return filename.rsplit('.', 1)[0] + '.' + sub_lang + '.' + sub_format",
        "begin_line": 1223,
        "end_line": 1224,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.date_from_str#1227",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_from_str(date_str)",
        "snippet": "def date_from_str(date_str):\n    \"\"\"\n    Return a datetime object from a string in the format YYYYMMDD or\n    (now|today)[+-][0-9](day|week|month|year)(s)?\"\"\"\n    today = datetime.date.today()\n    if date_str in ('now', 'today'):\n        return today\n    if date_str == 'yesterday':\n        return today - datetime.timedelta(days=1)\n    match = re.match(r'(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)\n    if match is not None:\n        sign = match.group('sign')\n        time = int(match.group('time'))\n        if sign == '-':\n            time = -time\n        unit = match.group('unit')\n        # A bad approximation?\n        if unit == 'month':\n            unit = 'day'\n            time *= 30\n        elif unit == 'year':\n            unit = 'day'\n            time *= 365\n        unit += 's'\n        delta = datetime.timedelta(**{unit: time})\n        return today + delta\n    return datetime.datetime.strptime(date_str, '%Y%m%d').date()",
        "begin_line": 1227,
        "end_line": 1253,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.hyphenate_date#1256",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.hyphenate_date(date_str)",
        "snippet": "def hyphenate_date(date_str):\n    \"\"\"\n    Convert a date in 'YYYYMMDD' format to 'YYYY-MM-DD' format\"\"\"\n    match = re.match(r'^(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$', date_str)\n    if match is not None:\n        return '-'.join(match.groups())\n    else:\n        return date_str",
        "begin_line": 1256,
        "end_line": 1263,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.DateRange.__init__#1269",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__init__(self, start=None, end=None)",
        "snippet": "    def __init__(self, start=None, end=None):\n        \"\"\"start and end must be strings in the format accepted by date\"\"\"\n        if start is not None:\n            self.start = date_from_str(start)\n        else:\n            self.start = datetime.datetime.min.date()\n        if end is not None:\n            self.end = date_from_str(end)\n        else:\n            self.end = datetime.datetime.max.date()\n        if self.start > self.end:\n            raise ValueError('Date range: \"%s\" , the start date must be before the end date' % self)",
        "begin_line": 1269,
        "end_line": 1280,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.DateRange.day#1283",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.day(cls, day)",
        "snippet": "    def day(cls, day):\n        \"\"\"Returns a range that only contains the given day\"\"\"\n        return cls(day, day)",
        "begin_line": 1283,
        "end_line": 1285,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.DateRange.__contains__#1287",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__contains__(self, date)",
        "snippet": "    def __contains__(self, date):\n        \"\"\"Check if the date is in the range\"\"\"\n        if not isinstance(date, datetime.date):\n            date = date_from_str(date)\n        return self.start <= date <= self.end",
        "begin_line": 1287,
        "end_line": 1291,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.DateRange.__str__#1293",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__str__(self)",
        "snippet": "    def __str__(self):\n        return '%s - %s' % (self.start.isoformat(), self.end.isoformat())",
        "begin_line": 1293,
        "end_line": 1294,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.platform_name#1297",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.platform_name()",
        "snippet": "def platform_name():\n    \"\"\" Returns the platform name as a compat_str \"\"\"\n    res = platform.platform()\n    if isinstance(res, bytes):\n        res = res.decode(preferredencoding())\n\n    assert isinstance(res, compat_str)\n    return res",
        "begin_line": 1297,
        "end_line": 1304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._windows_write_string#1307",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._windows_write_string(s, out)",
        "snippet": "def _windows_write_string(s, out):\n    \"\"\" Returns True if the string was written using special methods,\n    False if it has yet to be written out.\"\"\"\n    # Adapted from http://stackoverflow.com/a/3259271/35070\n\n    import ctypes\n    import ctypes.wintypes\n\n    WIN_OUTPUT_IDS = {\n        1: -11,\n        2: -12,\n    }\n\n    try:\n        fileno = out.fileno()\n    except AttributeError:\n        # If the output stream doesn't have a fileno, it's virtual\n        return False\n    except io.UnsupportedOperation:\n        # Some strange Windows pseudo files?\n        return False\n    if fileno not in WIN_OUTPUT_IDS:\n        return False\n\n    GetStdHandle = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD)(\n        (b'GetStdHandle', ctypes.windll.kernel32))\n    h = GetStdHandle(WIN_OUTPUT_IDS[fileno])\n\n    WriteConsoleW = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.wintypes.LPWSTR,\n        ctypes.wintypes.DWORD, ctypes.POINTER(ctypes.wintypes.DWORD),\n        ctypes.wintypes.LPVOID)((b'WriteConsoleW', ctypes.windll.kernel32))\n    written = ctypes.wintypes.DWORD(0)\n\n    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b'GetFileType', ctypes.windll.kernel32))\n    FILE_TYPE_CHAR = 0x0002\n    FILE_TYPE_REMOTE = 0x8000\n    GetConsoleMode = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE,\n        ctypes.POINTER(ctypes.wintypes.DWORD))(\n        (b'GetConsoleMode', ctypes.windll.kernel32))\n    INVALID_HANDLE_VALUE = ctypes.wintypes.DWORD(-1).value\n\n    def not_a_console(handle):\n        if handle == INVALID_HANDLE_VALUE or handle is None:\n            return True\n        return ((GetFileType(handle) & ~FILE_TYPE_REMOTE) != FILE_TYPE_CHAR or\n                GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0)\n\n    if not_a_console(h):\n        return False\n\n    def next_nonbmp_pos(s):\n        try:\n            return next(i for i, c in enumerate(s) if ord(c) > 0xffff)\n        except StopIteration:\n            return len(s)\n\n    while s:\n        count = min(next_nonbmp_pos(s), 1024)\n\n        ret = WriteConsoleW(\n            h, s, count if count else 2, ctypes.byref(written), None)\n        if ret == 0:\n            raise OSError('Failed to write string')\n        if not count:  # We just wrote a non-BMP character\n            assert written.value == 2\n            s = s[1:]\n        else:\n            assert written.value > 0\n            s = s[written.value:]\n    return True",
        "begin_line": 1307,
        "end_line": 1379,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.write_string#1382",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_string(s, out=None, encoding=None)",
        "snippet": "def write_string(s, out=None, encoding=None):\n    if out is None:\n        out = sys.stderr\n    assert type(s) == compat_str\n\n    if sys.platform == 'win32' and encoding is None and hasattr(out, 'fileno'):\n        if _windows_write_string(s, out):\n            return\n\n    if ('b' in getattr(out, 'mode', '') or\n            sys.version_info[0] < 3):  # Python 2 lies about mode of sys.stderr\n        byt = s.encode(encoding or preferredencoding(), 'ignore')\n        out.write(byt)\n    elif hasattr(out, 'buffer'):\n        enc = encoding or getattr(out, 'encoding', None) or preferredencoding()\n        byt = s.encode(enc, 'ignore')\n        out.buffer.write(byt)\n    else:\n        out.write(s)\n    out.flush()",
        "begin_line": 1382,
        "end_line": 1401,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.bytes_to_intlist#1404",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_intlist(bs)",
        "snippet": "def bytes_to_intlist(bs):\n    if not bs:\n        return []\n    if isinstance(bs[0], int):  # Python 3\n        return list(bs)\n    else:\n        return [ord(c) for c in bs]",
        "begin_line": 1404,
        "end_line": 1410,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.intlist_to_bytes#1413",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.intlist_to_bytes(xs)",
        "snippet": "def intlist_to_bytes(xs):\n    if not xs:\n        return b''\n    return compat_struct_pack('%dB' % len(xs), *xs)",
        "begin_line": 1413,
        "end_line": 1416,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._lock_file#1479",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._lock_file(f, exclusive)",
        "snippet": "        def _lock_file(f, exclusive):\n            fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)",
        "begin_line": 1479,
        "end_line": 1480,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._unlock_file#1482",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._unlock_file(f)",
        "snippet": "        def _unlock_file(f):\n            fcntl.flock(f, fcntl.LOCK_UN)",
        "begin_line": 1482,
        "end_line": 1483,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.__init__#1495",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__init__(self, filename, mode, encoding=None)",
        "snippet": "    def __init__(self, filename, mode, encoding=None):\n        assert mode in ['r', 'a', 'w']\n        self.f = io.open(filename, mode, encoding=encoding)\n        self.mode = mode",
        "begin_line": 1495,
        "end_line": 1498,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.__enter__#1500",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__enter__(self)",
        "snippet": "    def __enter__(self):\n        exclusive = self.mode != 'r'\n        try:\n            _lock_file(self.f, exclusive)\n        except IOError:\n            self.f.close()\n            raise\n        return self",
        "begin_line": 1500,
        "end_line": 1507,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.__exit__#1509",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__exit__(self, etype, value, traceback)",
        "snippet": "    def __exit__(self, etype, value, traceback):\n        try:\n            _unlock_file(self.f)\n        finally:\n            self.f.close()",
        "begin_line": 1509,
        "end_line": 1513,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.__iter__#1515",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.f)",
        "begin_line": 1515,
        "end_line": 1516,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.write#1518",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.write(self, *args)",
        "snippet": "    def write(self, *args):\n        return self.f.write(*args)",
        "begin_line": 1518,
        "end_line": 1519,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.locked_file.read#1521",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.read(self, *args)",
        "snippet": "    def read(self, *args):\n        return self.f.read(*args)",
        "begin_line": 1521,
        "end_line": 1522,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_filesystem_encoding#1525",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_filesystem_encoding()",
        "snippet": "def get_filesystem_encoding():\n    encoding = sys.getfilesystemencoding()\n    return encoding if encoding is not None else 'utf-8'",
        "begin_line": 1525,
        "end_line": 1527,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.shell_quote#1530",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.shell_quote(args)",
        "snippet": "def shell_quote(args):\n    quoted_args = []\n    encoding = get_filesystem_encoding()\n    for a in args:\n        if isinstance(a, bytes):\n            # We may get a filename encoded with 'encodeFilename'\n            a = a.decode(encoding)\n        quoted_args.append(compat_shlex_quote(a))\n    return ' '.join(quoted_args)",
        "begin_line": 1530,
        "end_line": 1538,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.smuggle_url#1541",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.smuggle_url(url, data)",
        "snippet": "def smuggle_url(url, data):\n    \"\"\" Pass additional data in a URL for internal use. \"\"\"\n\n    url, idata = unsmuggle_url(url, {})\n    data.update(idata)\n    sdata = compat_urllib_parse_urlencode(\n        {'__youtubedl_smuggle': json.dumps(data)})\n    return url + '#' + sdata",
        "begin_line": 1541,
        "end_line": 1548,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.unsmuggle_url#1551",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unsmuggle_url(smug_url, default=None)",
        "snippet": "def unsmuggle_url(smug_url, default=None):\n    if '#__youtubedl_smuggle' not in smug_url:\n        return smug_url, default\n    url, _, sdata = smug_url.rpartition('#')\n    jsond = compat_parse_qs(sdata)['__youtubedl_smuggle'][0]\n    data = json.loads(jsond)\n    return url, data",
        "begin_line": 1551,
        "end_line": 1557,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.format_bytes#1560",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.format_bytes(bytes)",
        "snippet": "def format_bytes(bytes):\n    if bytes is None:\n        return 'N/A'\n    if type(bytes) is str:\n        bytes = float(bytes)\n    if bytes == 0.0:\n        exponent = 0\n    else:\n        exponent = int(math.log(bytes, 1024.0))\n    suffix = ['B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'][exponent]\n    converted = float(bytes) / float(1024 ** exponent)\n    return '%.2f%s' % (converted, suffix)",
        "begin_line": 1560,
        "end_line": 1571,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.lookup_unit_table#1574",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.lookup_unit_table(unit_table, s)",
        "snippet": "def lookup_unit_table(unit_table, s):\n    units_re = '|'.join(re.escape(u) for u in unit_table)\n    m = re.match(\n        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\\s*(?P<unit>%s)\\b' % units_re, s)\n    if not m:\n        return None\n    num_str = m.group('num').replace(',', '.')\n    mult = unit_table[m.group('unit')]\n    return int(float(num_str) * mult)",
        "begin_line": 1574,
        "end_line": 1582,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_filesize#1585",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_filesize(s)",
        "snippet": "def parse_filesize(s):\n    if s is None:\n        return None\n\n    # The lower-case forms are of course incorrect and unofficial,\n    # but we support those too\n    _UNIT_TABLE = {\n        'B': 1,\n        'b': 1,\n        'bytes': 1,\n        'KiB': 1024,\n        'KB': 1000,\n        'kB': 1024,\n        'Kb': 1000,\n        'kb': 1000,\n        'kilobytes': 1000,\n        'kibibytes': 1024,\n        'MiB': 1024 ** 2,\n        'MB': 1000 ** 2,\n        'mB': 1024 ** 2,\n        'Mb': 1000 ** 2,\n        'mb': 1000 ** 2,\n        'megabytes': 1000 ** 2,\n        'mebibytes': 1024 ** 2,\n        'GiB': 1024 ** 3,\n        'GB': 1000 ** 3,\n        'gB': 1024 ** 3,\n        'Gb': 1000 ** 3,\n        'gb': 1000 ** 3,\n        'gigabytes': 1000 ** 3,\n        'gibibytes': 1024 ** 3,\n        'TiB': 1024 ** 4,\n        'TB': 1000 ** 4,\n        'tB': 1024 ** 4,\n        'Tb': 1000 ** 4,\n        'tb': 1000 ** 4,\n        'terabytes': 1000 ** 4,\n        'tebibytes': 1024 ** 4,\n        'PiB': 1024 ** 5,\n        'PB': 1000 ** 5,\n        'pB': 1024 ** 5,\n        'Pb': 1000 ** 5,\n        'pb': 1000 ** 5,\n        'petabytes': 1000 ** 5,\n        'pebibytes': 1024 ** 5,\n        'EiB': 1024 ** 6,\n        'EB': 1000 ** 6,\n        'eB': 1024 ** 6,\n        'Eb': 1000 ** 6,\n        'eb': 1000 ** 6,\n        'exabytes': 1000 ** 6,\n        'exbibytes': 1024 ** 6,\n        'ZiB': 1024 ** 7,\n        'ZB': 1000 ** 7,\n        'zB': 1024 ** 7,\n        'Zb': 1000 ** 7,\n        'zb': 1000 ** 7,\n        'zettabytes': 1000 ** 7,\n        'zebibytes': 1024 ** 7,\n        'YiB': 1024 ** 8,\n        'YB': 1000 ** 8,\n        'yB': 1024 ** 8,\n        'Yb': 1000 ** 8,\n        'yb': 1000 ** 8,\n        'yottabytes': 1000 ** 8,\n        'yobibytes': 1024 ** 8,\n    }\n\n    return lookup_unit_table(_UNIT_TABLE, s)",
        "begin_line": 1585,
        "end_line": 1653,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_count#1656",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_count(s)",
        "snippet": "def parse_count(s):\n    if s is None:\n        return None\n\n    s = s.strip()\n\n    if re.match(r'^[\\d,.]+$', s):\n        return str_to_int(s)\n\n    _UNIT_TABLE = {\n        'k': 1000,\n        'K': 1000,\n        'm': 1000 ** 2,\n        'M': 1000 ** 2,\n        'kk': 1000 ** 2,\n        'KK': 1000 ** 2,\n    }\n\n    return lookup_unit_table(_UNIT_TABLE, s)",
        "begin_line": 1656,
        "end_line": 1674,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.month_by_name#1677",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_name(name, lang='en')",
        "snippet": "def month_by_name(name, lang='en'):\n    \"\"\" Return the number of a month by (locale-independently) English name \"\"\"\n\n    month_names = MONTH_NAMES.get(lang, MONTH_NAMES['en'])\n\n    try:\n        return month_names.index(name) + 1\n    except ValueError:\n        return None",
        "begin_line": 1677,
        "end_line": 1685,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.month_by_abbreviation#1688",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_abbreviation(abbrev)",
        "snippet": "def month_by_abbreviation(abbrev):\n    \"\"\" Return the number of a month by (locale-independently) English\n        abbreviations \"\"\"\n\n    try:\n        return [s[:3] for s in ENGLISH_MONTH_NAMES].index(abbrev) + 1\n    except ValueError:\n        return None",
        "begin_line": 1688,
        "end_line": 1695,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.fix_xml_ampersands#1698",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_xml_ampersands(xml_str)",
        "snippet": "def fix_xml_ampersands(xml_str):\n    \"\"\"Replace all the '&' by '&amp;' in XML\"\"\"\n    return re.sub(\n        r'&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)',\n        '&amp;',\n        xml_str)",
        "begin_line": 1698,
        "end_line": 1703,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.setproctitle#1706",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.setproctitle(title)",
        "snippet": "def setproctitle(title):\n    assert isinstance(title, compat_str)\n\n    # ctypes in Jython is not complete\n    # http://bugs.jython.org/issue2148\n    if sys.platform.startswith('java'):\n        return\n\n    try:\n        libc = ctypes.cdll.LoadLibrary('libc.so.6')\n    except OSError:\n        return\n    except TypeError:\n        # LoadLibrary in Windows Python 2.7.13 only expects\n        # a bytestring, but since unicode_literals turns\n        # every string into a unicode string, it fails.\n        return\n    title_bytes = title.encode('utf-8')\n    buf = ctypes.create_string_buffer(len(title_bytes))\n    buf.value = title_bytes\n    try:\n        libc.prctl(15, buf, 0, 0, 0)\n    except AttributeError:\n        return  # Strange libc, just skip this",
        "begin_line": 1706,
        "end_line": 1729,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.remove_start#1732",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_start(s, start)",
        "snippet": "def remove_start(s, start):\n    return s[len(start):] if s is not None and s.startswith(start) else s",
        "begin_line": 1732,
        "end_line": 1733,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.remove_end#1736",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_end(s, end)",
        "snippet": "def remove_end(s, end):\n    return s[:-len(end)] if s is not None and s.endswith(end) else s",
        "begin_line": 1736,
        "end_line": 1737,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.remove_quotes#1740",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_quotes(s)",
        "snippet": "def remove_quotes(s):\n    if s is None or len(s) < 2:\n        return s\n    for quote in ('\"', \"'\", ):\n        if s[0] == quote and s[-1] == quote:\n            return s[1:-1]\n    return s",
        "begin_line": 1740,
        "end_line": 1746,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.url_basename#1749",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.url_basename(url)",
        "snippet": "def url_basename(url):\n    path = compat_urlparse.urlparse(url).path\n    return path.strip('/').split('/')[-1]",
        "begin_line": 1749,
        "end_line": 1751,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.base_url#1754",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.base_url(url)",
        "snippet": "def base_url(url):\n    return re.match(r'https?://[^?#&]+/', url).group()",
        "begin_line": 1754,
        "end_line": 1755,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.urljoin#1758",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urljoin(base, path)",
        "snippet": "def urljoin(base, path):\n    if isinstance(path, bytes):\n        path = path.decode('utf-8')\n    if not isinstance(path, compat_str) or not path:\n        return None\n    if re.match(r'^(?:https?:)?//', path):\n        return path\n    if isinstance(base, bytes):\n        base = base.decode('utf-8')\n    if not isinstance(base, compat_str) or not re.match(\n            r'^(?:https?:)?//', base):\n        return None\n    return compat_urlparse.urljoin(base, path)",
        "begin_line": 1758,
        "end_line": 1770,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.HEADRequest.get_method#1774",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HEADRequest",
        "signature": "youtube_dl.utils.HEADRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return 'HEAD'",
        "begin_line": 1774,
        "end_line": 1775,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.PUTRequest.get_method#1779",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PUTRequest",
        "signature": "youtube_dl.utils.PUTRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return 'PUT'",
        "begin_line": 1779,
        "end_line": 1780,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.int_or_none#1783",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.int_or_none(v, scale=1, default=None, get_attr=None, invscale=1)",
        "snippet": "def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):\n    if get_attr:\n        if v is not None:\n            v = getattr(v, get_attr, None)\n    if v == '':\n        v = None\n    if v is None:\n        return default\n    try:\n        return int(v) * invscale // scale\n    except ValueError:\n        return default",
        "begin_line": 1783,
        "end_line": 1794,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.str_or_none#1797",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_or_none(v, default=None)",
        "snippet": "def str_or_none(v, default=None):\n    return default if v is None else compat_str(v)",
        "begin_line": 1797,
        "end_line": 1798,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.str_to_int#1801",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_to_int(int_str)",
        "snippet": "def str_to_int(int_str):\n    \"\"\" A more relaxed version of int_or_none \"\"\"\n    if int_str is None:\n        return None\n    int_str = re.sub(r'[,\\.\\+]', '', int_str)\n    return int(int_str)",
        "begin_line": 1801,
        "end_line": 1806,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.float_or_none#1809",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.float_or_none(v, scale=1, invscale=1, default=None)",
        "snippet": "def float_or_none(v, scale=1, invscale=1, default=None):\n    if v is None:\n        return default\n    try:\n        return float(v) * invscale / scale\n    except ValueError:\n        return default",
        "begin_line": 1809,
        "end_line": 1815,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.strip_or_none#1818",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.strip_or_none(v)",
        "snippet": "def strip_or_none(v):\n    return None if v is None else v.strip()",
        "begin_line": 1818,
        "end_line": 1819,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_duration#1822",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_duration(s)",
        "snippet": "def parse_duration(s):\n    if not isinstance(s, compat_basestring):\n        return None\n\n    s = s.strip()\n\n    days, hours, mins, secs, ms = [None] * 5\n    m = re.match(r'(?:(?:(?:(?P<days>[0-9]+):)?(?P<hours>[0-9]+):)?(?P<mins>[0-9]+):)?(?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?Z?$', s)\n    if m:\n        days, hours, mins, secs, ms = m.groups()\n    else:\n        m = re.match(\n            r'''(?ix)(?:P?T)?\n                (?:\n                    (?P<days>[0-9]+)\\s*d(?:ays?)?\\s*\n                )?\n                (?:\n                    (?P<hours>[0-9]+)\\s*h(?:ours?)?\\s*\n                )?\n                (?:\n                    (?P<mins>[0-9]+)\\s*m(?:in(?:ute)?s?)?\\s*\n                )?\n                (?:\n                    (?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?\\s*s(?:ec(?:ond)?s?)?\\s*\n                )?Z?$''', s)\n        if m:\n            days, hours, mins, secs, ms = m.groups()\n        else:\n            m = re.match(r'(?i)(?:(?P<hours>[0-9.]+)\\s*(?:hours?)|(?P<mins>[0-9.]+)\\s*(?:mins?\\.?|minutes?)\\s*)Z?$', s)\n            if m:\n                hours, mins = m.groups()\n            else:\n                return None\n\n    duration = 0\n    if secs:\n        duration += float(secs)\n    if mins:\n        duration += float(mins) * 60\n    if hours:\n        duration += float(hours) * 60 * 60\n    if days:\n        duration += float(days) * 24 * 60 * 60\n    if ms:\n        duration += float(ms)\n    return duration",
        "begin_line": 1822,
        "end_line": 1867,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.prepend_extension#1870",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.prepend_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def prepend_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return (\n        '{0}.{1}{2}'.format(name, ext, real_ext)\n        if not expected_real_ext or real_ext[1:] == expected_real_ext\n        else '{0}.{1}'.format(filename, ext))",
        "begin_line": 1870,
        "end_line": 1875,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.replace_extension#1878",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_extension(filename, ext, expected_real_ext=None)",
        "snippet": "def replace_extension(filename, ext, expected_real_ext=None):\n    name, real_ext = os.path.splitext(filename)\n    return '{0}.{1}'.format(\n        name if not expected_real_ext or real_ext[1:] == expected_real_ext else filename,\n        ext)",
        "begin_line": 1878,
        "end_line": 1882,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.check_executable#1885",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.check_executable(exe, args=[])",
        "snippet": "def check_executable(exe, args=[]):\n    \"\"\" Checks if the given binary is installed somewhere in PATH, and returns its name.\n    args can be a list of arguments for a short output (like -version) \"\"\"\n    try:\n        subprocess.Popen([exe] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    except OSError:\n        return False\n    return exe",
        "begin_line": 1885,
        "end_line": 1892,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.get_exe_version#1895",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_exe_version(exe, args=['--version'], version_re=None, unrecognized='present')",
        "snippet": "def get_exe_version(exe, args=['--version'],\n                    version_re=None, unrecognized='present'):\n    \"\"\" Returns the version of the specified executable,\n    or False if the executable is not present \"\"\"\n    try:\n        # STDIN should be redirected too. On UNIX-like systems, ffmpeg triggers\n        # SIGTTOU if youtube-dl is run in the background.\n        # See https://github.com/rg3/youtube-dl/issues/955#issuecomment-209789656\n        out, _ = subprocess.Popen(\n            [encodeArgument(exe)] + args,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()\n    except OSError:\n        return False\n    if isinstance(out, bytes):  # Python 2.x\n        out = out.decode('ascii', 'ignore')\n    return detect_exe_version(out, version_re, unrecognized)",
        "begin_line": 1895,
        "end_line": 1911,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.detect_exe_version#1914",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.detect_exe_version(output, version_re=None, unrecognized='present')",
        "snippet": "def detect_exe_version(output, version_re=None, unrecognized='present'):\n    assert isinstance(output, compat_str)\n    if version_re is None:\n        version_re = r'version\\s+([-0-9._a-zA-Z]+)'\n    m = re.search(version_re, output)\n    if m:\n        return m.group(1)\n    else:\n        return unrecognized",
        "begin_line": 1914,
        "end_line": 1922,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.PagedList.__len__#1926",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__len__(self)",
        "snippet": "    def __len__(self):\n        # This is only useful for tests\n        return len(self.getslice())",
        "begin_line": 1926,
        "end_line": 1928,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.__init__#1932",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.__init__(self, pagefunc, pagesize, use_cache=False)",
        "snippet": "    def __init__(self, pagefunc, pagesize, use_cache=False):\n        self._pagefunc = pagefunc\n        self._pagesize = pagesize\n        self._use_cache = use_cache\n        if use_cache:\n            self._cache = {}",
        "begin_line": 1932,
        "end_line": 1937,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.OnDemandPagedList.getslice#1939",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.OnDemandPagedList",
        "signature": "youtube_dl.utils.OnDemandPagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        for pagenum in itertools.count(start // self._pagesize):\n            firstid = pagenum * self._pagesize\n            nextfirstid = pagenum * self._pagesize + self._pagesize\n            if start >= nextfirstid:\n                continue\n\n            page_results = None\n            if self._use_cache:\n                page_results = self._cache.get(pagenum)\n            if page_results is None:\n                page_results = list(self._pagefunc(pagenum))\n            if self._use_cache:\n                self._cache[pagenum] = page_results\n\n            startv = (\n                start % self._pagesize\n                if firstid <= start < nextfirstid\n                else 0)\n\n            endv = (\n                ((end - 1) % self._pagesize) + 1\n                if (end is not None and firstid <= end <= nextfirstid)\n                else None)\n\n            if startv != 0 or endv is not None:\n                page_results = page_results[startv:endv]\n            res.extend(page_results)\n\n            # A little optimization - if current page is not \"full\", ie. does\n            # not contain page_size videos then we can assume that this page\n            # is the last one - there are no more ids on further pages -\n            # i.e. no need to query again.\n            if len(page_results) + startv < self._pagesize:\n                break\n\n            # If we got the whole page, but the next page is not interesting,\n            # break out early as well\n            if end == nextfirstid:\n                break\n        return res",
        "begin_line": 1939,
        "end_line": 1980,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.__init__#1984",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.__init__(self, pagefunc, pagecount, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagecount, pagesize):\n        self._pagefunc = pagefunc\n        self._pagecount = pagecount\n        self._pagesize = pagesize",
        "begin_line": 1984,
        "end_line": 1987,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.InAdvancePagedList.getslice#1989",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.InAdvancePagedList",
        "signature": "youtube_dl.utils.InAdvancePagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        start_page = start // self._pagesize\n        end_page = (\n            self._pagecount if end is None else (end // self._pagesize + 1))\n        skip_elems = start - start_page * self._pagesize\n        only_more = None if end is None else end - start\n        for pagenum in range(start_page, end_page):\n            page = list(self._pagefunc(pagenum))\n            if skip_elems:\n                page = page[skip_elems:]\n                skip_elems = None\n            if only_more is not None:\n                if len(page) < only_more:\n                    only_more -= len(page)\n                else:\n                    page = page[:only_more]\n                    res.extend(page)\n                    break\n            res.extend(page)\n        return res",
        "begin_line": 1989,
        "end_line": 2009,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.uppercase_escape#2012",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.uppercase_escape(s)",
        "snippet": "def uppercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\U[0-9a-fA-F]{8}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 2012,
        "end_line": 2017,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.lowercase_escape#2020",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.lowercase_escape(s)",
        "snippet": "def lowercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\u[0-9a-fA-F]{4}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 2020,
        "end_line": 2025,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.escape_rfc3986#2028",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_rfc3986(s)",
        "snippet": "def escape_rfc3986(s):\n    \"\"\"Escape non-ASCII characters as suggested by RFC 3986\"\"\"\n    if sys.version_info < (3, 0) and isinstance(s, compat_str):\n        s = s.encode('utf-8')\n    return compat_urllib_parse.quote(s, b\"%/;:@&=+$,!~*'()?#[]\")",
        "begin_line": 2028,
        "end_line": 2032,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.escape_url#2035",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.escape_url(url)",
        "snippet": "def escape_url(url):\n    \"\"\"Escape URL as suggested by RFC 3986\"\"\"\n    url_parsed = compat_urllib_parse_urlparse(url)\n    return url_parsed._replace(\n        netloc=url_parsed.netloc.encode('idna').decode('ascii'),\n        path=escape_rfc3986(url_parsed.path),\n        params=escape_rfc3986(url_parsed.params),\n        query=escape_rfc3986(url_parsed.query),\n        fragment=escape_rfc3986(url_parsed.fragment)\n    ).geturl()",
        "begin_line": 2035,
        "end_line": 2044,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.read_batch_urls#2047",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.read_batch_urls(batch_fd)",
        "snippet": "def read_batch_urls(batch_fd):\n    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = '\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url\n\n    with contextlib.closing(batch_fd) as fd:\n        return [url for url in map(fixup, fd) if url]",
        "begin_line": 2047,
        "end_line": 2060,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.urlencode_postdata#2063",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlencode_postdata(*args, **kargs)",
        "snippet": "def urlencode_postdata(*args, **kargs):\n    return compat_urllib_parse_urlencode(*args, **kargs).encode('ascii')",
        "begin_line": 2063,
        "end_line": 2064,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.update_url_query#2067",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.update_url_query(url, query)",
        "snippet": "def update_url_query(url, query):\n    if not query:\n        return url\n    parsed_url = compat_urlparse.urlparse(url)\n    qs = compat_parse_qs(parsed_url.query)\n    qs.update(query)\n    return compat_urlparse.urlunparse(parsed_url._replace(\n        query=compat_urllib_parse_urlencode(qs, True)))",
        "begin_line": 2067,
        "end_line": 2074,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.update_Request#2077",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.update_Request(req, url=None, data=None, headers={}, query={})",
        "snippet": "def update_Request(req, url=None, data=None, headers={}, query={}):\n    req_headers = req.headers.copy()\n    req_headers.update(headers)\n    req_data = data or req.data\n    req_url = update_url_query(url or req.get_full_url(), query)\n    req_get_method = req.get_method()\n    if req_get_method == 'HEAD':\n        req_type = HEADRequest\n    elif req_get_method == 'PUT':\n        req_type = PUTRequest\n    else:\n        req_type = compat_urllib_request.Request\n    new_req = req_type(\n        req_url, data=req_data, headers=req_headers,\n        origin_req_host=req.origin_req_host, unverifiable=req.unverifiable)\n    if hasattr(req, 'timeout'):\n        new_req.timeout = req.timeout\n    return new_req",
        "begin_line": 2077,
        "end_line": 2094,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._multipart_encode_impl#2097",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._multipart_encode_impl(data, boundary)",
        "snippet": "def _multipart_encode_impl(data, boundary):\n    content_type = 'multipart/form-data; boundary=%s' % boundary\n\n    out = b''\n    for k, v in data.items():\n        out += b'--' + boundary.encode('ascii') + b'\\r\\n'\n        if isinstance(k, compat_str):\n            k = k.encode('utf-8')\n        if isinstance(v, compat_str):\n            v = v.encode('utf-8')\n        # RFC 2047 requires non-ASCII field names to be encoded, while RFC 7578\n        # suggests sending UTF-8 directly. Firefox sends UTF-8, too\n        content = b'Content-Disposition: form-data; name=\"' + k + b'\"\\r\\n\\r\\n' + v + b'\\r\\n'\n        if boundary.encode('ascii') in content:\n            raise ValueError('Boundary overlaps with data')\n        out += content\n\n    out += b'--' + boundary.encode('ascii') + b'--\\r\\n'\n\n    return out, content_type",
        "begin_line": 2097,
        "end_line": 2116,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.multipart_encode#2119",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.multipart_encode(data, boundary=None)",
        "snippet": "def multipart_encode(data, boundary=None):\n    '''\n    Encode a dict to RFC 7578-compliant form-data\n\n    data:\n        A dict where keys and values can be either Unicode or bytes-like\n        objects.\n    boundary:\n        If specified a Unicode object, it's used as the boundary. Otherwise\n        a random boundary is generated.\n\n    Reference: https://tools.ietf.org/html/rfc7578\n    '''\n    has_specified_boundary = boundary is not None\n\n    while True:\n        if boundary is None:\n            boundary = '---------------' + str(random.randrange(0x0fffffff, 0xffffffff))\n\n        try:\n            out, content_type = _multipart_encode_impl(data, boundary)\n            break\n        except ValueError:\n            if has_specified_boundary:\n                raise\n            boundary = None\n\n    return out, content_type",
        "begin_line": 2119,
        "end_line": 2146,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.dict_get#2149",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.dict_get(d, key_or_keys, default=None, skip_false_values=True)",
        "snippet": "def dict_get(d, key_or_keys, default=None, skip_false_values=True):\n    if isinstance(key_or_keys, (list, tuple)):\n        for key in key_or_keys:\n            if key not in d or d[key] is None or skip_false_values and not d[key]:\n                continue\n            return d[key]\n        return default\n    return d.get(key_or_keys, default)",
        "begin_line": 2149,
        "end_line": 2156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.try_get#2159",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.try_get(src, getter, expected_type=None)",
        "snippet": "def try_get(src, getter, expected_type=None):\n    if not isinstance(getter, (list, tuple)):\n        getter = [getter]\n    for get in getter:\n        try:\n            v = get(src)\n        except (AttributeError, KeyError, TypeError, IndexError):\n            pass\n        else:\n            if expected_type is None or isinstance(v, expected_type):\n                return v",
        "begin_line": 2159,
        "end_line": 2169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.encode_compat_str#2172",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encode_compat_str(string, encoding=preferredencoding(), errors='strict')",
        "snippet": "def encode_compat_str(string, encoding=preferredencoding(), errors='strict'):\n    return string if isinstance(string, compat_str) else compat_str(string, encoding, errors)",
        "begin_line": 2172,
        "end_line": 2173,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_age_limit#2195",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_age_limit(s)",
        "snippet": "def parse_age_limit(s):\n    if type(s) == int:\n        return s if 0 <= s <= 21 else None\n    if not isinstance(s, compat_basestring):\n        return None\n    m = re.match(r'^(?P<age>\\d{1,2})\\+?$', s)\n    if m:\n        return int(m.group('age'))\n    if s in US_RATINGS:\n        return US_RATINGS[s]\n    return TV_PARENTAL_GUIDELINES.get(s)",
        "begin_line": 2195,
        "end_line": 2205,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.strip_jsonp#2208",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.strip_jsonp(code)",
        "snippet": "def strip_jsonp(code):\n    return re.sub(\n        r'''(?sx)^\n            (?:window\\.)?(?P<func_name>[a-zA-Z0-9_.$]+)\n            (?:\\s*&&\\s*(?P=func_name))?\n            \\s*\\(\\s*(?P<callback_data>.*)\\);?\n            \\s*?(?://[^\\n]*)*$''',\n        r'\\g<callback_data>', code)",
        "begin_line": 2208,
        "end_line": 2215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.js_to_json#2218",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.js_to_json(code)",
        "snippet": "def js_to_json(code):\n    COMMENT_RE = r'/\\*(?:(?!\\*/).)*?\\*/|//[^\\n]*'\n    SKIP_RE = r'\\s*(?:{comment})?\\s*'.format(comment=COMMENT_RE)\n    INTEGER_TABLE = (\n        (r'(?s)^(0[xX][0-9a-fA-F]+){skip}:?$'.format(skip=SKIP_RE), 16),\n        (r'(?s)^(0+[0-7]+){skip}:?$'.format(skip=SKIP_RE), 8),\n    )\n\n    def fix_kv(m):\n        v = m.group(0)\n        if v in ('true', 'false', 'null'):\n            return v\n        elif v.startswith('/*') or v.startswith('//') or v == ',':\n            return \"\"\n\n        if v[0] in (\"'\", '\"'):\n            v = re.sub(r'(?s)\\\\.|\"', lambda m: {\n                '\"': '\\\\\"',\n                \"\\\\'\": \"'\",\n                '\\\\\\n': '',\n                '\\\\x': '\\\\u00',\n            }.get(m.group(0), m.group(0)), v[1:-1])\n\n        for regex, base in INTEGER_TABLE:\n            im = re.match(regex, v)\n            if im:\n                i = int(im.group(1), base)\n                return '\"%d\":' % i if v.endswith(':') else '%d' % i\n\n        return '\"%s\"' % v\n\n    return re.sub(r'''(?sx)\n        \"(?:[^\"\\\\]*(?:\\\\\\\\|\\\\['\"nurtbfx/\\n]))*[^\"\\\\]*\"|\n        '(?:[^'\\\\]*(?:\\\\\\\\|\\\\['\"nurtbfx/\\n]))*[^'\\\\]*'|\n        {comment}|,(?={skip}[\\]}}])|\n        [a-zA-Z_][.a-zA-Z_0-9]*|\n        \\b(?:0[xX][0-9a-fA-F]+|0+[0-7]+)(?:{skip}:)?|\n        [0-9]+(?={skip}:)\n        '''.format(comment=COMMENT_RE, skip=SKIP_RE), fix_kv, code)",
        "begin_line": 2218,
        "end_line": 2256,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.qualities#2259",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.qualities(quality_ids)",
        "snippet": "def qualities(quality_ids):\n    \"\"\" Get a numeric quality value out of a list of possible values \"\"\"\n    def q(qid):\n        try:\n            return quality_ids.index(qid)\n        except ValueError:\n            return -1\n    return q",
        "begin_line": 2259,
        "end_line": 2266,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.limit_length#2272",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.limit_length(s, length)",
        "snippet": "def limit_length(s, length):\n    \"\"\" Add ellipses to overly long strings \"\"\"\n    if s is None:\n        return None\n    ELLIPSES = '...'\n    if len(s) > length:\n        return s[:length - len(ELLIPSES)] + ELLIPSES\n    return s",
        "begin_line": 2272,
        "end_line": 2279,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.version_tuple#2282",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.version_tuple(v)",
        "snippet": "def version_tuple(v):\n    return tuple(int(e) for e in re.split(r'[-.]', v))",
        "begin_line": 2282,
        "end_line": 2283,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.is_outdated_version#2286",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_outdated_version(version, limit, assume_new=True)",
        "snippet": "def is_outdated_version(version, limit, assume_new=True):\n    if not version:\n        return not assume_new\n    try:\n        return version_tuple(version) < version_tuple(limit)\n    except ValueError:\n        return not assume_new",
        "begin_line": 2286,
        "end_line": 2292,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ytdl_is_updateable#2295",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.ytdl_is_updateable()",
        "snippet": "def ytdl_is_updateable():\n    \"\"\" Returns if youtube-dl can be updated with -U \"\"\"\n    from zipimport import zipimporter\n\n    return isinstance(globals().get('__loader__'), zipimporter) or hasattr(sys, 'frozen')",
        "begin_line": 2295,
        "end_line": 2299,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.args_to_str#2302",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.args_to_str(args)",
        "snippet": "def args_to_str(args):\n    # Get a short string representation for a subprocess command\n    return ' '.join(compat_shlex_quote(a) for a in args)",
        "begin_line": 2302,
        "end_line": 2304,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.error_to_compat_str#2307",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.error_to_compat_str(err)",
        "snippet": "def error_to_compat_str(err):\n    err_str = str(err)\n    # On python 2 error byte string must be decoded with proper\n    # encoding rather than ascii\n    if sys.version_info[0] < 3:\n        err_str = err_str.decode(preferredencoding())\n    return err_str",
        "begin_line": 2307,
        "end_line": 2313,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.mimetype2ext#2316",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.mimetype2ext(mt)",
        "snippet": "def mimetype2ext(mt):\n    if mt is None:\n        return None\n\n    ext = {\n        'audio/mp4': 'm4a',\n        # Per RFC 3003, audio/mpeg can be .mp1, .mp2 or .mp3. Here use .mp3 as\n        # it's the most popular one\n        'audio/mpeg': 'mp3',\n    }.get(mt)\n    if ext is not None:\n        return ext\n\n    _, _, res = mt.rpartition('/')\n    res = res.split(';')[0].strip().lower()\n\n    return {\n        '3gpp': '3gp',\n        'smptett+xml': 'tt',\n        'ttaf+xml': 'dfxp',\n        'ttml+xml': 'ttml',\n        'x-flv': 'flv',\n        'x-mp4-fragmented': 'mp4',\n        'x-ms-wmv': 'wmv',\n        'mpegurl': 'm3u8',\n        'x-mpegurl': 'm3u8',\n        'vnd.apple.mpegurl': 'm3u8',\n        'dash+xml': 'mpd',\n        'f4m+xml': 'f4m',\n        'hds+xml': 'f4m',\n        'vnd.ms-sstr+xml': 'ism',\n        'quicktime': 'mov',\n        'mp2t': 'ts',\n    }.get(res, res)",
        "begin_line": 2316,
        "end_line": 2349,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_codecs#2352",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_codecs(codecs_str)",
        "snippet": "def parse_codecs(codecs_str):\n    # http://tools.ietf.org/html/rfc6381\n    if not codecs_str:\n        return {}\n    splited_codecs = list(filter(None, map(\n        lambda str: str.strip(), codecs_str.strip().strip(',').split(','))))\n    vcodec, acodec = None, None\n    for full_codec in splited_codecs:\n        codec = full_codec.split('.')[0]\n        if codec in ('avc1', 'avc2', 'avc3', 'avc4', 'vp9', 'vp8', 'hev1', 'hev2', 'h263', 'h264', 'mp4v'):\n            if not vcodec:\n                vcodec = full_codec\n        elif codec in ('mp4a', 'opus', 'vorbis', 'mp3', 'aac', 'ac-3', 'ec-3', 'eac3', 'dtsc', 'dtse', 'dtsh', 'dtsl'):\n            if not acodec:\n                acodec = full_codec\n        else:\n            write_string('WARNING: Unknown codec %s\\n' % full_codec, sys.stderr)\n    if not vcodec and not acodec:\n        if len(splited_codecs) == 2:\n            return {\n                'vcodec': vcodec,\n                'acodec': acodec,\n            }\n        elif len(splited_codecs) == 1:\n            return {\n                'vcodec': 'none',\n                'acodec': vcodec,\n            }\n    else:\n        return {\n            'vcodec': vcodec or 'none',\n            'acodec': acodec or 'none',\n        }\n    return {}",
        "begin_line": 2352,
        "end_line": 2385,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.urlhandle_detect_ext#2388",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlhandle_detect_ext(url_handle)",
        "snippet": "def urlhandle_detect_ext(url_handle):\n    getheader = url_handle.headers.get\n\n    cd = getheader('Content-Disposition')\n    if cd:\n        m = re.match(r'attachment;\\s*filename=\"(?P<filename>[^\"]+)\"', cd)\n        if m:\n            e = determine_ext(m.group('filename'), default_ext=None)\n            if e:\n                return e\n\n    return mimetype2ext(getheader('Content-Type'))",
        "begin_line": 2388,
        "end_line": 2399,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.encode_data_uri#2402",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encode_data_uri(data, mime_type)",
        "snippet": "def encode_data_uri(data, mime_type):\n    return 'data:%s;base64,%s' % (mime_type, base64.b64encode(data).decode('ascii'))",
        "begin_line": 2402,
        "end_line": 2403,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.age_restricted#2406",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.age_restricted(content_limit, age_limit)",
        "snippet": "def age_restricted(content_limit, age_limit):\n    \"\"\" Returns True iff the content should be blocked \"\"\"\n\n    if age_limit is None:  # No limit set\n        return False\n    if content_limit is None:\n        return False  # Content available for everyone\n    return age_limit < content_limit",
        "begin_line": 2406,
        "end_line": 2413,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.is_html#2416",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.is_html(first_bytes)",
        "snippet": "def is_html(first_bytes):\n    \"\"\" Detect whether a file contains HTML by examining its first bytes. \"\"\"\n\n    BOMS = [\n        (b'\\xef\\xbb\\xbf', 'utf-8'),\n        (b'\\x00\\x00\\xfe\\xff', 'utf-32-be'),\n        (b'\\xff\\xfe\\x00\\x00', 'utf-32-le'),\n        (b'\\xff\\xfe', 'utf-16-le'),\n        (b'\\xfe\\xff', 'utf-16-be'),\n    ]\n    for bom, enc in BOMS:\n        if first_bytes.startswith(bom):\n            s = first_bytes[len(bom):].decode(enc, 'replace')\n            break\n    else:\n        s = first_bytes.decode('utf-8', 'replace')\n\n    return re.match(r'^\\s*<', s)",
        "begin_line": 2416,
        "end_line": 2433,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.determine_protocol#2436",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_protocol(info_dict)",
        "snippet": "def determine_protocol(info_dict):\n    protocol = info_dict.get('protocol')\n    if protocol is not None:\n        return protocol\n\n    url = info_dict['url']\n    if url.startswith('rtmp'):\n        return 'rtmp'\n    elif url.startswith('mms'):\n        return 'mms'\n    elif url.startswith('rtsp'):\n        return 'rtsp'\n\n    ext = determine_ext(url)\n    if ext == 'm3u8':\n        return 'm3u8'\n    elif ext == 'f4m':\n        return 'f4m'\n\n    return compat_urllib_parse_urlparse(url).scheme",
        "begin_line": 2436,
        "end_line": 2455,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.render_table#2458",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.render_table(header_row, data)",
        "snippet": "def render_table(header_row, data):\n    \"\"\" Render a list of rows, each as a list of values \"\"\"\n    table = [header_row] + data\n    max_lens = [max(len(compat_str(v)) for v in col) for col in zip(*table)]\n    format_str = ' '.join('%-' + compat_str(ml + 1) + 's' for ml in max_lens[:-1]) + '%s'\n    return '\\n'.join(format_str % tuple(row) for row in table)",
        "begin_line": 2458,
        "end_line": 2463,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils._match_one#2466",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._match_one(filter_part, dct)",
        "snippet": "def _match_one(filter_part, dct):\n    COMPARISON_OPERATORS = {\n        '<': operator.lt,\n        '<=': operator.le,\n        '>': operator.gt,\n        '>=': operator.ge,\n        '=': operator.eq,\n        '!=': operator.ne,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<key>[a-z_]+)\n        \\s*(?P<op>%s)(?P<none_inclusive>\\s*\\?)?\\s*\n        (?:\n            (?P<intval>[0-9.]+(?:[kKmMgGtTpPeEzZyY]i?[Bb]?)?)|\n            (?P<quote>[\"\\'])(?P<quotedstrval>(?:\\\\.|(?!(?P=quote)|\\\\).)+?)(?P=quote)|\n            (?P<strval>(?![0-9.])[a-z0-9A-Z]*)\n        )\n        \\s*$\n        ''' % '|'.join(map(re.escape, COMPARISON_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = COMPARISON_OPERATORS[m.group('op')]\n        actual_value = dct.get(m.group('key'))\n        if (m.group('quotedstrval') is not None or\n            m.group('strval') is not None or\n            # If the original field is a string and matching comparisonvalue is\n            # a number we should respect the origin of the original field\n            # and process comparison value as a string (see\n            # https://github.com/rg3/youtube-dl/issues/11082).\n            actual_value is not None and m.group('intval') is not None and\n                isinstance(actual_value, compat_str)):\n            if m.group('op') not in ('=', '!='):\n                raise ValueError(\n                    'Operator %s does not support string values!' % m.group('op'))\n            comparison_value = m.group('quotedstrval') or m.group('strval') or m.group('intval')\n            quote = m.group('quote')\n            if quote is not None:\n                comparison_value = comparison_value.replace(r'\\%s' % quote, quote)\n        else:\n            try:\n                comparison_value = int(m.group('intval'))\n            except ValueError:\n                comparison_value = parse_filesize(m.group('intval'))\n                if comparison_value is None:\n                    comparison_value = parse_filesize(m.group('intval') + 'B')\n                if comparison_value is None:\n                    raise ValueError(\n                        'Invalid integer value %r in filter part %r' % (\n                            m.group('intval'), filter_part))\n        if actual_value is None:\n            return m.group('none_inclusive')\n        return op(actual_value, comparison_value)\n\n    UNARY_OPERATORS = {\n        '': lambda v: v is not None,\n        '!': lambda v: v is None,\n    }\n    operator_rex = re.compile(r'''(?x)\\s*\n        (?P<op>%s)\\s*(?P<key>[a-z_]+)\n        \\s*$\n        ''' % '|'.join(map(re.escape, UNARY_OPERATORS.keys())))\n    m = operator_rex.search(filter_part)\n    if m:\n        op = UNARY_OPERATORS[m.group('op')]\n        actual_value = dct.get(m.group('key'))\n        return op(actual_value)\n\n    raise ValueError('Invalid filter part %r' % filter_part)",
        "begin_line": 2466,
        "end_line": 2533,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.match_str#2536",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_str(filter_str, dct)",
        "snippet": "def match_str(filter_str, dct):\n    \"\"\" Filter a dictionary with a simple string syntax. Returns True (=passes filter) or false \"\"\"\n\n    return all(\n        _match_one(filter_part, dct) for filter_part in filter_str.split('&'))",
        "begin_line": 2536,
        "end_line": 2540,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.match_filter_func#2543",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.match_filter_func(filter_str)",
        "snippet": "def match_filter_func(filter_str):\n    def _match_func(info_dict):\n        if match_str(filter_str, info_dict):\n            return None\n        else:\n            video_title = info_dict.get('title', info_dict.get('id', 'video'))\n            return '%s does not pass filter %s, skipping ..' % (video_title, filter_str)\n    return _match_func",
        "begin_line": 2543,
        "end_line": 2550,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_dfxp_time_expr#2553",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_dfxp_time_expr(time_expr)",
        "snippet": "def parse_dfxp_time_expr(time_expr):\n    if not time_expr:\n        return\n\n    mobj = re.match(r'^(?P<time_offset>\\d+(?:\\.\\d+)?)s?$', time_expr)\n    if mobj:\n        return float(mobj.group('time_offset'))\n\n    mobj = re.match(r'^(\\d+):(\\d\\d):(\\d\\d(?:(?:\\.|:)\\d+)?)$', time_expr)\n    if mobj:\n        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3).replace(':', '.'))",
        "begin_line": 2553,
        "end_line": 2563,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.srt_subtitles_timecode#2566",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.srt_subtitles_timecode(seconds)",
        "snippet": "def srt_subtitles_timecode(seconds):\n    return '%02d:%02d:%02d,%03d' % (seconds / 3600, (seconds % 3600) / 60, seconds % 60, (seconds % 1) * 1000)",
        "begin_line": 2566,
        "end_line": 2567,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.dfxp2srt#2570",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.dfxp2srt(dfxp_data)",
        "snippet": "def dfxp2srt(dfxp_data):\n    LEGACY_NAMESPACES = (\n        ('http://www.w3.org/ns/ttml', [\n            'http://www.w3.org/2004/11/ttaf1',\n            'http://www.w3.org/2006/04/ttaf1',\n            'http://www.w3.org/2006/10/ttaf1',\n        ]),\n        ('http://www.w3.org/ns/ttml#styling', [\n            'http://www.w3.org/ns/ttml#style',\n        ]),\n    )\n\n    SUPPORTED_STYLING = [\n        'color',\n        'fontFamily',\n        'fontSize',\n        'fontStyle',\n        'fontWeight',\n        'textDecoration'\n    ]\n\n    _x = functools.partial(xpath_with_ns, ns_map={\n        'ttml': 'http://www.w3.org/ns/ttml',\n        'tts': 'http://www.w3.org/ns/ttml#styling',\n    })\n\n    styles = {}\n    default_style = {}\n\n    class TTMLPElementParser(object):\n        _out = ''\n        _unclosed_elements = []\n        _applied_styles = []\n\n        def start(self, tag, attrib):\n            if tag in (_x('ttml:br'), 'br'):\n                self._out += '\\n'\n            else:\n                unclosed_elements = []\n                style = {}\n                element_style_id = attrib.get('style')\n                if default_style:\n                    style.update(default_style)\n                if element_style_id:\n                    style.update(styles.get(element_style_id, {}))\n                for prop in SUPPORTED_STYLING:\n                    prop_val = attrib.get(_x('tts:' + prop))\n                    if prop_val:\n                        style[prop] = prop_val\n                if style:\n                    font = ''\n                    for k, v in sorted(style.items()):\n                        if self._applied_styles and self._applied_styles[-1].get(k) == v:\n                            continue\n                        if k == 'color':\n                            font += ' color=\"%s\"' % v\n                        elif k == 'fontSize':\n                            font += ' size=\"%s\"' % v\n                        elif k == 'fontFamily':\n                            font += ' face=\"%s\"' % v\n                        elif k == 'fontWeight' and v == 'bold':\n                            self._out += '<b>'\n                            unclosed_elements.append('b')\n                        elif k == 'fontStyle' and v == 'italic':\n                            self._out += '<i>'\n                            unclosed_elements.append('i')\n                        elif k == 'textDecoration' and v == 'underline':\n                            self._out += '<u>'\n                            unclosed_elements.append('u')\n                    if font:\n                        self._out += '<font' + font + '>'\n                        unclosed_elements.append('font')\n                    applied_style = {}\n                    if self._applied_styles:\n                        applied_style.update(self._applied_styles[-1])\n                    applied_style.update(style)\n                    self._applied_styles.append(applied_style)\n                self._unclosed_elements.append(unclosed_elements)\n\n        def end(self, tag):\n            if tag not in (_x('ttml:br'), 'br'):\n                unclosed_elements = self._unclosed_elements.pop()\n                for element in reversed(unclosed_elements):\n                    self._out += '</%s>' % element\n                if unclosed_elements and self._applied_styles:\n                    self._applied_styles.pop()\n\n        def data(self, data):\n            self._out += data\n\n        def close(self):\n            return self._out.strip()\n\n    def parse_node(node):\n        target = TTMLPElementParser()\n        parser = xml.etree.ElementTree.XMLParser(target=target)\n        parser.feed(xml.etree.ElementTree.tostring(node))\n        return parser.close()\n\n    for k, v in LEGACY_NAMESPACES:\n        for ns in v:\n            dfxp_data = dfxp_data.replace(ns, k)\n\n    dfxp = compat_etree_fromstring(dfxp_data.encode('utf-8'))\n    out = []\n    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall('.//p')\n\n    if not paras:\n        raise ValueError('Invalid dfxp/TTML subtitle')\n\n    repeat = False\n    while True:\n        for style in dfxp.findall(_x('.//ttml:style')):\n            style_id = style.get('id')\n            parent_style_id = style.get('style')\n            if parent_style_id:\n                if parent_style_id not in styles:\n                    repeat = True\n                    continue\n                styles[style_id] = styles[parent_style_id].copy()\n            for prop in SUPPORTED_STYLING:\n                prop_val = style.get(_x('tts:' + prop))\n                if prop_val:\n                    styles.setdefault(style_id, {})[prop] = prop_val\n        if repeat:\n            repeat = False\n        else:\n            break\n\n    for p in ('body', 'div'):\n        ele = xpath_element(dfxp, [_x('.//ttml:' + p), './/' + p])\n        if ele is None:\n            continue\n        style = styles.get(ele.get('style'))\n        if not style:\n            continue\n        default_style.update(style)\n\n    for para, index in zip(paras, itertools.count(1)):\n        begin_time = parse_dfxp_time_expr(para.attrib.get('begin'))\n        end_time = parse_dfxp_time_expr(para.attrib.get('end'))\n        dur = parse_dfxp_time_expr(para.attrib.get('dur'))\n        if begin_time is None:\n            continue\n        if not end_time:\n            if not dur:\n                continue\n            end_time = begin_time + dur\n        out.append('%d\\n%s --> %s\\n%s\\n\\n' % (\n            index,\n            srt_subtitles_timecode(begin_time),\n            srt_subtitles_timecode(end_time),\n            parse_node(para)))\n\n    return ''.join(out)",
        "begin_line": 2570,
        "end_line": 2724,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.cli_option#2727",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_option(params, command_option, param)",
        "snippet": "def cli_option(params, command_option, param):\n    param = params.get(param)\n    if param:\n        param = compat_str(param)\n    return [command_option, param] if param is not None else []",
        "begin_line": 2727,
        "end_line": 2731,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.cli_bool_option#2734",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_bool_option(params, command_option, param, true_value='true', false_value='false', separator=None)",
        "snippet": "def cli_bool_option(params, command_option, param, true_value='true', false_value='false', separator=None):\n    param = params.get(param)\n    if param is None:\n        return []\n    assert isinstance(param, bool)\n    if separator:\n        return [command_option + separator + (true_value if param else false_value)]\n    return [command_option, true_value if param else false_value]",
        "begin_line": 2734,
        "end_line": 2741,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.cli_valueless_option#2744",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_valueless_option(params, command_option, param, expected_value=True)",
        "snippet": "def cli_valueless_option(params, command_option, param, expected_value=True):\n    param = params.get(param)\n    return [command_option] if param == expected_value else []",
        "begin_line": 2744,
        "end_line": 2746,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.cli_configuration_args#2749",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.cli_configuration_args(params, param, default=[])",
        "snippet": "def cli_configuration_args(params, param, default=[]):\n    ex_args = params.get(param)\n    if ex_args is None:\n        return default\n    assert isinstance(ex_args, list)\n    return ex_args",
        "begin_line": 2749,
        "end_line": 2754,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ISO639Utils.short2long#2947",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO639Utils",
        "signature": "youtube_dl.utils.ISO639Utils.short2long(cls, code)",
        "snippet": "    def short2long(cls, code):\n        \"\"\"Convert language code from ISO 639-1 to ISO 639-2/T\"\"\"\n        return cls._lang_map.get(code[:2])",
        "begin_line": 2947,
        "end_line": 2949,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ISO639Utils.long2short#2952",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO639Utils",
        "signature": "youtube_dl.utils.ISO639Utils.long2short(cls, code)",
        "snippet": "    def long2short(cls, code):\n        \"\"\"Convert language code from ISO 639-2/T to ISO 639-1\"\"\"\n        for short_name, long_name in cls._lang_map.items():\n            if long_name == code:\n                return short_name",
        "begin_line": 2952,
        "end_line": 2956,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ISO3166Utils.short2full#3214",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ISO3166Utils",
        "signature": "youtube_dl.utils.ISO3166Utils.short2full(cls, code)",
        "snippet": "    def short2full(cls, code):\n        \"\"\"Convert an ISO 3166-2 country code to the corresponding full name\"\"\"\n        return cls._country_map.get(code.upper())",
        "begin_line": 3214,
        "end_line": 3216,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.GeoUtils.random_ipv4#3462",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.GeoUtils",
        "signature": "youtube_dl.utils.GeoUtils.random_ipv4(cls, code)",
        "snippet": "    def random_ipv4(cls, code):\n        block = cls._country_ip_map.get(code.upper())\n        if not block:\n            return None\n        addr, preflen = block.split('/')\n        addr_min = compat_struct_unpack('!L', socket.inet_aton(addr))[0]\n        addr_max = addr_min | (0xffffffff >> int(preflen))\n        return compat_str(socket.inet_ntoa(\n            compat_struct_pack('!L', random.randint(addr_min, addr_max))))",
        "begin_line": 3462,
        "end_line": 3470,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.__init__#3474",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.__init__(self, proxies=None)",
        "snippet": "    def __init__(self, proxies=None):\n        # Set default handlers\n        for type in ('http', 'https'):\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy='__noproxy__', type=type, meth=self.proxy_open:\n                        meth(r, proxy, type))\n        return compat_urllib_request.ProxyHandler.__init__(self, proxies)",
        "begin_line": 3474,
        "end_line": 3480,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.PerRequestProxyHandler.proxy_open#3482",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PerRequestProxyHandler",
        "signature": "youtube_dl.utils.PerRequestProxyHandler.proxy_open(self, req, proxy, type)",
        "snippet": "    def proxy_open(self, req, proxy, type):\n        req_proxy = req.headers.get('Ytdl-request-proxy')\n        if req_proxy is not None:\n            proxy = req_proxy\n            del req.headers['Ytdl-request-proxy']\n\n        if proxy == '__noproxy__':\n            return None  # No Proxy\n        if compat_urlparse.urlparse(proxy).scheme.lower() in ('socks', 'socks4', 'socks4a', 'socks5'):\n            req.add_header('Ytdl-socks-proxy', proxy)\n            # youtube-dl's http/https handlers do wrapping the socket with socks\n            return None\n        return compat_urllib_request.ProxyHandler.proxy_open(\n            self, req, proxy, type)",
        "begin_line": 3482,
        "end_line": 3495,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.long_to_bytes#3502",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.long_to_bytes(n, blocksize=0)",
        "snippet": "def long_to_bytes(n, blocksize=0):\n    \"\"\"long_to_bytes(n:long, blocksize:int) : string\n    Convert a long integer to a byte string.\n\n    If optional blocksize is given and greater than zero, pad the front of the\n    byte string with binary zeros so that the length is a multiple of\n    blocksize.\n    \"\"\"\n    # after much testing, this algorithm was deemed to be the fastest\n    s = b''\n    n = int(n)\n    while n > 0:\n        s = compat_struct_pack('>I', n & 0xffffffff) + s\n        n = n >> 32\n    # strip off leading zeros\n    for i in range(len(s)):\n        if s[i] != b'\\000'[0]:\n            break\n    else:\n        # only happens when n == 0\n        s = b'\\000'\n        i = 0\n    s = s[i:]\n    # add back some pad bytes.  this could be done more efficiently w.r.t. the\n    # de-padding being done above, but sigh...\n    if blocksize > 0 and len(s) % blocksize:\n        s = (blocksize - len(s) % blocksize) * b'\\000' + s\n    return s",
        "begin_line": 3502,
        "end_line": 3529,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.bytes_to_long#3532",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_long(s)",
        "snippet": "def bytes_to_long(s):\n    \"\"\"bytes_to_long(string) : long\n    Convert a byte string to a long integer.\n\n    This is (essentially) the inverse of long_to_bytes().\n    \"\"\"\n    acc = 0\n    length = len(s)\n    if length % 4:\n        extra = (4 - length % 4)\n        s = b'\\000' * extra + s\n        length = length + extra\n    for i in range(0, length, 4):\n        acc = (acc << 32) + compat_struct_unpack('>I', s[i:i + 4])[0]\n    return acc",
        "begin_line": 3532,
        "end_line": 3546,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.ohdave_rsa_encrypt#3549",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.ohdave_rsa_encrypt(data, exponent, modulus)",
        "snippet": "def ohdave_rsa_encrypt(data, exponent, modulus):\n    '''\n    Implement OHDave's RSA algorithm. See http://www.ohdave.com/rsa/\n\n    Input:\n        data: data to encrypt, bytes-like object\n        exponent, modulus: parameter e and N of RSA algorithm, both integer\n    Output: hex string of encrypted data\n\n    Limitation: supports one block encryption only\n    '''\n\n    payload = int(binascii.hexlify(data[::-1]), 16)\n    encrypted = pow(payload, exponent, modulus)\n    return '%x' % encrypted",
        "begin_line": 3549,
        "end_line": 3563,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.pkcs1pad#3566",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.pkcs1pad(data, length)",
        "snippet": "def pkcs1pad(data, length):\n    \"\"\"\n    Padding input data with PKCS#1 scheme\n\n    @param {int[]} data        input data\n    @param {int}   length      target length\n    @returns {int[]}           padded data\n    \"\"\"\n    if len(data) > length - 11:\n        raise ValueError('Input data too long for PKCS#1 padding')\n\n    pseudo_random = [random.randint(0, 254) for _ in range(length - len(data) - 3)]\n    return [0, 2] + pseudo_random + [0] + data",
        "begin_line": 3566,
        "end_line": 3578,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.encode_base_n#3581",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encode_base_n(num, n, table=None)",
        "snippet": "def encode_base_n(num, n, table=None):\n    FULL_TABLE = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    if not table:\n        table = FULL_TABLE[:n]\n\n    if n > len(table):\n        raise ValueError('base %d exceeds table length %d' % (n, len(table)))\n\n    if num == 0:\n        return table[0]\n\n    ret = ''\n    while num:\n        ret = table[num % n] + ret\n        num = num // n\n    return ret",
        "begin_line": 3581,
        "end_line": 3596,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.decode_packed_codes#3599",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decode_packed_codes(code)",
        "snippet": "def decode_packed_codes(code):\n    mobj = re.search(PACKED_CODES_RE, code)\n    obfucasted_code, base, count, symbols = mobj.groups()\n    base = int(base)\n    count = int(count)\n    symbols = symbols.split('|')\n    symbol_table = {}\n\n    while count:\n        count -= 1\n        base_n_count = encode_base_n(count, base)\n        symbol_table[base_n_count] = symbols[count] or base_n_count\n\n    return re.sub(\n        r'\\b(\\w+)\\b', lambda mobj: symbol_table[mobj.group(0)],\n        obfucasted_code)",
        "begin_line": 3599,
        "end_line": 3614,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.parse_m3u8_attributes#3617",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_m3u8_attributes(attrib)",
        "snippet": "def parse_m3u8_attributes(attrib):\n    info = {}\n    for (key, val) in re.findall(r'(?P<key>[A-Z0-9-]+)=(?P<val>\"[^\"]+\"|[^\",]+)(?:,|$)', attrib):\n        if val.startswith('\"'):\n            val = val[1:-1]\n        info[key] = val\n    return info",
        "begin_line": 3617,
        "end_line": 3623,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.urshift#3626",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urshift(val, n)",
        "snippet": "def urshift(val, n):\n    return val >> n if val >= 0 else (val + 0x100000000) >> n",
        "begin_line": 3626,
        "end_line": 3627,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.decode_png#3632",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decode_png(png_data)",
        "snippet": "def decode_png(png_data):\n    # Reference: https://www.w3.org/TR/PNG/\n    header = png_data[8:]\n\n    if png_data[:8] != b'\\x89PNG\\x0d\\x0a\\x1a\\x0a' or header[4:8] != b'IHDR':\n        raise IOError('Not a valid PNG file.')\n\n    int_map = {1: '>B', 2: '>H', 4: '>I'}\n    unpack_integer = lambda x: compat_struct_unpack(int_map[len(x)], x)[0]\n\n    chunks = []\n\n    while header:\n        length = unpack_integer(header[:4])\n        header = header[4:]\n\n        chunk_type = header[:4]\n        header = header[4:]\n\n        chunk_data = header[:length]\n        header = header[length:]\n\n        header = header[4:]  # Skip CRC\n\n        chunks.append({\n            'type': chunk_type,\n            'length': length,\n            'data': chunk_data\n        })\n\n    ihdr = chunks[0]['data']\n\n    width = unpack_integer(ihdr[:4])\n    height = unpack_integer(ihdr[4:8])\n\n    idat = b''\n\n    for chunk in chunks:\n        if chunk['type'] == b'IDAT':\n            idat += chunk['data']\n\n    if not idat:\n        raise IOError('Unable to read PNG data.')\n\n    decompressed_data = bytearray(zlib.decompress(idat))\n\n    stride = width * 3\n    pixels = []\n\n    def _get_pixel(idx):\n        x = idx % stride\n        y = idx // stride\n        return pixels[y][x]\n\n    for y in range(height):\n        basePos = y * (1 + stride)\n        filter_type = decompressed_data[basePos]\n\n        current_row = []\n\n        pixels.append(current_row)\n\n        for x in range(stride):\n            color = decompressed_data[1 + basePos + x]\n            basex = y * stride + x\n            left = 0\n            up = 0\n\n            if x > 2:\n                left = _get_pixel(basex - 3)\n            if y > 0:\n                up = _get_pixel(basex - stride)\n\n            if filter_type == 1:  # Sub\n                color = (color + left) & 0xff\n            elif filter_type == 2:  # Up\n                color = (color + up) & 0xff\n            elif filter_type == 3:  # Average\n                color = (color + ((left + up) >> 1)) & 0xff\n            elif filter_type == 4:  # Paeth\n                a = left\n                b = up\n                c = 0\n\n                if x > 2 and y > 0:\n                    c = _get_pixel(basex - stride - 3)\n\n                p = a + b - c\n\n                pa = abs(p - a)\n                pb = abs(p - b)\n                pc = abs(p - c)\n\n                if pa <= pb and pa <= pc:\n                    color = (color + a) & 0xff\n                elif pb <= pc:\n                    color = (color + b) & 0xff\n                else:\n                    color = (color + c) & 0xff\n\n            current_row.append(color)\n\n    return width, height, pixels",
        "begin_line": 3632,
        "end_line": 3734,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.write_xattr#3737",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_xattr(path, key, value)",
        "snippet": "def write_xattr(path, key, value):\n    # This mess below finds the best xattr tool for the job\n    try:\n        # try the pyxattr module...\n        import xattr\n\n        if hasattr(xattr, 'set'):  # pyxattr\n            # Unicode arguments are not supported in python-pyxattr until\n            # version 0.5.0\n            # See https://github.com/rg3/youtube-dl/issues/5498\n            pyxattr_required_version = '0.5.0'\n            if version_tuple(xattr.__version__) < version_tuple(pyxattr_required_version):\n                # TODO: fallback to CLI tools\n                raise XAttrUnavailableError(\n                    'python-pyxattr is detected but is too old. '\n                    'youtube-dl requires %s or above while your version is %s. '\n                    'Falling back to other xattr implementations' % (\n                        pyxattr_required_version, xattr.__version__))\n\n            setxattr = xattr.set\n        else:  # xattr\n            setxattr = xattr.setxattr\n\n        try:\n            setxattr(path, key, value)\n        except EnvironmentError as e:\n            raise XAttrMetadataError(e.errno, e.strerror)\n\n    except ImportError:\n        if compat_os_name == 'nt':\n            # Write xattrs to NTFS Alternate Data Streams:\n            # http://en.wikipedia.org/wiki/NTFS#Alternate_data_streams_.28ADS.29\n            assert ':' not in key\n            assert os.path.exists(path)\n\n            ads_fn = path + ':' + key\n            try:\n                with open(ads_fn, 'wb') as f:\n                    f.write(value)\n            except EnvironmentError as e:\n                raise XAttrMetadataError(e.errno, e.strerror)\n        else:\n            user_has_setfattr = check_executable('setfattr', ['--version'])\n            user_has_xattr = check_executable('xattr', ['-h'])\n\n            if user_has_setfattr or user_has_xattr:\n\n                value = value.decode('utf-8')\n                if user_has_setfattr:\n                    executable = 'setfattr'\n                    opts = ['-n', key, '-v', value]\n                elif user_has_xattr:\n                    executable = 'xattr'\n                    opts = ['-w', key, value]\n\n                cmd = ([encodeFilename(executable, True)] +\n                       [encodeArgument(o) for o in opts] +\n                       [encodeFilename(path, True)])\n\n                try:\n                    p = subprocess.Popen(\n                        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n                except EnvironmentError as e:\n                    raise XAttrMetadataError(e.errno, e.strerror)\n                stdout, stderr = p.communicate()\n                stderr = stderr.decode('utf-8', 'replace')\n                if p.returncode != 0:\n                    raise XAttrMetadataError(p.returncode, stderr)\n\n            else:\n                # On Unix, and can't find pyxattr, setfattr, or xattr.\n                if sys.platform.startswith('linux'):\n                    raise XAttrUnavailableError(\n                        \"Couldn't find a tool to set the xattrs. \"\n                        \"Install either the python 'pyxattr' or 'xattr' \"\n                        \"modules, or the GNU 'attr' package \"\n                        \"(which contains the 'setfattr' tool).\")\n                else:\n                    raise XAttrUnavailableError(\n                        \"Couldn't find a tool to set the xattrs. \"\n                        \"Install either the python 'xattr' module, \"\n                        \"or the 'xattr' binary.\")",
        "begin_line": 3737,
        "end_line": 3818,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "youtube_dl.utils.random_birthday#3821",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.random_birthday(year_field, month_field, day_field)",
        "snippet": "def random_birthday(year_field, month_field, day_field):\n    return {\n        year_field: str(random.randint(1950, 1995)),\n        month_field: str(random.randint(1, 12)),\n        day_field: str(random.randint(1, 31)),\n    }",
        "begin_line": 3821,
        "end_line": 3826,
        "comment": "",
        "is_bug": false
    }
]